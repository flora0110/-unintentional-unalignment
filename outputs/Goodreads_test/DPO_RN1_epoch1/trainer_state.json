{
  "best_global_step": 128,
  "best_metric": 0.6927664279937744,
  "best_model_checkpoint": "/scratch/user/chuanhsin0110/LLMRec-Labs/unintentional-unalignment/outputs/Goodreads_test/DPO_RN1_epoch1/checkpoint-128",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 128,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0078125,
      "grad_norm": 7.405879020690918,
      "learning_rate": 0.0,
      "logits/chosen": 1.0408378839492798,
      "logits/rejected": 1.094241976737976,
      "logps/chosen": -38.69294357299805,
      "logps/rejected": -47.8370475769043,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.015625,
      "grad_norm": 6.002119541168213,
      "learning_rate": 5e-09,
      "logits/chosen": 1.147318720817566,
      "logits/rejected": 1.3783339262008667,
      "logps/chosen": -35.90400314331055,
      "logps/rejected": -43.805877685546875,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.0234375,
      "grad_norm": 6.32490348815918,
      "learning_rate": 1e-08,
      "logits/chosen": 1.4712402820587158,
      "logits/rejected": 1.4306221008300781,
      "logps/chosen": -38.19340133666992,
      "logps/rejected": -42.15299987792969,
      "loss": 0.6904,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007621025666594505,
      "rewards/margins": 0.005560660734772682,
      "rewards/rejected": 0.0020603653974831104,
      "step": 3
    },
    {
      "epoch": 0.03125,
      "grad_norm": 6.968328475952148,
      "learning_rate": 1.5e-08,
      "logits/chosen": 1.0171303749084473,
      "logits/rejected": 1.315388798713684,
      "logps/chosen": -42.61973571777344,
      "logps/rejected": -44.82645034790039,
      "loss": 0.6887,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006815028376877308,
      "rewards/margins": 0.008923722431063652,
      "rewards/rejected": -0.0021086931228637695,
      "step": 4
    },
    {
      "epoch": 0.0390625,
      "grad_norm": 6.764025688171387,
      "learning_rate": 2e-08,
      "logits/chosen": 1.1493693590164185,
      "logits/rejected": 1.2240878343582153,
      "logps/chosen": -32.77473068237305,
      "logps/rejected": -32.85055160522461,
      "loss": 0.6943,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.01013247948139906,
      "rewards/margins": -0.002345537766814232,
      "rewards/rejected": -0.007786941714584827,
      "step": 5
    },
    {
      "epoch": 0.046875,
      "grad_norm": 7.521026611328125,
      "learning_rate": 2.5e-08,
      "logits/chosen": 1.2249877452850342,
      "logits/rejected": 1.4256234169006348,
      "logps/chosen": -36.57373809814453,
      "logps/rejected": -41.59053039550781,
      "loss": 0.6956,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.008310270495712757,
      "rewards/margins": -0.004850316792726517,
      "rewards/rejected": -0.0034599541686475277,
      "step": 6
    },
    {
      "epoch": 0.0546875,
      "grad_norm": 5.192883014678955,
      "learning_rate": 3e-08,
      "logits/chosen": 1.1171897649765015,
      "logits/rejected": 1.4617773294448853,
      "logps/chosen": -35.262603759765625,
      "logps/rejected": -44.58807373046875,
      "loss": 0.6889,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.007741332985460758,
      "rewards/margins": 0.008609747514128685,
      "rewards/rejected": -0.01635107956826687,
      "step": 7
    },
    {
      "epoch": 0.0625,
      "grad_norm": 6.068546772003174,
      "learning_rate": 3.4999999999999996e-08,
      "logits/chosen": 1.127171277999878,
      "logits/rejected": 1.086251974105835,
      "logps/chosen": -35.06831741333008,
      "logps/rejected": -42.99154281616211,
      "loss": 0.6879,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008042669855058193,
      "rewards/margins": 0.010606670752167702,
      "rewards/rejected": -0.002564001129940152,
      "step": 8
    },
    {
      "epoch": 0.0703125,
      "grad_norm": 5.937211990356445,
      "learning_rate": 4e-08,
      "logits/chosen": 1.06760835647583,
      "logits/rejected": 1.0549712181091309,
      "logps/chosen": -36.04541778564453,
      "logps/rejected": -33.840938568115234,
      "loss": 0.6945,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.01038515567779541,
      "rewards/margins": -0.0027009486220777035,
      "rewards/rejected": -0.007684207055717707,
      "step": 9
    },
    {
      "epoch": 0.078125,
      "grad_norm": 4.956370830535889,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.2315583229064941,
      "logits/rejected": 1.5241122245788574,
      "logps/chosen": -37.88212966918945,
      "logps/rejected": -38.067535400390625,
      "loss": 0.6915,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.004832482431083918,
      "rewards/margins": 0.00334165059030056,
      "rewards/rejected": 0.0014908313751220703,
      "step": 10
    },
    {
      "epoch": 0.0859375,
      "grad_norm": 7.254544258117676,
      "learning_rate": 5e-08,
      "logits/chosen": 1.1487209796905518,
      "logits/rejected": 1.1802773475646973,
      "logps/chosen": -33.593017578125,
      "logps/rejected": -44.30930709838867,
      "loss": 0.6916,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0010560511145740747,
      "rewards/margins": 0.00307652959600091,
      "rewards/rejected": -0.0020204782485961914,
      "step": 11
    },
    {
      "epoch": 0.09375,
      "grad_norm": 4.9278764724731445,
      "learning_rate": 5.5e-08,
      "logits/chosen": 1.1530382633209229,
      "logits/rejected": 1.385002613067627,
      "logps/chosen": -29.425086975097656,
      "logps/rejected": -39.33383560180664,
      "loss": 0.6947,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0024429322220385075,
      "rewards/margins": -0.0030296328477561474,
      "rewards/rejected": 0.0054725646041333675,
      "step": 12
    },
    {
      "epoch": 0.1015625,
      "grad_norm": 6.056718826293945,
      "learning_rate": 6e-08,
      "logits/chosen": 1.0878558158874512,
      "logits/rejected": 0.954888105392456,
      "logps/chosen": -30.650482177734375,
      "logps/rejected": -42.57966613769531,
      "loss": 0.6925,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.002646708395332098,
      "rewards/margins": 0.0013596294447779655,
      "rewards/rejected": 0.0012870791833847761,
      "step": 13
    },
    {
      "epoch": 0.109375,
      "grad_norm": 6.037683010101318,
      "learning_rate": 6.5e-08,
      "logits/chosen": 1.1986374855041504,
      "logits/rejected": 1.3271156549453735,
      "logps/chosen": -34.924232482910156,
      "logps/rejected": -40.136474609375,
      "loss": 0.6959,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.008612370118498802,
      "rewards/margins": -0.005418872460722923,
      "rewards/rejected": 0.014031242579221725,
      "step": 14
    },
    {
      "epoch": 0.1171875,
      "grad_norm": 5.649278163909912,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.0824501514434814,
      "logits/rejected": 1.2655210494995117,
      "logps/chosen": -36.301631927490234,
      "logps/rejected": -41.70702362060547,
      "loss": 0.6852,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006051278207451105,
      "rewards/margins": 0.016109824180603027,
      "rewards/rejected": -0.01005854643881321,
      "step": 15
    },
    {
      "epoch": 0.125,
      "grad_norm": 6.256356716156006,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.0118558406829834,
      "logits/rejected": 1.0265129804611206,
      "logps/chosen": -37.8761100769043,
      "logps/rejected": -35.8276252746582,
      "loss": 0.6937,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.001737618469633162,
      "rewards/margins": -0.0011039974633604288,
      "rewards/rejected": 0.0028416155837476254,
      "step": 16
    },
    {
      "epoch": 0.1328125,
      "grad_norm": 4.901285648345947,
      "learning_rate": 8e-08,
      "logits/chosen": 1.2579114437103271,
      "logits/rejected": 1.469780445098877,
      "logps/chosen": -36.500511169433594,
      "logps/rejected": -38.068931579589844,
      "loss": 0.6878,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0058015817776322365,
      "rewards/margins": 0.010697269812226295,
      "rewards/rejected": -0.004895687568932772,
      "step": 17
    },
    {
      "epoch": 0.140625,
      "grad_norm": 6.148562908172607,
      "learning_rate": 8.5e-08,
      "logits/chosen": 1.3106399774551392,
      "logits/rejected": 1.1884900331497192,
      "logps/chosen": -43.67332077026367,
      "logps/rejected": -44.362754821777344,
      "loss": 0.697,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.005840111058205366,
      "rewards/margins": -0.007708287797868252,
      "rewards/rejected": 0.001868176506832242,
      "step": 18
    },
    {
      "epoch": 0.1484375,
      "grad_norm": 5.811038494110107,
      "learning_rate": 9e-08,
      "logits/chosen": 1.2377521991729736,
      "logits/rejected": 1.4545468091964722,
      "logps/chosen": -38.2415885925293,
      "logps/rejected": -39.82695388793945,
      "loss": 0.6922,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.008488916791975498,
      "rewards/margins": 0.0020250556990504265,
      "rewards/rejected": -0.010513972491025925,
      "step": 19
    },
    {
      "epoch": 0.15625,
      "grad_norm": 7.421085834503174,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.2470135688781738,
      "logits/rejected": 1.053048849105835,
      "logps/chosen": -38.05299377441406,
      "logps/rejected": -52.632225036621094,
      "loss": 0.6929,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00704801082611084,
      "rewards/margins": 0.0005860086530447006,
      "rewards/rejected": 0.006462001241743565,
      "step": 20
    },
    {
      "epoch": 0.1640625,
      "grad_norm": 6.651057243347168,
      "learning_rate": 1e-07,
      "logits/chosen": 1.1021747589111328,
      "logits/rejected": 0.9427728652954102,
      "logps/chosen": -37.758174896240234,
      "logps/rejected": -41.82209396362305,
      "loss": 0.6925,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005757832434028387,
      "rewards/margins": 0.0013173583429306746,
      "rewards/rejected": 0.004440474323928356,
      "step": 21
    },
    {
      "epoch": 0.171875,
      "grad_norm": 6.128073215484619,
      "learning_rate": 9.907407407407407e-08,
      "logits/chosen": 1.011230230331421,
      "logits/rejected": 0.9875026941299438,
      "logps/chosen": -34.676055908203125,
      "logps/rejected": -41.58039093017578,
      "loss": 0.6947,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.011436009779572487,
      "rewards/margins": -0.003093481296673417,
      "rewards/rejected": -0.008342528715729713,
      "step": 22
    },
    {
      "epoch": 0.1796875,
      "grad_norm": 5.93210506439209,
      "learning_rate": 9.814814814814815e-08,
      "logits/chosen": 1.4283069372177124,
      "logits/rejected": 1.2607522010803223,
      "logps/chosen": -36.3273811340332,
      "logps/rejected": -45.45662307739258,
      "loss": 0.6993,
      "rewards/accuracies": 0.0,
      "rewards/chosen": -0.00603375444188714,
      "rewards/margins": -0.012163449078798294,
      "rewards/rejected": 0.006129693705588579,
      "step": 23
    },
    {
      "epoch": 0.1875,
      "grad_norm": 6.782589435577393,
      "learning_rate": 9.722222222222221e-08,
      "logits/chosen": 1.2286067008972168,
      "logits/rejected": 1.1866679191589355,
      "logps/chosen": -40.69099044799805,
      "logps/rejected": -41.010643005371094,
      "loss": 0.6938,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.006886220537126064,
      "rewards/margins": -0.0012157200835645199,
      "rewards/rejected": -0.005670499987900257,
      "step": 24
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 6.516902446746826,
      "learning_rate": 9.629629629629629e-08,
      "logits/chosen": 1.241355061531067,
      "logits/rejected": 1.0544458627700806,
      "logps/chosen": -36.920135498046875,
      "logps/rejected": -45.017791748046875,
      "loss": 0.6892,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0133742094039917,
      "rewards/margins": 0.007977748289704323,
      "rewards/rejected": 0.005396462045609951,
      "step": 25
    },
    {
      "epoch": 0.203125,
      "grad_norm": 5.746082305908203,
      "learning_rate": 9.537037037037036e-08,
      "logits/chosen": 1.1921448707580566,
      "logits/rejected": 1.5155349969863892,
      "logps/chosen": -36.14492416381836,
      "logps/rejected": -34.779090881347656,
      "loss": 0.6889,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.00032649049535393715,
      "rewards/margins": 0.008681679144501686,
      "rewards/rejected": -0.009008169174194336,
      "step": 26
    },
    {
      "epoch": 0.2109375,
      "grad_norm": 6.713316440582275,
      "learning_rate": 9.444444444444444e-08,
      "logits/chosen": 1.0980932712554932,
      "logits/rejected": 1.220526099205017,
      "logps/chosen": -42.54212951660156,
      "logps/rejected": -36.339019775390625,
      "loss": 0.6909,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0015702963573858142,
      "rewards/margins": 0.0046460870653390884,
      "rewards/rejected": -0.00621638260781765,
      "step": 27
    },
    {
      "epoch": 0.21875,
      "grad_norm": 6.4514875411987305,
      "learning_rate": 9.351851851851851e-08,
      "logits/chosen": 1.0019631385803223,
      "logits/rejected": 1.1968750953674316,
      "logps/chosen": -35.161048889160156,
      "logps/rejected": -44.14872741699219,
      "loss": 0.6889,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0007835388532839715,
      "rewards/margins": 0.008655381388962269,
      "rewards/rejected": -0.007871842943131924,
      "step": 28
    },
    {
      "epoch": 0.2265625,
      "grad_norm": 6.750075817108154,
      "learning_rate": 9.259259259259259e-08,
      "logits/chosen": 0.5998764634132385,
      "logits/rejected": 1.18178129196167,
      "logps/chosen": -32.29651641845703,
      "logps/rejected": -43.69948959350586,
      "loss": 0.6927,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009586668573319912,
      "rewards/margins": 0.0009954692795872688,
      "rewards/rejected": 0.008591199293732643,
      "step": 29
    },
    {
      "epoch": 0.234375,
      "grad_norm": 5.372090816497803,
      "learning_rate": 9.166666666666665e-08,
      "logits/chosen": 1.25380539894104,
      "logits/rejected": 1.1960185766220093,
      "logps/chosen": -32.62110900878906,
      "logps/rejected": -36.7840690612793,
      "loss": 0.6929,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0005813358584418893,
      "rewards/margins": 0.000622081570327282,
      "rewards/rejected": -0.0012034177780151367,
      "step": 30
    },
    {
      "epoch": 0.2421875,
      "grad_norm": 7.2516889572143555,
      "learning_rate": 9.074074074074074e-08,
      "logits/chosen": 1.0133737325668335,
      "logits/rejected": 0.973567008972168,
      "logps/chosen": -34.12018585205078,
      "logps/rejected": -40.808475494384766,
      "loss": 0.692,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005765271373093128,
      "rewards/margins": 0.002409100765362382,
      "rewards/rejected": 0.0033561703749001026,
      "step": 31
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.208962917327881,
      "learning_rate": 8.98148148148148e-08,
      "logits/chosen": 1.1053310632705688,
      "logits/rejected": 1.4253379106521606,
      "logps/chosen": -36.999900817871094,
      "logps/rejected": -34.99577713012695,
      "loss": 0.6938,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0016886949306353927,
      "rewards/margins": -0.0012298822402954102,
      "rewards/rejected": -0.00045881280675530434,
      "step": 32
    },
    {
      "epoch": 0.2578125,
      "grad_norm": 7.170348644256592,
      "learning_rate": 8.888888888888888e-08,
      "logits/chosen": 0.9388622641563416,
      "logits/rejected": 1.1172962188720703,
      "logps/chosen": -35.49462127685547,
      "logps/rejected": -45.21783447265625,
      "loss": 0.6925,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004048681352287531,
      "rewards/margins": 0.0013908382970839739,
      "rewards/rejected": 0.0026578428223729134,
      "step": 33
    },
    {
      "epoch": 0.265625,
      "grad_norm": 6.037549018859863,
      "learning_rate": 8.796296296296296e-08,
      "logits/chosen": 1.2590456008911133,
      "logits/rejected": 1.4654401540756226,
      "logps/chosen": -34.51394271850586,
      "logps/rejected": -37.88471221923828,
      "loss": 0.6959,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.004998922348022461,
      "rewards/margins": -0.0054258122108876705,
      "rewards/rejected": 0.00042688893154263496,
      "step": 34
    },
    {
      "epoch": 0.2734375,
      "grad_norm": 6.591701030731201,
      "learning_rate": 8.703703703703703e-08,
      "logits/chosen": 1.1566859483718872,
      "logits/rejected": 1.311294674873352,
      "logps/chosen": -42.98884963989258,
      "logps/rejected": -43.095298767089844,
      "loss": 0.6897,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005512476433068514,
      "rewards/margins": 0.007085252553224564,
      "rewards/rejected": -0.0015727756544947624,
      "step": 35
    },
    {
      "epoch": 0.28125,
      "grad_norm": 7.336087226867676,
      "learning_rate": 8.611111111111111e-08,
      "logits/chosen": 0.9484003186225891,
      "logits/rejected": 1.1681945323944092,
      "logps/chosen": -39.89146041870117,
      "logps/rejected": -40.84504318237305,
      "loss": 0.6938,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00587806710973382,
      "rewards/margins": -0.0010148526635020971,
      "rewards/rejected": 0.006892920471727848,
      "step": 36
    },
    {
      "epoch": 0.2890625,
      "grad_norm": 7.314373016357422,
      "learning_rate": 8.518518518518519e-08,
      "logits/chosen": 1.1488629579544067,
      "logits/rejected": 1.0612843036651611,
      "logps/chosen": -33.007869720458984,
      "logps/rejected": -40.65229034423828,
      "loss": 0.6953,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.005141163244843483,
      "rewards/margins": -0.00423274002969265,
      "rewards/rejected": -0.0009084229823201895,
      "step": 37
    },
    {
      "epoch": 0.296875,
      "grad_norm": 7.472738265991211,
      "learning_rate": 8.425925925925925e-08,
      "logits/chosen": 1.2592064142227173,
      "logits/rejected": 0.8078681826591492,
      "logps/chosen": -38.541465759277344,
      "logps/rejected": -41.68238067626953,
      "loss": 0.6963,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0031631230376660824,
      "rewards/margins": -0.006153846625238657,
      "rewards/rejected": 0.0029907228890806437,
      "step": 38
    },
    {
      "epoch": 0.3046875,
      "grad_norm": 5.939811706542969,
      "learning_rate": 8.333333333333334e-08,
      "logits/chosen": 1.0355534553527832,
      "logits/rejected": 1.5760760307312012,
      "logps/chosen": -41.911033630371094,
      "logps/rejected": -39.718727111816406,
      "loss": 0.6984,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010369730181992054,
      "rewards/margins": -0.0104385856539011,
      "rewards/rejected": 6.885564653202891e-05,
      "step": 39
    },
    {
      "epoch": 0.3125,
      "grad_norm": 6.3882880210876465,
      "learning_rate": 8.24074074074074e-08,
      "logits/chosen": 1.3083664178848267,
      "logits/rejected": 0.9649176001548767,
      "logps/chosen": -34.90253448486328,
      "logps/rejected": -39.66646194458008,
      "loss": 0.6905,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0045850519090890884,
      "rewards/margins": 0.005319547839462757,
      "rewards/rejected": -0.0007344961632043123,
      "step": 40
    },
    {
      "epoch": 0.3203125,
      "grad_norm": 5.803717613220215,
      "learning_rate": 8.148148148148148e-08,
      "logits/chosen": 1.3777270317077637,
      "logits/rejected": 1.3800030946731567,
      "logps/chosen": -44.72251510620117,
      "logps/rejected": -43.433387756347656,
      "loss": 0.6966,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.005893612280488014,
      "rewards/margins": -0.006751418579369783,
      "rewards/rejected": 0.0008578058332204819,
      "step": 41
    },
    {
      "epoch": 0.328125,
      "grad_norm": 6.300612449645996,
      "learning_rate": 8.055555555555555e-08,
      "logits/chosen": 1.056728720664978,
      "logits/rejected": 1.0377280712127686,
      "logps/chosen": -36.44713592529297,
      "logps/rejected": -40.917537689208984,
      "loss": 0.694,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008625603280961514,
      "rewards/margins": -0.0016694546211510897,
      "rewards/rejected": 0.01029505766928196,
      "step": 42
    },
    {
      "epoch": 0.3359375,
      "grad_norm": 5.517541885375977,
      "learning_rate": 7.962962962962963e-08,
      "logits/chosen": 1.1981596946716309,
      "logits/rejected": 1.2897117137908936,
      "logps/chosen": -33.273719787597656,
      "logps/rejected": -35.41583251953125,
      "loss": 0.6884,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00899195671081543,
      "rewards/margins": 0.00958802830427885,
      "rewards/rejected": -0.0005960701964795589,
      "step": 43
    },
    {
      "epoch": 0.34375,
      "grad_norm": 5.70889139175415,
      "learning_rate": 7.87037037037037e-08,
      "logits/chosen": 1.2997620105743408,
      "logits/rejected": 1.4885711669921875,
      "logps/chosen": -36.80390548706055,
      "logps/rejected": -43.5733642578125,
      "loss": 0.6889,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009963203221559525,
      "rewards/margins": 0.008474325761198997,
      "rewards/rejected": 0.0014888765290379524,
      "step": 44
    },
    {
      "epoch": 0.3515625,
      "grad_norm": 5.609140872955322,
      "learning_rate": 7.777777777777778e-08,
      "logits/chosen": 1.2999579906463623,
      "logits/rejected": 1.4225561618804932,
      "logps/chosen": -40.64656448364258,
      "logps/rejected": -42.36402893066406,
      "loss": 0.6966,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.008951330557465553,
      "rewards/margins": -0.0068565611727535725,
      "rewards/rejected": -0.002094769384711981,
      "step": 45
    },
    {
      "epoch": 0.359375,
      "grad_norm": 6.6125617027282715,
      "learning_rate": 7.685185185185184e-08,
      "logits/chosen": 1.194669485092163,
      "logits/rejected": 1.1593618392944336,
      "logps/chosen": -33.67251205444336,
      "logps/rejected": -47.30220031738281,
      "loss": 0.6913,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.001073812716640532,
      "rewards/margins": 0.00395233603194356,
      "rewards/rejected": -0.002878522966057062,
      "step": 46
    },
    {
      "epoch": 0.3671875,
      "grad_norm": 5.881443977355957,
      "learning_rate": 7.592592592592592e-08,
      "logits/chosen": 1.2109125852584839,
      "logits/rejected": 1.0884071588516235,
      "logps/chosen": -35.541568756103516,
      "logps/rejected": -36.647064208984375,
      "loss": 0.6912,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00216925167478621,
      "rewards/margins": 0.0039016488008201122,
      "rewards/rejected": -0.0017323968932032585,
      "step": 47
    },
    {
      "epoch": 0.375,
      "grad_norm": 5.709496974945068,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.2420709133148193,
      "logits/rejected": 1.4236445426940918,
      "logps/chosen": -39.78348922729492,
      "logps/rejected": -40.62068176269531,
      "loss": 0.6901,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005432081408798695,
      "rewards/margins": 0.0060713766142725945,
      "rewards/rejected": -0.000639295787550509,
      "step": 48
    },
    {
      "epoch": 0.3828125,
      "grad_norm": 6.909196376800537,
      "learning_rate": 7.407407407407407e-08,
      "logits/chosen": 1.0143671035766602,
      "logits/rejected": 1.388035535812378,
      "logps/chosen": -46.39712905883789,
      "logps/rejected": -40.48831558227539,
      "loss": 0.6921,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -4.479906056076288e-05,
      "rewards/margins": 0.0021856785751879215,
      "rewards/rejected": -0.002230477286502719,
      "step": 49
    },
    {
      "epoch": 0.390625,
      "grad_norm": 6.506264686584473,
      "learning_rate": 7.314814814814815e-08,
      "logits/chosen": 1.132445216178894,
      "logits/rejected": 1.0999685525894165,
      "logps/chosen": -34.810733795166016,
      "logps/rejected": -37.85746765136719,
      "loss": 0.6939,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.007855366915464401,
      "rewards/margins": -0.0015056850388646126,
      "rewards/rejected": -0.006349682807922363,
      "step": 50
    },
    {
      "epoch": 0.3984375,
      "grad_norm": 7.125544548034668,
      "learning_rate": 7.222222222222221e-08,
      "logits/chosen": 1.1060065031051636,
      "logits/rejected": 1.3813316822052002,
      "logps/chosen": -37.92645263671875,
      "logps/rejected": -41.612491607666016,
      "loss": 0.6871,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.01239392813295126,
      "rewards/margins": 0.012346459552645683,
      "rewards/rejected": 4.746916238218546e-05,
      "step": 51
    },
    {
      "epoch": 0.40625,
      "grad_norm": 7.074392795562744,
      "learning_rate": 7.129629629629629e-08,
      "logits/chosen": 1.0322952270507812,
      "logits/rejected": 1.2684428691864014,
      "logps/chosen": -37.93524932861328,
      "logps/rejected": -50.16710662841797,
      "loss": 0.693,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003731989534571767,
      "rewards/margins": 0.00046699075028300285,
      "rewards/rejected": 0.0032649992499500513,
      "step": 52
    },
    {
      "epoch": 0.4140625,
      "grad_norm": 5.904209136962891,
      "learning_rate": 7.037037037037036e-08,
      "logits/chosen": 1.1341246366500854,
      "logits/rejected": 0.9513965845108032,
      "logps/chosen": -34.65300750732422,
      "logps/rejected": -35.14860534667969,
      "loss": 0.6942,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0037897583097219467,
      "rewards/margins": -0.002001785906031728,
      "rewards/rejected": -0.001787972287274897,
      "step": 53
    },
    {
      "epoch": 0.421875,
      "grad_norm": 6.713583469390869,
      "learning_rate": 6.944444444444444e-08,
      "logits/chosen": 1.3058552742004395,
      "logits/rejected": 1.3197349309921265,
      "logps/chosen": -44.43968200683594,
      "logps/rejected": -44.58235549926758,
      "loss": 0.6924,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.01226053200662136,
      "rewards/margins": 0.0016563166864216328,
      "rewards/rejected": 0.01060421485453844,
      "step": 54
    },
    {
      "epoch": 0.4296875,
      "grad_norm": 7.663620471954346,
      "learning_rate": 6.851851851851852e-08,
      "logits/chosen": 1.058093786239624,
      "logits/rejected": 1.3167297840118408,
      "logps/chosen": -40.97523880004883,
      "logps/rejected": -34.490806579589844,
      "loss": 0.6897,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004051733296364546,
      "rewards/margins": 0.006886410526931286,
      "rewards/rejected": -0.0028346776962280273,
      "step": 55
    },
    {
      "epoch": 0.4375,
      "grad_norm": 5.54641056060791,
      "learning_rate": 6.759259259259259e-08,
      "logits/chosen": 1.197939395904541,
      "logits/rejected": 0.9085119366645813,
      "logps/chosen": -33.88288116455078,
      "logps/rejected": -33.06116485595703,
      "loss": 0.6939,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0021777625661343336,
      "rewards/margins": -0.0014670609962195158,
      "rewards/rejected": 0.0036448242608457804,
      "step": 56
    },
    {
      "epoch": 0.4453125,
      "grad_norm": 5.68120813369751,
      "learning_rate": 6.666666666666665e-08,
      "logits/chosen": 1.295577049255371,
      "logits/rejected": 1.3485721349716187,
      "logps/chosen": -34.95863723754883,
      "logps/rejected": -42.45610809326172,
      "loss": 0.6981,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.004879307933151722,
      "rewards/margins": -0.009858895093202591,
      "rewards/rejected": 0.004979586694389582,
      "step": 57
    },
    {
      "epoch": 0.453125,
      "grad_norm": 5.626948833465576,
      "learning_rate": 6.574074074074074e-08,
      "logits/chosen": 1.3072293996810913,
      "logits/rejected": 1.2034441232681274,
      "logps/chosen": -38.793609619140625,
      "logps/rejected": -46.01997375488281,
      "loss": 0.6981,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.005108166020363569,
      "rewards/margins": -0.009905099868774414,
      "rewards/rejected": 0.004796934314072132,
      "step": 58
    },
    {
      "epoch": 0.4609375,
      "grad_norm": 7.289165496826172,
      "learning_rate": 6.481481481481481e-08,
      "logits/chosen": 1.0152642726898193,
      "logits/rejected": 1.1366993188858032,
      "logps/chosen": -36.57999038696289,
      "logps/rejected": -41.531097412109375,
      "loss": 0.6965,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.005334949120879173,
      "rewards/margins": -0.00658574141561985,
      "rewards/rejected": 0.011920690536499023,
      "step": 59
    },
    {
      "epoch": 0.46875,
      "grad_norm": 6.985562324523926,
      "learning_rate": 6.388888888888888e-08,
      "logits/chosen": 0.8844449520111084,
      "logits/rejected": 1.3596382141113281,
      "logps/chosen": -37.795372009277344,
      "logps/rejected": -45.33680725097656,
      "loss": 0.6918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007507395930588245,
      "rewards/margins": 0.002871132455766201,
      "rewards/rejected": 0.004636264406144619,
      "step": 60
    },
    {
      "epoch": 0.4765625,
      "grad_norm": 5.074923038482666,
      "learning_rate": 6.296296296296296e-08,
      "logits/chosen": 1.4278652667999268,
      "logits/rejected": 1.3564660549163818,
      "logps/chosen": -35.70165252685547,
      "logps/rejected": -36.82881164550781,
      "loss": 0.6942,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004331397823989391,
      "rewards/margins": -0.0021710628643631935,
      "rewards/rejected": 0.006502461154013872,
      "step": 61
    },
    {
      "epoch": 0.484375,
      "grad_norm": 5.158841609954834,
      "learning_rate": 6.203703703703704e-08,
      "logits/chosen": 1.2921061515808105,
      "logits/rejected": 1.5499669313430786,
      "logps/chosen": -38.60694122314453,
      "logps/rejected": -39.93461608886719,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.001190447947010398,
      "rewards/margins": -0.0025951145216822624,
      "rewards/rejected": 0.003785562701523304,
      "step": 62
    },
    {
      "epoch": 0.4921875,
      "grad_norm": 5.912731647491455,
      "learning_rate": 6.111111111111111e-08,
      "logits/chosen": 1.056809425354004,
      "logits/rejected": 1.4107745885849,
      "logps/chosen": -34.1916389465332,
      "logps/rejected": -43.06726837158203,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004551291465759277,
      "rewards/margins": 0.006352115422487259,
      "rewards/rejected": -0.0018008234910666943,
      "step": 63
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.088912487030029,
      "learning_rate": 6.018518518518519e-08,
      "logits/chosen": 1.1558494567871094,
      "logits/rejected": 1.2832894325256348,
      "logps/chosen": -35.752769470214844,
      "logps/rejected": -38.94169235229492,
      "loss": 0.6959,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0036430121399462223,
      "rewards/margins": -0.005408597178757191,
      "rewards/rejected": 0.009051608853042126,
      "step": 64
    },
    {
      "epoch": 0.5078125,
      "grad_norm": 17.690834045410156,
      "learning_rate": 5.925925925925925e-08,
      "logits/chosen": 1.2828651666641235,
      "logits/rejected": 1.2705243825912476,
      "logps/chosen": -36.50567626953125,
      "logps/rejected": -50.55085754394531,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0024315593764185905,
      "rewards/margins": -0.0027666334062814713,
      "rewards/rejected": 0.005198192782700062,
      "step": 65
    },
    {
      "epoch": 0.515625,
      "grad_norm": 6.594841480255127,
      "learning_rate": 5.833333333333333e-08,
      "logits/chosen": 1.0687793493270874,
      "logits/rejected": 1.4120887517929077,
      "logps/chosen": -38.689720153808594,
      "logps/rejected": -35.051231384277344,
      "loss": 0.6935,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.003342295065522194,
      "rewards/margins": -0.0007181165274232626,
      "rewards/rejected": 0.004060411360114813,
      "step": 66
    },
    {
      "epoch": 0.5234375,
      "grad_norm": 5.15162467956543,
      "learning_rate": 5.74074074074074e-08,
      "logits/chosen": 1.3031632900238037,
      "logits/rejected": 1.3219401836395264,
      "logps/chosen": -32.89917755126953,
      "logps/rejected": -41.700035095214844,
      "loss": 0.6971,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.002753019332885742,
      "rewards/margins": -0.00781862810254097,
      "rewards/rejected": 0.010571646504104137,
      "step": 67
    },
    {
      "epoch": 0.53125,
      "grad_norm": 7.934554100036621,
      "learning_rate": 5.648148148148147e-08,
      "logits/chosen": 1.1685216426849365,
      "logits/rejected": 1.2359024286270142,
      "logps/chosen": -40.73263168334961,
      "logps/rejected": -41.411170959472656,
      "loss": 0.6876,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0047799344174563885,
      "rewards/margins": 0.011212706565856934,
      "rewards/rejected": -0.006432771682739258,
      "step": 68
    },
    {
      "epoch": 0.5390625,
      "grad_norm": 5.801499366760254,
      "learning_rate": 5.5555555555555555e-08,
      "logits/chosen": 1.0712708234786987,
      "logits/rejected": 1.2566680908203125,
      "logps/chosen": -38.982810974121094,
      "logps/rejected": -37.99895095825195,
      "loss": 0.6925,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010287404991686344,
      "rewards/margins": 0.001370095880702138,
      "rewards/rejected": -0.011657500639557838,
      "step": 69
    },
    {
      "epoch": 0.546875,
      "grad_norm": 5.388514041900635,
      "learning_rate": 5.4629629629629624e-08,
      "logits/chosen": 1.1540130376815796,
      "logits/rejected": 1.2601083517074585,
      "logps/chosen": -33.95493698120117,
      "logps/rejected": -37.02037048339844,
      "loss": 0.7024,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.00693779019638896,
      "rewards/margins": -0.01831989362835884,
      "rewards/rejected": 0.011382102966308594,
      "step": 70
    },
    {
      "epoch": 0.5546875,
      "grad_norm": 5.3774213790893555,
      "learning_rate": 5.3703703703703707e-08,
      "logits/chosen": 0.953414797782898,
      "logits/rejected": 1.0556561946868896,
      "logps/chosen": -37.7889404296875,
      "logps/rejected": -34.1270751953125,
      "loss": 0.7001,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.005564236547797918,
      "rewards/margins": -0.013815070502460003,
      "rewards/rejected": 0.008250832557678223,
      "step": 71
    },
    {
      "epoch": 0.5625,
      "grad_norm": 5.498461723327637,
      "learning_rate": 5.2777777777777776e-08,
      "logits/chosen": 1.333620548248291,
      "logits/rejected": 1.2530945539474487,
      "logps/chosen": -37.60475158691406,
      "logps/rejected": -41.73023986816406,
      "loss": 0.6977,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.006132508162409067,
      "rewards/margins": -0.009053707122802734,
      "rewards/rejected": 0.002921199891716242,
      "step": 72
    },
    {
      "epoch": 0.5703125,
      "grad_norm": 5.679357051849365,
      "learning_rate": 5.1851851851851846e-08,
      "logits/chosen": 1.1472759246826172,
      "logits/rejected": 1.3666021823883057,
      "logps/chosen": -39.96989440917969,
      "logps/rejected": -46.01708984375,
      "loss": 0.6887,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0005032538902014494,
      "rewards/margins": 0.009030057117342949,
      "rewards/rejected": -0.009533310309052467,
      "step": 73
    },
    {
      "epoch": 0.578125,
      "grad_norm": 6.324443340301514,
      "learning_rate": 5.092592592592593e-08,
      "logits/chosen": 1.0234593152999878,
      "logits/rejected": 1.2726943492889404,
      "logps/chosen": -33.348976135253906,
      "logps/rejected": -41.103546142578125,
      "loss": 0.6896,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004460644908249378,
      "rewards/margins": 0.007098054978996515,
      "rewards/rejected": -0.0026374103035777807,
      "step": 74
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 6.027350902557373,
      "learning_rate": 5e-08,
      "logits/chosen": 1.3303532600402832,
      "logits/rejected": 1.2181875705718994,
      "logps/chosen": -34.795406341552734,
      "logps/rejected": -44.58521270751953,
      "loss": 0.6977,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0014498948585242033,
      "rewards/margins": -0.008940720930695534,
      "rewards/rejected": 0.007490825839340687,
      "step": 75
    },
    {
      "epoch": 0.59375,
      "grad_norm": 6.430253028869629,
      "learning_rate": 4.9074074074074074e-08,
      "logits/chosen": 1.3151839971542358,
      "logits/rejected": 1.2821499109268188,
      "logps/chosen": -38.649444580078125,
      "logps/rejected": -42.7336311340332,
      "loss": 0.6859,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.009929204359650612,
      "rewards/margins": 0.014698361977934837,
      "rewards/rejected": -0.0047691576182842255,
      "step": 76
    },
    {
      "epoch": 0.6015625,
      "grad_norm": 5.251346588134766,
      "learning_rate": 4.814814814814814e-08,
      "logits/chosen": 1.2977056503295898,
      "logits/rejected": 1.194016933441162,
      "logps/chosen": -29.78634262084961,
      "logps/rejected": -38.5230712890625,
      "loss": 0.6956,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.00010304444731445983,
      "rewards/margins": -0.004817605018615723,
      "rewards/rejected": 0.00492064980790019,
      "step": 77
    },
    {
      "epoch": 0.609375,
      "grad_norm": 6.43964958190918,
      "learning_rate": 4.722222222222222e-08,
      "logits/chosen": 1.27149498462677,
      "logits/rejected": 1.257664442062378,
      "logps/chosen": -36.4033088684082,
      "logps/rejected": -43.32879638671875,
      "loss": 0.695,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.004560637287795544,
      "rewards/margins": -0.0036139017902314663,
      "rewards/rejected": 0.008174538612365723,
      "step": 78
    },
    {
      "epoch": 0.6171875,
      "grad_norm": 5.39888858795166,
      "learning_rate": 4.6296296296296295e-08,
      "logits/chosen": 0.9358304738998413,
      "logits/rejected": 1.3707292079925537,
      "logps/chosen": -31.231765747070312,
      "logps/rejected": -38.90830993652344,
      "loss": 0.6949,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0028657675720751286,
      "rewards/margins": -0.0034487724769860506,
      "rewards/rejected": 0.006314540281891823,
      "step": 79
    },
    {
      "epoch": 0.625,
      "grad_norm": 5.184175968170166,
      "learning_rate": 4.537037037037037e-08,
      "logits/chosen": 1.1809673309326172,
      "logits/rejected": 1.2746599912643433,
      "logps/chosen": -30.615970611572266,
      "logps/rejected": -35.04204559326172,
      "loss": 0.6956,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0011289833346381783,
      "rewards/margins": -0.004854226019233465,
      "rewards/rejected": 0.005983209237456322,
      "step": 80
    },
    {
      "epoch": 0.6328125,
      "grad_norm": 5.52887487411499,
      "learning_rate": 4.444444444444444e-08,
      "logits/chosen": 0.9949849843978882,
      "logits/rejected": 1.314110279083252,
      "logps/chosen": -33.185569763183594,
      "logps/rejected": -42.92238235473633,
      "loss": 0.6853,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008453607559204102,
      "rewards/margins": 0.01580522023141384,
      "rewards/rejected": -0.007351613603532314,
      "step": 81
    },
    {
      "epoch": 0.640625,
      "grad_norm": 6.047219276428223,
      "learning_rate": 4.351851851851852e-08,
      "logits/chosen": 1.000341534614563,
      "logits/rejected": 1.126552700996399,
      "logps/chosen": -45.20922088623047,
      "logps/rejected": -37.41737365722656,
      "loss": 0.6878,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010781455785036087,
      "rewards/margins": 0.010797524824738503,
      "rewards/rejected": -1.606935984455049e-05,
      "step": 82
    },
    {
      "epoch": 0.6484375,
      "grad_norm": 6.788962364196777,
      "learning_rate": 4.259259259259259e-08,
      "logits/chosen": 0.8322761654853821,
      "logits/rejected": 1.5582126379013062,
      "logps/chosen": -34.2631721496582,
      "logps/rejected": -45.31505584716797,
      "loss": 0.6957,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.009592890739440918,
      "rewards/margins": -0.005012989044189453,
      "rewards/rejected": -0.004579901695251465,
      "step": 83
    },
    {
      "epoch": 0.65625,
      "grad_norm": 7.172541618347168,
      "learning_rate": 4.166666666666667e-08,
      "logits/chosen": 1.1024389266967773,
      "logits/rejected": 1.2125999927520752,
      "logps/chosen": -41.3612060546875,
      "logps/rejected": -48.19944763183594,
      "loss": 0.6914,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.012063169851899147,
      "rewards/margins": 0.0035937309730798006,
      "rewards/rejected": -0.01565690152347088,
      "step": 84
    },
    {
      "epoch": 0.6640625,
      "grad_norm": 5.459599494934082,
      "learning_rate": 4.074074074074074e-08,
      "logits/chosen": 1.119519829750061,
      "logits/rejected": 1.1879911422729492,
      "logps/chosen": -34.01019287109375,
      "logps/rejected": -43.45806121826172,
      "loss": 0.6929,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.008398342877626419,
      "rewards/margins": 0.0004572630859911442,
      "rewards/rejected": -0.008855605497956276,
      "step": 85
    },
    {
      "epoch": 0.671875,
      "grad_norm": 7.9570536613464355,
      "learning_rate": 3.9814814814814815e-08,
      "logits/chosen": 1.1038572788238525,
      "logits/rejected": 1.313276767730713,
      "logps/chosen": -41.795475006103516,
      "logps/rejected": -43.84187316894531,
      "loss": 0.6927,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006865120492875576,
      "rewards/margins": 0.001011490821838379,
      "rewards/rejected": 0.005853629671037197,
      "step": 86
    },
    {
      "epoch": 0.6796875,
      "grad_norm": 6.289668560028076,
      "learning_rate": 3.888888888888889e-08,
      "logits/chosen": 1.1281359195709229,
      "logits/rejected": 1.0751314163208008,
      "logps/chosen": -38.46357345581055,
      "logps/rejected": -45.130615234375,
      "loss": 0.6911,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002923464635387063,
      "rewards/margins": 0.004349756520241499,
      "rewards/rejected": -0.001426291768439114,
      "step": 87
    },
    {
      "epoch": 0.6875,
      "grad_norm": 5.734938621520996,
      "learning_rate": 3.796296296296296e-08,
      "logits/chosen": 1.1479030847549438,
      "logits/rejected": 1.2272742986679077,
      "logps/chosen": -34.652503967285156,
      "logps/rejected": -39.04074478149414,
      "loss": 0.6956,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0056479452177882195,
      "rewards/margins": -0.004919219296425581,
      "rewards/rejected": 0.010567164979875088,
      "step": 88
    },
    {
      "epoch": 0.6953125,
      "grad_norm": 6.190950393676758,
      "learning_rate": 3.7037037037037036e-08,
      "logits/chosen": 1.266575813293457,
      "logits/rejected": 0.9157266616821289,
      "logps/chosen": -39.34772491455078,
      "logps/rejected": -36.61341094970703,
      "loss": 0.6926,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0031440258026123047,
      "rewards/margins": 0.0010584350675344467,
      "rewards/rejected": -0.004202460870146751,
      "step": 89
    },
    {
      "epoch": 0.703125,
      "grad_norm": 7.0721435546875,
      "learning_rate": 3.6111111111111106e-08,
      "logits/chosen": 0.9626381993293762,
      "logits/rejected": 1.2791515588760376,
      "logps/chosen": -36.82598114013672,
      "logps/rejected": -41.83097457885742,
      "loss": 0.6974,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0009898425778374076,
      "rewards/margins": -0.008408594876527786,
      "rewards/rejected": 0.0074187517166137695,
      "step": 90
    },
    {
      "epoch": 0.7109375,
      "grad_norm": 7.5154218673706055,
      "learning_rate": 3.518518518518518e-08,
      "logits/chosen": 1.0393842458724976,
      "logits/rejected": 1.0525892972946167,
      "logps/chosen": -43.414920806884766,
      "logps/rejected": -41.22306823730469,
      "loss": 0.6949,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00564186554402113,
      "rewards/margins": -0.0034290319308638573,
      "rewards/rejected": 0.009070897474884987,
      "step": 91
    },
    {
      "epoch": 0.71875,
      "grad_norm": 6.2151103019714355,
      "learning_rate": 3.425925925925926e-08,
      "logits/chosen": 1.083252191543579,
      "logits/rejected": 0.9186880588531494,
      "logps/chosen": -37.18103790283203,
      "logps/rejected": -38.00471878051758,
      "loss": 0.6954,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0004231452476233244,
      "rewards/margins": -0.004355669021606445,
      "rewards/rejected": 0.004778814502060413,
      "step": 92
    },
    {
      "epoch": 0.7265625,
      "grad_norm": 6.874526023864746,
      "learning_rate": 3.333333333333333e-08,
      "logits/chosen": 1.0747990608215332,
      "logits/rejected": 1.0157015323638916,
      "logps/chosen": -37.54098892211914,
      "logps/rejected": -36.725799560546875,
      "loss": 0.6928,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003018307499587536,
      "rewards/margins": 0.0006402491126209497,
      "rewards/rejected": 0.002378058386966586,
      "step": 93
    },
    {
      "epoch": 0.734375,
      "grad_norm": 6.123867034912109,
      "learning_rate": 3.2407407407407403e-08,
      "logits/chosen": 1.0070619583129883,
      "logits/rejected": 1.3070231676101685,
      "logps/chosen": -36.62519836425781,
      "logps/rejected": -41.191585540771484,
      "loss": 0.6965,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.007581782527267933,
      "rewards/margins": -0.006450199522078037,
      "rewards/rejected": -0.0011315826559439301,
      "step": 94
    },
    {
      "epoch": 0.7421875,
      "grad_norm": 5.48925256729126,
      "learning_rate": 3.148148148148148e-08,
      "logits/chosen": 1.2317156791687012,
      "logits/rejected": 1.3949906826019287,
      "logps/chosen": -33.094146728515625,
      "logps/rejected": -40.68149185180664,
      "loss": 0.6875,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0017638446297496557,
      "rewards/margins": 0.011539912782609463,
      "rewards/rejected": -0.013303756713867188,
      "step": 95
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.086918830871582,
      "learning_rate": 3.0555555555555556e-08,
      "logits/chosen": 0.9971295595169067,
      "logits/rejected": 1.2755510807037354,
      "logps/chosen": -33.25067138671875,
      "logps/rejected": -40.45985412597656,
      "loss": 0.6918,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0035523653496056795,
      "rewards/margins": 0.0027512311935424805,
      "rewards/rejected": -0.006303596310317516,
      "step": 96
    },
    {
      "epoch": 0.7578125,
      "grad_norm": 5.9143805503845215,
      "learning_rate": 2.9629629629629625e-08,
      "logits/chosen": 1.4392461776733398,
      "logits/rejected": 1.1793028116226196,
      "logps/chosen": -33.18950653076172,
      "logps/rejected": -44.518646240234375,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005079245660454035,
      "rewards/margins": 5.4264673963189125e-05,
      "rewards/rejected": -0.005133509635925293,
      "step": 97
    },
    {
      "epoch": 0.765625,
      "grad_norm": 6.046730995178223,
      "learning_rate": 2.87037037037037e-08,
      "logits/chosen": 1.1708831787109375,
      "logits/rejected": 1.346489429473877,
      "logps/chosen": -37.05295181274414,
      "logps/rejected": -43.284183502197266,
      "loss": 0.6924,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.006148123648017645,
      "rewards/margins": 0.0015544414054602385,
      "rewards/rejected": 0.00459368247538805,
      "step": 98
    },
    {
      "epoch": 0.7734375,
      "grad_norm": 6.441595554351807,
      "learning_rate": 2.7777777777777777e-08,
      "logits/chosen": 0.7945175766944885,
      "logits/rejected": 1.2615687847137451,
      "logps/chosen": -36.39776611328125,
      "logps/rejected": -36.060794830322266,
      "loss": 0.6931,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.002227568533271551,
      "rewards/margins": 0.0003551484551280737,
      "rewards/rejected": 0.0018724205438047647,
      "step": 99
    },
    {
      "epoch": 0.78125,
      "grad_norm": 6.573389053344727,
      "learning_rate": 2.6851851851851853e-08,
      "logits/chosen": 1.1594148874282837,
      "logits/rejected": 1.4472997188568115,
      "logps/chosen": -42.383216857910156,
      "logps/rejected": -33.39816665649414,
      "loss": 0.6981,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.003571606008335948,
      "rewards/margins": -0.009922599419951439,
      "rewards/rejected": 0.01349420566111803,
      "step": 100
    },
    {
      "epoch": 0.7890625,
      "grad_norm": 6.458624362945557,
      "learning_rate": 2.5925925925925923e-08,
      "logits/chosen": 1.3322778940200806,
      "logits/rejected": 1.3856794834136963,
      "logps/chosen": -38.289878845214844,
      "logps/rejected": -40.74357604980469,
      "loss": 0.6944,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010308505035936832,
      "rewards/margins": -0.002351117320358753,
      "rewards/rejected": -0.00795738771557808,
      "step": 101
    },
    {
      "epoch": 0.796875,
      "grad_norm": 6.577197074890137,
      "learning_rate": 2.5e-08,
      "logits/chosen": 0.9034051299095154,
      "logits/rejected": 1.2677403688430786,
      "logps/chosen": -36.65259552001953,
      "logps/rejected": -42.95146179199219,
      "loss": 0.6964,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.009921623393893242,
      "rewards/margins": -0.0064768558368086815,
      "rewards/rejected": -0.0034447666257619858,
      "step": 102
    },
    {
      "epoch": 0.8046875,
      "grad_norm": 4.733892917633057,
      "learning_rate": 2.407407407407407e-08,
      "logits/chosen": 1.0713162422180176,
      "logits/rejected": 1.5939397811889648,
      "logps/chosen": -33.666221618652344,
      "logps/rejected": -35.87550735473633,
      "loss": 0.693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005118084140121937,
      "rewards/margins": 0.0004301547887735069,
      "rewards/rejected": 0.004687929525971413,
      "step": 103
    },
    {
      "epoch": 0.8125,
      "grad_norm": 5.990489959716797,
      "learning_rate": 2.3148148148148148e-08,
      "logits/chosen": 1.290501356124878,
      "logits/rejected": 1.3046071529388428,
      "logps/chosen": -40.3193473815918,
      "logps/rejected": -40.781585693359375,
      "loss": 0.6958,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.006689668167382479,
      "rewards/margins": -0.005162810906767845,
      "rewards/rejected": 0.011852479539811611,
      "step": 104
    },
    {
      "epoch": 0.8203125,
      "grad_norm": 6.379104137420654,
      "learning_rate": 2.222222222222222e-08,
      "logits/chosen": 1.4965890645980835,
      "logits/rejected": 1.3612802028656006,
      "logps/chosen": -38.33320999145508,
      "logps/rejected": -46.10273742675781,
      "loss": 0.7003,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0012546539073809981,
      "rewards/margins": -0.014122867956757545,
      "rewards/rejected": 0.015377521514892578,
      "step": 105
    },
    {
      "epoch": 0.828125,
      "grad_norm": 5.613941192626953,
      "learning_rate": 2.1296296296296297e-08,
      "logits/chosen": 1.2592823505401611,
      "logits/rejected": 1.575786828994751,
      "logps/chosen": -39.47283935546875,
      "logps/rejected": -46.3462028503418,
      "loss": 0.6934,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0011264323256909847,
      "rewards/margins": -0.0003960368921980262,
      "rewards/rejected": 0.0015224694507196546,
      "step": 106
    },
    {
      "epoch": 0.8359375,
      "grad_norm": 5.055581092834473,
      "learning_rate": 2.037037037037037e-08,
      "logits/chosen": 1.2072824239730835,
      "logits/rejected": 1.3123623132705688,
      "logps/chosen": -34.012794494628906,
      "logps/rejected": -42.47319030761719,
      "loss": 0.6889,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007047629915177822,
      "rewards/margins": 0.008622312918305397,
      "rewards/rejected": -0.0015746832359582186,
      "step": 107
    },
    {
      "epoch": 0.84375,
      "grad_norm": 5.398423671722412,
      "learning_rate": 1.9444444444444445e-08,
      "logits/chosen": 1.028279423713684,
      "logits/rejected": 1.3177928924560547,
      "logps/chosen": -32.06507110595703,
      "logps/rejected": -37.88296127319336,
      "loss": 0.6992,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.010632800869643688,
      "rewards/margins": -0.012072563171386719,
      "rewards/rejected": 0.0014397623017430305,
      "step": 108
    },
    {
      "epoch": 0.8515625,
      "grad_norm": 6.755819797515869,
      "learning_rate": 1.8518518518518518e-08,
      "logits/chosen": 1.156245231628418,
      "logits/rejected": 1.1495940685272217,
      "logps/chosen": -42.462730407714844,
      "logps/rejected": -44.89847183227539,
      "loss": 0.6947,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.00753707904368639,
      "rewards/margins": -0.0030088666826486588,
      "rewards/rejected": 0.010545944795012474,
      "step": 109
    },
    {
      "epoch": 0.859375,
      "grad_norm": 6.157196521759033,
      "learning_rate": 1.759259259259259e-08,
      "logits/chosen": 1.0755761861801147,
      "logits/rejected": 1.4412537813186646,
      "logps/chosen": -32.33170700073242,
      "logps/rejected": -44.608245849609375,
      "loss": 0.6919,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005486678797751665,
      "rewards/margins": 0.002523540984839201,
      "rewards/rejected": 0.0029631375800818205,
      "step": 110
    },
    {
      "epoch": 0.8671875,
      "grad_norm": 7.4378581047058105,
      "learning_rate": 1.6666666666666664e-08,
      "logits/chosen": 1.0299227237701416,
      "logits/rejected": 1.1785259246826172,
      "logps/chosen": -32.637298583984375,
      "logps/rejected": -45.633052825927734,
      "loss": 0.6912,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0008778811898082495,
      "rewards/margins": 0.0038767103105783463,
      "rewards/rejected": -0.002998828887939453,
      "step": 111
    },
    {
      "epoch": 0.875,
      "grad_norm": 7.769891738891602,
      "learning_rate": 1.574074074074074e-08,
      "logits/chosen": 1.4381651878356934,
      "logits/rejected": 1.507440447807312,
      "logps/chosen": -41.425621032714844,
      "logps/rejected": -44.97773742675781,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.007828043773770332,
      "rewards/margins": 0.006335735786706209,
      "rewards/rejected": -0.014163780026137829,
      "step": 112
    },
    {
      "epoch": 0.8828125,
      "grad_norm": 7.783110618591309,
      "learning_rate": 1.4814814814814813e-08,
      "logits/chosen": 0.868135929107666,
      "logits/rejected": 1.1339938640594482,
      "logps/chosen": -34.51052474975586,
      "logps/rejected": -44.9434814453125,
      "loss": 0.6901,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003214240074157715,
      "rewards/margins": 0.0061958786100149155,
      "rewards/rejected": -0.002981639001518488,
      "step": 113
    },
    {
      "epoch": 0.890625,
      "grad_norm": 4.589605331420898,
      "learning_rate": 1.3888888888888889e-08,
      "logits/chosen": 1.4668254852294922,
      "logits/rejected": 1.5421321392059326,
      "logps/chosen": -31.026039123535156,
      "logps/rejected": -43.13536071777344,
      "loss": 0.6954,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005455708596855402,
      "rewards/margins": -0.004378676880151033,
      "rewards/rejected": -0.0010770318331196904,
      "step": 114
    },
    {
      "epoch": 0.8984375,
      "grad_norm": 5.536567687988281,
      "learning_rate": 1.2962962962962961e-08,
      "logits/chosen": 1.2859883308410645,
      "logits/rejected": 1.2829476594924927,
      "logps/chosen": -35.094879150390625,
      "logps/rejected": -40.35495376586914,
      "loss": 0.6955,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005224442575126886,
      "rewards/margins": -0.004663849249482155,
      "rewards/rejected": 0.009888292290270329,
      "step": 115
    },
    {
      "epoch": 0.90625,
      "grad_norm": 5.663449764251709,
      "learning_rate": 1.2037037037037036e-08,
      "logits/chosen": 0.8973942995071411,
      "logits/rejected": 1.0038167238235474,
      "logps/chosen": -31.11229133605957,
      "logps/rejected": -34.125003814697266,
      "loss": 0.6903,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008806873112916946,
      "rewards/margins": 0.005666232667863369,
      "rewards/rejected": 0.0031406404450535774,
      "step": 116
    },
    {
      "epoch": 0.9140625,
      "grad_norm": 6.799071311950684,
      "learning_rate": 1.111111111111111e-08,
      "logits/chosen": 1.2169475555419922,
      "logits/rejected": 1.1150797605514526,
      "logps/chosen": -32.741641998291016,
      "logps/rejected": -38.58196258544922,
      "loss": 0.6956,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.003128909971565008,
      "rewards/margins": -0.004730343818664551,
      "rewards/rejected": 0.001601433614268899,
      "step": 117
    },
    {
      "epoch": 0.921875,
      "grad_norm": 6.275606155395508,
      "learning_rate": 1.0185185185185185e-08,
      "logits/chosen": 1.311614990234375,
      "logits/rejected": 1.2760417461395264,
      "logps/chosen": -39.566463470458984,
      "logps/rejected": -40.83721923828125,
      "loss": 0.6919,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.001557779498398304,
      "rewards/margins": 0.002674627583473921,
      "rewards/rejected": -0.0011168478522449732,
      "step": 118
    },
    {
      "epoch": 0.9296875,
      "grad_norm": 6.238402843475342,
      "learning_rate": 9.259259259259259e-09,
      "logits/chosen": 1.1410634517669678,
      "logits/rejected": 1.3422504663467407,
      "logps/chosen": -38.303016662597656,
      "logps/rejected": -41.17222595214844,
      "loss": 0.7003,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.006962776184082031,
      "rewards/margins": -0.014090322889387608,
      "rewards/rejected": 0.007127548102289438,
      "step": 119
    },
    {
      "epoch": 0.9375,
      "grad_norm": 6.405856609344482,
      "learning_rate": 8.333333333333332e-09,
      "logits/chosen": 1.229702353477478,
      "logits/rejected": 1.1562488079071045,
      "logps/chosen": -36.344993591308594,
      "logps/rejected": -37.28598403930664,
      "loss": 0.6935,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0016703370492905378,
      "rewards/margins": -0.0007040979107841849,
      "rewards/rejected": 0.0023744343779981136,
      "step": 120
    },
    {
      "epoch": 0.9453125,
      "grad_norm": 7.260377407073975,
      "learning_rate": 7.407407407407406e-09,
      "logits/chosen": 1.0825326442718506,
      "logits/rejected": 1.2202259302139282,
      "logps/chosen": -37.0356559753418,
      "logps/rejected": -47.514930725097656,
      "loss": 0.6966,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.008321022614836693,
      "rewards/margins": -0.006792545784264803,
      "rewards/rejected": 0.015113567933440208,
      "step": 121
    },
    {
      "epoch": 0.953125,
      "grad_norm": 6.67820405960083,
      "learning_rate": 6.481481481481481e-09,
      "logits/chosen": 1.2370824813842773,
      "logits/rejected": 1.3743242025375366,
      "logps/chosen": -34.085479736328125,
      "logps/rejected": -45.65609359741211,
      "loss": 0.6874,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01368560828268528,
      "rewards/margins": 0.011449575424194336,
      "rewards/rejected": 0.0022360326256603003,
      "step": 122
    },
    {
      "epoch": 0.9609375,
      "grad_norm": 7.111855506896973,
      "learning_rate": 5.555555555555555e-09,
      "logits/chosen": 1.228887677192688,
      "logits/rejected": 1.04184091091156,
      "logps/chosen": -38.59794235229492,
      "logps/rejected": -42.27731704711914,
      "loss": 0.7021,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.004487395752221346,
      "rewards/margins": -0.017671920359134674,
      "rewards/rejected": 0.01318452414125204,
      "step": 123
    },
    {
      "epoch": 0.96875,
      "grad_norm": 6.050224304199219,
      "learning_rate": 4.6296296296296295e-09,
      "logits/chosen": 0.9809213280677795,
      "logits/rejected": 1.2043178081512451,
      "logps/chosen": -36.35446548461914,
      "logps/rejected": -42.41106414794922,
      "loss": 0.6985,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.006650161929428577,
      "rewards/margins": -0.01060473918914795,
      "rewards/rejected": 0.003954577725380659,
      "step": 124
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 5.788334846496582,
      "learning_rate": 3.703703703703703e-09,
      "logits/chosen": 1.4679911136627197,
      "logits/rejected": 1.2444475889205933,
      "logps/chosen": -39.31904220581055,
      "logps/rejected": -40.75438690185547,
      "loss": 0.6936,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0063155414536595345,
      "rewards/margins": -0.0007883552461862564,
      "rewards/rejected": 0.007103896699845791,
      "step": 125
    },
    {
      "epoch": 0.984375,
      "grad_norm": 7.920106887817383,
      "learning_rate": 2.7777777777777776e-09,
      "logits/chosen": 0.9132689833641052,
      "logits/rejected": 1.0426397323608398,
      "logps/chosen": -33.58228302001953,
      "logps/rejected": -45.983734130859375,
      "loss": 0.7019,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.004018115811049938,
      "rewards/margins": -0.017295146360993385,
      "rewards/rejected": 0.013277030549943447,
      "step": 126
    },
    {
      "epoch": 0.9921875,
      "grad_norm": 6.091961860656738,
      "learning_rate": 1.8518518518518516e-09,
      "logits/chosen": 1.372882604598999,
      "logits/rejected": 1.3627214431762695,
      "logps/chosen": -43.362037658691406,
      "logps/rejected": -42.13080978393555,
      "loss": 0.6931,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.006650233641266823,
      "rewards/margins": 0.00016059819608926773,
      "rewards/rejected": -0.006810832768678665,
      "step": 127
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.75388240814209,
      "learning_rate": 9.259259259259258e-10,
      "logits/chosen": 1.5069947242736816,
      "logits/rejected": 1.3970874547958374,
      "logps/chosen": -40.57387924194336,
      "logps/rejected": -36.262237548828125,
      "loss": 0.6919,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.00140969711355865,
      "rewards/margins": 0.0025546790566295385,
      "rewards/rejected": -0.003964376635849476,
      "step": 128
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 1.11881422996521,
      "eval_logits/rejected": 1.1873375177383423,
      "eval_logps/chosen": -36.6551399230957,
      "eval_logps/rejected": -42.06150817871094,
      "eval_loss": 0.6927664279937744,
      "eval_rewards/accuracies": 0.54296875,
      "eval_rewards/chosen": 0.001331815728917718,
      "eval_rewards/margins": 0.0008512467611581087,
      "eval_rewards/rejected": 0.0004805691714864224,
      "eval_runtime": 7.0233,
      "eval_samples_per_second": 36.45,
      "eval_steps_per_second": 18.225,
      "step": 128
    },
    {
      "epoch": 1.0,
      "step": 128,
      "total_flos": 0.0,
      "train_loss": 0.6933585330843925,
      "train_runtime": 79.8232,
      "train_samples_per_second": 12.828,
      "train_steps_per_second": 1.604
    }
  ],
  "logging_steps": 1,
  "max_steps": 128,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
