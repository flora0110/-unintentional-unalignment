{
  "best_global_step": 91,
  "best_metric": 0.6903262138366699,
  "best_model_checkpoint": "/scratch/user/chuanhsin0110/LLMRec-Labs/unintentional-unalignment/outputs/Goodreads_test/ln_ches_score_top100/checkpoint-91",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 91,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 6.428817272186279,
      "learning_rate": 0.0,
      "logits/chosen": 0.9054259061813354,
      "logits/rejected": 1.464247226715088,
      "logps/chosen": -35.74313735961914,
      "logps/rejected": -48.85862731933594,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.107241630554199,
      "learning_rate": 5e-09,
      "logits/chosen": 0.5086570978164673,
      "logits/rejected": 1.4601354598999023,
      "logps/chosen": -35.24644088745117,
      "logps/rejected": -43.02483367919922,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.736878871917725,
      "learning_rate": 1e-08,
      "logits/chosen": 0.764705240726471,
      "logits/rejected": 1.418893814086914,
      "logps/chosen": -45.343299865722656,
      "logps/rejected": -43.076805114746094,
      "loss": 0.699,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.008596444502472878,
      "rewards/margins": -0.011580300517380238,
      "rewards/rejected": 0.0029838562477380037,
      "step": 3
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.347262859344482,
      "learning_rate": 1.5e-08,
      "logits/chosen": 0.6903715133666992,
      "logits/rejected": 1.4363714456558228,
      "logps/chosen": -37.866859436035156,
      "logps/rejected": -38.897727966308594,
      "loss": 0.695,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0019239424727857113,
      "rewards/margins": -0.003693508915603161,
      "rewards/rejected": 0.0056174518540501595,
      "step": 4
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.239800930023193,
      "learning_rate": 2e-08,
      "logits/chosen": 0.8591561317443848,
      "logits/rejected": 1.4260010719299316,
      "logps/chosen": -34.35904312133789,
      "logps/rejected": -42.53819274902344,
      "loss": 0.6919,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0013637784868478775,
      "rewards/margins": 0.002602195367217064,
      "rewards/rejected": -0.003965974319726229,
      "step": 5
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.361380577087402,
      "learning_rate": 2.5e-08,
      "logits/chosen": 0.7124603390693665,
      "logits/rejected": 1.46966552734375,
      "logps/chosen": -33.22773742675781,
      "logps/rejected": -42.905372619628906,
      "loss": 0.6948,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.006779718212783337,
      "rewards/margins": -0.003254961920902133,
      "rewards/rejected": 0.010034680366516113,
      "step": 6
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.847661972045898,
      "learning_rate": 3e-08,
      "logits/chosen": 0.7389699220657349,
      "logits/rejected": 1.558082103729248,
      "logps/chosen": -29.145870208740234,
      "logps/rejected": -33.543739318847656,
      "loss": 0.6957,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.006223606877028942,
      "rewards/margins": -0.005161380395293236,
      "rewards/rejected": -0.0010622263653203845,
      "step": 7
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.056343078613281,
      "learning_rate": 3.4999999999999996e-08,
      "logits/chosen": 0.6335445642471313,
      "logits/rejected": 1.4677091836929321,
      "logps/chosen": -39.9307861328125,
      "logps/rejected": -46.128143310546875,
      "loss": 0.6847,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.011400175280869007,
      "rewards/margins": 0.017063211649656296,
      "rewards/rejected": -0.005663037300109863,
      "step": 8
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.050502777099609,
      "learning_rate": 4e-08,
      "logits/chosen": 0.6457346677780151,
      "logits/rejected": 1.45792555809021,
      "logps/chosen": -38.75764465332031,
      "logps/rejected": -40.61576843261719,
      "loss": 0.695,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0008114812662824988,
      "rewards/margins": -0.003551554400473833,
      "rewards/rejected": 0.004363036248832941,
      "step": 9
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.254057884216309,
      "learning_rate": 4.5e-08,
      "logits/chosen": 0.8285114765167236,
      "logits/rejected": 1.449779987335205,
      "logps/chosen": -45.31275177001953,
      "logps/rejected": -45.90330505371094,
      "loss": 0.6922,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0008099074475467205,
      "rewards/margins": 0.001986718038097024,
      "rewards/rejected": -0.0027966259513050318,
      "step": 10
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.490525245666504,
      "learning_rate": 5e-08,
      "logits/chosen": 0.8072168231010437,
      "logits/rejected": 1.341081976890564,
      "logps/chosen": -40.95579528808594,
      "logps/rejected": -35.25293731689453,
      "loss": 0.6963,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.007976842112839222,
      "rewards/margins": -0.006233954336494207,
      "rewards/rejected": -0.0017428873106837273,
      "step": 11
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.353468894958496,
      "learning_rate": 5.5e-08,
      "logits/chosen": 0.46689242124557495,
      "logits/rejected": 1.5347321033477783,
      "logps/chosen": -34.85390853881836,
      "logps/rejected": -34.331844329833984,
      "loss": 0.6915,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004482794553041458,
      "rewards/margins": 0.0034902808256447315,
      "rewards/rejected": 0.0009925125632435083,
      "step": 12
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.492400169372559,
      "learning_rate": 6e-08,
      "logits/chosen": 0.8436086177825928,
      "logits/rejected": 1.4478447437286377,
      "logps/chosen": -43.58490753173828,
      "logps/rejected": -37.084171295166016,
      "loss": 0.694,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.007894706912338734,
      "rewards/margins": -0.0016609195154160261,
      "rewards/rejected": -0.006233787629753351,
      "step": 13
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 1.0059549808502197,
      "eval_logits/rejected": 1.430189609527588,
      "eval_logps/chosen": -38.3263053894043,
      "eval_logps/rejected": -42.20656204223633,
      "eval_loss": 0.6923865675926208,
      "eval_rewards/accuracies": 0.5600000023841858,
      "eval_rewards/chosen": -0.0024141944013535976,
      "eval_rewards/margins": 0.0016084174858406186,
      "eval_rewards/rejected": -0.004022611770778894,
      "eval_runtime": 2.7537,
      "eval_samples_per_second": 36.314,
      "eval_steps_per_second": 18.157,
      "step": 13
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.950829029083252,
      "learning_rate": 6.5e-08,
      "logits/chosen": 0.8921337723731995,
      "logits/rejected": 1.4169814586639404,
      "logps/chosen": -36.71812057495117,
      "logps/rejected": -38.090946197509766,
      "loss": 0.6939,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0032013654708862305,
      "rewards/margins": -0.0015302891843020916,
      "rewards/rejected": -0.0016710762865841389,
      "step": 14
    },
    {
      "epoch": 1.16,
      "grad_norm": 5.670483589172363,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 0.717674732208252,
      "logits/rejected": 1.3729140758514404,
      "logps/chosen": -40.19995880126953,
      "logps/rejected": -38.080963134765625,
      "loss": 0.6921,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.008355021476745605,
      "rewards/margins": 0.002138590905815363,
      "rewards/rejected": -0.010493611916899681,
      "step": 15
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.732256889343262,
      "learning_rate": 7.5e-08,
      "logits/chosen": 0.7514374852180481,
      "logits/rejected": 1.472712516784668,
      "logps/chosen": -36.7023811340332,
      "logps/rejected": -46.89738082885742,
      "loss": 0.6868,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.013131214305758476,
      "rewards/margins": 0.012917686253786087,
      "rewards/rejected": 0.00021352770272642374,
      "step": 16
    },
    {
      "epoch": 1.32,
      "grad_norm": 7.104625701904297,
      "learning_rate": 8e-08,
      "logits/chosen": 0.7110202312469482,
      "logits/rejected": 1.4143311977386475,
      "logps/chosen": -44.117095947265625,
      "logps/rejected": -44.942996978759766,
      "loss": 0.6956,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.006845808122307062,
      "rewards/margins": -0.004765415098518133,
      "rewards/rejected": -0.002080393023788929,
      "step": 17
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.722866058349609,
      "learning_rate": 8.5e-08,
      "logits/chosen": 0.6611582040786743,
      "logits/rejected": 1.3280489444732666,
      "logps/chosen": -36.306190490722656,
      "logps/rejected": -40.76875686645508,
      "loss": 0.6897,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.001353096915408969,
      "rewards/margins": 0.0072075380012393,
      "rewards/rejected": -0.008560635149478912,
      "step": 18
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.1914448738098145,
      "learning_rate": 9e-08,
      "logits/chosen": 0.5837529897689819,
      "logits/rejected": 1.398640751838684,
      "logps/chosen": -38.959739685058594,
      "logps/rejected": -42.6179313659668,
      "loss": 0.697,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0031349421478807926,
      "rewards/margins": -0.007733440492302179,
      "rewards/rejected": 0.004598498344421387,
      "step": 19
    },
    {
      "epoch": 1.56,
      "grad_norm": 5.830338478088379,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 0.8270244598388672,
      "logits/rejected": 1.5211464166641235,
      "logps/chosen": -37.209407806396484,
      "logps/rejected": -38.03506851196289,
      "loss": 0.6881,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.014139367267489433,
      "rewards/margins": 0.010224890895187855,
      "rewards/rejected": 0.003914475440979004,
      "step": 20
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 5.391281604766846,
      "learning_rate": 1e-07,
      "logits/chosen": 0.7108885645866394,
      "logits/rejected": 1.5675970315933228,
      "logps/chosen": -30.03421974182129,
      "logps/rejected": -34.53471374511719,
      "loss": 0.6903,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.002071905415505171,
      "rewards/margins": 0.005711222067475319,
      "rewards/rejected": -0.003639316651970148,
      "step": 21
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.329249858856201,
      "learning_rate": 9.909090909090909e-08,
      "logits/chosen": 0.8415828347206116,
      "logits/rejected": 1.580840826034546,
      "logps/chosen": -36.327632904052734,
      "logps/rejected": -41.38648986816406,
      "loss": 0.6911,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003955149091780186,
      "rewards/margins": 0.004293370060622692,
      "rewards/rejected": -0.0003382205031812191,
      "step": 22
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.17939567565918,
      "learning_rate": 9.818181818181818e-08,
      "logits/chosen": 0.7281926870346069,
      "logits/rejected": 1.468246340751648,
      "logps/chosen": -39.34052658081055,
      "logps/rejected": -43.20445251464844,
      "loss": 0.693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.002284097485244274,
      "rewards/margins": 0.0004693269729614258,
      "rewards/rejected": -0.0027534242253750563,
      "step": 23
    },
    {
      "epoch": 1.88,
      "grad_norm": 6.499281883239746,
      "learning_rate": 9.727272727272727e-08,
      "logits/chosen": 0.5438905358314514,
      "logits/rejected": 1.5096805095672607,
      "logps/chosen": -37.060699462890625,
      "logps/rejected": -40.886627197265625,
      "loss": 0.688,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0037271741311997175,
      "rewards/margins": 0.010465120896697044,
      "rewards/rejected": -0.006737947463989258,
      "step": 24
    },
    {
      "epoch": 1.96,
      "grad_norm": 6.990479469299316,
      "learning_rate": 9.636363636363636e-08,
      "logits/chosen": 0.8013401627540588,
      "logits/rejected": 1.5030428171157837,
      "logps/chosen": -40.66284942626953,
      "logps/rejected": -47.377044677734375,
      "loss": 0.6961,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.004543471150100231,
      "rewards/margins": -0.005869364831596613,
      "rewards/rejected": 0.0013258932158350945,
      "step": 25
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.422956466674805,
      "learning_rate": 9.545454545454546e-08,
      "logits/chosen": 0.727580189704895,
      "logits/rejected": 1.4994714260101318,
      "logps/chosen": -37.737205505371094,
      "logps/rejected": -34.162654876708984,
      "loss": 0.699,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.006026935763657093,
      "rewards/margins": -0.01152110192924738,
      "rewards/rejected": 0.005494165699928999,
      "step": 26
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 1.0050129890441895,
      "eval_logits/rejected": 1.4278849363327026,
      "eval_logps/chosen": -38.28041076660156,
      "eval_logps/rejected": -42.18095779418945,
      "eval_loss": 0.6913873553276062,
      "eval_rewards/accuracies": 0.5400000214576721,
      "eval_rewards/chosen": 0.002175380941480398,
      "eval_rewards/margins": 0.0036377792712301016,
      "eval_rewards/rejected": -0.0014623984461650252,
      "eval_runtime": 2.7476,
      "eval_samples_per_second": 36.396,
      "eval_steps_per_second": 18.198,
      "step": 26
    },
    {
      "epoch": 2.08,
      "grad_norm": 6.535917282104492,
      "learning_rate": 9.454545454545454e-08,
      "logits/chosen": 0.8603215217590332,
      "logits/rejected": 1.4319065809249878,
      "logps/chosen": -38.96549987792969,
      "logps/rejected": -44.19790267944336,
      "loss": 0.6952,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.006281805224716663,
      "rewards/margins": -0.004127574153244495,
      "rewards/rejected": 0.010409378446638584,
      "step": 27
    },
    {
      "epoch": 2.16,
      "grad_norm": 5.919561386108398,
      "learning_rate": 9.363636363636364e-08,
      "logits/chosen": 0.6922289729118347,
      "logits/rejected": 1.5363909006118774,
      "logps/chosen": -40.60883331298828,
      "logps/rejected": -37.26764678955078,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0025339131243526936,
      "rewards/margins": -0.0026428219862282276,
      "rewards/rejected": 0.005176735110580921,
      "step": 28
    },
    {
      "epoch": 2.24,
      "grad_norm": 6.438477516174316,
      "learning_rate": 9.272727272727272e-08,
      "logits/chosen": 0.7989718317985535,
      "logits/rejected": 1.4665032625198364,
      "logps/chosen": -35.065399169921875,
      "logps/rejected": -39.81959915161133,
      "loss": 0.6913,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00020473008044064045,
      "rewards/margins": 0.0038858887273818254,
      "rewards/rejected": -0.003681158646941185,
      "step": 29
    },
    {
      "epoch": 2.32,
      "grad_norm": 7.075738906860352,
      "learning_rate": 9.181818181818182e-08,
      "logits/chosen": 0.9340692758560181,
      "logits/rejected": 1.5517637729644775,
      "logps/chosen": -39.082618713378906,
      "logps/rejected": -39.853816986083984,
      "loss": 0.6938,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0025522231590002775,
      "rewards/margins": -0.0012552732368931174,
      "rewards/rejected": 0.0038074972108006477,
      "step": 30
    },
    {
      "epoch": 2.4,
      "grad_norm": 6.189622402191162,
      "learning_rate": 9.09090909090909e-08,
      "logits/chosen": 0.833778440952301,
      "logits/rejected": 1.4063529968261719,
      "logps/chosen": -36.57189178466797,
      "logps/rejected": -42.01644515991211,
      "loss": 0.6971,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.00343246478587389,
      "rewards/margins": -0.0079498291015625,
      "rewards/rejected": 0.00451736431568861,
      "step": 31
    },
    {
      "epoch": 2.48,
      "grad_norm": 5.534319877624512,
      "learning_rate": 9e-08,
      "logits/chosen": 0.5670593976974487,
      "logits/rejected": 1.4525645971298218,
      "logps/chosen": -34.867218017578125,
      "logps/rejected": -37.30368423461914,
      "loss": 0.6913,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0004981518723070621,
      "rewards/margins": 0.0037720201071351767,
      "rewards/rejected": -0.004270171746611595,
      "step": 32
    },
    {
      "epoch": 2.56,
      "grad_norm": 7.223954200744629,
      "learning_rate": 8.909090909090908e-08,
      "logits/chosen": 0.5600770115852356,
      "logits/rejected": 1.491842269897461,
      "logps/chosen": -39.3691291809082,
      "logps/rejected": -43.35930252075195,
      "loss": 0.6908,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.002238702494651079,
      "rewards/margins": 0.004830528050661087,
      "rewards/rejected": -0.007069230545312166,
      "step": 33
    },
    {
      "epoch": 2.64,
      "grad_norm": 5.791284561157227,
      "learning_rate": 8.818181818181818e-08,
      "logits/chosen": 0.6095821857452393,
      "logits/rejected": 1.5394352674484253,
      "logps/chosen": -31.92440414428711,
      "logps/rejected": -41.20236587524414,
      "loss": 0.6937,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0015979530289769173,
      "rewards/margins": -0.001004003919661045,
      "rewards/rejected": -0.0005939484108239412,
      "step": 34
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 6.867719650268555,
      "learning_rate": 8.727272727272726e-08,
      "logits/chosen": 0.6816155910491943,
      "logits/rejected": 1.4348691701889038,
      "logps/chosen": -34.12434005737305,
      "logps/rejected": -39.724769592285156,
      "loss": 0.6893,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01362149603664875,
      "rewards/margins": 0.007787585258483887,
      "rewards/rejected": 0.0058339121751487255,
      "step": 35
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.029165744781494,
      "learning_rate": 8.636363636363636e-08,
      "logits/chosen": 0.6555092334747314,
      "logits/rejected": 1.3612920045852661,
      "logps/chosen": -41.669578552246094,
      "logps/rejected": -42.808570861816406,
      "loss": 0.6961,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003951406572014093,
      "rewards/margins": -0.005662393756210804,
      "rewards/rejected": 0.0017109874170273542,
      "step": 36
    },
    {
      "epoch": 2.88,
      "grad_norm": 6.306492805480957,
      "learning_rate": 8.545454545454544e-08,
      "logits/chosen": 0.6897847652435303,
      "logits/rejected": 1.471298098564148,
      "logps/chosen": -35.710182189941406,
      "logps/rejected": -42.72030258178711,
      "loss": 0.6887,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009636163711547852,
      "rewards/margins": 0.00892407912760973,
      "rewards/rejected": 0.0007120847003534436,
      "step": 37
    },
    {
      "epoch": 2.96,
      "grad_norm": 6.805698871612549,
      "learning_rate": 8.454545454545454e-08,
      "logits/chosen": 0.8678370714187622,
      "logits/rejected": 1.265188217163086,
      "logps/chosen": -46.838783264160156,
      "logps/rejected": -44.94319152832031,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008060717955231667,
      "rewards/margins": 0.006362342741340399,
      "rewards/rejected": 0.0016983748646453023,
      "step": 38
    },
    {
      "epoch": 3.0,
      "grad_norm": 9.533015251159668,
      "learning_rate": 8.363636363636363e-08,
      "logits/chosen": 0.7035021185874939,
      "logits/rejected": 1.5130234956741333,
      "logps/chosen": -34.798099517822266,
      "logps/rejected": -36.414669036865234,
      "loss": 0.7023,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.003571128938347101,
      "rewards/margins": -0.018201446160674095,
      "rewards/rejected": 0.014630317687988281,
      "step": 39
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": 1.005651593208313,
      "eval_logits/rejected": 1.4299232959747314,
      "eval_logps/chosen": -38.27977752685547,
      "eval_logps/rejected": -42.162696838378906,
      "eval_loss": 0.6922590732574463,
      "eval_rewards/accuracies": 0.5600000023841858,
      "eval_rewards/chosen": 0.0022386780474334955,
      "eval_rewards/margins": 0.0018752362811937928,
      "eval_rewards/rejected": 0.00036344153340905905,
      "eval_runtime": 2.7492,
      "eval_samples_per_second": 36.374,
      "eval_steps_per_second": 18.187,
      "step": 39
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.948022365570068,
      "learning_rate": 8.272727272727272e-08,
      "logits/chosen": 0.6545853614807129,
      "logits/rejected": 1.3875057697296143,
      "logps/chosen": -32.91937255859375,
      "logps/rejected": -32.70152282714844,
      "loss": 0.6973,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.001982402987778187,
      "rewards/margins": -0.008203864097595215,
      "rewards/rejected": 0.006221461575478315,
      "step": 40
    },
    {
      "epoch": 3.16,
      "grad_norm": 6.770774841308594,
      "learning_rate": 8.181818181818182e-08,
      "logits/chosen": 0.4908003807067871,
      "logits/rejected": 1.3925508260726929,
      "logps/chosen": -38.67699432373047,
      "logps/rejected": -37.22997283935547,
      "loss": 0.6954,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0010557891800999641,
      "rewards/margins": -0.004501557443290949,
      "rewards/rejected": 0.0034457682631909847,
      "step": 41
    },
    {
      "epoch": 3.24,
      "grad_norm": 7.350766658782959,
      "learning_rate": 8.09090909090909e-08,
      "logits/chosen": 0.6685320138931274,
      "logits/rejected": 1.5317689180374146,
      "logps/chosen": -41.922874450683594,
      "logps/rejected": -45.575904846191406,
      "loss": 0.6894,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.000830245204269886,
      "rewards/margins": 0.0075450181029737,
      "rewards/rejected": -0.006714772433042526,
      "step": 42
    },
    {
      "epoch": 3.32,
      "grad_norm": 6.644537925720215,
      "learning_rate": 8e-08,
      "logits/chosen": 0.7597082853317261,
      "logits/rejected": 1.441462516784668,
      "logps/chosen": -35.9055061340332,
      "logps/rejected": -40.73069763183594,
      "loss": 0.695,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.008456516079604626,
      "rewards/margins": -0.003684520721435547,
      "rewards/rejected": 0.012141036801040173,
      "step": 43
    },
    {
      "epoch": 3.4,
      "grad_norm": 5.7706708908081055,
      "learning_rate": 7.909090909090909e-08,
      "logits/chosen": 0.8515206575393677,
      "logits/rejected": 1.441333293914795,
      "logps/chosen": -34.796653747558594,
      "logps/rejected": -39.24687957763672,
      "loss": 0.6926,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0026580332778394222,
      "rewards/margins": 0.0010756015544757247,
      "rewards/rejected": -0.0037336349487304688,
      "step": 44
    },
    {
      "epoch": 3.48,
      "grad_norm": 5.621545791625977,
      "learning_rate": 7.818181818181818e-08,
      "logits/chosen": 0.7177613377571106,
      "logits/rejected": 1.5458935499191284,
      "logps/chosen": -36.26597213745117,
      "logps/rejected": -37.00956726074219,
      "loss": 0.6868,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.005439281463623047,
      "rewards/margins": 0.013013983145356178,
      "rewards/rejected": -0.007574701681733131,
      "step": 45
    },
    {
      "epoch": 3.56,
      "grad_norm": 7.8170928955078125,
      "learning_rate": 7.727272727272727e-08,
      "logits/chosen": 0.7441926598548889,
      "logits/rejected": 1.421433448791504,
      "logps/chosen": -42.42622375488281,
      "logps/rejected": -41.62118148803711,
      "loss": 0.6943,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0005372045561671257,
      "rewards/margins": -0.002209687139838934,
      "rewards/rejected": 0.002746892161667347,
      "step": 46
    },
    {
      "epoch": 3.64,
      "grad_norm": 6.431344509124756,
      "learning_rate": 7.636363636363636e-08,
      "logits/chosen": 0.844172477722168,
      "logits/rejected": 1.413010597229004,
      "logps/chosen": -44.108306884765625,
      "logps/rejected": -39.344573974609375,
      "loss": 0.6932,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0033339017536491156,
      "rewards/margins": -1.4547258615493774e-06,
      "rewards/rejected": -0.003332447959110141,
      "step": 47
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 6.870316982269287,
      "learning_rate": 7.545454545454545e-08,
      "logits/chosen": 0.6176844239234924,
      "logits/rejected": 1.5350818634033203,
      "logps/chosen": -39.827491760253906,
      "logps/rejected": -45.64750671386719,
      "loss": 0.6972,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.001870941836386919,
      "rewards/margins": -0.007964586839079857,
      "rewards/rejected": 0.006093645468354225,
      "step": 48
    },
    {
      "epoch": 3.8,
      "grad_norm": 6.024698734283447,
      "learning_rate": 7.454545454545455e-08,
      "logits/chosen": 0.7912150621414185,
      "logits/rejected": 1.461519479751587,
      "logps/chosen": -36.5981559753418,
      "logps/rejected": -42.011451721191406,
      "loss": 0.6904,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.006358266342431307,
      "rewards/margins": 0.005579948890954256,
      "rewards/rejected": 0.0007783176843076944,
      "step": 49
    },
    {
      "epoch": 3.88,
      "grad_norm": 7.300527095794678,
      "learning_rate": 7.363636363636363e-08,
      "logits/chosen": 0.7897079586982727,
      "logits/rejected": 1.335776925086975,
      "logps/chosen": -38.50515365600586,
      "logps/rejected": -49.15533447265625,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -7.867813110351562e-06,
      "rewards/margins": -0.0026710270904004574,
      "rewards/rejected": 0.002663159277290106,
      "step": 50
    },
    {
      "epoch": 3.96,
      "grad_norm": 5.786130905151367,
      "learning_rate": 7.272727272727273e-08,
      "logits/chosen": 0.6649529933929443,
      "logits/rejected": 1.4432414770126343,
      "logps/chosen": -30.31365966796875,
      "logps/rejected": -41.86083984375,
      "loss": 0.6885,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003617024514824152,
      "rewards/margins": 0.00932984333485365,
      "rewards/rejected": -0.0057128192856907845,
      "step": 51
    },
    {
      "epoch": 4.0,
      "grad_norm": 9.363767623901367,
      "learning_rate": 7.181818181818181e-08,
      "logits/chosen": 0.8858025074005127,
      "logits/rejected": 1.6845273971557617,
      "logps/chosen": -40.03171157836914,
      "logps/rejected": -42.74679946899414,
      "loss": 0.6909,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010943030938506126,
      "rewards/margins": 0.004630470182746649,
      "rewards/rejected": 0.006312561221420765,
      "step": 52
    },
    {
      "epoch": 4.0,
      "eval_logits/chosen": 1.0013267993927002,
      "eval_logits/rejected": 1.4259980916976929,
      "eval_logps/chosen": -38.25653839111328,
      "eval_logps/rejected": -42.14749526977539,
      "eval_loss": 0.6918603777885437,
      "eval_rewards/accuracies": 0.6000000238418579,
      "eval_rewards/chosen": 0.004562275484204292,
      "eval_rewards/margins": 0.0026784557849168777,
      "eval_rewards/rejected": 0.0018838195828720927,
      "eval_runtime": 2.752,
      "eval_samples_per_second": 36.337,
      "eval_steps_per_second": 18.169,
      "step": 52
    },
    {
      "epoch": 4.08,
      "grad_norm": 7.599002361297607,
      "learning_rate": 7.090909090909091e-08,
      "logits/chosen": 0.6155765056610107,
      "logits/rejected": 1.3405948877334595,
      "logps/chosen": -36.047122955322266,
      "logps/rejected": -40.413169860839844,
      "loss": 0.6948,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00047154456842690706,
      "rewards/margins": -0.0032063715625554323,
      "rewards/rejected": 0.0027348275762051344,
      "step": 53
    },
    {
      "epoch": 4.16,
      "grad_norm": 5.899988651275635,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 0.7159496545791626,
      "logits/rejected": 1.411226511001587,
      "logps/chosen": -36.035465240478516,
      "logps/rejected": -38.9951171875,
      "loss": 0.6914,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00411834754049778,
      "rewards/margins": 0.003650617552921176,
      "rewards/rejected": -0.0077689653262495995,
      "step": 54
    },
    {
      "epoch": 4.24,
      "grad_norm": 7.664285182952881,
      "learning_rate": 6.909090909090909e-08,
      "logits/chosen": 0.7243471145629883,
      "logits/rejected": 1.3316881656646729,
      "logps/chosen": -44.158447265625,
      "logps/rejected": -40.64606857299805,
      "loss": 0.696,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.006977606564760208,
      "rewards/margins": -0.00563776446506381,
      "rewards/rejected": -0.0013398410519585013,
      "step": 55
    },
    {
      "epoch": 4.32,
      "grad_norm": 5.712168216705322,
      "learning_rate": 6.818181818181817e-08,
      "logits/chosen": 0.6482688188552856,
      "logits/rejected": 1.4913150072097778,
      "logps/chosen": -37.13908386230469,
      "logps/rejected": -38.89641571044922,
      "loss": 0.6906,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006185221951454878,
      "rewards/margins": 0.005227779969573021,
      "rewards/rejected": 0.000957441283389926,
      "step": 56
    },
    {
      "epoch": 4.4,
      "grad_norm": 5.749118804931641,
      "learning_rate": 6.727272727272727e-08,
      "logits/chosen": 0.9003725647926331,
      "logits/rejected": 1.4457452297210693,
      "logps/chosen": -34.878501892089844,
      "logps/rejected": -42.594791412353516,
      "loss": 0.6956,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0052901748567819595,
      "rewards/margins": -0.004702425561845303,
      "rewards/rejected": -0.0005877494113519788,
      "step": 57
    },
    {
      "epoch": 4.48,
      "grad_norm": 5.081296920776367,
      "learning_rate": 6.636363636363637e-08,
      "logits/chosen": 0.634132444858551,
      "logits/rejected": 1.5383884906768799,
      "logps/chosen": -32.36787414550781,
      "logps/rejected": -39.30636978149414,
      "loss": 0.6888,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007195949554443359,
      "rewards/margins": 0.008771825581789017,
      "rewards/rejected": -0.0015758750960230827,
      "step": 58
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 6.383573055267334,
      "learning_rate": 6.545454545454545e-08,
      "logits/chosen": 0.744212806224823,
      "logits/rejected": 1.5663948059082031,
      "logps/chosen": -36.915138244628906,
      "logps/rejected": -44.793373107910156,
      "loss": 0.6901,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0040890928357839584,
      "rewards/margins": 0.00608451385051012,
      "rewards/rejected": -0.0019954205490648746,
      "step": 59
    },
    {
      "epoch": 4.64,
      "grad_norm": 5.917513370513916,
      "learning_rate": 6.454545454545455e-08,
      "logits/chosen": 0.48559749126434326,
      "logits/rejected": 1.3628114461898804,
      "logps/chosen": -34.405216217041016,
      "logps/rejected": -35.85540771484375,
      "loss": 0.6895,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008004928007721901,
      "rewards/margins": 0.007327604573220015,
      "rewards/rejected": 0.0006773234345018864,
      "step": 60
    },
    {
      "epoch": 4.72,
      "grad_norm": 6.214596271514893,
      "learning_rate": 6.363636363636363e-08,
      "logits/chosen": 0.5988697409629822,
      "logits/rejected": 1.3914024829864502,
      "logps/chosen": -34.644386291503906,
      "logps/rejected": -37.24907302856445,
      "loss": 0.6968,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0031953095458447933,
      "rewards/margins": -0.00712351780384779,
      "rewards/rejected": 0.003928208723664284,
      "step": 61
    },
    {
      "epoch": 4.8,
      "grad_norm": 8.223599433898926,
      "learning_rate": 6.272727272727273e-08,
      "logits/chosen": 0.765548050403595,
      "logits/rejected": 1.5556385517120361,
      "logps/chosen": -43.6251220703125,
      "logps/rejected": -45.09827423095703,
      "loss": 0.6931,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.001704453956335783,
      "rewards/margins": 0.00022368389181792736,
      "rewards/rejected": 0.0014807702973484993,
      "step": 62
    },
    {
      "epoch": 4.88,
      "grad_norm": 6.379623889923096,
      "learning_rate": 6.181818181818181e-08,
      "logits/chosen": 0.8051762580871582,
      "logits/rejected": 1.49832284450531,
      "logps/chosen": -36.24443054199219,
      "logps/rejected": -43.129173278808594,
      "loss": 0.6879,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013645339757204056,
      "rewards/margins": 0.010586738586425781,
      "rewards/rejected": 0.0030586004722863436,
      "step": 63
    },
    {
      "epoch": 4.96,
      "grad_norm": 7.3155436515808105,
      "learning_rate": 6.090909090909091e-08,
      "logits/chosen": 0.8510472178459167,
      "logits/rejected": 1.5374574661254883,
      "logps/chosen": -45.333736419677734,
      "logps/rejected": -47.98169708251953,
      "loss": 0.6946,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.003971552941948175,
      "rewards/margins": -0.0027868507895618677,
      "rewards/rejected": 0.006758403964340687,
      "step": 64
    },
    {
      "epoch": 5.0,
      "grad_norm": 8.110604286193848,
      "learning_rate": 6e-08,
      "logits/chosen": 0.943335771560669,
      "logits/rejected": 1.3336436748504639,
      "logps/chosen": -41.00334167480469,
      "logps/rejected": -37.05327606201172,
      "loss": 0.7012,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.014356613159179688,
      "rewards/margins": -0.01599130593240261,
      "rewards/rejected": 0.0016346932388842106,
      "step": 65
    },
    {
      "epoch": 5.0,
      "eval_logits/chosen": 1.0019556283950806,
      "eval_logits/rejected": 1.4258211851119995,
      "eval_logps/chosen": -38.275367736816406,
      "eval_logps/rejected": -42.15760803222656,
      "eval_loss": 0.6922987103462219,
      "eval_rewards/accuracies": 0.5600000023841858,
      "eval_rewards/chosen": 0.0026796874590218067,
      "eval_rewards/margins": 0.001806560903787613,
      "eval_rewards/rejected": 0.000873127079103142,
      "eval_runtime": 2.75,
      "eval_samples_per_second": 36.364,
      "eval_steps_per_second": 18.182,
      "step": 65
    },
    {
      "epoch": 5.08,
      "grad_norm": 6.659619331359863,
      "learning_rate": 5.909090909090909e-08,
      "logits/chosen": 0.5273029208183289,
      "logits/rejected": 1.45235276222229,
      "logps/chosen": -38.19847106933594,
      "logps/rejected": -42.962791442871094,
      "loss": 0.6879,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00303804874420166,
      "rewards/margins": 0.01072788331657648,
      "rewards/rejected": -0.007689833641052246,
      "step": 66
    },
    {
      "epoch": 5.16,
      "grad_norm": 7.201521873474121,
      "learning_rate": 5.8181818181818176e-08,
      "logits/chosen": 0.7314907312393188,
      "logits/rejected": 1.5208486318588257,
      "logps/chosen": -39.523170471191406,
      "logps/rejected": -42.51557159423828,
      "loss": 0.6914,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006556010339409113,
      "rewards/margins": 0.0034811256919056177,
      "rewards/rejected": 0.0030748844146728516,
      "step": 67
    },
    {
      "epoch": 5.24,
      "grad_norm": 5.202761173248291,
      "learning_rate": 5.727272727272727e-08,
      "logits/chosen": 0.6812541484832764,
      "logits/rejected": 1.5480716228485107,
      "logps/chosen": -31.536354064941406,
      "logps/rejected": -37.43800735473633,
      "loss": 0.6895,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.01283049676567316,
      "rewards/margins": 0.007402539253234863,
      "rewards/rejected": 0.005427956581115723,
      "step": 68
    },
    {
      "epoch": 5.32,
      "grad_norm": 6.209536552429199,
      "learning_rate": 5.636363636363636e-08,
      "logits/chosen": 0.8209503889083862,
      "logits/rejected": 1.4596847295761108,
      "logps/chosen": -38.55781936645508,
      "logps/rejected": -37.19700622558594,
      "loss": 0.6946,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.0017739057075232267,
      "rewards/margins": -0.002914119279012084,
      "rewards/rejected": 0.0046880245208740234,
      "step": 69
    },
    {
      "epoch": 5.4,
      "grad_norm": 6.795343399047852,
      "learning_rate": 5.5454545454545454e-08,
      "logits/chosen": 0.6196308135986328,
      "logits/rejected": 1.3533722162246704,
      "logps/chosen": -41.886802673339844,
      "logps/rejected": -33.88348388671875,
      "loss": 0.6906,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0006225345423445106,
      "rewards/margins": 0.005208754912018776,
      "rewards/rejected": -0.004586219787597656,
      "step": 70
    },
    {
      "epoch": 5.48,
      "grad_norm": 6.615207195281982,
      "learning_rate": 5.454545454545454e-08,
      "logits/chosen": 0.8009732365608215,
      "logits/rejected": 1.5081454515457153,
      "logps/chosen": -42.006919860839844,
      "logps/rejected": -42.10432434082031,
      "loss": 0.693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005789018236100674,
      "rewards/margins": 0.00042567297350615263,
      "rewards/rejected": 0.005363345146179199,
      "step": 71
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 6.016444206237793,
      "learning_rate": 5.3636363636363635e-08,
      "logits/chosen": 0.7056407332420349,
      "logits/rejected": 1.4619016647338867,
      "logps/chosen": -35.148651123046875,
      "logps/rejected": -41.605228424072266,
      "loss": 0.6935,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0048195840790867805,
      "rewards/margins": -0.0006314278580248356,
      "rewards/rejected": 0.0054510124027729034,
      "step": 72
    },
    {
      "epoch": 5.64,
      "grad_norm": 6.027312755584717,
      "learning_rate": 5.272727272727272e-08,
      "logits/chosen": 0.7897788286209106,
      "logits/rejected": 1.5146546363830566,
      "logps/chosen": -35.40239334106445,
      "logps/rejected": -40.41084289550781,
      "loss": 0.696,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0025566816329956055,
      "rewards/margins": -0.005693579092621803,
      "rewards/rejected": 0.003136897459626198,
      "step": 73
    },
    {
      "epoch": 5.72,
      "grad_norm": 7.089559078216553,
      "learning_rate": 5.1818181818181817e-08,
      "logits/chosen": 0.7025455236434937,
      "logits/rejected": 1.4599159955978394,
      "logps/chosen": -35.63046646118164,
      "logps/rejected": -41.35790252685547,
      "loss": 0.6919,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006413698196411133,
      "rewards/margins": 0.002603054977953434,
      "rewards/rejected": 0.0038106441497802734,
      "step": 74
    },
    {
      "epoch": 5.8,
      "grad_norm": 7.324119567871094,
      "learning_rate": 5.09090909090909e-08,
      "logits/chosen": 0.7783328294754028,
      "logits/rejected": 1.4678223133087158,
      "logps/chosen": -40.813812255859375,
      "logps/rejected": -48.13527297973633,
      "loss": 0.692,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006140517070889473,
      "rewards/margins": 0.0023665432818233967,
      "rewards/rejected": 0.003773975418880582,
      "step": 75
    },
    {
      "epoch": 5.88,
      "grad_norm": 5.865968227386475,
      "learning_rate": 5e-08,
      "logits/chosen": 1.0210703611373901,
      "logits/rejected": 1.3938343524932861,
      "logps/chosen": -39.768775939941406,
      "logps/rejected": -42.32395935058594,
      "loss": 0.6921,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0005162239540368319,
      "rewards/margins": 0.0021132943220436573,
      "rewards/rejected": -0.002629518508911133,
      "step": 76
    },
    {
      "epoch": 5.96,
      "grad_norm": 6.503735542297363,
      "learning_rate": 4.909090909090909e-08,
      "logits/chosen": 0.5540376901626587,
      "logits/rejected": 1.465511679649353,
      "logps/chosen": -37.714622497558594,
      "logps/rejected": -39.765724182128906,
      "loss": 0.688,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006660843268036842,
      "rewards/margins": 0.010295987129211426,
      "rewards/rejected": -0.0036351443268358707,
      "step": 77
    },
    {
      "epoch": 6.0,
      "grad_norm": 8.767267227172852,
      "learning_rate": 4.818181818181818e-08,
      "logits/chosen": 0.599356472492218,
      "logits/rejected": 1.293008804321289,
      "logps/chosen": -31.400842666625977,
      "logps/rejected": -47.55805206298828,
      "loss": 0.6936,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.013937901705503464,
      "rewards/margins": -0.0007450580596923828,
      "rewards/rejected": 0.014682959765195847,
      "step": 78
    },
    {
      "epoch": 6.0,
      "eval_logits/chosen": 1.0005598068237305,
      "eval_logits/rejected": 1.4252489805221558,
      "eval_logps/chosen": -38.2883186340332,
      "eval_logps/rejected": -42.18620300292969,
      "eval_loss": 0.6915146708488464,
      "eval_rewards/accuracies": 0.5099999904632568,
      "eval_rewards/chosen": 0.0013844360364601016,
      "eval_rewards/margins": 0.0033710801508277655,
      "eval_rewards/rejected": -0.001986644696444273,
      "eval_runtime": 2.7517,
      "eval_samples_per_second": 36.341,
      "eval_steps_per_second": 18.171,
      "step": 78
    },
    {
      "epoch": 6.08,
      "grad_norm": 6.362889289855957,
      "learning_rate": 4.727272727272727e-08,
      "logits/chosen": 0.7175834774971008,
      "logits/rejected": 1.4026257991790771,
      "logps/chosen": -36.60242462158203,
      "logps/rejected": -34.852699279785156,
      "loss": 0.6922,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0014280796749517322,
      "rewards/margins": 0.0019550323486328125,
      "rewards/rejected": -0.003383111674338579,
      "step": 79
    },
    {
      "epoch": 6.16,
      "grad_norm": 6.362491607666016,
      "learning_rate": 4.636363636363636e-08,
      "logits/chosen": 0.7980905771255493,
      "logits/rejected": 1.4676915407180786,
      "logps/chosen": -34.774879455566406,
      "logps/rejected": -39.246337890625,
      "loss": 0.6931,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00016808602958917618,
      "rewards/margins": 0.00024878978729248047,
      "rewards/rejected": -0.00041687488555908203,
      "step": 80
    },
    {
      "epoch": 6.24,
      "grad_norm": 5.819602012634277,
      "learning_rate": 4.545454545454545e-08,
      "logits/chosen": 0.8069314956665039,
      "logits/rejected": 1.5179567337036133,
      "logps/chosen": -36.35218811035156,
      "logps/rejected": -39.183658599853516,
      "loss": 0.6901,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007810711860656738,
      "rewards/margins": 0.006130838766694069,
      "rewards/rejected": 0.0016798735596239567,
      "step": 81
    },
    {
      "epoch": 6.32,
      "grad_norm": 7.519451141357422,
      "learning_rate": 4.454545454545454e-08,
      "logits/chosen": 0.8011914491653442,
      "logits/rejected": 1.5683929920196533,
      "logps/chosen": -46.959678649902344,
      "logps/rejected": -45.34275436401367,
      "loss": 0.6921,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005713844206184149,
      "rewards/margins": 0.0022701499983668327,
      "rewards/rejected": 0.0034436939749866724,
      "step": 82
    },
    {
      "epoch": 6.4,
      "grad_norm": 5.867407321929932,
      "learning_rate": 4.363636363636363e-08,
      "logits/chosen": 0.6494333744049072,
      "logits/rejected": 1.518433928489685,
      "logps/chosen": -33.53137969970703,
      "logps/rejected": -37.95178985595703,
      "loss": 0.6925,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0006935358978807926,
      "rewards/margins": 0.0012879371643066406,
      "rewards/rejected": -0.0005944013246335089,
      "step": 83
    },
    {
      "epoch": 6.48,
      "grad_norm": 6.579042434692383,
      "learning_rate": 4.272727272727272e-08,
      "logits/chosen": 0.6944402456283569,
      "logits/rejected": 1.4159448146820068,
      "logps/chosen": -41.157135009765625,
      "logps/rejected": -34.68527603149414,
      "loss": 0.6887,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0037959334440529346,
      "rewards/margins": 0.009097527712583542,
      "rewards/rejected": -0.0053015947341918945,
      "step": 84
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 6.811002731323242,
      "learning_rate": 4.181818181818181e-08,
      "logits/chosen": 0.6958229541778564,
      "logits/rejected": 1.5188318490982056,
      "logps/chosen": -39.46571350097656,
      "logps/rejected": -44.12250518798828,
      "loss": 0.6836,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.020759891718626022,
      "rewards/margins": 0.019249845296144485,
      "rewards/rejected": 0.001510047703050077,
      "step": 85
    },
    {
      "epoch": 6.64,
      "grad_norm": 7.007140159606934,
      "learning_rate": 4.090909090909091e-08,
      "logits/chosen": 0.8123064041137695,
      "logits/rejected": 1.4224839210510254,
      "logps/chosen": -41.37483215332031,
      "logps/rejected": -48.74085998535156,
      "loss": 0.6951,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.010340666398406029,
      "rewards/margins": -0.003664993681013584,
      "rewards/rejected": 0.014005661010742188,
      "step": 86
    },
    {
      "epoch": 6.72,
      "grad_norm": 6.364195823669434,
      "learning_rate": 4e-08,
      "logits/chosen": 0.49562641978263855,
      "logits/rejected": 1.427473783493042,
      "logps/chosen": -34.96891784667969,
      "logps/rejected": -41.487037658691406,
      "loss": 0.6954,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0077915191650390625,
      "rewards/margins": -0.004415678791701794,
      "rewards/rejected": 0.01220719888806343,
      "step": 87
    },
    {
      "epoch": 6.8,
      "grad_norm": 6.72400426864624,
      "learning_rate": 3.909090909090909e-08,
      "logits/chosen": 0.6480047702789307,
      "logits/rejected": 1.2555254697799683,
      "logps/chosen": -36.79465866088867,
      "logps/rejected": -49.40253448486328,
      "loss": 0.6919,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009013652801513672,
      "rewards/margins": 0.0026005979161709547,
      "rewards/rejected": 0.0064130546525120735,
      "step": 88
    },
    {
      "epoch": 6.88,
      "grad_norm": 6.292778968811035,
      "learning_rate": 3.818181818181818e-08,
      "logits/chosen": 0.914851188659668,
      "logits/rejected": 1.5583299398422241,
      "logps/chosen": -38.9266471862793,
      "logps/rejected": -39.85399627685547,
      "loss": 0.6879,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007964516058564186,
      "rewards/margins": 0.010602498427033424,
      "rewards/rejected": -0.0026379828341305256,
      "step": 89
    },
    {
      "epoch": 6.96,
      "grad_norm": 5.599131107330322,
      "learning_rate": 3.727272727272727e-08,
      "logits/chosen": 0.7005835175514221,
      "logits/rejected": 1.3185076713562012,
      "logps/chosen": -32.057861328125,
      "logps/rejected": -36.486961364746094,
      "loss": 0.6926,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007980823516845703,
      "rewards/margins": 0.0011405707336962223,
      "rewards/rejected": 0.006840253248810768,
      "step": 90
    },
    {
      "epoch": 7.0,
      "grad_norm": 8.562969207763672,
      "learning_rate": 3.636363636363636e-08,
      "logits/chosen": 0.5230180025100708,
      "logits/rejected": 1.6207371950149536,
      "logps/chosen": -37.43425750732422,
      "logps/rejected": -43.96131896972656,
      "loss": 0.688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011352396570146084,
      "rewards/margins": 0.010436821728944778,
      "rewards/rejected": 0.0009155753068625927,
      "step": 91
    },
    {
      "epoch": 7.0,
      "eval_logits/chosen": 1.000776767730713,
      "eval_logits/rejected": 1.424422025680542,
      "eval_logps/chosen": -38.25035095214844,
      "eval_logps/rejected": -42.1719970703125,
      "eval_loss": 0.6903262138366699,
      "eval_rewards/accuracies": 0.6200000047683716,
      "eval_rewards/chosen": 0.005181292071938515,
      "eval_rewards/margins": 0.005747808609157801,
      "eval_rewards/rejected": -0.0005665169446729124,
      "eval_runtime": 2.7526,
      "eval_samples_per_second": 36.329,
      "eval_steps_per_second": 18.164,
      "step": 91
    }
  ],
  "logging_steps": 1,
  "max_steps": 130,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
