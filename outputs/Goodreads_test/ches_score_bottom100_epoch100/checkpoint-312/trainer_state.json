{
  "best_global_step": 312,
  "best_metric": 0.6783867478370667,
  "best_model_checkpoint": "/scratch/user/chuanhsin0110/LLMRec-Labs/unintentional-unalignment/outputs/Goodreads_test/ches_score_bottom100_epoch100/checkpoint-312",
  "epoch": 24.0,
  "eval_steps": 500,
  "global_step": 312,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 6.709115982055664,
      "learning_rate": 0.0,
      "logits/chosen": 1.0990867614746094,
      "logits/rejected": 1.337613821029663,
      "logps/chosen": -37.61271286010742,
      "logps/rejected": -34.199867248535156,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.291076183319092,
      "learning_rate": 5e-09,
      "logits/chosen": 0.7988958954811096,
      "logits/rejected": 1.1719108819961548,
      "logps/chosen": -34.36517333984375,
      "logps/rejected": -30.754512786865234,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.2750749588012695,
      "learning_rate": 1e-08,
      "logits/chosen": 0.7899613380432129,
      "logits/rejected": 1.2086418867111206,
      "logps/chosen": -39.376792907714844,
      "logps/rejected": -38.072715759277344,
      "loss": 0.6898,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006915784440934658,
      "rewards/margins": 0.006813573185354471,
      "rewards/rejected": 0.00010221032425761223,
      "step": 3
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.885657787322998,
      "learning_rate": 1.5e-08,
      "logits/chosen": 0.990527868270874,
      "logits/rejected": 1.3402847051620483,
      "logps/chosen": -43.55611038208008,
      "logps/rejected": -32.0267333984375,
      "loss": 0.6964,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.0066412691958248615,
      "rewards/margins": -0.006498861592262983,
      "rewards/rejected": -0.00014240737073123455,
      "step": 4
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.27970552444458,
      "learning_rate": 2e-08,
      "logits/chosen": 0.8935129642486572,
      "logits/rejected": 1.2093185186386108,
      "logps/chosen": -38.1536979675293,
      "logps/rejected": -31.8596134185791,
      "loss": 0.6923,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0025615692138671875,
      "rewards/margins": 0.001835989998653531,
      "rewards/rejected": -0.004397558979690075,
      "step": 5
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.800257682800293,
      "learning_rate": 2.5e-08,
      "logits/chosen": 0.7525733709335327,
      "logits/rejected": 1.3676550388336182,
      "logps/chosen": -36.158782958984375,
      "logps/rejected": -32.15117645263672,
      "loss": 0.6951,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.004573296755552292,
      "rewards/margins": -0.00379202445037663,
      "rewards/rejected": 0.008365321904420853,
      "step": 6
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.532329082489014,
      "learning_rate": 3e-08,
      "logits/chosen": 1.2524421215057373,
      "logits/rejected": 1.5272715091705322,
      "logps/chosen": -53.62794876098633,
      "logps/rejected": -38.75059509277344,
      "loss": 0.6967,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.003302144818007946,
      "rewards/margins": -0.007095193490386009,
      "rewards/rejected": 0.0037930491380393505,
      "step": 7
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.331345081329346,
      "learning_rate": 3.4999999999999996e-08,
      "logits/chosen": 0.9050082564353943,
      "logits/rejected": 1.1916636228561401,
      "logps/chosen": -43.11958694458008,
      "logps/rejected": -33.14360427856445,
      "loss": 0.6948,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003491187235340476,
      "rewards/margins": -0.0030970810912549496,
      "rewards/rejected": -0.00039410614408552647,
      "step": 8
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.925868988037109,
      "learning_rate": 4e-08,
      "logits/chosen": 0.9924639463424683,
      "logits/rejected": 1.309018611907959,
      "logps/chosen": -37.106204986572266,
      "logps/rejected": -36.129112243652344,
      "loss": 0.6927,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.001151824020780623,
      "rewards/margins": 0.0010099411010742188,
      "rewards/rejected": -0.00216176500543952,
      "step": 9
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.700453281402588,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.0286602973937988,
      "logits/rejected": 1.4237511157989502,
      "logps/chosen": -48.987586975097656,
      "logps/rejected": -36.54966735839844,
      "loss": 0.6885,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0033156871795654297,
      "rewards/margins": 0.009417987428605556,
      "rewards/rejected": -0.006102299317717552,
      "step": 10
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.527313709259033,
      "learning_rate": 5e-08,
      "logits/chosen": 1.372244954109192,
      "logits/rejected": 1.5031764507293701,
      "logps/chosen": -55.394081115722656,
      "logps/rejected": -40.55934143066406,
      "loss": 0.6785,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.019340157508850098,
      "rewards/margins": 0.02959292009472847,
      "rewards/rejected": -0.010252762585878372,
      "step": 11
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.56732177734375,
      "learning_rate": 5.5e-08,
      "logits/chosen": 1.16019606590271,
      "logits/rejected": 1.5425915718078613,
      "logps/chosen": -55.81883239746094,
      "logps/rejected": -35.73973846435547,
      "loss": 0.6925,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00315954745747149,
      "rewards/margins": 0.0012929437216371298,
      "rewards/rejected": 0.0018666030373424292,
      "step": 12
    },
    {
      "epoch": 1.0,
      "grad_norm": 10.591206550598145,
      "learning_rate": 6e-08,
      "logits/chosen": 0.8500713109970093,
      "logits/rejected": 0.8993687033653259,
      "logps/chosen": -45.58700180053711,
      "logps/rejected": -31.939485549926758,
      "loss": 0.6906,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005274343304336071,
      "rewards/margins": 0.005182456690818071,
      "rewards/rejected": 9.188672993332148e-05,
      "step": 13
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 0.9971684813499451,
      "eval_logits/rejected": 1.1690491437911987,
      "eval_logps/chosen": -39.745582580566406,
      "eval_logps/rejected": -37.24195861816406,
      "eval_loss": 0.6917719841003418,
      "eval_rewards/accuracies": 0.5899999737739563,
      "eval_rewards/chosen": -0.002001384738832712,
      "eval_rewards/margins": 0.002855052938684821,
      "eval_rewards/rejected": -0.004856437910348177,
      "eval_runtime": 3.2046,
      "eval_samples_per_second": 31.205,
      "eval_steps_per_second": 15.603,
      "step": 13
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.843635082244873,
      "learning_rate": 6.5e-08,
      "logits/chosen": 0.7933278679847717,
      "logits/rejected": 0.9922299385070801,
      "logps/chosen": -41.304019927978516,
      "logps/rejected": -31.940540313720703,
      "loss": 0.6999,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.021083736792206764,
      "rewards/margins": -0.013391494750976562,
      "rewards/rejected": -0.007692242041230202,
      "step": 14
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.759454727172852,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.040766954421997,
      "logits/rejected": 1.3057368993759155,
      "logps/chosen": -46.5846061706543,
      "logps/rejected": -40.652000427246094,
      "loss": 0.691,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002939081285148859,
      "rewards/margins": 0.00431447010487318,
      "rewards/rejected": -0.0013753894018009305,
      "step": 15
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.107090950012207,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.3255705833435059,
      "logits/rejected": 1.4985101222991943,
      "logps/chosen": -43.92372131347656,
      "logps/rejected": -29.341686248779297,
      "loss": 0.692,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.002388668479397893,
      "rewards/margins": 0.0023384569212794304,
      "rewards/rejected": -0.00472712516784668,
      "step": 16
    },
    {
      "epoch": 1.32,
      "grad_norm": 7.438884735107422,
      "learning_rate": 8e-08,
      "logits/chosen": 0.9074220061302185,
      "logits/rejected": 1.1084386110305786,
      "logps/chosen": -36.12068557739258,
      "logps/rejected": -34.70988464355469,
      "loss": 0.6918,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004902529530227184,
      "rewards/margins": 0.0029528618324548006,
      "rewards/rejected": 0.0019496678141877055,
      "step": 17
    },
    {
      "epoch": 1.4,
      "grad_norm": 7.085333347320557,
      "learning_rate": 8.5e-08,
      "logits/chosen": 1.0299785137176514,
      "logits/rejected": 1.152707576751709,
      "logps/chosen": -46.843597412109375,
      "logps/rejected": -32.250736236572266,
      "loss": 0.6848,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008601046167314053,
      "rewards/margins": 0.016770601272583008,
      "rewards/rejected": -0.00816955603659153,
      "step": 18
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.090489864349365,
      "learning_rate": 9e-08,
      "logits/chosen": 0.758023738861084,
      "logits/rejected": 1.2477123737335205,
      "logps/chosen": -55.21455383300781,
      "logps/rejected": -35.828712463378906,
      "loss": 0.6883,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006011080928146839,
      "rewards/margins": 0.009845519438385963,
      "rewards/rejected": -0.0038344385102391243,
      "step": 19
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.773453235626221,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 0.8326095938682556,
      "logits/rejected": 1.385363221168518,
      "logps/chosen": -38.25042724609375,
      "logps/rejected": -35.361183166503906,
      "loss": 0.7025,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.01598525047302246,
      "rewards/margins": -0.018649768084287643,
      "rewards/rejected": 0.00266451807692647,
      "step": 20
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 7.512157440185547,
      "learning_rate": 1e-07,
      "logits/chosen": 1.1055508852005005,
      "logits/rejected": 1.3456625938415527,
      "logps/chosen": -50.238990783691406,
      "logps/rejected": -41.019142150878906,
      "loss": 0.6892,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004627871792763472,
      "rewards/margins": 0.007947325706481934,
      "rewards/rejected": -0.0033194541465491056,
      "step": 21
    },
    {
      "epoch": 1.72,
      "grad_norm": 6.130929470062256,
      "learning_rate": 9.9921875e-08,
      "logits/chosen": 1.0102534294128418,
      "logits/rejected": 1.4522043466567993,
      "logps/chosen": -36.905364990234375,
      "logps/rejected": -36.63972854614258,
      "loss": 0.6955,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0003993511199951172,
      "rewards/margins": -0.004737424664199352,
      "rewards/rejected": 0.004338073544204235,
      "step": 22
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.900429725646973,
      "learning_rate": 9.984375e-08,
      "logits/chosen": 1.0422172546386719,
      "logits/rejected": 1.5464603900909424,
      "logps/chosen": -39.73739242553711,
      "logps/rejected": -33.919883728027344,
      "loss": 0.6954,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0021353240590542555,
      "rewards/margins": -0.004433727823197842,
      "rewards/rejected": 0.002298403065651655,
      "step": 23
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.462644100189209,
      "learning_rate": 9.9765625e-08,
      "logits/chosen": 1.1288655996322632,
      "logits/rejected": 1.3199573755264282,
      "logps/chosen": -45.42910385131836,
      "logps/rejected": -33.78968811035156,
      "loss": 0.6916,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0016854762798175216,
      "rewards/margins": 0.0032959464006125927,
      "rewards/rejected": -0.0016104704700410366,
      "step": 24
    },
    {
      "epoch": 1.96,
      "grad_norm": 6.373569488525391,
      "learning_rate": 9.968749999999999e-08,
      "logits/chosen": 1.007607102394104,
      "logits/rejected": 1.3802082538604736,
      "logps/chosen": -36.007835388183594,
      "logps/rejected": -31.06424903869629,
      "loss": 0.6886,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01217341423034668,
      "rewards/margins": 0.009101415053009987,
      "rewards/rejected": 0.00307199964299798,
      "step": 25
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.963044166564941,
      "learning_rate": 9.9609375e-08,
      "logits/chosen": 1.1997168064117432,
      "logits/rejected": 1.538003921508789,
      "logps/chosen": -59.44445037841797,
      "logps/rejected": -38.70488739013672,
      "loss": 0.698,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0058276173658668995,
      "rewards/margins": -0.009580468758940697,
      "rewards/rejected": 0.0037528513930737972,
      "step": 26
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 0.9961938261985779,
      "eval_logits/rejected": 1.1693743467330933,
      "eval_logps/chosen": -39.719757080078125,
      "eval_logps/rejected": -37.201602935791016,
      "eval_loss": 0.6925113797187805,
      "eval_rewards/accuracies": 0.5400000214576721,
      "eval_rewards/chosen": 0.0005811917944811285,
      "eval_rewards/margins": 0.0014018155634403229,
      "eval_rewards/rejected": -0.0008206234779208899,
      "eval_runtime": 3.2009,
      "eval_samples_per_second": 31.241,
      "eval_steps_per_second": 15.621,
      "step": 26
    },
    {
      "epoch": 2.08,
      "grad_norm": 8.145777702331543,
      "learning_rate": 9.953125e-08,
      "logits/chosen": 0.8078108429908752,
      "logits/rejected": 0.8987727165222168,
      "logps/chosen": -33.70423889160156,
      "logps/rejected": -31.012916564941406,
      "loss": 0.6883,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0013403896009549499,
      "rewards/margins": 0.009682584553956985,
      "rewards/rejected": -0.008342195302248001,
      "step": 27
    },
    {
      "epoch": 2.16,
      "grad_norm": 7.0337324142456055,
      "learning_rate": 9.945312499999999e-08,
      "logits/chosen": 1.247746467590332,
      "logits/rejected": 1.4598238468170166,
      "logps/chosen": -52.1287727355957,
      "logps/rejected": -41.43938446044922,
      "loss": 0.6946,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.002217555418610573,
      "rewards/margins": -0.002865934744477272,
      "rewards/rejected": 0.0006483795586973429,
      "step": 28
    },
    {
      "epoch": 2.24,
      "grad_norm": 5.35697603225708,
      "learning_rate": 9.9375e-08,
      "logits/chosen": 1.0286729335784912,
      "logits/rejected": 1.3654327392578125,
      "logps/chosen": -31.430530548095703,
      "logps/rejected": -31.127395629882812,
      "loss": 0.6929,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002547407289966941,
      "rewards/margins": 0.0005848405417054892,
      "rewards/rejected": 0.001962566515430808,
      "step": 29
    },
    {
      "epoch": 2.32,
      "grad_norm": 7.1746745109558105,
      "learning_rate": 9.929687499999999e-08,
      "logits/chosen": 0.6736584305763245,
      "logits/rejected": 1.4322413206100464,
      "logps/chosen": -43.96207809448242,
      "logps/rejected": -32.33006286621094,
      "loss": 0.6935,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.007084202952682972,
      "rewards/margins": -0.0005486251320689917,
      "rewards/rejected": -0.006535578053444624,
      "step": 30
    },
    {
      "epoch": 2.4,
      "grad_norm": 7.361041069030762,
      "learning_rate": 9.921874999999999e-08,
      "logits/chosen": 1.1389113664627075,
      "logits/rejected": 1.3727495670318604,
      "logps/chosen": -51.55073547363281,
      "logps/rejected": -39.40497589111328,
      "loss": 0.697,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.000928163412027061,
      "rewards/margins": -0.007503677159547806,
      "rewards/rejected": 0.006575513165444136,
      "step": 31
    },
    {
      "epoch": 2.48,
      "grad_norm": 6.849386692047119,
      "learning_rate": 9.9140625e-08,
      "logits/chosen": 1.0496010780334473,
      "logits/rejected": 1.2429585456848145,
      "logps/chosen": -48.52138900756836,
      "logps/rejected": -30.495819091796875,
      "loss": 0.6884,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01325688324868679,
      "rewards/margins": 0.009598136879503727,
      "rewards/rejected": 0.003658747300505638,
      "step": 32
    },
    {
      "epoch": 2.56,
      "grad_norm": 7.952323913574219,
      "learning_rate": 9.906249999999999e-08,
      "logits/chosen": 1.0091137886047363,
      "logits/rejected": 1.2340779304504395,
      "logps/chosen": -46.782039642333984,
      "logps/rejected": -40.3558349609375,
      "loss": 0.6909,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0031022068578749895,
      "rewards/margins": 0.004672574810683727,
      "rewards/rejected": -0.0015703679528087378,
      "step": 33
    },
    {
      "epoch": 2.64,
      "grad_norm": 7.386361122131348,
      "learning_rate": 9.898437499999999e-08,
      "logits/chosen": 1.1632393598556519,
      "logits/rejected": 1.2270817756652832,
      "logps/chosen": -56.71692657470703,
      "logps/rejected": -31.426231384277344,
      "loss": 0.6921,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.01699068583548069,
      "rewards/margins": 0.002238345565274358,
      "rewards/rejected": 0.014752340503036976,
      "step": 34
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 5.931171417236328,
      "learning_rate": 9.890624999999999e-08,
      "logits/chosen": 1.0813236236572266,
      "logits/rejected": 1.3926606178283691,
      "logps/chosen": -38.31128692626953,
      "logps/rejected": -30.434921264648438,
      "loss": 0.6902,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.000721836113370955,
      "rewards/margins": 0.006002307403832674,
      "rewards/rejected": -0.006724143400788307,
      "step": 35
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.429315567016602,
      "learning_rate": 9.8828125e-08,
      "logits/chosen": 1.1389734745025635,
      "logits/rejected": 1.323803186416626,
      "logps/chosen": -45.587242126464844,
      "logps/rejected": -36.36223220825195,
      "loss": 0.692,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0002171992091462016,
      "rewards/margins": 0.0023223874159157276,
      "rewards/rejected": -0.002105188323184848,
      "step": 36
    },
    {
      "epoch": 2.88,
      "grad_norm": 6.325748920440674,
      "learning_rate": 9.875e-08,
      "logits/chosen": 0.8857517242431641,
      "logits/rejected": 1.2290364503860474,
      "logps/chosen": -37.39078903198242,
      "logps/rejected": -34.99634552001953,
      "loss": 0.6981,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0049034361727535725,
      "rewards/margins": -0.00983500573784113,
      "rewards/rejected": 0.014738441444933414,
      "step": 37
    },
    {
      "epoch": 2.96,
      "grad_norm": 6.780261039733887,
      "learning_rate": 9.8671875e-08,
      "logits/chosen": 0.7882591485977173,
      "logits/rejected": 1.3679132461547852,
      "logps/chosen": -41.816314697265625,
      "logps/rejected": -37.0064811706543,
      "loss": 0.6915,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.000853752950206399,
      "rewards/margins": 0.003513431642204523,
      "rewards/rejected": -0.002659677993506193,
      "step": 38
    },
    {
      "epoch": 3.0,
      "grad_norm": 9.38017749786377,
      "learning_rate": 9.859375e-08,
      "logits/chosen": 1.0599303245544434,
      "logits/rejected": 1.5150164365768433,
      "logps/chosen": -36.048789978027344,
      "logps/rejected": -38.54088592529297,
      "loss": 0.6892,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00011348724365234375,
      "rewards/margins": 0.00800318643450737,
      "rewards/rejected": -0.008116674609482288,
      "step": 39
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": 0.991814374923706,
      "eval_logits/rejected": 1.162576675415039,
      "eval_logps/chosen": -39.65986251831055,
      "eval_logps/rejected": -37.17219161987305,
      "eval_loss": 0.6909801363945007,
      "eval_rewards/accuracies": 0.5699999928474426,
      "eval_rewards/chosen": 0.006571040954440832,
      "eval_rewards/margins": 0.004450269974768162,
      "eval_rewards/rejected": 0.0021207714453339577,
      "eval_runtime": 3.2016,
      "eval_samples_per_second": 31.234,
      "eval_steps_per_second": 15.617,
      "step": 39
    },
    {
      "epoch": 3.08,
      "grad_norm": 6.375286102294922,
      "learning_rate": 9.8515625e-08,
      "logits/chosen": 0.9424063563346863,
      "logits/rejected": 1.1581690311431885,
      "logps/chosen": -40.40752410888672,
      "logps/rejected": -38.232810974121094,
      "loss": 0.6946,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0019096609903499484,
      "rewards/margins": -0.002949452493339777,
      "rewards/rejected": 0.001039791270159185,
      "step": 40
    },
    {
      "epoch": 3.16,
      "grad_norm": 7.351808071136475,
      "learning_rate": 9.84375e-08,
      "logits/chosen": 1.0273034572601318,
      "logits/rejected": 1.4691284894943237,
      "logps/chosen": -40.24363708496094,
      "logps/rejected": -35.00669860839844,
      "loss": 0.6917,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0003724335692822933,
      "rewards/margins": 0.002971053123474121,
      "rewards/rejected": -0.0025986195541918278,
      "step": 41
    },
    {
      "epoch": 3.24,
      "grad_norm": 8.026728630065918,
      "learning_rate": 9.8359375e-08,
      "logits/chosen": 0.9779242277145386,
      "logits/rejected": 1.2816119194030762,
      "logps/chosen": -55.72669219970703,
      "logps/rejected": -38.42906951904297,
      "loss": 0.6958,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 2.079014666378498e-05,
      "rewards/margins": -0.00528333242982626,
      "rewards/rejected": 0.005304121877998114,
      "step": 42
    },
    {
      "epoch": 3.32,
      "grad_norm": 6.381297588348389,
      "learning_rate": 9.828125e-08,
      "logits/chosen": 1.0061981678009033,
      "logits/rejected": 1.3248003721237183,
      "logps/chosen": -36.267799377441406,
      "logps/rejected": -35.84465789794922,
      "loss": 0.6883,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.011035013943910599,
      "rewards/margins": 0.009961534291505814,
      "rewards/rejected": 0.0010734791867434978,
      "step": 43
    },
    {
      "epoch": 3.4,
      "grad_norm": 9.102852821350098,
      "learning_rate": 9.8203125e-08,
      "logits/chosen": 0.749973714351654,
      "logits/rejected": 1.1830039024353027,
      "logps/chosen": -48.50389099121094,
      "logps/rejected": -33.86820983886719,
      "loss": 0.6892,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0006037000566720963,
      "rewards/margins": 0.008034421131014824,
      "rewards/rejected": -0.008638119325041771,
      "step": 44
    },
    {
      "epoch": 3.48,
      "grad_norm": 6.623807430267334,
      "learning_rate": 9.812499999999999e-08,
      "logits/chosen": 1.0598260164260864,
      "logits/rejected": 1.2571618556976318,
      "logps/chosen": -41.14792251586914,
      "logps/rejected": -33.12139129638672,
      "loss": 0.6936,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0017055273056030273,
      "rewards/margins": -0.0007676362874917686,
      "rewards/rejected": -0.0009378913091495633,
      "step": 45
    },
    {
      "epoch": 3.56,
      "grad_norm": 6.925830364227295,
      "learning_rate": 9.8046875e-08,
      "logits/chosen": 0.9211094379425049,
      "logits/rejected": 1.3912914991378784,
      "logps/chosen": -41.63481903076172,
      "logps/rejected": -32.74662399291992,
      "loss": 0.6877,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.011006522923707962,
      "rewards/margins": 0.01111524272710085,
      "rewards/rejected": -0.00010871898848563433,
      "step": 46
    },
    {
      "epoch": 3.64,
      "grad_norm": 7.6037750244140625,
      "learning_rate": 9.796875e-08,
      "logits/chosen": 1.0499647855758667,
      "logits/rejected": 1.3333550691604614,
      "logps/chosen": -49.340118408203125,
      "logps/rejected": -33.42619705200195,
      "loss": 0.6942,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.002980876015499234,
      "rewards/margins": -0.00199487223289907,
      "rewards/rejected": 0.004975747782737017,
      "step": 47
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 6.0397725105285645,
      "learning_rate": 9.789062499999999e-08,
      "logits/chosen": 0.9033225774765015,
      "logits/rejected": 1.3040785789489746,
      "logps/chosen": -36.90910339355469,
      "logps/rejected": -29.9155216217041,
      "loss": 0.6963,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.004628967493772507,
      "rewards/margins": -0.006201315205544233,
      "rewards/rejected": 0.001572346780449152,
      "step": 48
    },
    {
      "epoch": 3.8,
      "grad_norm": 6.555365562438965,
      "learning_rate": 9.78125e-08,
      "logits/chosen": 1.1502156257629395,
      "logits/rejected": 1.4144349098205566,
      "logps/chosen": -45.977779388427734,
      "logps/rejected": -31.883209228515625,
      "loss": 0.692,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0017212394159287214,
      "rewards/margins": 0.002387428190559149,
      "rewards/rejected": -0.0006661893567070365,
      "step": 49
    },
    {
      "epoch": 3.88,
      "grad_norm": 6.546139717102051,
      "learning_rate": 9.773437499999999e-08,
      "logits/chosen": 1.0409777164459229,
      "logits/rejected": 1.3337856531143188,
      "logps/chosen": -45.642398834228516,
      "logps/rejected": -36.4705924987793,
      "loss": 0.6919,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0004382610786706209,
      "rewards/margins": 0.0024637936148792505,
      "rewards/rejected": -0.0029020546935498714,
      "step": 50
    },
    {
      "epoch": 3.96,
      "grad_norm": 6.530989646911621,
      "learning_rate": 9.765624999999999e-08,
      "logits/chosen": 1.271930456161499,
      "logits/rejected": 1.3205535411834717,
      "logps/chosen": -44.273292541503906,
      "logps/rejected": -34.83209991455078,
      "loss": 0.6911,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.003924012184143066,
      "rewards/margins": 0.004166960716247559,
      "rewards/rejected": -0.00024294886679854244,
      "step": 51
    },
    {
      "epoch": 4.0,
      "grad_norm": 11.053746223449707,
      "learning_rate": 9.7578125e-08,
      "logits/chosen": 0.8378796577453613,
      "logits/rejected": 1.5609318017959595,
      "logps/chosen": -39.65733337402344,
      "logps/rejected": -43.84376525878906,
      "loss": 0.6909,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.013460064306855202,
      "rewards/margins": 0.004897307138890028,
      "rewards/rejected": 0.008562755770981312,
      "step": 52
    },
    {
      "epoch": 4.0,
      "eval_logits/chosen": 0.9946545362472534,
      "eval_logits/rejected": 1.1656792163848877,
      "eval_logps/chosen": -39.72013473510742,
      "eval_logps/rejected": -37.216400146484375,
      "eval_loss": 0.6917729377746582,
      "eval_rewards/accuracies": 0.5,
      "eval_rewards/chosen": 0.0005438420921564102,
      "eval_rewards/margins": 0.002844396745786071,
      "eval_rewards/rejected": -0.0023005541879683733,
      "eval_runtime": 3.2089,
      "eval_samples_per_second": 31.163,
      "eval_steps_per_second": 15.582,
      "step": 52
    },
    {
      "epoch": 4.08,
      "grad_norm": 7.601210117340088,
      "learning_rate": 9.749999999999999e-08,
      "logits/chosen": 1.0017679929733276,
      "logits/rejected": 1.2872943878173828,
      "logps/chosen": -36.16529846191406,
      "logps/rejected": -35.95166015625,
      "loss": 0.6861,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005355120170861483,
      "rewards/margins": 0.014207720756530762,
      "rewards/rejected": -0.008852601051330566,
      "step": 53
    },
    {
      "epoch": 4.16,
      "grad_norm": 6.36844539642334,
      "learning_rate": 9.7421875e-08,
      "logits/chosen": 1.0768674612045288,
      "logits/rejected": 1.3638441562652588,
      "logps/chosen": -43.97085952758789,
      "logps/rejected": -37.06367874145508,
      "loss": 0.6944,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003985691349953413,
      "rewards/margins": -0.002509522717446089,
      "rewards/rejected": -0.0014761686325073242,
      "step": 54
    },
    {
      "epoch": 4.24,
      "grad_norm": 7.199442386627197,
      "learning_rate": 9.734375e-08,
      "logits/chosen": 0.8759633898735046,
      "logits/rejected": 1.2077641487121582,
      "logps/chosen": -44.51886749267578,
      "logps/rejected": -39.569915771484375,
      "loss": 0.6878,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.012899734079837799,
      "rewards/margins": 0.011024021543562412,
      "rewards/rejected": 0.0018757106736302376,
      "step": 55
    },
    {
      "epoch": 4.32,
      "grad_norm": 6.370686054229736,
      "learning_rate": 9.7265625e-08,
      "logits/chosen": 1.2325698137283325,
      "logits/rejected": 1.5851831436157227,
      "logps/chosen": -52.89772033691406,
      "logps/rejected": -39.637969970703125,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.012247372418642044,
      "rewards/margins": 0.0064165592193603516,
      "rewards/rejected": 0.005830812733620405,
      "step": 56
    },
    {
      "epoch": 4.4,
      "grad_norm": 7.1458821296691895,
      "learning_rate": 9.71875e-08,
      "logits/chosen": 1.2292001247406006,
      "logits/rejected": 1.3726882934570312,
      "logps/chosen": -47.252559661865234,
      "logps/rejected": -33.446468353271484,
      "loss": 0.6916,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.007883048616349697,
      "rewards/margins": 0.0033319955691695213,
      "rewards/rejected": 0.004551053047180176,
      "step": 57
    },
    {
      "epoch": 4.48,
      "grad_norm": 7.069450855255127,
      "learning_rate": 9.7109375e-08,
      "logits/chosen": 1.0249919891357422,
      "logits/rejected": 1.6180751323699951,
      "logps/chosen": -45.21247100830078,
      "logps/rejected": -31.523841857910156,
      "loss": 0.696,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005477333441376686,
      "rewards/margins": -0.005686474032700062,
      "rewards/rejected": 0.00020914076594635844,
      "step": 58
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 6.197713851928711,
      "learning_rate": 9.703125e-08,
      "logits/chosen": 1.0230224132537842,
      "logits/rejected": 1.209626317024231,
      "logps/chosen": -43.93439483642578,
      "logps/rejected": -29.883209228515625,
      "loss": 0.6915,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.010990237817168236,
      "rewards/margins": 0.0033889056649059057,
      "rewards/rejected": 0.007601332850754261,
      "step": 59
    },
    {
      "epoch": 4.64,
      "grad_norm": 6.697905540466309,
      "learning_rate": 9.695312499999998e-08,
      "logits/chosen": 1.1802518367767334,
      "logits/rejected": 1.110393762588501,
      "logps/chosen": -40.75708770751953,
      "logps/rejected": -33.94086456298828,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.002848697127774358,
      "rewards/margins": -1.544947735965252e-05,
      "rewards/rejected": 0.0028641459066420794,
      "step": 60
    },
    {
      "epoch": 4.72,
      "grad_norm": 8.612298965454102,
      "learning_rate": 9.6875e-08,
      "logits/chosen": 0.8668298721313477,
      "logits/rejected": 1.0116462707519531,
      "logps/chosen": -43.47385787963867,
      "logps/rejected": -31.989397048950195,
      "loss": 0.6894,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0001852985005825758,
      "rewards/margins": 0.007686829660087824,
      "rewards/rejected": -0.00787212885916233,
      "step": 61
    },
    {
      "epoch": 4.8,
      "grad_norm": 7.610164165496826,
      "learning_rate": 9.6796875e-08,
      "logits/chosen": 0.9788137674331665,
      "logits/rejected": 1.2672317028045654,
      "logps/chosen": -39.691349029541016,
      "logps/rejected": -36.59880065917969,
      "loss": 0.6917,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.005144000053405762,
      "rewards/margins": 0.002940726699307561,
      "rewards/rejected": 0.002203273819759488,
      "step": 62
    },
    {
      "epoch": 4.88,
      "grad_norm": 6.403478622436523,
      "learning_rate": 9.671874999999999e-08,
      "logits/chosen": 0.8071137070655823,
      "logits/rejected": 1.2969965934753418,
      "logps/chosen": -38.95131301879883,
      "logps/rejected": -31.290191650390625,
      "loss": 0.694,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.006616377737373114,
      "rewards/margins": -0.001685833907686174,
      "rewards/rejected": 0.00830221176147461,
      "step": 63
    },
    {
      "epoch": 4.96,
      "grad_norm": 7.014068603515625,
      "learning_rate": 9.6640625e-08,
      "logits/chosen": 1.0223138332366943,
      "logits/rejected": 1.4510856866836548,
      "logps/chosen": -51.00844192504883,
      "logps/rejected": -37.97916793823242,
      "loss": 0.6851,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013115406036376953,
      "rewards/margins": 0.01631185971200466,
      "rewards/rejected": -0.0031964541412889957,
      "step": 64
    },
    {
      "epoch": 5.0,
      "grad_norm": 10.539191246032715,
      "learning_rate": 9.656249999999999e-08,
      "logits/chosen": 0.48123252391815186,
      "logits/rejected": 0.9614670276641846,
      "logps/chosen": -35.284725189208984,
      "logps/rejected": -33.36429214477539,
      "loss": 0.6937,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004861926659941673,
      "rewards/margins": -0.0010164740961045027,
      "rewards/rejected": 0.00587840098887682,
      "step": 65
    },
    {
      "epoch": 5.0,
      "eval_logits/chosen": 0.9916885495185852,
      "eval_logits/rejected": 1.164110779762268,
      "eval_logps/chosen": -39.65080642700195,
      "eval_logps/rejected": -37.14141082763672,
      "eval_loss": 0.6920716762542725,
      "eval_rewards/accuracies": 0.5199999809265137,
      "eval_rewards/chosen": 0.007476577535271645,
      "eval_rewards/margins": 0.0022783430758863688,
      "eval_rewards/rejected": 0.005198234226554632,
      "eval_runtime": 3.2005,
      "eval_samples_per_second": 31.245,
      "eval_steps_per_second": 15.623,
      "step": 65
    },
    {
      "epoch": 5.08,
      "grad_norm": 6.9294610023498535,
      "learning_rate": 9.648437499999999e-08,
      "logits/chosen": 0.6869928240776062,
      "logits/rejected": 1.169288158416748,
      "logps/chosen": -37.134765625,
      "logps/rejected": -36.61583709716797,
      "loss": 0.6968,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.002939558122307062,
      "rewards/margins": -0.007142591755837202,
      "rewards/rejected": 0.010082149878144264,
      "step": 66
    },
    {
      "epoch": 5.16,
      "grad_norm": 6.95296049118042,
      "learning_rate": 9.640625e-08,
      "logits/chosen": 0.80265212059021,
      "logits/rejected": 1.1223989725112915,
      "logps/chosen": -36.998497009277344,
      "logps/rejected": -29.650413513183594,
      "loss": 0.6919,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0018603804055601358,
      "rewards/margins": 0.0026339292526245117,
      "rewards/rejected": -0.0007735489634796977,
      "step": 67
    },
    {
      "epoch": 5.24,
      "grad_norm": 7.161109447479248,
      "learning_rate": 9.632812499999999e-08,
      "logits/chosen": 1.0847995281219482,
      "logits/rejected": 1.3041353225708008,
      "logps/chosen": -45.981170654296875,
      "logps/rejected": -31.427276611328125,
      "loss": 0.6855,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.017838336527347565,
      "rewards/margins": 0.015427350997924805,
      "rewards/rejected": 0.0024109836667776108,
      "step": 68
    },
    {
      "epoch": 5.32,
      "grad_norm": 7.819099426269531,
      "learning_rate": 9.624999999999999e-08,
      "logits/chosen": 0.8561302423477173,
      "logits/rejected": 1.4069958925247192,
      "logps/chosen": -51.90293884277344,
      "logps/rejected": -38.94142150878906,
      "loss": 0.6911,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.013031554408371449,
      "rewards/margins": 0.0041970256716012955,
      "rewards/rejected": 0.008834529668092728,
      "step": 69
    },
    {
      "epoch": 5.4,
      "grad_norm": 8.470585823059082,
      "learning_rate": 9.617187499999999e-08,
      "logits/chosen": 1.0338917970657349,
      "logits/rejected": 1.442173957824707,
      "logps/chosen": -50.537261962890625,
      "logps/rejected": -38.33855056762695,
      "loss": 0.691,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.012065577320754528,
      "rewards/margins": 0.00436825817450881,
      "rewards/rejected": 0.00769732054322958,
      "step": 70
    },
    {
      "epoch": 5.48,
      "grad_norm": 6.806547164916992,
      "learning_rate": 9.609374999999999e-08,
      "logits/chosen": 0.9103844165802002,
      "logits/rejected": 1.2581779956817627,
      "logps/chosen": -38.35282897949219,
      "logps/rejected": -33.470703125,
      "loss": 0.6953,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0012892005033791065,
      "rewards/margins": -0.004277372267097235,
      "rewards/rejected": 0.0055665732361376286,
      "step": 71
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 6.977409362792969,
      "learning_rate": 9.6015625e-08,
      "logits/chosen": 1.084014892578125,
      "logits/rejected": 1.166404366493225,
      "logps/chosen": -52.85076904296875,
      "logps/rejected": -38.50536346435547,
      "loss": 0.6843,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015920234844088554,
      "rewards/margins": 0.017847802489995956,
      "rewards/rejected": -0.0019275665981695056,
      "step": 72
    },
    {
      "epoch": 5.64,
      "grad_norm": 6.2998881340026855,
      "learning_rate": 9.59375e-08,
      "logits/chosen": 1.0534420013427734,
      "logits/rejected": 1.4282654523849487,
      "logps/chosen": -45.66916275024414,
      "logps/rejected": -37.521331787109375,
      "loss": 0.6955,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.008060145191848278,
      "rewards/margins": -0.0045600892044603825,
      "rewards/rejected": -0.0035000562202185392,
      "step": 73
    },
    {
      "epoch": 5.72,
      "grad_norm": 6.67858362197876,
      "learning_rate": 9.5859375e-08,
      "logits/chosen": 1.1000933647155762,
      "logits/rejected": 1.307350754737854,
      "logps/chosen": -45.89311599731445,
      "logps/rejected": -34.92268371582031,
      "loss": 0.6911,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.015765881165862083,
      "rewards/margins": 0.004131507594138384,
      "rewards/rejected": 0.011634373106062412,
      "step": 74
    },
    {
      "epoch": 5.8,
      "grad_norm": 5.7466535568237305,
      "learning_rate": 9.578125e-08,
      "logits/chosen": 1.4506267309188843,
      "logits/rejected": 1.5255858898162842,
      "logps/chosen": -43.326602935791016,
      "logps/rejected": -33.53205490112305,
      "loss": 0.6919,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006989551242440939,
      "rewards/margins": 0.002538275672122836,
      "rewards/rejected": 0.004451274871826172,
      "step": 75
    },
    {
      "epoch": 5.88,
      "grad_norm": 7.341449737548828,
      "learning_rate": 9.5703125e-08,
      "logits/chosen": 1.242462396621704,
      "logits/rejected": 1.199074625968933,
      "logps/chosen": -36.151668548583984,
      "logps/rejected": -33.66511535644531,
      "loss": 0.6926,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0014986754395067692,
      "rewards/margins": 0.0012292147148400545,
      "rewards/rejected": -0.00272788992151618,
      "step": 76
    },
    {
      "epoch": 5.96,
      "grad_norm": 5.962982654571533,
      "learning_rate": 9.5625e-08,
      "logits/chosen": 0.786054253578186,
      "logits/rejected": 1.2640442848205566,
      "logps/chosen": -40.28010559082031,
      "logps/rejected": -33.67002487182617,
      "loss": 0.6866,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.015639662742614746,
      "rewards/margins": 0.013332891277968884,
      "rewards/rejected": 0.0023067714646458626,
      "step": 77
    },
    {
      "epoch": 6.0,
      "grad_norm": 11.891239166259766,
      "learning_rate": 9.5546875e-08,
      "logits/chosen": 0.8648620843887329,
      "logits/rejected": 1.38939368724823,
      "logps/chosen": -39.9318733215332,
      "logps/rejected": -30.031545639038086,
      "loss": 0.6865,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018935585394501686,
      "rewards/margins": 0.013368844985961914,
      "rewards/rejected": 0.005566739942878485,
      "step": 78
    },
    {
      "epoch": 6.0,
      "eval_logits/chosen": 0.9953264594078064,
      "eval_logits/rejected": 1.1661560535430908,
      "eval_logps/chosen": -39.64116668701172,
      "eval_logps/rejected": -37.152191162109375,
      "eval_loss": 0.6910526752471924,
      "eval_rewards/accuracies": 0.5799999833106995,
      "eval_rewards/chosen": 0.008440359495580196,
      "eval_rewards/margins": 0.004320127423852682,
      "eval_rewards/rejected": 0.004120232071727514,
      "eval_runtime": 3.1993,
      "eval_samples_per_second": 31.257,
      "eval_steps_per_second": 15.629,
      "step": 78
    },
    {
      "epoch": 6.08,
      "grad_norm": 7.151512145996094,
      "learning_rate": 9.546875e-08,
      "logits/chosen": 0.8319171071052551,
      "logits/rejected": 1.1425087451934814,
      "logps/chosen": -40.38364791870117,
      "logps/rejected": -35.59136962890625,
      "loss": 0.6943,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.003869200125336647,
      "rewards/margins": -0.0022739649284631014,
      "rewards/rejected": -0.001595234964042902,
      "step": 79
    },
    {
      "epoch": 6.16,
      "grad_norm": 6.464174747467041,
      "learning_rate": 9.539062499999999e-08,
      "logits/chosen": 0.9285497069358826,
      "logits/rejected": 1.1520220041275024,
      "logps/chosen": -40.71749496459961,
      "logps/rejected": -37.12488555908203,
      "loss": 0.6944,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0028662681579589844,
      "rewards/margins": -0.0023717163130640984,
      "rewards/rejected": -0.0004945516702719033,
      "step": 80
    },
    {
      "epoch": 6.24,
      "grad_norm": 6.305961608886719,
      "learning_rate": 9.53125e-08,
      "logits/chosen": 1.0239934921264648,
      "logits/rejected": 1.2497031688690186,
      "logps/chosen": -43.42626953125,
      "logps/rejected": -41.67084884643555,
      "loss": 0.6915,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007209086790680885,
      "rewards/margins": 0.0033540488220751286,
      "rewards/rejected": 0.0038550379686057568,
      "step": 81
    },
    {
      "epoch": 6.32,
      "grad_norm": 7.4012675285339355,
      "learning_rate": 9.5234375e-08,
      "logits/chosen": 1.0944069623947144,
      "logits/rejected": 1.3789401054382324,
      "logps/chosen": -51.66243362426758,
      "logps/rejected": -37.13008117675781,
      "loss": 0.6918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.003082466311752796,
      "rewards/margins": 0.002903915010392666,
      "rewards/rejected": 0.00017855176702141762,
      "step": 82
    },
    {
      "epoch": 6.4,
      "grad_norm": 6.14565372467041,
      "learning_rate": 9.515624999999999e-08,
      "logits/chosen": 1.087674856185913,
      "logits/rejected": 1.4557162523269653,
      "logps/chosen": -43.79356384277344,
      "logps/rejected": -31.8904972076416,
      "loss": 0.6879,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.001765370718203485,
      "rewards/margins": 0.010654782876372337,
      "rewards/rejected": -0.008889412507414818,
      "step": 83
    },
    {
      "epoch": 6.48,
      "grad_norm": 6.746584892272949,
      "learning_rate": 9.5078125e-08,
      "logits/chosen": 0.8677185773849487,
      "logits/rejected": 1.313662052154541,
      "logps/chosen": -35.489376068115234,
      "logps/rejected": -35.377601623535156,
      "loss": 0.6828,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01923994906246662,
      "rewards/margins": 0.020992349833250046,
      "rewards/rejected": -0.001752400305122137,
      "step": 84
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 8.211324691772461,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 0.9982614517211914,
      "logits/rejected": 1.2650327682495117,
      "logps/chosen": -47.98617172241211,
      "logps/rejected": -31.918855667114258,
      "loss": 0.6856,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010321117006242275,
      "rewards/margins": 0.015196919441223145,
      "rewards/rejected": -0.004875803366303444,
      "step": 85
    },
    {
      "epoch": 6.64,
      "grad_norm": 6.059122085571289,
      "learning_rate": 9.492187499999999e-08,
      "logits/chosen": 0.9941432476043701,
      "logits/rejected": 1.3644707202911377,
      "logps/chosen": -36.11667251586914,
      "logps/rejected": -33.28763198852539,
      "loss": 0.6832,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014403248205780983,
      "rewards/margins": 0.02009608782827854,
      "rewards/rejected": -0.005692839622497559,
      "step": 86
    },
    {
      "epoch": 6.72,
      "grad_norm": 6.7309370040893555,
      "learning_rate": 9.484375e-08,
      "logits/chosen": 0.7795321345329285,
      "logits/rejected": 1.2752082347869873,
      "logps/chosen": -40.21783447265625,
      "logps/rejected": -38.12887191772461,
      "loss": 0.693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007021808996796608,
      "rewards/margins": 0.0003945116186514497,
      "rewards/rejected": 0.00662729749456048,
      "step": 87
    },
    {
      "epoch": 6.8,
      "grad_norm": 7.515785217285156,
      "learning_rate": 9.476562499999999e-08,
      "logits/chosen": 1.1473705768585205,
      "logits/rejected": 1.3626811504364014,
      "logps/chosen": -37.07759094238281,
      "logps/rejected": -30.391952514648438,
      "loss": 0.6912,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01059036236256361,
      "rewards/margins": 0.003972816281020641,
      "rewards/rejected": 0.006617546081542969,
      "step": 88
    },
    {
      "epoch": 6.88,
      "grad_norm": 7.148480415344238,
      "learning_rate": 9.46875e-08,
      "logits/chosen": 0.8800739049911499,
      "logits/rejected": 1.3873406648635864,
      "logps/chosen": -42.82258605957031,
      "logps/rejected": -34.073326110839844,
      "loss": 0.6859,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008434772491455078,
      "rewards/margins": 0.014536334201693535,
      "rewards/rejected": -0.006101560778915882,
      "step": 89
    },
    {
      "epoch": 6.96,
      "grad_norm": 7.087950229644775,
      "learning_rate": 9.4609375e-08,
      "logits/chosen": 1.3649041652679443,
      "logits/rejected": 1.3540641069412231,
      "logps/chosen": -57.64570999145508,
      "logps/rejected": -35.324989318847656,
      "loss": 0.6875,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.02000279538333416,
      "rewards/margins": 0.011556839570403099,
      "rewards/rejected": 0.008445954881608486,
      "step": 90
    },
    {
      "epoch": 7.0,
      "grad_norm": 9.312378883361816,
      "learning_rate": 9.453125e-08,
      "logits/chosen": 0.9502219557762146,
      "logits/rejected": 1.44223952293396,
      "logps/chosen": -55.7471923828125,
      "logps/rejected": -27.605602264404297,
      "loss": 0.6948,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.001721716020256281,
      "rewards/margins": -0.0033195018768310547,
      "rewards/rejected": 0.005041217897087336,
      "step": 91
    },
    {
      "epoch": 7.0,
      "eval_logits/chosen": 0.9921351671218872,
      "eval_logits/rejected": 1.1634597778320312,
      "eval_logps/chosen": -39.634525299072266,
      "eval_logps/rejected": -37.20121765136719,
      "eval_loss": 0.6882705688476562,
      "eval_rewards/accuracies": 0.6899999976158142,
      "eval_rewards/chosen": 0.009104732424020767,
      "eval_rewards/margins": 0.009886689484119415,
      "eval_rewards/rejected": -0.0007819557213224471,
      "eval_runtime": 3.197,
      "eval_samples_per_second": 31.279,
      "eval_steps_per_second": 15.64,
      "step": 91
    },
    {
      "epoch": 7.08,
      "grad_norm": 6.968864917755127,
      "learning_rate": 9.4453125e-08,
      "logits/chosen": 1.1313979625701904,
      "logits/rejected": 1.3427194356918335,
      "logps/chosen": -42.36518859863281,
      "logps/rejected": -37.975372314453125,
      "loss": 0.6928,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007784771732985973,
      "rewards/margins": 0.0008336775936186314,
      "rewards/rejected": 0.006951094139367342,
      "step": 92
    },
    {
      "epoch": 7.16,
      "grad_norm": 6.367112636566162,
      "learning_rate": 9.4375e-08,
      "logits/chosen": 1.1468406915664673,
      "logits/rejected": 1.4421461820602417,
      "logps/chosen": -44.089134216308594,
      "logps/rejected": -31.712505340576172,
      "loss": 0.6839,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01562967337667942,
      "rewards/margins": 0.01871466636657715,
      "rewards/rejected": -0.0030849932227283716,
      "step": 93
    },
    {
      "epoch": 7.24,
      "grad_norm": 6.965477466583252,
      "learning_rate": 9.4296875e-08,
      "logits/chosen": 0.806583046913147,
      "logits/rejected": 1.3523741960525513,
      "logps/chosen": -41.58807373046875,
      "logps/rejected": -35.59907150268555,
      "loss": 0.6968,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.006076383404433727,
      "rewards/margins": -0.0071020605973899364,
      "rewards/rejected": 0.0010256764944642782,
      "step": 94
    },
    {
      "epoch": 7.32,
      "grad_norm": 7.756554126739502,
      "learning_rate": 9.421875e-08,
      "logits/chosen": 0.8595650792121887,
      "logits/rejected": 1.2811012268066406,
      "logps/chosen": -37.65396499633789,
      "logps/rejected": -36.52933120727539,
      "loss": 0.6949,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.008154679089784622,
      "rewards/margins": -0.003419160842895508,
      "rewards/rejected": 0.01157383993268013,
      "step": 95
    },
    {
      "epoch": 7.4,
      "grad_norm": 7.508108139038086,
      "learning_rate": 9.4140625e-08,
      "logits/chosen": 0.849469780921936,
      "logits/rejected": 1.1979159116744995,
      "logps/chosen": -38.42758560180664,
      "logps/rejected": -32.48723220825195,
      "loss": 0.6847,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014148427173495293,
      "rewards/margins": 0.017009997740387917,
      "rewards/rejected": -0.002861571963876486,
      "step": 96
    },
    {
      "epoch": 7.48,
      "grad_norm": 5.967552185058594,
      "learning_rate": 9.40625e-08,
      "logits/chosen": 0.9049423933029175,
      "logits/rejected": 1.4017820358276367,
      "logps/chosen": -32.318939208984375,
      "logps/rejected": -33.129798889160156,
      "loss": 0.6957,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005329513922333717,
      "rewards/margins": -0.005002617835998535,
      "rewards/rejected": -0.0003268956206738949,
      "step": 97
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 7.1198039054870605,
      "learning_rate": 9.3984375e-08,
      "logits/chosen": 1.0510615110397339,
      "logits/rejected": 1.3126261234283447,
      "logps/chosen": -43.25672912597656,
      "logps/rejected": -35.58232116699219,
      "loss": 0.6836,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013344502076506615,
      "rewards/margins": 0.01927044615149498,
      "rewards/rejected": -0.005925941281020641,
      "step": 98
    },
    {
      "epoch": 7.64,
      "grad_norm": 7.729773044586182,
      "learning_rate": 9.390625e-08,
      "logits/chosen": 1.0417499542236328,
      "logits/rejected": 1.3695917129516602,
      "logps/chosen": -53.55278015136719,
      "logps/rejected": -35.74537658691406,
      "loss": 0.6921,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007951498031616211,
      "rewards/margins": 0.002191686537116766,
      "rewards/rejected": 0.005759811960160732,
      "step": 99
    },
    {
      "epoch": 7.72,
      "grad_norm": 6.094496726989746,
      "learning_rate": 9.382812499999999e-08,
      "logits/chosen": 1.1938279867172241,
      "logits/rejected": 1.1818424463272095,
      "logps/chosen": -49.593963623046875,
      "logps/rejected": -32.55708312988281,
      "loss": 0.6844,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.026491381227970123,
      "rewards/margins": 0.017793750390410423,
      "rewards/rejected": 0.00869762897491455,
      "step": 100
    },
    {
      "epoch": 7.8,
      "grad_norm": 6.799489974975586,
      "learning_rate": 9.375e-08,
      "logits/chosen": 1.0855833292007446,
      "logits/rejected": 1.3554291725158691,
      "logps/chosen": -52.39702606201172,
      "logps/rejected": -33.405914306640625,
      "loss": 0.685,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01792926900088787,
      "rewards/margins": 0.01643359661102295,
      "rewards/rejected": 0.0014956709928810596,
      "step": 101
    },
    {
      "epoch": 7.88,
      "grad_norm": 7.2634758949279785,
      "learning_rate": 9.3671875e-08,
      "logits/chosen": 0.9971801042556763,
      "logits/rejected": 1.4391083717346191,
      "logps/chosen": -53.671688079833984,
      "logps/rejected": -37.99146270751953,
      "loss": 0.6884,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00717468187212944,
      "rewards/margins": 0.009527062997221947,
      "rewards/rejected": -0.0023523811250925064,
      "step": 102
    },
    {
      "epoch": 7.96,
      "grad_norm": 6.917149066925049,
      "learning_rate": 9.359374999999999e-08,
      "logits/chosen": 0.9444535374641418,
      "logits/rejected": 1.2953267097473145,
      "logps/chosen": -38.52326202392578,
      "logps/rejected": -34.112464904785156,
      "loss": 0.6875,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011269260197877884,
      "rewards/margins": 0.011366486549377441,
      "rewards/rejected": -9.722704999148846e-05,
      "step": 103
    },
    {
      "epoch": 8.0,
      "grad_norm": 8.237066268920898,
      "learning_rate": 9.351562499999999e-08,
      "logits/chosen": 0.8413815498352051,
      "logits/rejected": 1.029418706893921,
      "logps/chosen": -35.029964447021484,
      "logps/rejected": -37.32424545288086,
      "loss": 0.6908,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006591320037841797,
      "rewards/margins": 0.004862118046730757,
      "rewards/rejected": 0.0017292022239416838,
      "step": 104
    },
    {
      "epoch": 8.0,
      "eval_logits/chosen": 0.9920199513435364,
      "eval_logits/rejected": 1.1652339696884155,
      "eval_logps/chosen": -39.594635009765625,
      "eval_logps/rejected": -37.1557502746582,
      "eval_loss": 0.6885599493980408,
      "eval_rewards/accuracies": 0.6700000166893005,
      "eval_rewards/chosen": 0.013093482702970505,
      "eval_rewards/margins": 0.009329034946858883,
      "eval_rewards/rejected": 0.0037644461262971163,
      "eval_runtime": 3.2072,
      "eval_samples_per_second": 31.18,
      "eval_steps_per_second": 15.59,
      "step": 104
    },
    {
      "epoch": 8.08,
      "grad_norm": 7.122239589691162,
      "learning_rate": 9.343749999999999e-08,
      "logits/chosen": 0.8964688181877136,
      "logits/rejected": 1.0306177139282227,
      "logps/chosen": -42.105262756347656,
      "logps/rejected": -40.97315979003906,
      "loss": 0.6919,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.002538442611694336,
      "rewards/margins": 0.002545619383454323,
      "rewards/rejected": -7.17630609869957e-06,
      "step": 105
    },
    {
      "epoch": 8.16,
      "grad_norm": 6.644867897033691,
      "learning_rate": 9.335937499999999e-08,
      "logits/chosen": 1.1127961874008179,
      "logits/rejected": 1.2049267292022705,
      "logps/chosen": -51.460750579833984,
      "logps/rejected": -33.73360824584961,
      "loss": 0.6877,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.012232376262545586,
      "rewards/margins": 0.010952925309538841,
      "rewards/rejected": 0.0012794494396075606,
      "step": 106
    },
    {
      "epoch": 8.24,
      "grad_norm": 7.220613956451416,
      "learning_rate": 9.328125e-08,
      "logits/chosen": 0.9694152474403381,
      "logits/rejected": 1.2662044763565063,
      "logps/chosen": -51.736114501953125,
      "logps/rejected": -40.46048355102539,
      "loss": 0.6907,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.011146355420351028,
      "rewards/margins": 0.0049468278884887695,
      "rewards/rejected": 0.006199526600539684,
      "step": 107
    },
    {
      "epoch": 8.32,
      "grad_norm": 6.5487565994262695,
      "learning_rate": 9.3203125e-08,
      "logits/chosen": 0.9275935292243958,
      "logits/rejected": 1.269958257675171,
      "logps/chosen": -35.80400848388672,
      "logps/rejected": -30.17024040222168,
      "loss": 0.6868,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005206656642258167,
      "rewards/margins": 0.012825560756027699,
      "rewards/rejected": -0.007618905045092106,
      "step": 108
    },
    {
      "epoch": 8.4,
      "grad_norm": 5.837649345397949,
      "learning_rate": 9.3125e-08,
      "logits/chosen": 0.9741606712341309,
      "logits/rejected": 1.3076817989349365,
      "logps/chosen": -37.36552810668945,
      "logps/rejected": -30.716899871826172,
      "loss": 0.6856,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.012311100959777832,
      "rewards/margins": 0.015350126661360264,
      "rewards/rejected": -0.0030390264000743628,
      "step": 109
    },
    {
      "epoch": 8.48,
      "grad_norm": 6.553142070770264,
      "learning_rate": 9.3046875e-08,
      "logits/chosen": 1.2764840126037598,
      "logits/rejected": 1.4198848009109497,
      "logps/chosen": -47.33196258544922,
      "logps/rejected": -33.90688705444336,
      "loss": 0.6838,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02568648010492325,
      "rewards/margins": 0.018885396420955658,
      "rewards/rejected": 0.0068010808899998665,
      "step": 110
    },
    {
      "epoch": 8.56,
      "grad_norm": 7.8541388511657715,
      "learning_rate": 9.296875e-08,
      "logits/chosen": 0.9983784556388855,
      "logits/rejected": 1.1839653253555298,
      "logps/chosen": -47.727020263671875,
      "logps/rejected": -36.26138687133789,
      "loss": 0.6855,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.018152881413698196,
      "rewards/margins": 0.015426279045641422,
      "rewards/rejected": 0.002726602600887418,
      "step": 111
    },
    {
      "epoch": 8.64,
      "grad_norm": 8.108871459960938,
      "learning_rate": 9.2890625e-08,
      "logits/chosen": 1.0328127145767212,
      "logits/rejected": 1.306189775466919,
      "logps/chosen": -43.45566177368164,
      "logps/rejected": -35.03512954711914,
      "loss": 0.6797,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.022986888885498047,
      "rewards/margins": 0.0270705483853817,
      "rewards/rejected": -0.004083657171577215,
      "step": 112
    },
    {
      "epoch": 8.72,
      "grad_norm": 6.128379821777344,
      "learning_rate": 9.28125e-08,
      "logits/chosen": 0.85566645860672,
      "logits/rejected": 1.4297497272491455,
      "logps/chosen": -41.87773132324219,
      "logps/rejected": -28.35685157775879,
      "loss": 0.683,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02534322813153267,
      "rewards/margins": 0.020540762692689896,
      "rewards/rejected": 0.0048024654388427734,
      "step": 113
    },
    {
      "epoch": 8.8,
      "grad_norm": 7.426728248596191,
      "learning_rate": 9.2734375e-08,
      "logits/chosen": 0.8066003918647766,
      "logits/rejected": 1.3982136249542236,
      "logps/chosen": -46.90538787841797,
      "logps/rejected": -40.361228942871094,
      "loss": 0.6891,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010116673074662685,
      "rewards/margins": 0.008217073045670986,
      "rewards/rejected": 0.0018995999125763774,
      "step": 114
    },
    {
      "epoch": 8.88,
      "grad_norm": 7.090595245361328,
      "learning_rate": 9.265624999999999e-08,
      "logits/chosen": 1.2737501859664917,
      "logits/rejected": 1.3705908060073853,
      "logps/chosen": -48.487064361572266,
      "logps/rejected": -37.815277099609375,
      "loss": 0.6876,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.030822180211544037,
      "rewards/margins": 0.011236190795898438,
      "rewards/rejected": 0.01958599127829075,
      "step": 115
    },
    {
      "epoch": 8.96,
      "grad_norm": 6.221371650695801,
      "learning_rate": 9.2578125e-08,
      "logits/chosen": 0.9040022492408752,
      "logits/rejected": 1.487352728843689,
      "logps/chosen": -34.70765686035156,
      "logps/rejected": -29.6165828704834,
      "loss": 0.6886,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.016249824315309525,
      "rewards/margins": 0.009253001771867275,
      "rewards/rejected": 0.006996822543442249,
      "step": 116
    },
    {
      "epoch": 9.0,
      "grad_norm": 12.025716781616211,
      "learning_rate": 9.25e-08,
      "logits/chosen": 0.9598003625869751,
      "logits/rejected": 1.4397705793380737,
      "logps/chosen": -30.48678207397461,
      "logps/rejected": -36.0106086730957,
      "loss": 0.6851,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017031097784638405,
      "rewards/margins": 0.01612548902630806,
      "rewards/rejected": 0.0009056087583303452,
      "step": 117
    },
    {
      "epoch": 9.0,
      "eval_logits/chosen": 0.9903152585029602,
      "eval_logits/rejected": 1.161380648612976,
      "eval_logps/chosen": -39.594154357910156,
      "eval_logps/rejected": -37.13819885253906,
      "eval_loss": 0.6894062161445618,
      "eval_rewards/accuracies": 0.6600000262260437,
      "eval_rewards/chosen": 0.013141172006726265,
      "eval_rewards/margins": 0.007621156517416239,
      "eval_rewards/rejected": 0.005520015489310026,
      "eval_runtime": 3.2019,
      "eval_samples_per_second": 31.231,
      "eval_steps_per_second": 15.616,
      "step": 117
    },
    {
      "epoch": 9.08,
      "grad_norm": 7.068387031555176,
      "learning_rate": 9.242187499999999e-08,
      "logits/chosen": 1.0953556299209595,
      "logits/rejected": 1.2233715057373047,
      "logps/chosen": -37.82918930053711,
      "logps/rejected": -36.963645935058594,
      "loss": 0.6856,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01744108274579048,
      "rewards/margins": 0.015166806988418102,
      "rewards/rejected": 0.0022742748260498047,
      "step": 118
    },
    {
      "epoch": 9.16,
      "grad_norm": 7.866189002990723,
      "learning_rate": 9.234375e-08,
      "logits/chosen": 1.0199666023254395,
      "logits/rejected": 1.1145904064178467,
      "logps/chosen": -47.382347106933594,
      "logps/rejected": -33.318721771240234,
      "loss": 0.6903,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0131095414981246,
      "rewards/margins": 0.005739831365644932,
      "rewards/rejected": 0.007369708735495806,
      "step": 119
    },
    {
      "epoch": 9.24,
      "grad_norm": 6.40624475479126,
      "learning_rate": 9.226562499999999e-08,
      "logits/chosen": 0.9742833375930786,
      "logits/rejected": 1.3581161499023438,
      "logps/chosen": -41.19375228881836,
      "logps/rejected": -32.092498779296875,
      "loss": 0.6869,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.020740818232297897,
      "rewards/margins": 0.012720108032226562,
      "rewards/rejected": 0.008020712062716484,
      "step": 120
    },
    {
      "epoch": 9.32,
      "grad_norm": 5.752214431762695,
      "learning_rate": 9.218749999999999e-08,
      "logits/chosen": 0.8577598333358765,
      "logits/rejected": 1.3731663227081299,
      "logps/chosen": -38.35020446777344,
      "logps/rejected": -34.796382904052734,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01479342021048069,
      "rewards/margins": 0.010460447520017624,
      "rewards/rejected": 0.004332971293479204,
      "step": 121
    },
    {
      "epoch": 9.4,
      "grad_norm": 6.23384428024292,
      "learning_rate": 9.2109375e-08,
      "logits/chosen": 1.096727728843689,
      "logits/rejected": 1.3498393297195435,
      "logps/chosen": -42.27449417114258,
      "logps/rejected": -31.400074005126953,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010886002331972122,
      "rewards/margins": 0.010410737246274948,
      "rewards/rejected": 0.0004752634558826685,
      "step": 122
    },
    {
      "epoch": 9.48,
      "grad_norm": 7.120491027832031,
      "learning_rate": 9.203124999999999e-08,
      "logits/chosen": 0.9818129539489746,
      "logits/rejected": 1.3708107471466064,
      "logps/chosen": -45.60252380371094,
      "logps/rejected": -30.96188735961914,
      "loss": 0.687,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016637183725833893,
      "rewards/margins": 0.012465571984648705,
      "rewards/rejected": 0.004171609878540039,
      "step": 123
    },
    {
      "epoch": 9.56,
      "grad_norm": 7.3743720054626465,
      "learning_rate": 9.195312499999999e-08,
      "logits/chosen": 0.9825968146324158,
      "logits/rejected": 1.2770308256149292,
      "logps/chosen": -49.023529052734375,
      "logps/rejected": -39.4998779296875,
      "loss": 0.6793,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02288021892309189,
      "rewards/margins": 0.02794685587286949,
      "rewards/rejected": -0.005066633690148592,
      "step": 124
    },
    {
      "epoch": 9.64,
      "grad_norm": 7.359724998474121,
      "learning_rate": 9.1875e-08,
      "logits/chosen": 0.8802157640457153,
      "logits/rejected": 1.250007152557373,
      "logps/chosen": -52.085205078125,
      "logps/rejected": -29.284992218017578,
      "loss": 0.689,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.015285182744264603,
      "rewards/margins": 0.008455204777419567,
      "rewards/rejected": 0.006829977501183748,
      "step": 125
    },
    {
      "epoch": 9.72,
      "grad_norm": 5.481923580169678,
      "learning_rate": 9.1796875e-08,
      "logits/chosen": 1.0195162296295166,
      "logits/rejected": 1.3616125583648682,
      "logps/chosen": -29.73146629333496,
      "logps/rejected": -37.245521545410156,
      "loss": 0.6889,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.015189815312623978,
      "rewards/margins": 0.008547330275177956,
      "rewards/rejected": 0.006642485037446022,
      "step": 126
    },
    {
      "epoch": 9.8,
      "grad_norm": 6.563933849334717,
      "learning_rate": 9.171875e-08,
      "logits/chosen": 0.9546874761581421,
      "logits/rejected": 1.3144493103027344,
      "logps/chosen": -46.0885124206543,
      "logps/rejected": -36.42718505859375,
      "loss": 0.6862,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.019993091002106667,
      "rewards/margins": 0.014103889465332031,
      "rewards/rejected": 0.005889201536774635,
      "step": 127
    },
    {
      "epoch": 9.88,
      "grad_norm": 8.677895545959473,
      "learning_rate": 9.1640625e-08,
      "logits/chosen": 1.0807780027389526,
      "logits/rejected": 1.3378705978393555,
      "logps/chosen": -42.93069839477539,
      "logps/rejected": -39.41569900512695,
      "loss": 0.6846,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.017343545332551003,
      "rewards/margins": 0.017240406945347786,
      "rewards/rejected": 0.00010313955135643482,
      "step": 128
    },
    {
      "epoch": 9.96,
      "grad_norm": 6.856288909912109,
      "learning_rate": 9.15625e-08,
      "logits/chosen": 1.0332971811294556,
      "logits/rejected": 1.533277153968811,
      "logps/chosen": -44.331851959228516,
      "logps/rejected": -35.01091003417969,
      "loss": 0.6766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03027193434536457,
      "rewards/margins": 0.03345322608947754,
      "rewards/rejected": -0.003181290812790394,
      "step": 129
    },
    {
      "epoch": 10.0,
      "grad_norm": 11.395115852355957,
      "learning_rate": 9.1484375e-08,
      "logits/chosen": 1.034348964691162,
      "logits/rejected": 0.9226876497268677,
      "logps/chosen": -54.48692321777344,
      "logps/rejected": -37.674285888671875,
      "loss": 0.6898,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.014737940393388271,
      "rewards/margins": 0.00683174142614007,
      "rewards/rejected": 0.007906198501586914,
      "step": 130
    },
    {
      "epoch": 10.0,
      "eval_logits/chosen": 0.9899916648864746,
      "eval_logits/rejected": 1.1614028215408325,
      "eval_logps/chosen": -39.57130813598633,
      "eval_logps/rejected": -37.14375686645508,
      "eval_loss": 0.6879839897155762,
      "eval_rewards/accuracies": 0.7099999785423279,
      "eval_rewards/chosen": 0.015426495112478733,
      "eval_rewards/margins": 0.010462634265422821,
      "eval_rewards/rejected": 0.004963861312717199,
      "eval_runtime": 3.2065,
      "eval_samples_per_second": 31.187,
      "eval_steps_per_second": 15.593,
      "step": 130
    },
    {
      "epoch": 10.08,
      "grad_norm": 7.105384826660156,
      "learning_rate": 9.140625e-08,
      "logits/chosen": 0.8928589224815369,
      "logits/rejected": 1.2601594924926758,
      "logps/chosen": -33.82968521118164,
      "logps/rejected": -34.200843811035156,
      "loss": 0.6859,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02051069773733616,
      "rewards/margins": 0.014543866738677025,
      "rewards/rejected": 0.005966830067336559,
      "step": 131
    },
    {
      "epoch": 10.16,
      "grad_norm": 7.140416145324707,
      "learning_rate": 9.1328125e-08,
      "logits/chosen": 0.6993227005004883,
      "logits/rejected": 1.4835706949234009,
      "logps/chosen": -46.08112335205078,
      "logps/rejected": -33.475528717041016,
      "loss": 0.6815,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01994180679321289,
      "rewards/margins": 0.023673199117183685,
      "rewards/rejected": -0.0037313939537853003,
      "step": 132
    },
    {
      "epoch": 10.24,
      "grad_norm": 6.689767837524414,
      "learning_rate": 9.125e-08,
      "logits/chosen": 0.9108357429504395,
      "logits/rejected": 1.1389023065567017,
      "logps/chosen": -33.495155334472656,
      "logps/rejected": -34.269676208496094,
      "loss": 0.6839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015000938437879086,
      "rewards/margins": 0.018612241372466087,
      "rewards/rejected": -0.0036113024689257145,
      "step": 133
    },
    {
      "epoch": 10.32,
      "grad_norm": 7.305379867553711,
      "learning_rate": 9.1171875e-08,
      "logits/chosen": 1.108302354812622,
      "logits/rejected": 1.3415961265563965,
      "logps/chosen": -62.3573112487793,
      "logps/rejected": -34.88567352294922,
      "loss": 0.6822,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02889242395758629,
      "rewards/margins": 0.02221977710723877,
      "rewards/rejected": 0.006672644522041082,
      "step": 134
    },
    {
      "epoch": 10.4,
      "grad_norm": 7.177065372467041,
      "learning_rate": 9.109374999999999e-08,
      "logits/chosen": 0.9177247881889343,
      "logits/rejected": 1.1705806255340576,
      "logps/chosen": -43.84912872314453,
      "logps/rejected": -40.85641098022461,
      "loss": 0.6777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.032660722732543945,
      "rewards/margins": 0.031090760603547096,
      "rewards/rejected": 0.00156996282748878,
      "step": 135
    },
    {
      "epoch": 10.48,
      "grad_norm": 6.679068565368652,
      "learning_rate": 9.1015625e-08,
      "logits/chosen": 1.083337426185608,
      "logits/rejected": 1.3232226371765137,
      "logps/chosen": -43.78779983520508,
      "logps/rejected": -36.69190216064453,
      "loss": 0.6853,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.018338393419981003,
      "rewards/margins": 0.01593804359436035,
      "rewards/rejected": 0.002400350756943226,
      "step": 136
    },
    {
      "epoch": 10.56,
      "grad_norm": 6.036821365356445,
      "learning_rate": 9.09375e-08,
      "logits/chosen": 1.1676452159881592,
      "logits/rejected": 1.458812952041626,
      "logps/chosen": -41.517791748046875,
      "logps/rejected": -35.707313537597656,
      "loss": 0.6892,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010192704387009144,
      "rewards/margins": 0.008113360032439232,
      "rewards/rejected": 0.0020793441217392683,
      "step": 137
    },
    {
      "epoch": 10.64,
      "grad_norm": 7.275341033935547,
      "learning_rate": 9.085937499999999e-08,
      "logits/chosen": 0.8021739721298218,
      "logits/rejected": 1.3684747219085693,
      "logps/chosen": -39.51918029785156,
      "logps/rejected": -33.743309020996094,
      "loss": 0.6811,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02823662757873535,
      "rewards/margins": 0.024236584082245827,
      "rewards/rejected": 0.004000043962150812,
      "step": 138
    },
    {
      "epoch": 10.72,
      "grad_norm": 6.442506790161133,
      "learning_rate": 9.078125e-08,
      "logits/chosen": 1.0387362241744995,
      "logits/rejected": 1.3092001676559448,
      "logps/chosen": -44.103790283203125,
      "logps/rejected": -34.25720977783203,
      "loss": 0.6902,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008653784170746803,
      "rewards/margins": 0.005950832273811102,
      "rewards/rejected": 0.002702951431274414,
      "step": 139
    },
    {
      "epoch": 10.8,
      "grad_norm": 8.06812858581543,
      "learning_rate": 9.070312499999999e-08,
      "logits/chosen": 1.1204800605773926,
      "logits/rejected": 1.2499361038208008,
      "logps/chosen": -42.842594146728516,
      "logps/rejected": -31.004796981811523,
      "loss": 0.6803,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02327554114162922,
      "rewards/margins": 0.026044510304927826,
      "rewards/rejected": -0.002768969628959894,
      "step": 140
    },
    {
      "epoch": 10.88,
      "grad_norm": 7.314370155334473,
      "learning_rate": 9.062499999999999e-08,
      "logits/chosen": 1.1205289363861084,
      "logits/rejected": 1.3504765033721924,
      "logps/chosen": -50.68214416503906,
      "logps/rejected": -40.319679260253906,
      "loss": 0.6879,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.021834541112184525,
      "rewards/margins": 0.010554410517215729,
      "rewards/rejected": 0.011280130594968796,
      "step": 141
    },
    {
      "epoch": 10.96,
      "grad_norm": 6.879570007324219,
      "learning_rate": 9.0546875e-08,
      "logits/chosen": 0.9776679873466492,
      "logits/rejected": 1.2467776536941528,
      "logps/chosen": -41.6431884765625,
      "logps/rejected": -28.078109741210938,
      "loss": 0.6814,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.019718527793884277,
      "rewards/margins": 0.023850228637456894,
      "rewards/rejected": -0.00413169851526618,
      "step": 142
    },
    {
      "epoch": 11.0,
      "grad_norm": 7.76852560043335,
      "learning_rate": 9.046875e-08,
      "logits/chosen": 1.1283879280090332,
      "logits/rejected": 1.5054645538330078,
      "logps/chosen": -40.100921630859375,
      "logps/rejected": -36.10822296142578,
      "loss": 0.6923,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009730100631713867,
      "rewards/margins": 0.0017335889860987663,
      "rewards/rejected": 0.007996510714292526,
      "step": 143
    },
    {
      "epoch": 11.0,
      "eval_logits/chosen": 0.9892396330833435,
      "eval_logits/rejected": 1.1604217290878296,
      "eval_logps/chosen": -39.560516357421875,
      "eval_logps/rejected": -37.13340759277344,
      "eval_loss": 0.6879611015319824,
      "eval_rewards/accuracies": 0.6700000166893005,
      "eval_rewards/chosen": 0.01650523766875267,
      "eval_rewards/margins": 0.01050659641623497,
      "eval_rewards/rejected": 0.005998640786856413,
      "eval_runtime": 3.1995,
      "eval_samples_per_second": 31.255,
      "eval_steps_per_second": 15.628,
      "step": 143
    },
    {
      "epoch": 11.08,
      "grad_norm": 8.172398567199707,
      "learning_rate": 9.0390625e-08,
      "logits/chosen": 1.0624626874923706,
      "logits/rejected": 1.2816818952560425,
      "logps/chosen": -34.36448669433594,
      "logps/rejected": -31.552236557006836,
      "loss": 0.6854,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013076377101242542,
      "rewards/margins": 0.01568775065243244,
      "rewards/rejected": -0.0026113749481737614,
      "step": 144
    },
    {
      "epoch": 11.16,
      "grad_norm": 6.860278129577637,
      "learning_rate": 9.03125e-08,
      "logits/chosen": 1.1600840091705322,
      "logits/rejected": 1.3159546852111816,
      "logps/chosen": -51.089595794677734,
      "logps/rejected": -38.73316955566406,
      "loss": 0.6884,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.028873277828097343,
      "rewards/margins": 0.009513425640761852,
      "rewards/rejected": 0.019359851256012917,
      "step": 145
    },
    {
      "epoch": 11.24,
      "grad_norm": 6.919933795928955,
      "learning_rate": 9.0234375e-08,
      "logits/chosen": 0.9774820804595947,
      "logits/rejected": 1.3834195137023926,
      "logps/chosen": -49.44579315185547,
      "logps/rejected": -37.75151062011719,
      "loss": 0.6829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013057375326752663,
      "rewards/margins": 0.02057809755206108,
      "rewards/rejected": -0.00752072362229228,
      "step": 146
    },
    {
      "epoch": 11.32,
      "grad_norm": 7.567263603210449,
      "learning_rate": 9.015625e-08,
      "logits/chosen": 1.0571919679641724,
      "logits/rejected": 1.3522623777389526,
      "logps/chosen": -44.835243225097656,
      "logps/rejected": -33.663875579833984,
      "loss": 0.6872,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010076500475406647,
      "rewards/margins": 0.011956287547945976,
      "rewards/rejected": -0.0018797875382006168,
      "step": 147
    },
    {
      "epoch": 11.4,
      "grad_norm": 6.836869716644287,
      "learning_rate": 9.0078125e-08,
      "logits/chosen": 1.000920295715332,
      "logits/rejected": 1.2884544134140015,
      "logps/chosen": -41.9354248046875,
      "logps/rejected": -31.63601303100586,
      "loss": 0.6851,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009767293930053711,
      "rewards/margins": 0.016332410275936127,
      "rewards/rejected": -0.006565118208527565,
      "step": 148
    },
    {
      "epoch": 11.48,
      "grad_norm": 6.6102495193481445,
      "learning_rate": 9e-08,
      "logits/chosen": 1.3353687524795532,
      "logits/rejected": 1.2573896646499634,
      "logps/chosen": -49.84101867675781,
      "logps/rejected": -30.41726303100586,
      "loss": 0.6818,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.025548148900270462,
      "rewards/margins": 0.02309253253042698,
      "rewards/rejected": 0.0024556161370128393,
      "step": 149
    },
    {
      "epoch": 11.56,
      "grad_norm": 6.220541954040527,
      "learning_rate": 8.992187499999999e-08,
      "logits/chosen": 0.985889196395874,
      "logits/rejected": 1.4415180683135986,
      "logps/chosen": -44.84925842285156,
      "logps/rejected": -33.2464485168457,
      "loss": 0.6895,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009267759509384632,
      "rewards/margins": 0.007443713489919901,
      "rewards/rejected": 0.0018240450881421566,
      "step": 150
    },
    {
      "epoch": 11.64,
      "grad_norm": 7.800483226776123,
      "learning_rate": 8.984375e-08,
      "logits/chosen": 0.6500913500785828,
      "logits/rejected": 1.0446401834487915,
      "logps/chosen": -36.622825622558594,
      "logps/rejected": -36.49494552612305,
      "loss": 0.6795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015540648251771927,
      "rewards/margins": 0.027541255578398705,
      "rewards/rejected": -0.012000607326626778,
      "step": 151
    },
    {
      "epoch": 11.72,
      "grad_norm": 6.648280620574951,
      "learning_rate": 8.9765625e-08,
      "logits/chosen": 0.7846070528030396,
      "logits/rejected": 1.3341295719146729,
      "logps/chosen": -45.05934143066406,
      "logps/rejected": -37.57972717285156,
      "loss": 0.6846,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.022890616208314896,
      "rewards/margins": 0.01729152351617813,
      "rewards/rejected": 0.005599093157798052,
      "step": 152
    },
    {
      "epoch": 11.8,
      "grad_norm": 6.1249518394470215,
      "learning_rate": 8.968749999999999e-08,
      "logits/chosen": 1.02541983127594,
      "logits/rejected": 1.3012831211090088,
      "logps/chosen": -40.37221145629883,
      "logps/rejected": -41.117515563964844,
      "loss": 0.6881,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.021918058395385742,
      "rewards/margins": 0.010206746868789196,
      "rewards/rejected": 0.011711311526596546,
      "step": 153
    },
    {
      "epoch": 11.88,
      "grad_norm": 7.004861831665039,
      "learning_rate": 8.9609375e-08,
      "logits/chosen": 1.2952709197998047,
      "logits/rejected": 1.4299644231796265,
      "logps/chosen": -46.96553421020508,
      "logps/rejected": -33.284576416015625,
      "loss": 0.6843,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.017504453659057617,
      "rewards/margins": 0.01799016073346138,
      "rewards/rejected": -0.00048570625949651003,
      "step": 154
    },
    {
      "epoch": 11.96,
      "grad_norm": 7.096333026885986,
      "learning_rate": 8.953124999999999e-08,
      "logits/chosen": 0.7580217123031616,
      "logits/rejected": 1.3103302717208862,
      "logps/chosen": -40.293827056884766,
      "logps/rejected": -33.54273986816406,
      "loss": 0.6814,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.018012547865509987,
      "rewards/margins": 0.023671627044677734,
      "rewards/rejected": -0.0056590791791677475,
      "step": 155
    },
    {
      "epoch": 12.0,
      "grad_norm": 7.246706962585449,
      "learning_rate": 8.945312499999999e-08,
      "logits/chosen": 1.035080909729004,
      "logits/rejected": 1.3430695533752441,
      "logps/chosen": -36.94151306152344,
      "logps/rejected": -33.27266311645508,
      "loss": 0.695,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.003092431928962469,
      "rewards/margins": -0.003653812687844038,
      "rewards/rejected": 0.006746244616806507,
      "step": 156
    },
    {
      "epoch": 12.0,
      "eval_logits/chosen": 0.9879753589630127,
      "eval_logits/rejected": 1.159414529800415,
      "eval_logps/chosen": -39.52799606323242,
      "eval_logps/rejected": -37.12544250488281,
      "eval_loss": 0.6867411136627197,
      "eval_rewards/accuracies": 0.7400000095367432,
      "eval_rewards/chosen": 0.019757479429244995,
      "eval_rewards/margins": 0.012962408363819122,
      "eval_rewards/rejected": 0.006795072928071022,
      "eval_runtime": 3.2085,
      "eval_samples_per_second": 31.167,
      "eval_steps_per_second": 15.583,
      "step": 156
    },
    {
      "epoch": 12.08,
      "grad_norm": 5.992313861846924,
      "learning_rate": 8.9375e-08,
      "logits/chosen": 0.9539171457290649,
      "logits/rejected": 1.3760886192321777,
      "logps/chosen": -41.448463439941406,
      "logps/rejected": -32.4405632019043,
      "loss": 0.6786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02583005279302597,
      "rewards/margins": 0.02942976914346218,
      "rewards/rejected": -0.003599715419113636,
      "step": 157
    },
    {
      "epoch": 12.16,
      "grad_norm": 7.027353286743164,
      "learning_rate": 8.929687499999999e-08,
      "logits/chosen": 0.8751950263977051,
      "logits/rejected": 1.324336290359497,
      "logps/chosen": -39.18895721435547,
      "logps/rejected": -35.083343505859375,
      "loss": 0.6828,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02128293551504612,
      "rewards/margins": 0.020847344771027565,
      "rewards/rejected": 0.000435591209679842,
      "step": 158
    },
    {
      "epoch": 12.24,
      "grad_norm": 7.269432544708252,
      "learning_rate": 8.921874999999999e-08,
      "logits/chosen": 0.7948407530784607,
      "logits/rejected": 1.3460350036621094,
      "logps/chosen": -41.840293884277344,
      "logps/rejected": -33.559051513671875,
      "loss": 0.6863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008557820692658424,
      "rewards/margins": 0.013788438402116299,
      "rewards/rejected": -0.005230617709457874,
      "step": 159
    },
    {
      "epoch": 12.32,
      "grad_norm": 6.042418003082275,
      "learning_rate": 8.9140625e-08,
      "logits/chosen": 1.337188959121704,
      "logits/rejected": 1.1805660724639893,
      "logps/chosen": -43.02857971191406,
      "logps/rejected": -30.304405212402344,
      "loss": 0.6897,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010888935066759586,
      "rewards/margins": 0.007080293260514736,
      "rewards/rejected": 0.0038086415734142065,
      "step": 160
    },
    {
      "epoch": 12.4,
      "grad_norm": 8.187335014343262,
      "learning_rate": 8.90625e-08,
      "logits/chosen": 0.9857970476150513,
      "logits/rejected": 1.1869492530822754,
      "logps/chosen": -55.2337646484375,
      "logps/rejected": -33.268733978271484,
      "loss": 0.6869,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01738896407186985,
      "rewards/margins": 0.012842250056564808,
      "rewards/rejected": 0.004546714015305042,
      "step": 161
    },
    {
      "epoch": 12.48,
      "grad_norm": 6.663760662078857,
      "learning_rate": 8.8984375e-08,
      "logits/chosen": 0.8872979283332825,
      "logits/rejected": 1.2580251693725586,
      "logps/chosen": -33.972557067871094,
      "logps/rejected": -37.381614685058594,
      "loss": 0.6851,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.022717785090208054,
      "rewards/margins": 0.016210222616791725,
      "rewards/rejected": 0.00650756387040019,
      "step": 162
    },
    {
      "epoch": 12.56,
      "grad_norm": 6.825160980224609,
      "learning_rate": 8.890625e-08,
      "logits/chosen": 1.1797947883605957,
      "logits/rejected": 1.2668839693069458,
      "logps/chosen": -58.5816764831543,
      "logps/rejected": -34.214359283447266,
      "loss": 0.6835,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.029747987166047096,
      "rewards/margins": 0.019527245312929153,
      "rewards/rejected": 0.010220741853117943,
      "step": 163
    },
    {
      "epoch": 12.64,
      "grad_norm": 8.23798942565918,
      "learning_rate": 8.8828125e-08,
      "logits/chosen": 0.9655806422233582,
      "logits/rejected": 0.9866547584533691,
      "logps/chosen": -39.97512435913086,
      "logps/rejected": -38.11891174316406,
      "loss": 0.6828,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02552783489227295,
      "rewards/margins": 0.0208391435444355,
      "rewards/rejected": 0.004688691813498735,
      "step": 164
    },
    {
      "epoch": 12.72,
      "grad_norm": 6.062641143798828,
      "learning_rate": 8.875e-08,
      "logits/chosen": 1.2479398250579834,
      "logits/rejected": 1.5380680561065674,
      "logps/chosen": -48.29668045043945,
      "logps/rejected": -38.8469123840332,
      "loss": 0.6822,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.019582677632570267,
      "rewards/margins": 0.022132301703095436,
      "rewards/rejected": -0.0025496245361864567,
      "step": 165
    },
    {
      "epoch": 12.8,
      "grad_norm": 7.582151889801025,
      "learning_rate": 8.8671875e-08,
      "logits/chosen": 1.129346251487732,
      "logits/rejected": 1.5677769184112549,
      "logps/chosen": -42.544532775878906,
      "logps/rejected": -40.357261657714844,
      "loss": 0.6884,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.030077435076236725,
      "rewards/margins": 0.009674716740846634,
      "rewards/rejected": 0.02040271833539009,
      "step": 166
    },
    {
      "epoch": 12.88,
      "grad_norm": 7.562099933624268,
      "learning_rate": 8.859375e-08,
      "logits/chosen": 0.9399271011352539,
      "logits/rejected": 1.3259812593460083,
      "logps/chosen": -39.829959869384766,
      "logps/rejected": -34.3912467956543,
      "loss": 0.6812,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.026406383141875267,
      "rewards/margins": 0.024157501757144928,
      "rewards/rejected": 0.002248883480206132,
      "step": 167
    },
    {
      "epoch": 12.96,
      "grad_norm": 6.900786876678467,
      "learning_rate": 8.8515625e-08,
      "logits/chosen": 0.8891445398330688,
      "logits/rejected": 1.3860498666763306,
      "logps/chosen": -45.15284729003906,
      "logps/rejected": -33.016944885253906,
      "loss": 0.6756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02393357828259468,
      "rewards/margins": 0.03548753634095192,
      "rewards/rejected": -0.011553955264389515,
      "step": 168
    },
    {
      "epoch": 13.0,
      "grad_norm": 7.454054832458496,
      "learning_rate": 8.84375e-08,
      "logits/chosen": 0.6809279918670654,
      "logits/rejected": 1.1954679489135742,
      "logps/chosen": -28.938297271728516,
      "logps/rejected": -28.822616577148438,
      "loss": 0.6905,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.011912775225937366,
      "rewards/margins": 0.005390787031501532,
      "rewards/rejected": 0.006521988660097122,
      "step": 169
    },
    {
      "epoch": 13.0,
      "eval_logits/chosen": 0.98726487159729,
      "eval_logits/rejected": 1.1604808568954468,
      "eval_logps/chosen": -39.53911209106445,
      "eval_logps/rejected": -37.133392333984375,
      "eval_loss": 0.686911404132843,
      "eval_rewards/accuracies": 0.699999988079071,
      "eval_rewards/chosen": 0.01864619180560112,
      "eval_rewards/margins": 0.012645583599805832,
      "eval_rewards/rejected": 0.006000608671456575,
      "eval_runtime": 3.2009,
      "eval_samples_per_second": 31.242,
      "eval_steps_per_second": 15.621,
      "step": 169
    },
    {
      "epoch": 13.08,
      "grad_norm": 6.1757683753967285,
      "learning_rate": 8.835937499999999e-08,
      "logits/chosen": 0.9106065630912781,
      "logits/rejected": 1.1922024488449097,
      "logps/chosen": -44.355918884277344,
      "logps/rejected": -35.06133270263672,
      "loss": 0.6882,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02161872386932373,
      "rewards/margins": 0.009993935003876686,
      "rewards/rejected": 0.011624788865447044,
      "step": 170
    },
    {
      "epoch": 13.16,
      "grad_norm": 7.479901313781738,
      "learning_rate": 8.828125e-08,
      "logits/chosen": 0.978118896484375,
      "logits/rejected": 1.3201847076416016,
      "logps/chosen": -47.60044479370117,
      "logps/rejected": -35.526702880859375,
      "loss": 0.681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03223707526922226,
      "rewards/margins": 0.024519063532352448,
      "rewards/rejected": 0.007718014996498823,
      "step": 171
    },
    {
      "epoch": 13.24,
      "grad_norm": 6.1342549324035645,
      "learning_rate": 8.8203125e-08,
      "logits/chosen": 1.0705301761627197,
      "logits/rejected": 1.2502185106277466,
      "logps/chosen": -43.52918243408203,
      "logps/rejected": -30.235519409179688,
      "loss": 0.6771,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028650641441345215,
      "rewards/margins": 0.03238673508167267,
      "rewards/rejected": -0.0037360910791903734,
      "step": 172
    },
    {
      "epoch": 13.32,
      "grad_norm": 7.123756408691406,
      "learning_rate": 8.812499999999999e-08,
      "logits/chosen": 0.7300408482551575,
      "logits/rejected": 1.3331785202026367,
      "logps/chosen": -49.869178771972656,
      "logps/rejected": -36.39591979980469,
      "loss": 0.681,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02116239070892334,
      "rewards/margins": 0.02468283101916313,
      "rewards/rejected": -0.003520440775901079,
      "step": 173
    },
    {
      "epoch": 13.4,
      "grad_norm": 6.728851318359375,
      "learning_rate": 8.8046875e-08,
      "logits/chosen": 1.0328986644744873,
      "logits/rejected": 1.4721956253051758,
      "logps/chosen": -40.3387451171875,
      "logps/rejected": -34.09061050415039,
      "loss": 0.676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02983563020825386,
      "rewards/margins": 0.03474030643701553,
      "rewards/rejected": -0.004904675297439098,
      "step": 174
    },
    {
      "epoch": 13.48,
      "grad_norm": 6.824306488037109,
      "learning_rate": 8.796874999999999e-08,
      "logits/chosen": 0.9586600065231323,
      "logits/rejected": 1.336495041847229,
      "logps/chosen": -39.59482192993164,
      "logps/rejected": -38.154541015625,
      "loss": 0.6862,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02176513709127903,
      "rewards/margins": 0.013987064361572266,
      "rewards/rejected": 0.007778072729706764,
      "step": 175
    },
    {
      "epoch": 13.56,
      "grad_norm": 6.918764114379883,
      "learning_rate": 8.789062499999999e-08,
      "logits/chosen": 1.290202260017395,
      "logits/rejected": 1.7205427885055542,
      "logps/chosen": -45.63035583496094,
      "logps/rejected": -38.19529724121094,
      "loss": 0.6892,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.019649624824523926,
      "rewards/margins": 0.008126402273774147,
      "rewards/rejected": 0.011523223482072353,
      "step": 176
    },
    {
      "epoch": 13.64,
      "grad_norm": 6.722177982330322,
      "learning_rate": 8.78125e-08,
      "logits/chosen": 0.9466984868049622,
      "logits/rejected": 1.0950864553451538,
      "logps/chosen": -36.02774429321289,
      "logps/rejected": -37.90302276611328,
      "loss": 0.6806,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025392891839146614,
      "rewards/margins": 0.02539963647723198,
      "rewards/rejected": -6.747315637767315e-06,
      "step": 177
    },
    {
      "epoch": 13.72,
      "grad_norm": 6.941641807556152,
      "learning_rate": 8.7734375e-08,
      "logits/chosen": 0.8446895480155945,
      "logits/rejected": 1.2696733474731445,
      "logps/chosen": -41.52747344970703,
      "logps/rejected": -33.6075325012207,
      "loss": 0.6801,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02611394040286541,
      "rewards/margins": 0.026389027014374733,
      "rewards/rejected": -0.00027508719358593225,
      "step": 178
    },
    {
      "epoch": 13.8,
      "grad_norm": 7.5291571617126465,
      "learning_rate": 8.765625e-08,
      "logits/chosen": 0.9075920581817627,
      "logits/rejected": 1.196871280670166,
      "logps/chosen": -42.727272033691406,
      "logps/rejected": -34.43045425415039,
      "loss": 0.6809,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02863321453332901,
      "rewards/margins": 0.024672530591487885,
      "rewards/rejected": 0.003960681147873402,
      "step": 179
    },
    {
      "epoch": 13.88,
      "grad_norm": 6.735498905181885,
      "learning_rate": 8.7578125e-08,
      "logits/chosen": 1.2474627494812012,
      "logits/rejected": 1.4130048751831055,
      "logps/chosen": -43.12409973144531,
      "logps/rejected": -29.061025619506836,
      "loss": 0.6854,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.021744919940829277,
      "rewards/margins": 0.015548253431916237,
      "rewards/rejected": 0.0061966655775904655,
      "step": 180
    },
    {
      "epoch": 13.96,
      "grad_norm": 8.029991149902344,
      "learning_rate": 8.75e-08,
      "logits/chosen": 0.9548676609992981,
      "logits/rejected": 1.0478019714355469,
      "logps/chosen": -45.16176223754883,
      "logps/rejected": -36.342350006103516,
      "loss": 0.687,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.016456246376037598,
      "rewards/margins": 0.012380624189972878,
      "rewards/rejected": 0.004075623117387295,
      "step": 181
    },
    {
      "epoch": 14.0,
      "grad_norm": 10.802923202514648,
      "learning_rate": 8.7421875e-08,
      "logits/chosen": 1.0394680500030518,
      "logits/rejected": 1.4152960777282715,
      "logps/chosen": -47.35048294067383,
      "logps/rejected": -32.645408630371094,
      "loss": 0.6815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026370860636234283,
      "rewards/margins": 0.02353654056787491,
      "rewards/rejected": 0.002834320068359375,
      "step": 182
    },
    {
      "epoch": 14.0,
      "eval_logits/chosen": 0.9875741600990295,
      "eval_logits/rejected": 1.1594680547714233,
      "eval_logps/chosen": -39.51654815673828,
      "eval_logps/rejected": -37.13163757324219,
      "eval_loss": 0.6858863830566406,
      "eval_rewards/accuracies": 0.7200000286102295,
      "eval_rewards/chosen": 0.020902249962091446,
      "eval_rewards/margins": 0.014726635068655014,
      "eval_rewards/rejected": 0.00617561349645257,
      "eval_runtime": 3.2133,
      "eval_samples_per_second": 31.12,
      "eval_steps_per_second": 15.56,
      "step": 182
    },
    {
      "epoch": 14.08,
      "grad_norm": 7.815036773681641,
      "learning_rate": 8.734375e-08,
      "logits/chosen": 0.9718518257141113,
      "logits/rejected": 1.4278347492218018,
      "logps/chosen": -41.195640563964844,
      "logps/rejected": -36.707183837890625,
      "loss": 0.6892,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01559913158416748,
      "rewards/margins": 0.008154178038239479,
      "rewards/rejected": 0.007444954011589289,
      "step": 183
    },
    {
      "epoch": 14.16,
      "grad_norm": 7.887627601623535,
      "learning_rate": 8.7265625e-08,
      "logits/chosen": 1.1099398136138916,
      "logits/rejected": 1.295911192893982,
      "logps/chosen": -46.984474182128906,
      "logps/rejected": -41.123355865478516,
      "loss": 0.6862,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01964447647333145,
      "rewards/margins": 0.014180469326674938,
      "rewards/rejected": 0.005464005749672651,
      "step": 184
    },
    {
      "epoch": 14.24,
      "grad_norm": 7.599674224853516,
      "learning_rate": 8.718749999999999e-08,
      "logits/chosen": 1.1186821460723877,
      "logits/rejected": 1.318913459777832,
      "logps/chosen": -48.21076202392578,
      "logps/rejected": -29.793357849121094,
      "loss": 0.6806,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.03231382369995117,
      "rewards/margins": 0.025410080328583717,
      "rewards/rejected": 0.006903743837028742,
      "step": 185
    },
    {
      "epoch": 14.32,
      "grad_norm": 6.375941276550293,
      "learning_rate": 8.7109375e-08,
      "logits/chosen": 0.86117023229599,
      "logits/rejected": 1.3195165395736694,
      "logps/chosen": -38.08857345581055,
      "logps/rejected": -32.770042419433594,
      "loss": 0.6846,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016939951106905937,
      "rewards/margins": 0.017133045941591263,
      "rewards/rejected": -0.00019309530034661293,
      "step": 186
    },
    {
      "epoch": 14.4,
      "grad_norm": 6.795361518859863,
      "learning_rate": 8.703125e-08,
      "logits/chosen": 1.1344366073608398,
      "logits/rejected": 1.2591978311538696,
      "logps/chosen": -48.22761154174805,
      "logps/rejected": -33.87983322143555,
      "loss": 0.6811,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02578919008374214,
      "rewards/margins": 0.0244600772857666,
      "rewards/rejected": 0.0013291120994836092,
      "step": 187
    },
    {
      "epoch": 14.48,
      "grad_norm": 6.461367607116699,
      "learning_rate": 8.695312499999999e-08,
      "logits/chosen": 0.9307911396026611,
      "logits/rejected": 1.2524492740631104,
      "logps/chosen": -37.526893615722656,
      "logps/rejected": -34.45610427856445,
      "loss": 0.6914,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.012374497018754482,
      "rewards/margins": 0.0036683320067822933,
      "rewards/rejected": 0.008706165477633476,
      "step": 188
    },
    {
      "epoch": 14.56,
      "grad_norm": 6.0688300132751465,
      "learning_rate": 8.6875e-08,
      "logits/chosen": 0.886216938495636,
      "logits/rejected": 1.14763343334198,
      "logps/chosen": -35.94532012939453,
      "logps/rejected": -38.33631134033203,
      "loss": 0.6761,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03604171425104141,
      "rewards/margins": 0.034519195556640625,
      "rewards/rejected": 0.0015225171810016036,
      "step": 189
    },
    {
      "epoch": 14.64,
      "grad_norm": 6.013044357299805,
      "learning_rate": 8.679687499999999e-08,
      "logits/chosen": 0.8861210346221924,
      "logits/rejected": 1.3985466957092285,
      "logps/chosen": -37.6961784362793,
      "logps/rejected": -37.299930572509766,
      "loss": 0.6851,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02520301379263401,
      "rewards/margins": 0.016124391928315163,
      "rewards/rejected": 0.009078621864318848,
      "step": 190
    },
    {
      "epoch": 14.72,
      "grad_norm": 7.468744277954102,
      "learning_rate": 8.671874999999999e-08,
      "logits/chosen": 0.9012625217437744,
      "logits/rejected": 1.2502623796463013,
      "logps/chosen": -45.19150924682617,
      "logps/rejected": -34.019737243652344,
      "loss": 0.6846,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02630608156323433,
      "rewards/margins": 0.017264770343899727,
      "rewards/rejected": 0.009041309356689453,
      "step": 191
    },
    {
      "epoch": 14.8,
      "grad_norm": 7.092419147491455,
      "learning_rate": 8.6640625e-08,
      "logits/chosen": 1.1896229982376099,
      "logits/rejected": 1.4043411016464233,
      "logps/chosen": -57.62498474121094,
      "logps/rejected": -31.444190979003906,
      "loss": 0.6782,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.030443573370575905,
      "rewards/margins": 0.03031313419342041,
      "rewards/rejected": 0.00013043871149420738,
      "step": 192
    },
    {
      "epoch": 14.88,
      "grad_norm": 7.314545154571533,
      "learning_rate": 8.656249999999999e-08,
      "logits/chosen": 0.9489394426345825,
      "logits/rejected": 1.311727523803711,
      "logps/chosen": -48.64164352416992,
      "logps/rejected": -37.084136962890625,
      "loss": 0.6833,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.029973100870847702,
      "rewards/margins": 0.02008824422955513,
      "rewards/rejected": 0.009884858503937721,
      "step": 193
    },
    {
      "epoch": 14.96,
      "grad_norm": 6.381030559539795,
      "learning_rate": 8.648437499999999e-08,
      "logits/chosen": 0.6711323261260986,
      "logits/rejected": 1.2727577686309814,
      "logps/chosen": -37.397911071777344,
      "logps/rejected": -33.379974365234375,
      "loss": 0.6758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028889276087284088,
      "rewards/margins": 0.035001374781131744,
      "rewards/rejected": -0.0061120991595089436,
      "step": 194
    },
    {
      "epoch": 15.0,
      "grad_norm": 8.523486137390137,
      "learning_rate": 8.640624999999999e-08,
      "logits/chosen": 1.3627336025238037,
      "logits/rejected": 1.2232210636138916,
      "logps/chosen": -40.72593688964844,
      "logps/rejected": -29.88129234313965,
      "loss": 0.6807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021897222846746445,
      "rewards/margins": 0.025071144104003906,
      "rewards/rejected": -0.0031739238183945417,
      "step": 195
    },
    {
      "epoch": 15.0,
      "eval_logits/chosen": 0.9845183491706848,
      "eval_logits/rejected": 1.1561278104782104,
      "eval_logps/chosen": -39.494747161865234,
      "eval_logps/rejected": -37.13703536987305,
      "eval_loss": 0.6845212578773499,
      "eval_rewards/accuracies": 0.7900000214576721,
      "eval_rewards/chosen": 0.02308235876262188,
      "eval_rewards/margins": 0.01744619570672512,
      "eval_rewards/rejected": 0.005636167712509632,
      "eval_runtime": 3.2107,
      "eval_samples_per_second": 31.146,
      "eval_steps_per_second": 15.573,
      "step": 195
    },
    {
      "epoch": 15.08,
      "grad_norm": 6.17588472366333,
      "learning_rate": 8.6328125e-08,
      "logits/chosen": 1.017296552658081,
      "logits/rejected": 1.2807142734527588,
      "logps/chosen": -39.68939208984375,
      "logps/rejected": -31.461421966552734,
      "loss": 0.6831,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014193223789334297,
      "rewards/margins": 0.020166708156466484,
      "rewards/rejected": -0.005973482504487038,
      "step": 196
    },
    {
      "epoch": 15.16,
      "grad_norm": 7.108457565307617,
      "learning_rate": 8.625e-08,
      "logits/chosen": 1.041938304901123,
      "logits/rejected": 1.4158581495285034,
      "logps/chosen": -41.620147705078125,
      "logps/rejected": -35.2277946472168,
      "loss": 0.6807,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.030457761138677597,
      "rewards/margins": 0.02520425245165825,
      "rewards/rejected": 0.005253505427390337,
      "step": 197
    },
    {
      "epoch": 15.24,
      "grad_norm": 7.227321147918701,
      "learning_rate": 8.6171875e-08,
      "logits/chosen": 1.0669454336166382,
      "logits/rejected": 1.1686699390411377,
      "logps/chosen": -45.72798156738281,
      "logps/rejected": -43.005836486816406,
      "loss": 0.6911,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.016753364354372025,
      "rewards/margins": 0.004094814881682396,
      "rewards/rejected": 0.012658549472689629,
      "step": 198
    },
    {
      "epoch": 15.32,
      "grad_norm": 6.2374348640441895,
      "learning_rate": 8.609375e-08,
      "logits/chosen": 0.9829411506652832,
      "logits/rejected": 1.293938398361206,
      "logps/chosen": -43.198768615722656,
      "logps/rejected": -34.9267578125,
      "loss": 0.6876,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.027804231271147728,
      "rewards/margins": 0.011270570568740368,
      "rewards/rejected": 0.016533661633729935,
      "step": 199
    },
    {
      "epoch": 15.4,
      "grad_norm": 7.9782185554504395,
      "learning_rate": 8.6015625e-08,
      "logits/chosen": 0.8698121309280396,
      "logits/rejected": 1.381117820739746,
      "logps/chosen": -34.001197814941406,
      "logps/rejected": -34.38673400878906,
      "loss": 0.6795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034958433359861374,
      "rewards/margins": 0.027600383386015892,
      "rewards/rejected": 0.0073580509051680565,
      "step": 200
    },
    {
      "epoch": 15.48,
      "grad_norm": 6.525725364685059,
      "learning_rate": 8.59375e-08,
      "logits/chosen": 1.040624737739563,
      "logits/rejected": 1.4705597162246704,
      "logps/chosen": -48.97252655029297,
      "logps/rejected": -28.606338500976562,
      "loss": 0.6796,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025390077382326126,
      "rewards/margins": 0.02737893909215927,
      "rewards/rejected": -0.0019888635724782944,
      "step": 201
    },
    {
      "epoch": 15.56,
      "grad_norm": 6.132177352905273,
      "learning_rate": 8.5859375e-08,
      "logits/chosen": 0.8568705320358276,
      "logits/rejected": 1.4159479141235352,
      "logps/chosen": -40.27033233642578,
      "logps/rejected": -37.278324127197266,
      "loss": 0.6777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030338384211063385,
      "rewards/margins": 0.0312594436109066,
      "rewards/rejected": -0.000921058701351285,
      "step": 202
    },
    {
      "epoch": 15.64,
      "grad_norm": 7.0368218421936035,
      "learning_rate": 8.578125e-08,
      "logits/chosen": 0.8389081358909607,
      "logits/rejected": 1.2870615720748901,
      "logps/chosen": -46.257354736328125,
      "logps/rejected": -34.69764709472656,
      "loss": 0.6759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03203275054693222,
      "rewards/margins": 0.03487281873822212,
      "rewards/rejected": -0.002840066095814109,
      "step": 203
    },
    {
      "epoch": 15.72,
      "grad_norm": 6.967923164367676,
      "learning_rate": 8.5703125e-08,
      "logits/chosen": 1.096709966659546,
      "logits/rejected": 1.1894291639328003,
      "logps/chosen": -42.6492919921875,
      "logps/rejected": -37.32164764404297,
      "loss": 0.679,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02494950406253338,
      "rewards/margins": 0.028588341549038887,
      "rewards/rejected": -0.0036388400476425886,
      "step": 204
    },
    {
      "epoch": 15.8,
      "grad_norm": 7.540487766265869,
      "learning_rate": 8.562499999999999e-08,
      "logits/chosen": 0.9711670875549316,
      "logits/rejected": 1.3906269073486328,
      "logps/chosen": -41.07941818237305,
      "logps/rejected": -33.88494873046875,
      "loss": 0.6718,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03514392673969269,
      "rewards/margins": 0.04345882683992386,
      "rewards/rejected": -0.008314896374940872,
      "step": 205
    },
    {
      "epoch": 15.88,
      "grad_norm": 7.68705415725708,
      "learning_rate": 8.5546875e-08,
      "logits/chosen": 0.7680326700210571,
      "logits/rejected": 1.1605063676834106,
      "logps/chosen": -44.03024673461914,
      "logps/rejected": -32.70145797729492,
      "loss": 0.6846,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.029748966917395592,
      "rewards/margins": 0.017443513497710228,
      "rewards/rejected": 0.012305451557040215,
      "step": 206
    },
    {
      "epoch": 15.96,
      "grad_norm": 6.862789154052734,
      "learning_rate": 8.546875e-08,
      "logits/chosen": 1.2168140411376953,
      "logits/rejected": 1.2644619941711426,
      "logps/chosen": -51.453887939453125,
      "logps/rejected": -35.64642333984375,
      "loss": 0.6876,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.02813420444726944,
      "rewards/margins": 0.0112395528703928,
      "rewards/rejected": 0.01689465157687664,
      "step": 207
    },
    {
      "epoch": 16.0,
      "grad_norm": 9.150660514831543,
      "learning_rate": 8.539062499999999e-08,
      "logits/chosen": 1.083871603012085,
      "logits/rejected": 1.1751430034637451,
      "logps/chosen": -47.73516845703125,
      "logps/rejected": -32.04314422607422,
      "loss": 0.6839,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.03130684047937393,
      "rewards/margins": 0.018641948699951172,
      "rewards/rejected": 0.01266488991677761,
      "step": 208
    },
    {
      "epoch": 16.0,
      "eval_logits/chosen": 0.9836480617523193,
      "eval_logits/rejected": 1.1546924114227295,
      "eval_logps/chosen": -39.466285705566406,
      "eval_logps/rejected": -37.099510192871094,
      "eval_loss": 0.6849728226661682,
      "eval_rewards/accuracies": 0.7599999904632568,
      "eval_rewards/chosen": 0.025928761810064316,
      "eval_rewards/margins": 0.01654031313955784,
      "eval_rewards/rejected": 0.009388447739183903,
      "eval_runtime": 3.2012,
      "eval_samples_per_second": 31.239,
      "eval_steps_per_second": 15.619,
      "step": 208
    },
    {
      "epoch": 16.08,
      "grad_norm": 7.24628210067749,
      "learning_rate": 8.53125e-08,
      "logits/chosen": 0.8090273141860962,
      "logits/rejected": 1.4348393678665161,
      "logps/chosen": -48.401573181152344,
      "logps/rejected": -35.49839782714844,
      "loss": 0.6807,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.036151956766843796,
      "rewards/margins": 0.02516958676278591,
      "rewards/rejected": 0.010982371866703033,
      "step": 209
    },
    {
      "epoch": 16.16,
      "grad_norm": 6.302029609680176,
      "learning_rate": 8.523437499999999e-08,
      "logits/chosen": 1.2667934894561768,
      "logits/rejected": 1.3851327896118164,
      "logps/chosen": -50.63496780395508,
      "logps/rejected": -39.673301696777344,
      "loss": 0.6844,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.027785517275333405,
      "rewards/margins": 0.017721081152558327,
      "rewards/rejected": 0.010064435191452503,
      "step": 210
    },
    {
      "epoch": 16.24,
      "grad_norm": 6.557783126831055,
      "learning_rate": 8.515624999999999e-08,
      "logits/chosen": 0.7318204045295715,
      "logits/rejected": 1.1864906549453735,
      "logps/chosen": -39.81378173828125,
      "logps/rejected": -31.63555908203125,
      "loss": 0.6845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018107224255800247,
      "rewards/margins": 0.017486073076725006,
      "rewards/rejected": 0.0006211520521901548,
      "step": 211
    },
    {
      "epoch": 16.32,
      "grad_norm": 7.763466835021973,
      "learning_rate": 8.5078125e-08,
      "logits/chosen": 1.1055920124053955,
      "logits/rejected": 1.4932093620300293,
      "logps/chosen": -51.38581085205078,
      "logps/rejected": -37.15961456298828,
      "loss": 0.6796,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022758031263947487,
      "rewards/margins": 0.02726149559020996,
      "rewards/rejected": -0.004503464326262474,
      "step": 212
    },
    {
      "epoch": 16.4,
      "grad_norm": 6.797053337097168,
      "learning_rate": 8.5e-08,
      "logits/chosen": 0.8646864891052246,
      "logits/rejected": 1.2526664733886719,
      "logps/chosen": -34.75894546508789,
      "logps/rejected": -35.098411560058594,
      "loss": 0.6832,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.024576235562562943,
      "rewards/margins": 0.020009255036711693,
      "rewards/rejected": 0.004566979594528675,
      "step": 213
    },
    {
      "epoch": 16.48,
      "grad_norm": 7.678524017333984,
      "learning_rate": 8.4921875e-08,
      "logits/chosen": 0.9002561569213867,
      "logits/rejected": 1.279971718788147,
      "logps/chosen": -42.774375915527344,
      "logps/rejected": -32.59485626220703,
      "loss": 0.6771,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02879660204052925,
      "rewards/margins": 0.0325542688369751,
      "rewards/rejected": -0.0037576681934297085,
      "step": 214
    },
    {
      "epoch": 16.56,
      "grad_norm": 6.892497539520264,
      "learning_rate": 8.484375e-08,
      "logits/chosen": 0.9867788553237915,
      "logits/rejected": 1.2948678731918335,
      "logps/chosen": -34.54072952270508,
      "logps/rejected": -33.666133880615234,
      "loss": 0.6755,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03428225591778755,
      "rewards/margins": 0.035779811441898346,
      "rewards/rejected": -0.0014975545927882195,
      "step": 215
    },
    {
      "epoch": 16.64,
      "grad_norm": 6.760197639465332,
      "learning_rate": 8.4765625e-08,
      "logits/chosen": 0.9637514352798462,
      "logits/rejected": 1.3068331480026245,
      "logps/chosen": -41.502159118652344,
      "logps/rejected": -36.28091812133789,
      "loss": 0.6804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03287713602185249,
      "rewards/margins": 0.025729965418577194,
      "rewards/rejected": 0.0071471696719527245,
      "step": 216
    },
    {
      "epoch": 16.72,
      "grad_norm": 5.277157783508301,
      "learning_rate": 8.46875e-08,
      "logits/chosen": 0.8122605681419373,
      "logits/rejected": 1.243188738822937,
      "logps/chosen": -35.88698196411133,
      "logps/rejected": -31.44174575805664,
      "loss": 0.6847,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.025739334523677826,
      "rewards/margins": 0.017012596130371094,
      "rewards/rejected": 0.008726740255951881,
      "step": 217
    },
    {
      "epoch": 16.8,
      "grad_norm": 6.681907653808594,
      "learning_rate": 8.4609375e-08,
      "logits/chosen": 1.249549388885498,
      "logits/rejected": 1.2669472694396973,
      "logps/chosen": -49.51699447631836,
      "logps/rejected": -33.77760314941406,
      "loss": 0.6823,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03476116806268692,
      "rewards/margins": 0.021817851811647415,
      "rewards/rejected": 0.012943316251039505,
      "step": 218
    },
    {
      "epoch": 16.88,
      "grad_norm": 8.77807903289795,
      "learning_rate": 8.453125e-08,
      "logits/chosen": 1.073080062866211,
      "logits/rejected": 1.1898692846298218,
      "logps/chosen": -42.19208526611328,
      "logps/rejected": -33.62709426879883,
      "loss": 0.6794,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03358614817261696,
      "rewards/margins": 0.02780463919043541,
      "rewards/rejected": 0.005781507585197687,
      "step": 219
    },
    {
      "epoch": 16.96,
      "grad_norm": 6.392523765563965,
      "learning_rate": 8.445312499999999e-08,
      "logits/chosen": 1.0056239366531372,
      "logits/rejected": 1.1405736207962036,
      "logps/chosen": -46.1815185546875,
      "logps/rejected": -37.54741668701172,
      "loss": 0.676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.035793449729681015,
      "rewards/margins": 0.03464937210083008,
      "rewards/rejected": 0.0011440750677138567,
      "step": 220
    },
    {
      "epoch": 17.0,
      "grad_norm": 8.798298835754395,
      "learning_rate": 8.4375e-08,
      "logits/chosen": 0.9458733797073364,
      "logits/rejected": 1.4976441860198975,
      "logps/chosen": -50.00127410888672,
      "logps/rejected": -34.54071044921875,
      "loss": 0.6775,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.030756857246160507,
      "rewards/margins": 0.03188972547650337,
      "rewards/rejected": -0.001132869627326727,
      "step": 221
    },
    {
      "epoch": 17.0,
      "eval_logits/chosen": 0.9838354587554932,
      "eval_logits/rejected": 1.1550754308700562,
      "eval_logps/chosen": -39.47025680541992,
      "eval_logps/rejected": -37.12871551513672,
      "eval_loss": 0.68373703956604,
      "eval_rewards/accuracies": 0.7300000190734863,
      "eval_rewards/chosen": 0.02553137019276619,
      "eval_rewards/margins": 0.019063524901866913,
      "eval_rewards/rejected": 0.006467845290899277,
      "eval_runtime": 3.2003,
      "eval_samples_per_second": 31.247,
      "eval_steps_per_second": 15.624,
      "step": 221
    },
    {
      "epoch": 17.08,
      "grad_norm": 6.8479413986206055,
      "learning_rate": 8.4296875e-08,
      "logits/chosen": 1.0104244947433472,
      "logits/rejected": 1.2729856967926025,
      "logps/chosen": -41.526947021484375,
      "logps/rejected": -36.388427734375,
      "loss": 0.6761,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.035729385912418365,
      "rewards/margins": 0.034554123878479004,
      "rewards/rejected": 0.0011752608697861433,
      "step": 222
    },
    {
      "epoch": 17.16,
      "grad_norm": 6.112931728363037,
      "learning_rate": 8.421874999999999e-08,
      "logits/chosen": 1.0327104330062866,
      "logits/rejected": 1.427505373954773,
      "logps/chosen": -36.8834114074707,
      "logps/rejected": -32.73175048828125,
      "loss": 0.6813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025960206985473633,
      "rewards/margins": 0.023785782977938652,
      "rewards/rejected": 0.0021744249388575554,
      "step": 223
    },
    {
      "epoch": 17.24,
      "grad_norm": 6.926791667938232,
      "learning_rate": 8.4140625e-08,
      "logits/chosen": 1.1589010953903198,
      "logits/rejected": 1.504380702972412,
      "logps/chosen": -49.20989990234375,
      "logps/rejected": -36.46143341064453,
      "loss": 0.6839,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.039647508412599564,
      "rewards/margins": 0.018796587362885475,
      "rewards/rejected": 0.02085091918706894,
      "step": 224
    },
    {
      "epoch": 17.32,
      "grad_norm": 6.654617786407471,
      "learning_rate": 8.406249999999999e-08,
      "logits/chosen": 1.0094760656356812,
      "logits/rejected": 1.4388090372085571,
      "logps/chosen": -36.18039321899414,
      "logps/rejected": -34.214385986328125,
      "loss": 0.6763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04428064823150635,
      "rewards/margins": 0.034095071256160736,
      "rewards/rejected": 0.010185575112700462,
      "step": 225
    },
    {
      "epoch": 17.4,
      "grad_norm": 6.831750392913818,
      "learning_rate": 8.398437499999999e-08,
      "logits/chosen": 0.9907487630844116,
      "logits/rejected": 1.3202425241470337,
      "logps/chosen": -47.17194366455078,
      "logps/rejected": -33.535926818847656,
      "loss": 0.6765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.037151362746953964,
      "rewards/margins": 0.03364846855401993,
      "rewards/rejected": 0.0035028932616114616,
      "step": 226
    },
    {
      "epoch": 17.48,
      "grad_norm": 6.748156547546387,
      "learning_rate": 8.390625e-08,
      "logits/chosen": 0.7917318344116211,
      "logits/rejected": 1.1960201263427734,
      "logps/chosen": -36.96868133544922,
      "logps/rejected": -32.10077667236328,
      "loss": 0.6805,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.028783582150936127,
      "rewards/margins": 0.02543916553258896,
      "rewards/rejected": 0.0033444163855165243,
      "step": 227
    },
    {
      "epoch": 17.56,
      "grad_norm": 8.489765167236328,
      "learning_rate": 8.382812499999999e-08,
      "logits/chosen": 1.0507878065109253,
      "logits/rejected": 1.382651925086975,
      "logps/chosen": -56.234310150146484,
      "logps/rejected": -37.5119743347168,
      "loss": 0.6692,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.05077838897705078,
      "rewards/margins": 0.04901421070098877,
      "rewards/rejected": 0.0017641782760620117,
      "step": 228
    },
    {
      "epoch": 17.64,
      "grad_norm": 6.564920425415039,
      "learning_rate": 8.374999999999999e-08,
      "logits/chosen": 1.0874322652816772,
      "logits/rejected": 0.9322249889373779,
      "logps/chosen": -40.10774230957031,
      "logps/rejected": -28.455150604248047,
      "loss": 0.6812,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024439144879579544,
      "rewards/margins": 0.024079633876681328,
      "rewards/rejected": 0.0003595112939365208,
      "step": 229
    },
    {
      "epoch": 17.72,
      "grad_norm": 6.704054832458496,
      "learning_rate": 8.367187499999999e-08,
      "logits/chosen": 1.0620384216308594,
      "logits/rejected": 1.2843152284622192,
      "logps/chosen": -39.42580032348633,
      "logps/rejected": -39.46049499511719,
      "loss": 0.6792,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.023307133466005325,
      "rewards/margins": 0.028109025210142136,
      "rewards/rejected": -0.004801893141120672,
      "step": 230
    },
    {
      "epoch": 17.8,
      "grad_norm": 6.676177501678467,
      "learning_rate": 8.359375e-08,
      "logits/chosen": 0.9517647624015808,
      "logits/rejected": 1.3674366474151611,
      "logps/chosen": -48.00311279296875,
      "logps/rejected": -36.3510627746582,
      "loss": 0.6728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.036464620381593704,
      "rewards/margins": 0.04112262651324272,
      "rewards/rejected": -0.0046580079942941666,
      "step": 231
    },
    {
      "epoch": 17.88,
      "grad_norm": 7.7560882568359375,
      "learning_rate": 8.3515625e-08,
      "logits/chosen": 0.8426128625869751,
      "logits/rejected": 1.2765133380889893,
      "logps/chosen": -51.319114685058594,
      "logps/rejected": -31.29105567932129,
      "loss": 0.6808,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0323060005903244,
      "rewards/margins": 0.024887727573513985,
      "rewards/rejected": 0.007418275345116854,
      "step": 232
    },
    {
      "epoch": 17.96,
      "grad_norm": 6.358179569244385,
      "learning_rate": 8.34375e-08,
      "logits/chosen": 0.8128694295883179,
      "logits/rejected": 1.2523609399795532,
      "logps/chosen": -38.7485466003418,
      "logps/rejected": -38.65147399902344,
      "loss": 0.6748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0415877103805542,
      "rewards/margins": 0.03724219650030136,
      "rewards/rejected": 0.004345512483268976,
      "step": 233
    },
    {
      "epoch": 18.0,
      "grad_norm": 10.37019157409668,
      "learning_rate": 8.3359375e-08,
      "logits/chosen": 1.0747594833374023,
      "logits/rejected": 1.4900469779968262,
      "logps/chosen": -40.15242004394531,
      "logps/rejected": -36.09027862548828,
      "loss": 0.6854,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.039852239191532135,
      "rewards/margins": 0.015696240589022636,
      "rewards/rejected": 0.0241559986025095,
      "step": 234
    },
    {
      "epoch": 18.0,
      "eval_logits/chosen": 0.9828016757965088,
      "eval_logits/rejected": 1.1541712284088135,
      "eval_logps/chosen": -39.438419342041016,
      "eval_logps/rejected": -37.11381912231445,
      "eval_loss": 0.6829216480255127,
      "eval_rewards/accuracies": 0.7599999904632568,
      "eval_rewards/chosen": 0.028715305030345917,
      "eval_rewards/margins": 0.020758261904120445,
      "eval_rewards/rejected": 0.00795704685151577,
      "eval_runtime": 3.2209,
      "eval_samples_per_second": 31.047,
      "eval_steps_per_second": 15.524,
      "step": 234
    },
    {
      "epoch": 18.08,
      "grad_norm": 6.382909297943115,
      "learning_rate": 8.328125e-08,
      "logits/chosen": 0.878914475440979,
      "logits/rejected": 1.3847291469573975,
      "logps/chosen": -37.74687194824219,
      "logps/rejected": -32.04269790649414,
      "loss": 0.6816,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0291840061545372,
      "rewards/margins": 0.02332773059606552,
      "rewards/rejected": 0.00585627555847168,
      "step": 235
    },
    {
      "epoch": 18.16,
      "grad_norm": 6.835203647613525,
      "learning_rate": 8.3203125e-08,
      "logits/chosen": 1.0333645343780518,
      "logits/rejected": 1.2674745321273804,
      "logps/chosen": -44.634368896484375,
      "logps/rejected": -40.365325927734375,
      "loss": 0.6824,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.04565546661615372,
      "rewards/margins": 0.02182614803314209,
      "rewards/rejected": 0.023829318583011627,
      "step": 236
    },
    {
      "epoch": 18.24,
      "grad_norm": 6.466838836669922,
      "learning_rate": 8.3125e-08,
      "logits/chosen": 0.8212800025939941,
      "logits/rejected": 1.1727749109268188,
      "logps/chosen": -41.12421798706055,
      "logps/rejected": -35.26033020019531,
      "loss": 0.6813,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.022614598274230957,
      "rewards/margins": 0.02401268482208252,
      "rewards/rejected": -0.0013980865478515625,
      "step": 237
    },
    {
      "epoch": 18.32,
      "grad_norm": 7.764700412750244,
      "learning_rate": 8.3046875e-08,
      "logits/chosen": 0.7841242551803589,
      "logits/rejected": 1.3864935636520386,
      "logps/chosen": -58.56840133666992,
      "logps/rejected": -36.229652404785156,
      "loss": 0.6665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05901229754090309,
      "rewards/margins": 0.053949400782585144,
      "rewards/rejected": 0.005062890239059925,
      "step": 238
    },
    {
      "epoch": 18.4,
      "grad_norm": 6.795853137969971,
      "learning_rate": 8.296875e-08,
      "logits/chosen": 1.1282861232757568,
      "logits/rejected": 1.1140481233596802,
      "logps/chosen": -42.79328918457031,
      "logps/rejected": -32.73862838745117,
      "loss": 0.6749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04200882837176323,
      "rewards/margins": 0.03703146055340767,
      "rewards/rejected": 0.0049773696810007095,
      "step": 239
    },
    {
      "epoch": 18.48,
      "grad_norm": 6.505430221557617,
      "learning_rate": 8.289062499999999e-08,
      "logits/chosen": 1.197671890258789,
      "logits/rejected": 1.681480050086975,
      "logps/chosen": -40.37078857421875,
      "logps/rejected": -30.182350158691406,
      "loss": 0.6811,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.03366811200976372,
      "rewards/margins": 0.024392269551753998,
      "rewards/rejected": 0.00927584245800972,
      "step": 240
    },
    {
      "epoch": 18.56,
      "grad_norm": 7.553402423858643,
      "learning_rate": 8.28125e-08,
      "logits/chosen": 0.7320769429206848,
      "logits/rejected": 1.2688854932785034,
      "logps/chosen": -31.761348724365234,
      "logps/rejected": -32.54558563232422,
      "loss": 0.6748,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03519222512841225,
      "rewards/margins": 0.037198614329099655,
      "rewards/rejected": -0.0020063878037035465,
      "step": 241
    },
    {
      "epoch": 18.64,
      "grad_norm": 8.186359405517578,
      "learning_rate": 8.2734375e-08,
      "logits/chosen": 0.9797898530960083,
      "logits/rejected": 1.4504311084747314,
      "logps/chosen": -45.00052261352539,
      "logps/rejected": -35.90851593017578,
      "loss": 0.678,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.045438386499881744,
      "rewards/margins": 0.03069593757390976,
      "rewards/rejected": 0.014742446132004261,
      "step": 242
    },
    {
      "epoch": 18.72,
      "grad_norm": 5.988753795623779,
      "learning_rate": 8.265624999999999e-08,
      "logits/chosen": 0.8316704630851746,
      "logits/rejected": 1.2051939964294434,
      "logps/chosen": -41.25926971435547,
      "logps/rejected": -32.29472351074219,
      "loss": 0.6763,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.031655095517635345,
      "rewards/margins": 0.034212470054626465,
      "rewards/rejected": -0.002557372907176614,
      "step": 243
    },
    {
      "epoch": 18.8,
      "grad_norm": 7.019861698150635,
      "learning_rate": 8.2578125e-08,
      "logits/chosen": 1.0261459350585938,
      "logits/rejected": 1.1492185592651367,
      "logps/chosen": -45.854331970214844,
      "logps/rejected": -33.62052536010742,
      "loss": 0.6669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.050373125821352005,
      "rewards/margins": 0.05342550203204155,
      "rewards/rejected": -0.0030523776076734066,
      "step": 244
    },
    {
      "epoch": 18.88,
      "grad_norm": 6.787487506866455,
      "learning_rate": 8.249999999999999e-08,
      "logits/chosen": 1.1799520254135132,
      "logits/rejected": 1.1131572723388672,
      "logps/chosen": -45.47941589355469,
      "logps/rejected": -41.91216278076172,
      "loss": 0.6762,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04711537808179855,
      "rewards/margins": 0.034238673746585846,
      "rewards/rejected": 0.012876701541244984,
      "step": 245
    },
    {
      "epoch": 18.96,
      "grad_norm": 7.222323417663574,
      "learning_rate": 8.242187499999999e-08,
      "logits/chosen": 1.1322757005691528,
      "logits/rejected": 1.2820802927017212,
      "logps/chosen": -50.93561935424805,
      "logps/rejected": -34.73299026489258,
      "loss": 0.6729,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.036741189658641815,
      "rewards/margins": 0.041063882410526276,
      "rewards/rejected": -0.004322695080190897,
      "step": 246
    },
    {
      "epoch": 19.0,
      "grad_norm": 6.945464134216309,
      "learning_rate": 8.234375e-08,
      "logits/chosen": 1.1256883144378662,
      "logits/rejected": 1.4328773021697998,
      "logps/chosen": -31.456832885742188,
      "logps/rejected": -34.468746185302734,
      "loss": 0.6855,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.016972064971923828,
      "rewards/margins": 0.015488052740693092,
      "rewards/rejected": 0.0014840125804767013,
      "step": 247
    },
    {
      "epoch": 19.0,
      "eval_logits/chosen": 0.9812267422676086,
      "eval_logits/rejected": 1.1520498991012573,
      "eval_logps/chosen": -39.37588882446289,
      "eval_logps/rejected": -37.03156280517578,
      "eval_loss": 0.6838797926902771,
      "eval_rewards/accuracies": 0.7699999809265137,
      "eval_rewards/chosen": 0.03496810048818588,
      "eval_rewards/margins": 0.018784932792186737,
      "eval_rewards/rejected": 0.016183165833353996,
      "eval_runtime": 3.2182,
      "eval_samples_per_second": 31.073,
      "eval_steps_per_second": 15.536,
      "step": 247
    },
    {
      "epoch": 19.08,
      "grad_norm": 7.393557071685791,
      "learning_rate": 8.226562499999999e-08,
      "logits/chosen": 1.1017727851867676,
      "logits/rejected": 1.126983880996704,
      "logps/chosen": -37.42992401123047,
      "logps/rejected": -35.43160629272461,
      "loss": 0.6701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04408712685108185,
      "rewards/margins": 0.04685597121715546,
      "rewards/rejected": -0.0027688504196703434,
      "step": 248
    },
    {
      "epoch": 19.16,
      "grad_norm": 7.37894344329834,
      "learning_rate": 8.21875e-08,
      "logits/chosen": 0.9555284976959229,
      "logits/rejected": 1.1555687189102173,
      "logps/chosen": -40.536556243896484,
      "logps/rejected": -32.183624267578125,
      "loss": 0.672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.045095156878232956,
      "rewards/margins": 0.042876794934272766,
      "rewards/rejected": 0.0022183656692504883,
      "step": 249
    },
    {
      "epoch": 19.24,
      "grad_norm": 7.238245010375977,
      "learning_rate": 8.2109375e-08,
      "logits/chosen": 0.752435564994812,
      "logits/rejected": 1.3336031436920166,
      "logps/chosen": -49.494380950927734,
      "logps/rejected": -30.963035583496094,
      "loss": 0.6762,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04067106544971466,
      "rewards/margins": 0.034263208508491516,
      "rewards/rejected": 0.006407857406884432,
      "step": 250
    },
    {
      "epoch": 19.32,
      "grad_norm": 7.653852939605713,
      "learning_rate": 8.203125e-08,
      "logits/chosen": 0.8330053687095642,
      "logits/rejected": 1.2591801881790161,
      "logps/chosen": -45.10233688354492,
      "logps/rejected": -31.214418411254883,
      "loss": 0.6779,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03302722051739693,
      "rewards/margins": 0.030976487323641777,
      "rewards/rejected": 0.0020507334265857935,
      "step": 251
    },
    {
      "epoch": 19.4,
      "grad_norm": 7.136594295501709,
      "learning_rate": 8.1953125e-08,
      "logits/chosen": 1.0483074188232422,
      "logits/rejected": 1.1291097402572632,
      "logps/chosen": -46.21168899536133,
      "logps/rejected": -38.085140228271484,
      "loss": 0.6789,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04272143915295601,
      "rewards/margins": 0.028798293322324753,
      "rewards/rejected": 0.013923144899308681,
      "step": 252
    },
    {
      "epoch": 19.48,
      "grad_norm": 6.080962181091309,
      "learning_rate": 8.1875e-08,
      "logits/chosen": 1.2042858600616455,
      "logits/rejected": 1.4850380420684814,
      "logps/chosen": -50.15913391113281,
      "logps/rejected": -33.43839645385742,
      "loss": 0.679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024575019255280495,
      "rewards/margins": 0.028559302911162376,
      "rewards/rejected": -0.003984284587204456,
      "step": 253
    },
    {
      "epoch": 19.56,
      "grad_norm": 9.287163734436035,
      "learning_rate": 8.1796875e-08,
      "logits/chosen": 0.9608374834060669,
      "logits/rejected": 1.1406131982803345,
      "logps/chosen": -44.76728057861328,
      "logps/rejected": -38.23094177246094,
      "loss": 0.6696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.041617896407842636,
      "rewards/margins": 0.04784546047449112,
      "rewards/rejected": -0.006227564997971058,
      "step": 254
    },
    {
      "epoch": 19.64,
      "grad_norm": 6.510843276977539,
      "learning_rate": 8.171875e-08,
      "logits/chosen": 1.090707778930664,
      "logits/rejected": 1.361146092414856,
      "logps/chosen": -42.84585189819336,
      "logps/rejected": -38.6380500793457,
      "loss": 0.6782,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03460123389959335,
      "rewards/margins": 0.030301334336400032,
      "rewards/rejected": 0.00429990328848362,
      "step": 255
    },
    {
      "epoch": 19.72,
      "grad_norm": 5.840361595153809,
      "learning_rate": 8.1640625e-08,
      "logits/chosen": 0.8433656096458435,
      "logits/rejected": 1.3791784048080444,
      "logps/chosen": -40.56886291503906,
      "logps/rejected": -37.843719482421875,
      "loss": 0.6821,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.02976701408624649,
      "rewards/margins": 0.022496819496154785,
      "rewards/rejected": 0.007270194590091705,
      "step": 256
    },
    {
      "epoch": 19.8,
      "grad_norm": 5.646764278411865,
      "learning_rate": 8.15625e-08,
      "logits/chosen": 1.1088743209838867,
      "logits/rejected": 1.4675467014312744,
      "logps/chosen": -40.47377014160156,
      "logps/rejected": -30.242219924926758,
      "loss": 0.6778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.035687901079654694,
      "rewards/margins": 0.030997682362794876,
      "rewards/rejected": 0.00469021825119853,
      "step": 257
    },
    {
      "epoch": 19.88,
      "grad_norm": 6.252272605895996,
      "learning_rate": 8.1484375e-08,
      "logits/chosen": 1.0855159759521484,
      "logits/rejected": 1.5191240310668945,
      "logps/chosen": -30.486343383789062,
      "logps/rejected": -35.660003662109375,
      "loss": 0.6715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03575191646814346,
      "rewards/margins": 0.04393060505390167,
      "rewards/rejected": -0.00817868672311306,
      "step": 258
    },
    {
      "epoch": 19.96,
      "grad_norm": 7.510254859924316,
      "learning_rate": 8.140625e-08,
      "logits/chosen": 0.8815625905990601,
      "logits/rejected": 1.335142970085144,
      "logps/chosen": -51.891868591308594,
      "logps/rejected": -36.0780029296875,
      "loss": 0.6874,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.028751585632562637,
      "rewards/margins": 0.01155252568423748,
      "rewards/rejected": 0.017199065536260605,
      "step": 259
    },
    {
      "epoch": 20.0,
      "grad_norm": 10.374503135681152,
      "learning_rate": 8.132812499999999e-08,
      "logits/chosen": 0.9840766787528992,
      "logits/rejected": 1.146613359451294,
      "logps/chosen": -42.92787170410156,
      "logps/rejected": -34.410343170166016,
      "loss": 0.6698,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.06548552215099335,
      "rewards/margins": 0.04744802042841911,
      "rewards/rejected": 0.01803750917315483,
      "step": 260
    },
    {
      "epoch": 20.0,
      "eval_logits/chosen": 0.9801377654075623,
      "eval_logits/rejected": 1.1526442766189575,
      "eval_logps/chosen": -39.38718032836914,
      "eval_logps/rejected": -37.07651138305664,
      "eval_loss": 0.6822194457054138,
      "eval_rewards/accuracies": 0.7599999904632568,
      "eval_rewards/chosen": 0.03383861482143402,
      "eval_rewards/margins": 0.022150149568915367,
      "eval_rewards/rejected": 0.011688463389873505,
      "eval_runtime": 3.2062,
      "eval_samples_per_second": 31.189,
      "eval_steps_per_second": 15.595,
      "step": 260
    },
    {
      "epoch": 20.08,
      "grad_norm": 5.589931964874268,
      "learning_rate": 8.124999999999999e-08,
      "logits/chosen": 1.1374800205230713,
      "logits/rejected": 1.2333935499191284,
      "logps/chosen": -35.64149475097656,
      "logps/rejected": -37.443115234375,
      "loss": 0.6829,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.03644929081201553,
      "rewards/margins": 0.020720243453979492,
      "rewards/rejected": 0.01572904735803604,
      "step": 261
    },
    {
      "epoch": 20.16,
      "grad_norm": 7.441241264343262,
      "learning_rate": 8.1171875e-08,
      "logits/chosen": 0.7881657481193542,
      "logits/rejected": 1.0334407091140747,
      "logps/chosen": -40.50962829589844,
      "logps/rejected": -32.352230072021484,
      "loss": 0.6731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03920163959264755,
      "rewards/margins": 0.040531422942876816,
      "rewards/rejected": -0.0013297796249389648,
      "step": 262
    },
    {
      "epoch": 20.24,
      "grad_norm": 6.767670154571533,
      "learning_rate": 8.109374999999999e-08,
      "logits/chosen": 0.7435445785522461,
      "logits/rejected": 1.173694372177124,
      "logps/chosen": -32.144134521484375,
      "logps/rejected": -32.04441452026367,
      "loss": 0.6735,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.044323135167360306,
      "rewards/margins": 0.03974969685077667,
      "rewards/rejected": 0.004573440179228783,
      "step": 263
    },
    {
      "epoch": 20.32,
      "grad_norm": 7.040326118469238,
      "learning_rate": 8.101562499999999e-08,
      "logits/chosen": 1.106377124786377,
      "logits/rejected": 1.322441816329956,
      "logps/chosen": -38.66030502319336,
      "logps/rejected": -32.326332092285156,
      "loss": 0.6767,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.032553933560848236,
      "rewards/margins": 0.03325720131397247,
      "rewards/rejected": -0.0007032635621726513,
      "step": 264
    },
    {
      "epoch": 20.4,
      "grad_norm": 7.5965256690979,
      "learning_rate": 8.093749999999999e-08,
      "logits/chosen": 0.9755901098251343,
      "logits/rejected": 1.3212504386901855,
      "logps/chosen": -49.47292709350586,
      "logps/rejected": -36.71820068359375,
      "loss": 0.6745,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.047637246549129486,
      "rewards/margins": 0.037870265543460846,
      "rewards/rejected": 0.009766984730958939,
      "step": 265
    },
    {
      "epoch": 20.48,
      "grad_norm": 8.8369140625,
      "learning_rate": 8.0859375e-08,
      "logits/chosen": 0.9811099767684937,
      "logits/rejected": 1.1387457847595215,
      "logps/chosen": -51.08171081542969,
      "logps/rejected": -34.4035758972168,
      "loss": 0.6704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0488312728703022,
      "rewards/margins": 0.0462498664855957,
      "rewards/rejected": 0.0025814056862145662,
      "step": 266
    },
    {
      "epoch": 20.56,
      "grad_norm": 6.323297500610352,
      "learning_rate": 8.078125e-08,
      "logits/chosen": 1.0710206031799316,
      "logits/rejected": 1.4761772155761719,
      "logps/chosen": -44.1169548034668,
      "logps/rejected": -31.73261260986328,
      "loss": 0.6737,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03845496103167534,
      "rewards/margins": 0.039496637880802155,
      "rewards/rejected": -0.001041674753651023,
      "step": 267
    },
    {
      "epoch": 20.64,
      "grad_norm": 7.187185764312744,
      "learning_rate": 8.0703125e-08,
      "logits/chosen": 1.0033832788467407,
      "logits/rejected": 1.3562053442001343,
      "logps/chosen": -38.81742858886719,
      "logps/rejected": -36.37517547607422,
      "loss": 0.6747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.046285487711429596,
      "rewards/margins": 0.03739936649799347,
      "rewards/rejected": 0.008886123076081276,
      "step": 268
    },
    {
      "epoch": 20.72,
      "grad_norm": 7.175174713134766,
      "learning_rate": 8.0625e-08,
      "logits/chosen": 1.2075990438461304,
      "logits/rejected": 1.4399982690811157,
      "logps/chosen": -56.448280334472656,
      "logps/rejected": -41.187225341796875,
      "loss": 0.6794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04284853860735893,
      "rewards/margins": 0.027852870523929596,
      "rewards/rejected": 0.01499567087739706,
      "step": 269
    },
    {
      "epoch": 20.8,
      "grad_norm": 6.43555212020874,
      "learning_rate": 8.0546875e-08,
      "logits/chosen": 1.1105961799621582,
      "logits/rejected": 1.3014936447143555,
      "logps/chosen": -37.64749526977539,
      "logps/rejected": -31.467803955078125,
      "loss": 0.6728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04449035972356796,
      "rewards/margins": 0.04125194251537323,
      "rewards/rejected": 0.0032384158112108707,
      "step": 270
    },
    {
      "epoch": 20.88,
      "grad_norm": 6.82477331161499,
      "learning_rate": 8.046875e-08,
      "logits/chosen": 0.8190505504608154,
      "logits/rejected": 1.4945931434631348,
      "logps/chosen": -33.74683380126953,
      "logps/rejected": -34.31759262084961,
      "loss": 0.6797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04535792022943497,
      "rewards/margins": 0.027151253074407578,
      "rewards/rejected": 0.01820666715502739,
      "step": 271
    },
    {
      "epoch": 20.96,
      "grad_norm": 6.681294918060303,
      "learning_rate": 8.0390625e-08,
      "logits/chosen": 0.9579738974571228,
      "logits/rejected": 1.131151556968689,
      "logps/chosen": -51.284149169921875,
      "logps/rejected": -39.00440979003906,
      "loss": 0.6811,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.03179755061864853,
      "rewards/margins": 0.024324797093868256,
      "rewards/rejected": 0.0074727535247802734,
      "step": 272
    },
    {
      "epoch": 21.0,
      "grad_norm": 9.929516792297363,
      "learning_rate": 8.03125e-08,
      "logits/chosen": 0.99604332447052,
      "logits/rejected": 1.569624900817871,
      "logps/chosen": -62.62936782836914,
      "logps/rejected": -31.174640655517578,
      "loss": 0.6642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05918703228235245,
      "rewards/margins": 0.05899806320667267,
      "rewards/rejected": 0.00018897070549428463,
      "step": 273
    },
    {
      "epoch": 21.0,
      "eval_logits/chosen": 0.9793030023574829,
      "eval_logits/rejected": 1.1489465236663818,
      "eval_logps/chosen": -39.36552047729492,
      "eval_logps/rejected": -37.084327697753906,
      "eval_loss": 0.6807788014411926,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.03600499778985977,
      "eval_rewards/margins": 0.025097884237766266,
      "eval_rewards/rejected": 0.010907110758125782,
      "eval_runtime": 3.2029,
      "eval_samples_per_second": 31.221,
      "eval_steps_per_second": 15.611,
      "step": 273
    },
    {
      "epoch": 21.08,
      "grad_norm": 7.0345964431762695,
      "learning_rate": 8.0234375e-08,
      "logits/chosen": 1.0361722707748413,
      "logits/rejected": 1.2923851013183594,
      "logps/chosen": -44.88897705078125,
      "logps/rejected": -35.19789505004883,
      "loss": 0.678,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.040006451308727264,
      "rewards/margins": 0.030663324519991875,
      "rewards/rejected": 0.009343123994767666,
      "step": 274
    },
    {
      "epoch": 21.16,
      "grad_norm": 6.724541664123535,
      "learning_rate": 8.015624999999999e-08,
      "logits/chosen": 0.973344087600708,
      "logits/rejected": 1.4386961460113525,
      "logps/chosen": -44.63835144042969,
      "logps/rejected": -34.00179672241211,
      "loss": 0.6678,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06067362055182457,
      "rewards/margins": 0.05160515010356903,
      "rewards/rejected": 0.009068464860320091,
      "step": 275
    },
    {
      "epoch": 21.24,
      "grad_norm": 5.825507164001465,
      "learning_rate": 8.0078125e-08,
      "logits/chosen": 1.2183786630630493,
      "logits/rejected": 1.3272720575332642,
      "logps/chosen": -39.765716552734375,
      "logps/rejected": -35.81827163696289,
      "loss": 0.6778,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.04158146306872368,
      "rewards/margins": 0.030973030254244804,
      "rewards/rejected": 0.010608434677124023,
      "step": 276
    },
    {
      "epoch": 21.32,
      "grad_norm": 6.383982181549072,
      "learning_rate": 8e-08,
      "logits/chosen": 0.5645382404327393,
      "logits/rejected": 1.273148536682129,
      "logps/chosen": -32.03984451293945,
      "logps/rejected": -29.91509437561035,
      "loss": 0.6779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.033696964383125305,
      "rewards/margins": 0.030794909223914146,
      "rewards/rejected": 0.0029020551592111588,
      "step": 277
    },
    {
      "epoch": 21.4,
      "grad_norm": 7.906901836395264,
      "learning_rate": 7.992187499999999e-08,
      "logits/chosen": 1.227912187576294,
      "logits/rejected": 1.4794254302978516,
      "logps/chosen": -52.41422653198242,
      "logps/rejected": -32.30693817138672,
      "loss": 0.6679,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.05846579372882843,
      "rewards/margins": 0.051458004862070084,
      "rewards/rejected": 0.0070077902637422085,
      "step": 278
    },
    {
      "epoch": 21.48,
      "grad_norm": 6.953657150268555,
      "learning_rate": 7.984375e-08,
      "logits/chosen": 0.983966052532196,
      "logits/rejected": 1.0737719535827637,
      "logps/chosen": -39.646156311035156,
      "logps/rejected": -30.67947769165039,
      "loss": 0.6678,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0472608357667923,
      "rewards/margins": 0.051685646176338196,
      "rewards/rejected": -0.0044248104095458984,
      "step": 279
    },
    {
      "epoch": 21.56,
      "grad_norm": 6.889209747314453,
      "learning_rate": 7.976562499999999e-08,
      "logits/chosen": 0.585905909538269,
      "logits/rejected": 1.4948627948760986,
      "logps/chosen": -34.700408935546875,
      "logps/rejected": -33.105587005615234,
      "loss": 0.674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03237342834472656,
      "rewards/margins": 0.038681816309690475,
      "rewards/rejected": -0.006308388896286488,
      "step": 280
    },
    {
      "epoch": 21.64,
      "grad_norm": 7.565279960632324,
      "learning_rate": 7.968749999999999e-08,
      "logits/chosen": 0.9820970892906189,
      "logits/rejected": 1.0700204372406006,
      "logps/chosen": -44.3335075378418,
      "logps/rejected": -40.739688873291016,
      "loss": 0.6675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05928247049450874,
      "rewards/margins": 0.052097298204898834,
      "rewards/rejected": 0.007185173220932484,
      "step": 281
    },
    {
      "epoch": 21.72,
      "grad_norm": 6.858097076416016,
      "learning_rate": 7.9609375e-08,
      "logits/chosen": 1.143239974975586,
      "logits/rejected": 1.3703728914260864,
      "logps/chosen": -38.76747131347656,
      "logps/rejected": -40.622093200683594,
      "loss": 0.6763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.043151140213012695,
      "rewards/margins": 0.03404559940099716,
      "rewards/rejected": 0.009105538949370384,
      "step": 282
    },
    {
      "epoch": 21.8,
      "grad_norm": 8.070802688598633,
      "learning_rate": 7.953124999999999e-08,
      "logits/chosen": 0.9599902629852295,
      "logits/rejected": 1.383608341217041,
      "logps/chosen": -47.7894287109375,
      "logps/rejected": -34.5322265625,
      "loss": 0.6696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05953719839453697,
      "rewards/margins": 0.04788201302289963,
      "rewards/rejected": 0.011655187234282494,
      "step": 283
    },
    {
      "epoch": 21.88,
      "grad_norm": 7.321317195892334,
      "learning_rate": 7.9453125e-08,
      "logits/chosen": 1.1475236415863037,
      "logits/rejected": 1.19693124294281,
      "logps/chosen": -65.0133056640625,
      "logps/rejected": -36.534400939941406,
      "loss": 0.6662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04831819236278534,
      "rewards/margins": 0.05482210963964462,
      "rewards/rejected": -0.0065039158798754215,
      "step": 284
    },
    {
      "epoch": 21.96,
      "grad_norm": 5.733200550079346,
      "learning_rate": 7.9375e-08,
      "logits/chosen": 0.8386262655258179,
      "logits/rejected": 1.1551334857940674,
      "logps/chosen": -33.22597122192383,
      "logps/rejected": -29.794313430786133,
      "loss": 0.6758,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.04073760658502579,
      "rewards/margins": 0.03513910621404648,
      "rewards/rejected": 0.0055984980426728725,
      "step": 285
    },
    {
      "epoch": 22.0,
      "grad_norm": 8.169095039367676,
      "learning_rate": 7.9296875e-08,
      "logits/chosen": 1.377213954925537,
      "logits/rejected": 1.4900085926055908,
      "logps/chosen": -46.276405334472656,
      "logps/rejected": -43.73784637451172,
      "loss": 0.6789,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.04684748500585556,
      "rewards/margins": 0.028708696365356445,
      "rewards/rejected": 0.018138790503144264,
      "step": 286
    },
    {
      "epoch": 22.0,
      "eval_logits/chosen": 0.9795113205909729,
      "eval_logits/rejected": 1.150712013244629,
      "eval_logps/chosen": -39.367210388183594,
      "eval_logps/rejected": -37.112674713134766,
      "eval_loss": 0.6794779896736145,
      "eval_rewards/accuracies": 0.8299999833106995,
      "eval_rewards/chosen": 0.035835810005664825,
      "eval_rewards/margins": 0.027763621881604195,
      "eval_rewards/rejected": 0.008072185330092907,
      "eval_runtime": 3.206,
      "eval_samples_per_second": 31.192,
      "eval_steps_per_second": 15.596,
      "step": 286
    },
    {
      "epoch": 22.08,
      "grad_norm": 7.41373348236084,
      "learning_rate": 7.921875e-08,
      "logits/chosen": 0.9113803505897522,
      "logits/rejected": 1.266655445098877,
      "logps/chosen": -45.86802291870117,
      "logps/rejected": -32.45836639404297,
      "loss": 0.6684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05592906475067139,
      "rewards/margins": 0.05012686178088188,
      "rewards/rejected": 0.005802202504128218,
      "step": 287
    },
    {
      "epoch": 22.16,
      "grad_norm": 6.411657810211182,
      "learning_rate": 7.9140625e-08,
      "logits/chosen": 1.0684936046600342,
      "logits/rejected": 1.262835144996643,
      "logps/chosen": -44.29587936401367,
      "logps/rejected": -35.28173828125,
      "loss": 0.6779,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.04756195843219757,
      "rewards/margins": 0.030855869874358177,
      "rewards/rejected": 0.016706086695194244,
      "step": 288
    },
    {
      "epoch": 22.24,
      "grad_norm": 6.693457126617432,
      "learning_rate": 7.90625e-08,
      "logits/chosen": 1.1784613132476807,
      "logits/rejected": 1.2657380104064941,
      "logps/chosen": -42.41529846191406,
      "logps/rejected": -38.279075622558594,
      "loss": 0.6659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.059745028614997864,
      "rewards/margins": 0.05550646781921387,
      "rewards/rejected": 0.004238557536154985,
      "step": 289
    },
    {
      "epoch": 22.32,
      "grad_norm": 7.414420127868652,
      "learning_rate": 7.8984375e-08,
      "logits/chosen": 1.1184033155441284,
      "logits/rejected": 1.4080610275268555,
      "logps/chosen": -54.57183837890625,
      "logps/rejected": -35.18233871459961,
      "loss": 0.6719,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05390026420354843,
      "rewards/margins": 0.04318294674158096,
      "rewards/rejected": 0.010717321187257767,
      "step": 290
    },
    {
      "epoch": 22.4,
      "grad_norm": 7.37832498550415,
      "learning_rate": 7.890625e-08,
      "logits/chosen": 1.3109174966812134,
      "logits/rejected": 1.406101942062378,
      "logps/chosen": -43.78179168701172,
      "logps/rejected": -32.341285705566406,
      "loss": 0.6694,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.043665122240781784,
      "rewards/margins": 0.04841775819659233,
      "rewards/rejected": -0.00475263549014926,
      "step": 291
    },
    {
      "epoch": 22.48,
      "grad_norm": 5.137059211730957,
      "learning_rate": 7.8828125e-08,
      "logits/chosen": 0.8664615154266357,
      "logits/rejected": 1.3017107248306274,
      "logps/chosen": -29.805744171142578,
      "logps/rejected": -26.959884643554688,
      "loss": 0.6765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04065752029418945,
      "rewards/margins": 0.03361065313220024,
      "rewards/rejected": 0.007046866696327925,
      "step": 292
    },
    {
      "epoch": 22.56,
      "grad_norm": 7.215821266174316,
      "learning_rate": 7.875e-08,
      "logits/chosen": 0.5940784811973572,
      "logits/rejected": 1.3863487243652344,
      "logps/chosen": -44.499935150146484,
      "logps/rejected": -35.007484436035156,
      "loss": 0.6717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04604611545801163,
      "rewards/margins": 0.04336905479431152,
      "rewards/rejected": 0.002677059266716242,
      "step": 293
    },
    {
      "epoch": 22.64,
      "grad_norm": 7.987455368041992,
      "learning_rate": 7.8671875e-08,
      "logits/chosen": 0.864190399646759,
      "logits/rejected": 1.364195704460144,
      "logps/chosen": -41.775604248046875,
      "logps/rejected": -32.24625015258789,
      "loss": 0.6677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05112569034099579,
      "rewards/margins": 0.051896143704652786,
      "rewards/rejected": -0.0007704496383666992,
      "step": 294
    },
    {
      "epoch": 22.72,
      "grad_norm": 6.947572708129883,
      "learning_rate": 7.859374999999999e-08,
      "logits/chosen": 0.8757482767105103,
      "logits/rejected": 1.2646840810775757,
      "logps/chosen": -35.75994110107422,
      "logps/rejected": -32.53165817260742,
      "loss": 0.6719,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.05038485676050186,
      "rewards/margins": 0.043150901794433594,
      "rewards/rejected": 0.007233954034745693,
      "step": 295
    },
    {
      "epoch": 22.8,
      "grad_norm": 7.010723114013672,
      "learning_rate": 7.8515625e-08,
      "logits/chosen": 0.8934523463249207,
      "logits/rejected": 1.5308181047439575,
      "logps/chosen": -40.50491714477539,
      "logps/rejected": -43.66236114501953,
      "loss": 0.6705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.044954750686883926,
      "rewards/margins": 0.04599886015057564,
      "rewards/rejected": -0.0010441062040627003,
      "step": 296
    },
    {
      "epoch": 22.88,
      "grad_norm": 7.19597053527832,
      "learning_rate": 7.84375e-08,
      "logits/chosen": 0.9864444732666016,
      "logits/rejected": 1.075972318649292,
      "logps/chosen": -40.9501838684082,
      "logps/rejected": -35.35638427734375,
      "loss": 0.6774,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.04530370235443115,
      "rewards/margins": 0.032195135951042175,
      "rewards/rejected": 0.013108563609421253,
      "step": 297
    },
    {
      "epoch": 22.96,
      "grad_norm": 6.912856101989746,
      "learning_rate": 7.835937499999999e-08,
      "logits/chosen": 1.2305552959442139,
      "logits/rejected": 1.347806692123413,
      "logps/chosen": -52.23468017578125,
      "logps/rejected": -39.9859504699707,
      "loss": 0.6701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0583958625793457,
      "rewards/margins": 0.046710941940546036,
      "rewards/rejected": 0.011684918776154518,
      "step": 298
    },
    {
      "epoch": 23.0,
      "grad_norm": 10.65858268737793,
      "learning_rate": 7.828125e-08,
      "logits/chosen": 0.8306947946548462,
      "logits/rejected": 0.8543052673339844,
      "logps/chosen": -47.225074768066406,
      "logps/rejected": -31.26160430908203,
      "loss": 0.6829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03207836300134659,
      "rewards/margins": 0.02067556604743004,
      "rewards/rejected": 0.01140279695391655,
      "step": 299
    },
    {
      "epoch": 23.0,
      "eval_logits/chosen": 0.9769546389579773,
      "eval_logits/rejected": 1.1485531330108643,
      "eval_logps/chosen": -39.29607391357422,
      "eval_logps/rejected": -37.04690170288086,
      "eval_loss": 0.6791993975639343,
      "eval_rewards/accuracies": 0.8799999952316284,
      "eval_rewards/chosen": 0.04294953495264053,
      "eval_rewards/margins": 0.028300471603870392,
      "eval_rewards/rejected": 0.014649060554802418,
      "eval_runtime": 3.2104,
      "eval_samples_per_second": 31.149,
      "eval_steps_per_second": 15.574,
      "step": 299
    },
    {
      "epoch": 23.08,
      "grad_norm": 6.321667194366455,
      "learning_rate": 7.820312499999999e-08,
      "logits/chosen": 1.1768338680267334,
      "logits/rejected": 1.2999869585037231,
      "logps/chosen": -39.649192810058594,
      "logps/rejected": -34.164154052734375,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06068430095911026,
      "rewards/margins": 0.05644972249865532,
      "rewards/rejected": 0.0042345765978097916,
      "step": 300
    },
    {
      "epoch": 23.16,
      "grad_norm": 6.590737342834473,
      "learning_rate": 7.812499999999999e-08,
      "logits/chosen": 1.0237290859222412,
      "logits/rejected": 1.401693344116211,
      "logps/chosen": -43.03831100463867,
      "logps/rejected": -33.68793487548828,
      "loss": 0.6754,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.04675665125250816,
      "rewards/margins": 0.03605249151587486,
      "rewards/rejected": 0.0107041597366333,
      "step": 301
    },
    {
      "epoch": 23.24,
      "grad_norm": 8.077176094055176,
      "learning_rate": 7.804687500000001e-08,
      "logits/chosen": 0.9941450357437134,
      "logits/rejected": 1.39522385597229,
      "logps/chosen": -44.49125671386719,
      "logps/rejected": -35.011470794677734,
      "loss": 0.666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05253095552325249,
      "rewards/margins": 0.055239204317331314,
      "rewards/rejected": -0.002708244603127241,
      "step": 302
    },
    {
      "epoch": 23.32,
      "grad_norm": 5.741445064544678,
      "learning_rate": 7.796875e-08,
      "logits/chosen": 1.1427950859069824,
      "logits/rejected": 1.3409929275512695,
      "logps/chosen": -48.58921813964844,
      "logps/rejected": -38.898475646972656,
      "loss": 0.6743,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.044080331921577454,
      "rewards/margins": 0.03814201429486275,
      "rewards/rejected": 0.00593831529840827,
      "step": 303
    },
    {
      "epoch": 23.4,
      "grad_norm": 7.037152290344238,
      "learning_rate": 7.7890625e-08,
      "logits/chosen": 1.012666940689087,
      "logits/rejected": 1.3930020332336426,
      "logps/chosen": -48.27544021606445,
      "logps/rejected": -37.05926513671875,
      "loss": 0.6682,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.05754063278436661,
      "rewards/margins": 0.050702549517154694,
      "rewards/rejected": 0.006838083267211914,
      "step": 304
    },
    {
      "epoch": 23.48,
      "grad_norm": 7.098758697509766,
      "learning_rate": 7.78125e-08,
      "logits/chosen": 0.9443119168281555,
      "logits/rejected": 1.3592324256896973,
      "logps/chosen": -38.53541564941406,
      "logps/rejected": -33.48288345336914,
      "loss": 0.6711,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.04348564147949219,
      "rewards/margins": 0.044893648475408554,
      "rewards/rejected": -0.0014080055989325047,
      "step": 305
    },
    {
      "epoch": 23.56,
      "grad_norm": 7.586842060089111,
      "learning_rate": 7.7734375e-08,
      "logits/chosen": 0.8584258556365967,
      "logits/rejected": 1.1499476432800293,
      "logps/chosen": -46.20441436767578,
      "logps/rejected": -36.45567321777344,
      "loss": 0.6732,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.05706458166241646,
      "rewards/margins": 0.04050426557660103,
      "rewards/rejected": 0.01656031608581543,
      "step": 306
    },
    {
      "epoch": 23.64,
      "grad_norm": 6.808773994445801,
      "learning_rate": 7.765625e-08,
      "logits/chosen": 0.8703171014785767,
      "logits/rejected": 1.3426721096038818,
      "logps/chosen": -47.643218994140625,
      "logps/rejected": -35.79396438598633,
      "loss": 0.6693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06033668667078018,
      "rewards/margins": 0.04842293635010719,
      "rewards/rejected": 0.011913752183318138,
      "step": 307
    },
    {
      "epoch": 23.72,
      "grad_norm": 7.294742107391357,
      "learning_rate": 7.7578125e-08,
      "logits/chosen": 0.6698094606399536,
      "logits/rejected": 1.2048993110656738,
      "logps/chosen": -42.76405715942383,
      "logps/rejected": -31.612699508666992,
      "loss": 0.6703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05440826341509819,
      "rewards/margins": 0.04625358432531357,
      "rewards/rejected": 0.008154679089784622,
      "step": 308
    },
    {
      "epoch": 23.8,
      "grad_norm": 5.8639349937438965,
      "learning_rate": 7.75e-08,
      "logits/chosen": 0.9408875703811646,
      "logits/rejected": 1.2361443042755127,
      "logps/chosen": -36.085018157958984,
      "logps/rejected": -32.21422576904297,
      "loss": 0.6726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05534815788269043,
      "rewards/margins": 0.04172973707318306,
      "rewards/rejected": 0.013618421740829945,
      "step": 309
    },
    {
      "epoch": 23.88,
      "grad_norm": 7.011785507202148,
      "learning_rate": 7.742187499999999e-08,
      "logits/chosen": 1.0699193477630615,
      "logits/rejected": 1.2949419021606445,
      "logps/chosen": -37.47217559814453,
      "logps/rejected": -33.66069030761719,
      "loss": 0.6641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.059816744178533554,
      "rewards/margins": 0.05904834344983101,
      "rewards/rejected": 0.0007683988660573959,
      "step": 310
    },
    {
      "epoch": 23.96,
      "grad_norm": 7.659888744354248,
      "learning_rate": 7.734375e-08,
      "logits/chosen": 1.0238022804260254,
      "logits/rejected": 1.237051010131836,
      "logps/chosen": -49.93217849731445,
      "logps/rejected": -36.456756591796875,
      "loss": 0.6696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05733481049537659,
      "rewards/margins": 0.04791836440563202,
      "rewards/rejected": 0.009416436776518822,
      "step": 311
    },
    {
      "epoch": 24.0,
      "grad_norm": 8.981305122375488,
      "learning_rate": 7.7265625e-08,
      "logits/chosen": 0.9700530767440796,
      "logits/rejected": 0.9875553250312805,
      "logps/chosen": -33.70744323730469,
      "logps/rejected": -32.959842681884766,
      "loss": 0.6683,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.039487458765506744,
      "rewards/margins": 0.050702523440122604,
      "rewards/rejected": -0.01121506653726101,
      "step": 312
    },
    {
      "epoch": 24.0,
      "eval_logits/chosen": 0.9763616919517517,
      "eval_logits/rejected": 1.1476081609725952,
      "eval_logps/chosen": -39.294921875,
      "eval_logps/rejected": -37.06243133544922,
      "eval_loss": 0.6783867478370667,
      "eval_rewards/accuracies": 0.8700000047683716,
      "eval_rewards/chosen": 0.04306473210453987,
      "eval_rewards/margins": 0.029968511313199997,
      "eval_rewards/rejected": 0.013096220791339874,
      "eval_runtime": 3.2166,
      "eval_samples_per_second": 31.089,
      "eval_steps_per_second": 15.545,
      "step": 312
    }
  ],
  "logging_steps": 1,
  "max_steps": 1300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
