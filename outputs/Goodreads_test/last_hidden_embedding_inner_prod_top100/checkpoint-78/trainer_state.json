{
  "best_global_step": 78,
  "best_metric": 0.69060879945755,
  "best_model_checkpoint": "/scratch/user/chuanhsin0110/LLMRec-Labs/unintentional-unalignment/outputs/Goodreads_test/last_hidden_embedding_inner_prod_top100/checkpoint-78",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 78,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 6.087185382843018,
      "learning_rate": 0.0,
      "logits/chosen": 1.3085854053497314,
      "logits/rejected": 1.354912519454956,
      "logps/chosen": -43.2645149230957,
      "logps/rejected": -42.922813415527344,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.669334411621094,
      "learning_rate": 5e-09,
      "logits/chosen": 1.329612374305725,
      "logits/rejected": 1.1660025119781494,
      "logps/chosen": -42.44950485229492,
      "logps/rejected": -45.075050354003906,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.476437091827393,
      "learning_rate": 1e-08,
      "logits/chosen": 1.0438008308410645,
      "logits/rejected": 1.2589610815048218,
      "logps/chosen": -37.85212326049805,
      "logps/rejected": -44.064971923828125,
      "loss": 0.692,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003791713621467352,
      "rewards/margins": 0.002581977751106024,
      "rewards/rejected": -0.006373691838234663,
      "step": 3
    },
    {
      "epoch": 0.32,
      "grad_norm": 8.930471420288086,
      "learning_rate": 1.5e-08,
      "logits/chosen": 0.8361316919326782,
      "logits/rejected": 1.2348120212554932,
      "logps/chosen": -38.816349029541016,
      "logps/rejected": -40.7824592590332,
      "loss": 0.6983,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010554719716310501,
      "rewards/margins": -0.010083317756652832,
      "rewards/rejected": -0.00047140137758105993,
      "step": 4
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.115653991699219,
      "learning_rate": 2e-08,
      "logits/chosen": 1.4423351287841797,
      "logits/rejected": 1.2933834791183472,
      "logps/chosen": -44.06068420410156,
      "logps/rejected": -46.684234619140625,
      "loss": 0.6903,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009691786952316761,
      "rewards/margins": 0.005781960673630238,
      "rewards/rejected": 0.003909826744347811,
      "step": 5
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.894260883331299,
      "learning_rate": 2.5e-08,
      "logits/chosen": 1.3404059410095215,
      "logits/rejected": 1.4038150310516357,
      "logps/chosen": -40.875633239746094,
      "logps/rejected": -39.428714752197266,
      "loss": 0.6971,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0001403571804985404,
      "rewards/margins": -0.007839202880859375,
      "rewards/rejected": 0.007979560643434525,
      "step": 6
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.827328205108643,
      "learning_rate": 3e-08,
      "logits/chosen": 0.9566646218299866,
      "logits/rejected": 1.2844816446304321,
      "logps/chosen": -39.72224044799805,
      "logps/rejected": -48.14327621459961,
      "loss": 0.6935,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0008855104679241776,
      "rewards/margins": -0.0005485774017870426,
      "rewards/rejected": 0.0014340875204652548,
      "step": 7
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.239068031311035,
      "learning_rate": 3.4999999999999996e-08,
      "logits/chosen": 0.968086302280426,
      "logits/rejected": 1.2149937152862549,
      "logps/chosen": -36.16902160644531,
      "logps/rejected": -46.74949264526367,
      "loss": 0.6935,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.004923105239868164,
      "rewards/margins": -0.00047974660992622375,
      "rewards/rejected": 0.005402850918471813,
      "step": 8
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.118812561035156,
      "learning_rate": 4e-08,
      "logits/chosen": 0.9706990122795105,
      "logits/rejected": 1.242666244506836,
      "logps/chosen": -35.65559005737305,
      "logps/rejected": -47.6392822265625,
      "loss": 0.6907,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0023808241821825504,
      "rewards/margins": 0.005059027578681707,
      "rewards/rejected": -0.007439851760864258,
      "step": 9
    },
    {
      "epoch": 0.8,
      "grad_norm": 6.24561071395874,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.2228021621704102,
      "logits/rejected": 1.3834553956985474,
      "logps/chosen": -35.843353271484375,
      "logps/rejected": -44.481529235839844,
      "loss": 0.6939,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0016902684001252055,
      "rewards/margins": -0.0014893293846398592,
      "rewards/rejected": 0.003179597668349743,
      "step": 10
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.393795013427734,
      "learning_rate": 5e-08,
      "logits/chosen": 0.9673507809638977,
      "logits/rejected": 1.271558403968811,
      "logps/chosen": -35.092308044433594,
      "logps/rejected": -43.820945739746094,
      "loss": 0.6919,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007133007049560547,
      "rewards/margins": 0.0025800704024732113,
      "rewards/rejected": 0.004552936181426048,
      "step": 11
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.4408698081970215,
      "learning_rate": 5.5e-08,
      "logits/chosen": 1.3295881748199463,
      "logits/rejected": 1.3068197965621948,
      "logps/chosen": -37.39216995239258,
      "logps/rejected": -38.97688293457031,
      "loss": 0.6883,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.012000799179077148,
      "rewards/margins": 0.00976345594972372,
      "rewards/rejected": 0.002237343695014715,
      "step": 12
    },
    {
      "epoch": 1.0,
      "grad_norm": 11.637125968933105,
      "learning_rate": 6e-08,
      "logits/chosen": 0.8920672535896301,
      "logits/rejected": 1.0801327228546143,
      "logps/chosen": -46.01161193847656,
      "logps/rejected": -54.825374603271484,
      "loss": 0.6874,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0049141403287649155,
      "rewards/margins": 0.011501169763505459,
      "rewards/rejected": -0.006587028503417969,
      "step": 13
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 1.0662275552749634,
      "eval_logits/rejected": 1.0972964763641357,
      "eval_logps/chosen": -37.893428802490234,
      "eval_logps/rejected": -43.922969818115234,
      "eval_loss": 0.6920735836029053,
      "eval_rewards/accuracies": 0.6000000238418579,
      "eval_rewards/chosen": 0.0024579123128205538,
      "eval_rewards/margins": 0.0022240104153752327,
      "eval_rewards/rejected": 0.00023390192654915154,
      "eval_runtime": 2.7689,
      "eval_samples_per_second": 36.115,
      "eval_steps_per_second": 18.057,
      "step": 13
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.086549758911133,
      "learning_rate": 6.5e-08,
      "logits/chosen": 1.1340281963348389,
      "logits/rejected": 1.2424440383911133,
      "logps/chosen": -44.52901840209961,
      "logps/rejected": -46.31299591064453,
      "loss": 0.694,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.009470606222748756,
      "rewards/margins": -0.0016303062438964844,
      "rewards/rejected": 0.01110091246664524,
      "step": 14
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.324874401092529,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.1129971742630005,
      "logits/rejected": 1.2334449291229248,
      "logps/chosen": -42.17463684082031,
      "logps/rejected": -44.299713134765625,
      "loss": 0.6895,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00897371768951416,
      "rewards/margins": 0.007628226652741432,
      "rewards/rejected": 0.0013454915024340153,
      "step": 15
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.008811950683594,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.0339257717132568,
      "logits/rejected": 1.3378187417984009,
      "logps/chosen": -42.096275329589844,
      "logps/rejected": -41.476261138916016,
      "loss": 0.6783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011650562286376953,
      "rewards/margins": 0.02990398369729519,
      "rewards/rejected": -0.018253421410918236,
      "step": 16
    },
    {
      "epoch": 1.32,
      "grad_norm": 5.909616947174072,
      "learning_rate": 8e-08,
      "logits/chosen": 1.2968343496322632,
      "logits/rejected": 1.2321666479110718,
      "logps/chosen": -39.036109924316406,
      "logps/rejected": -46.01801300048828,
      "loss": 0.687,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0031522512435913086,
      "rewards/margins": 0.012495636940002441,
      "rewards/rejected": -0.009343385696411133,
      "step": 17
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.5669846534729,
      "learning_rate": 8.5e-08,
      "logits/chosen": 0.9619736671447754,
      "logits/rejected": 1.1840879917144775,
      "logps/chosen": -37.51762390136719,
      "logps/rejected": -41.221160888671875,
      "loss": 0.7041,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.013232327066361904,
      "rewards/margins": -0.021684955805540085,
      "rewards/rejected": 0.00845263060182333,
      "step": 18
    },
    {
      "epoch": 1.48,
      "grad_norm": 8.649325370788574,
      "learning_rate": 9e-08,
      "logits/chosen": 1.1523222923278809,
      "logits/rejected": 1.0280992984771729,
      "logps/chosen": -40.49774932861328,
      "logps/rejected": -43.46598815917969,
      "loss": 0.6875,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01298363134264946,
      "rewards/margins": 0.011407708749175072,
      "rewards/rejected": 0.0015759225934743881,
      "step": 19
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.695199012756348,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.190061330795288,
      "logits/rejected": 1.416502833366394,
      "logps/chosen": -37.02449035644531,
      "logps/rejected": -42.82274627685547,
      "loss": 0.6871,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.002799510955810547,
      "rewards/margins": 0.01220688782632351,
      "rewards/rejected": -0.009407376870512962,
      "step": 20
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 6.78552770614624,
      "learning_rate": 1e-07,
      "logits/chosen": 1.1342352628707886,
      "logits/rejected": 1.2520136833190918,
      "logps/chosen": -35.09575653076172,
      "logps/rejected": -46.228294372558594,
      "loss": 0.6972,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.011363482102751732,
      "rewards/margins": -0.007867741398513317,
      "rewards/rejected": -0.003495741169899702,
      "step": 21
    },
    {
      "epoch": 1.72,
      "grad_norm": 5.667208671569824,
      "learning_rate": 9.909090909090909e-08,
      "logits/chosen": 1.2408103942871094,
      "logits/rejected": 1.3390761613845825,
      "logps/chosen": -33.88409423828125,
      "logps/rejected": -44.89376449584961,
      "loss": 0.6869,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01136109884828329,
      "rewards/margins": 0.01266565453261137,
      "rewards/rejected": -0.0013045549858361483,
      "step": 22
    },
    {
      "epoch": 1.8,
      "grad_norm": 6.457792282104492,
      "learning_rate": 9.818181818181818e-08,
      "logits/chosen": 1.2474186420440674,
      "logits/rejected": 1.3929526805877686,
      "logps/chosen": -42.233177185058594,
      "logps/rejected": -50.721229553222656,
      "loss": 0.6873,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004893206991255283,
      "rewards/margins": 0.011964226141571999,
      "rewards/rejected": -0.007071018218994141,
      "step": 23
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.4156389236450195,
      "learning_rate": 9.727272727272727e-08,
      "logits/chosen": 1.3481923341751099,
      "logits/rejected": 1.1906423568725586,
      "logps/chosen": -38.303009033203125,
      "logps/rejected": -42.487579345703125,
      "loss": 0.6909,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0006626845570281148,
      "rewards/margins": 0.004706120118498802,
      "rewards/rejected": -0.005368804559111595,
      "step": 24
    },
    {
      "epoch": 1.96,
      "grad_norm": 8.147132873535156,
      "learning_rate": 9.636363636363636e-08,
      "logits/chosen": 0.7954069972038269,
      "logits/rejected": 1.353971004486084,
      "logps/chosen": -37.051414489746094,
      "logps/rejected": -47.00872039794922,
      "loss": 0.6927,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009150361642241478,
      "rewards/margins": 0.001094483770430088,
      "rewards/rejected": 0.008055876940488815,
      "step": 25
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.178364753723145,
      "learning_rate": 9.545454545454546e-08,
      "logits/chosen": 1.0409454107284546,
      "logits/rejected": 1.2954397201538086,
      "logps/chosen": -41.191986083984375,
      "logps/rejected": -38.95178985595703,
      "loss": 0.6947,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.00712089566513896,
      "rewards/margins": -0.0030240057967603207,
      "rewards/rejected": -0.004096889868378639,
      "step": 26
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 1.065419316291809,
      "eval_logits/rejected": 1.0965867042541504,
      "eval_logps/chosen": -37.918949127197266,
      "eval_logps/rejected": -43.91560363769531,
      "eval_loss": 0.6937294006347656,
      "eval_rewards/accuracies": 0.5099999904632568,
      "eval_rewards/chosen": -9.419642447028309e-05,
      "eval_rewards/margins": -0.0010640011169016361,
      "eval_rewards/rejected": 0.0009698046487756073,
      "eval_runtime": 2.7684,
      "eval_samples_per_second": 36.123,
      "eval_steps_per_second": 18.061,
      "step": 26
    },
    {
      "epoch": 2.08,
      "grad_norm": 8.045276641845703,
      "learning_rate": 9.454545454545454e-08,
      "logits/chosen": 1.0320829153060913,
      "logits/rejected": 1.1187820434570312,
      "logps/chosen": -41.81967544555664,
      "logps/rejected": -45.2420768737793,
      "loss": 0.6927,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0012002945877611637,
      "rewards/margins": 0.00103855156339705,
      "rewards/rejected": 0.00016174325719475746,
      "step": 27
    },
    {
      "epoch": 2.16,
      "grad_norm": 8.070381164550781,
      "learning_rate": 9.363636363636364e-08,
      "logits/chosen": 0.8317556977272034,
      "logits/rejected": 1.1075894832611084,
      "logps/chosen": -36.533512115478516,
      "logps/rejected": -50.71516036987305,
      "loss": 0.6951,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.005455374252051115,
      "rewards/margins": -0.003633666317909956,
      "rewards/rejected": -0.00182170863263309,
      "step": 28
    },
    {
      "epoch": 2.24,
      "grad_norm": 6.887124538421631,
      "learning_rate": 9.272727272727272e-08,
      "logits/chosen": 1.1897271871566772,
      "logits/rejected": 1.3383846282958984,
      "logps/chosen": -42.203330993652344,
      "logps/rejected": -45.95842742919922,
      "loss": 0.6898,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00747494725510478,
      "rewards/margins": 0.006791543681174517,
      "rewards/rejected": 0.0006834025261923671,
      "step": 29
    },
    {
      "epoch": 2.32,
      "grad_norm": 7.358640670776367,
      "learning_rate": 9.181818181818182e-08,
      "logits/chosen": 0.9219821095466614,
      "logits/rejected": 1.2551054954528809,
      "logps/chosen": -38.2530632019043,
      "logps/rejected": -41.654029846191406,
      "loss": 0.6959,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005895376205444336,
      "rewards/margins": -0.005225658416748047,
      "rewards/rejected": -0.0006697175558656454,
      "step": 30
    },
    {
      "epoch": 2.4,
      "grad_norm": 5.068868637084961,
      "learning_rate": 9.09090909090909e-08,
      "logits/chosen": 1.240185260772705,
      "logits/rejected": 1.3883779048919678,
      "logps/chosen": -39.829097747802734,
      "logps/rejected": -40.5966796875,
      "loss": 0.6955,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.002593779470771551,
      "rewards/margins": -0.004703165031969547,
      "rewards/rejected": 0.007296944968402386,
      "step": 31
    },
    {
      "epoch": 2.48,
      "grad_norm": 6.018889904022217,
      "learning_rate": 9e-08,
      "logits/chosen": 1.1578048467636108,
      "logits/rejected": 1.3370251655578613,
      "logps/chosen": -37.54014205932617,
      "logps/rejected": -45.168251037597656,
      "loss": 0.6923,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0021647214889526367,
      "rewards/margins": 0.001686358591541648,
      "rewards/rejected": 0.0004783628392033279,
      "step": 32
    },
    {
      "epoch": 2.56,
      "grad_norm": 6.826430320739746,
      "learning_rate": 8.909090909090908e-08,
      "logits/chosen": 1.391810655593872,
      "logits/rejected": 1.3589935302734375,
      "logps/chosen": -33.4606819152832,
      "logps/rejected": -45.127235412597656,
      "loss": 0.6935,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0014942882116883993,
      "rewards/margins": -0.0004189964383840561,
      "rewards/rejected": -0.0010752920061349869,
      "step": 33
    },
    {
      "epoch": 2.64,
      "grad_norm": 6.079700946807861,
      "learning_rate": 8.818181818181818e-08,
      "logits/chosen": 1.4195343255996704,
      "logits/rejected": 1.2229126691818237,
      "logps/chosen": -38.63076400756836,
      "logps/rejected": -47.10460662841797,
      "loss": 0.6861,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.005449533462524414,
      "rewards/margins": 0.014096450060606003,
      "rewards/rejected": -0.008646917529404163,
      "step": 34
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 7.091153621673584,
      "learning_rate": 8.727272727272726e-08,
      "logits/chosen": 0.9216824769973755,
      "logits/rejected": 1.3270490169525146,
      "logps/chosen": -40.146766662597656,
      "logps/rejected": -44.23097610473633,
      "loss": 0.6907,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004871702287346125,
      "rewards/margins": 0.0050154696218669415,
      "rewards/rejected": -0.00014376622857525945,
      "step": 35
    },
    {
      "epoch": 2.8,
      "grad_norm": 6.674053192138672,
      "learning_rate": 8.636363636363636e-08,
      "logits/chosen": 1.0565083026885986,
      "logits/rejected": 1.3140335083007812,
      "logps/chosen": -38.49163818359375,
      "logps/rejected": -43.73876953125,
      "loss": 0.6956,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.006631231401115656,
      "rewards/margins": -0.004678583703935146,
      "rewards/rejected": -0.0019526483956724405,
      "step": 36
    },
    {
      "epoch": 2.88,
      "grad_norm": 7.661518096923828,
      "learning_rate": 8.545454545454544e-08,
      "logits/chosen": 1.3145414590835571,
      "logits/rejected": 1.343285083770752,
      "logps/chosen": -45.20484161376953,
      "logps/rejected": -45.33729553222656,
      "loss": 0.6908,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01062388438731432,
      "rewards/margins": 0.004914259538054466,
      "rewards/rejected": 0.005709624849259853,
      "step": 37
    },
    {
      "epoch": 2.96,
      "grad_norm": 6.105170249938965,
      "learning_rate": 8.454545454545454e-08,
      "logits/chosen": 1.0486799478530884,
      "logits/rejected": 1.2290058135986328,
      "logps/chosen": -38.715824127197266,
      "logps/rejected": -40.34971618652344,
      "loss": 0.6947,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0009430884383618832,
      "rewards/margins": -0.002949619200080633,
      "rewards/rejected": 0.0038927083369344473,
      "step": 38
    },
    {
      "epoch": 3.0,
      "grad_norm": 7.557465553283691,
      "learning_rate": 8.363636363636363e-08,
      "logits/chosen": 1.4796478748321533,
      "logits/rejected": 1.2186100482940674,
      "logps/chosen": -38.724388122558594,
      "logps/rejected": -42.48838806152344,
      "loss": 0.6858,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.017904948443174362,
      "rewards/margins": 0.014933204278349876,
      "rewards/rejected": 0.002971744630485773,
      "step": 39
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": 1.0657551288604736,
      "eval_logits/rejected": 1.0957173109054565,
      "eval_logps/chosen": -37.890052795410156,
      "eval_logps/rejected": -43.916954040527344,
      "eval_loss": 0.6922346353530884,
      "eval_rewards/accuracies": 0.5199999809265137,
      "eval_rewards/chosen": 0.0027954252436757088,
      "eval_rewards/margins": 0.001959585351869464,
      "eval_rewards/rejected": 0.0008358401828445494,
      "eval_runtime": 2.7693,
      "eval_samples_per_second": 36.11,
      "eval_steps_per_second": 18.055,
      "step": 39
    },
    {
      "epoch": 3.08,
      "grad_norm": 5.709173202514648,
      "learning_rate": 8.272727272727272e-08,
      "logits/chosen": 1.1632211208343506,
      "logits/rejected": 1.3634113073349,
      "logps/chosen": -38.40037536621094,
      "logps/rejected": -43.70662307739258,
      "loss": 0.6916,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.01081087626516819,
      "rewards/margins": 0.0033108950592577457,
      "rewards/rejected": 0.007499980740249157,
      "step": 40
    },
    {
      "epoch": 3.16,
      "grad_norm": 5.260519027709961,
      "learning_rate": 8.181818181818182e-08,
      "logits/chosen": 1.254509687423706,
      "logits/rejected": 1.3498210906982422,
      "logps/chosen": -39.359310150146484,
      "logps/rejected": -42.95930862426758,
      "loss": 0.6908,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -4.296284168958664e-05,
      "rewards/margins": 0.004811381921172142,
      "rewards/rejected": -0.004854345694184303,
      "step": 41
    },
    {
      "epoch": 3.24,
      "grad_norm": 6.858907222747803,
      "learning_rate": 8.09090909090909e-08,
      "logits/chosen": 0.9572625160217285,
      "logits/rejected": 1.120439887046814,
      "logps/chosen": -34.18871307373047,
      "logps/rejected": -44.07714080810547,
      "loss": 0.6995,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0003657579654827714,
      "rewards/margins": -0.012557625770568848,
      "rewards/rejected": 0.01219186745584011,
      "step": 42
    },
    {
      "epoch": 3.32,
      "grad_norm": 6.7142333984375,
      "learning_rate": 8e-08,
      "logits/chosen": 1.303017258644104,
      "logits/rejected": 1.2427325248718262,
      "logps/chosen": -37.85988998413086,
      "logps/rejected": -45.31217956542969,
      "loss": 0.6936,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.003414797829464078,
      "rewards/margins": -0.0007780313026160002,
      "rewards/rejected": 0.004192829132080078,
      "step": 43
    },
    {
      "epoch": 3.4,
      "grad_norm": 7.528603553771973,
      "learning_rate": 7.909090909090909e-08,
      "logits/chosen": 1.0807362794876099,
      "logits/rejected": 1.2182902097702026,
      "logps/chosen": -40.650150299072266,
      "logps/rejected": -45.57839584350586,
      "loss": 0.6926,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.002794313710182905,
      "rewards/margins": 0.0012055401457473636,
      "rewards/rejected": -0.003999853506684303,
      "step": 44
    },
    {
      "epoch": 3.48,
      "grad_norm": 7.6851725578308105,
      "learning_rate": 7.818181818181818e-08,
      "logits/chosen": 0.9528794288635254,
      "logits/rejected": 1.1718151569366455,
      "logps/chosen": -36.7232780456543,
      "logps/rejected": -44.83412170410156,
      "loss": 0.6869,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006704759784042835,
      "rewards/margins": 0.01254358235746622,
      "rewards/rejected": -0.00583882350474596,
      "step": 45
    },
    {
      "epoch": 3.56,
      "grad_norm": 8.02531623840332,
      "learning_rate": 7.727272727272727e-08,
      "logits/chosen": 1.0235042572021484,
      "logits/rejected": 1.3093605041503906,
      "logps/chosen": -40.61659240722656,
      "logps/rejected": -48.18236541748047,
      "loss": 0.6956,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.00148019811604172,
      "rewards/margins": -0.004709696397185326,
      "rewards/rejected": 0.003229498863220215,
      "step": 46
    },
    {
      "epoch": 3.64,
      "grad_norm": 7.277647972106934,
      "learning_rate": 7.636363636363636e-08,
      "logits/chosen": 1.2795727252960205,
      "logits/rejected": 1.3580453395843506,
      "logps/chosen": -42.394405364990234,
      "logps/rejected": -38.624969482421875,
      "loss": 0.6954,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0036292551085352898,
      "rewards/margins": -0.004457926377654076,
      "rewards/rejected": 0.0008286712691187859,
      "step": 47
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 6.871992588043213,
      "learning_rate": 7.545454545454545e-08,
      "logits/chosen": 0.9155687689781189,
      "logits/rejected": 1.181760311126709,
      "logps/chosen": -42.98064422607422,
      "logps/rejected": -47.87800598144531,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0022517205215990543,
      "rewards/margins": 0.010431052185595036,
      "rewards/rejected": -0.012682772241532803,
      "step": 48
    },
    {
      "epoch": 3.8,
      "grad_norm": 6.869329929351807,
      "learning_rate": 7.454545454545455e-08,
      "logits/chosen": 1.0876543521881104,
      "logits/rejected": 1.2736327648162842,
      "logps/chosen": -36.979881286621094,
      "logps/rejected": -42.807769775390625,
      "loss": 0.6962,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00028152461163699627,
      "rewards/margins": -0.005911064334213734,
      "rewards/rejected": 0.005629539489746094,
      "step": 49
    },
    {
      "epoch": 3.88,
      "grad_norm": 5.878155708312988,
      "learning_rate": 7.363636363636363e-08,
      "logits/chosen": 1.4349967241287231,
      "logits/rejected": 1.3831548690795898,
      "logps/chosen": -43.260032653808594,
      "logps/rejected": -45.49818420410156,
      "loss": 0.6942,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005288409534841776,
      "rewards/margins": -0.0019417754374444485,
      "rewards/rejected": -0.0033466338645666838,
      "step": 50
    },
    {
      "epoch": 3.96,
      "grad_norm": 7.370457172393799,
      "learning_rate": 7.272727272727273e-08,
      "logits/chosen": 0.9931484460830688,
      "logits/rejected": 1.3226429224014282,
      "logps/chosen": -39.46049499511719,
      "logps/rejected": -43.94175338745117,
      "loss": 0.6979,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0005667447112500668,
      "rewards/margins": -0.009373927488923073,
      "rewards/rejected": 0.008807182312011719,
      "step": 51
    },
    {
      "epoch": 4.0,
      "grad_norm": 8.047088623046875,
      "learning_rate": 7.181818181818181e-08,
      "logits/chosen": 1.4697691202163696,
      "logits/rejected": 1.2398601770401,
      "logps/chosen": -35.045738220214844,
      "logps/rejected": -45.51879119873047,
      "loss": 0.6963,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0033106328919529915,
      "rewards/margins": -0.006217813119292259,
      "rewards/rejected": 0.002907180693000555,
      "step": 52
    },
    {
      "epoch": 4.0,
      "eval_logits/chosen": 1.065608024597168,
      "eval_logits/rejected": 1.0960376262664795,
      "eval_logps/chosen": -37.920684814453125,
      "eval_logps/rejected": -43.92835998535156,
      "eval_loss": 0.6931661367416382,
      "eval_rewards/accuracies": 0.47999998927116394,
      "eval_rewards/chosen": -0.0002681502664927393,
      "eval_rewards/margins": 3.722205656231381e-05,
      "eval_rewards/rejected": -0.0003053723194170743,
      "eval_runtime": 2.7773,
      "eval_samples_per_second": 36.006,
      "eval_steps_per_second": 18.003,
      "step": 52
    },
    {
      "epoch": 4.08,
      "grad_norm": 8.58820915222168,
      "learning_rate": 7.090909090909091e-08,
      "logits/chosen": 1.1675419807434082,
      "logits/rejected": 1.1548537015914917,
      "logps/chosen": -37.295494079589844,
      "logps/rejected": -46.30349349975586,
      "loss": 0.6973,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0027658939361572266,
      "rewards/margins": -0.008176255971193314,
      "rewards/rejected": 0.01094214990735054,
      "step": 53
    },
    {
      "epoch": 4.16,
      "grad_norm": 5.705097198486328,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.2125828266143799,
      "logits/rejected": 1.2257685661315918,
      "logps/chosen": -36.493499755859375,
      "logps/rejected": -42.600074768066406,
      "loss": 0.6921,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0005766870453953743,
      "rewards/margins": 0.002228259574621916,
      "rewards/rejected": -0.0016515731113031507,
      "step": 54
    },
    {
      "epoch": 4.24,
      "grad_norm": 6.966613292694092,
      "learning_rate": 6.909090909090909e-08,
      "logits/chosen": 0.8102076649665833,
      "logits/rejected": 1.3618718385696411,
      "logps/chosen": -37.92442321777344,
      "logps/rejected": -40.748233795166016,
      "loss": 0.6905,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0013768193311989307,
      "rewards/margins": 0.0054578534327447414,
      "rewards/rejected": -0.004081034567207098,
      "step": 55
    },
    {
      "epoch": 4.32,
      "grad_norm": 7.710505485534668,
      "learning_rate": 6.818181818181817e-08,
      "logits/chosen": 1.2300001382827759,
      "logits/rejected": 1.2414016723632812,
      "logps/chosen": -39.628517150878906,
      "logps/rejected": -41.872108459472656,
      "loss": 0.6868,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010929537005722523,
      "rewards/margins": 0.012761570513248444,
      "rewards/rejected": -0.0018320323433727026,
      "step": 56
    },
    {
      "epoch": 4.4,
      "grad_norm": 6.717627048492432,
      "learning_rate": 6.727272727272727e-08,
      "logits/chosen": 0.9608161449432373,
      "logits/rejected": 1.2831979990005493,
      "logps/chosen": -36.1590576171875,
      "logps/rejected": -41.813507080078125,
      "loss": 0.6948,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0009899854194372892,
      "rewards/margins": -0.0030870912596583366,
      "rewards/rejected": 0.002097106073051691,
      "step": 57
    },
    {
      "epoch": 4.48,
      "grad_norm": 6.188192844390869,
      "learning_rate": 6.636363636363637e-08,
      "logits/chosen": 1.3846076726913452,
      "logits/rejected": 1.3772258758544922,
      "logps/chosen": -41.43364715576172,
      "logps/rejected": -43.161746978759766,
      "loss": 0.6968,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.002210665261372924,
      "rewards/margins": -0.0072495462372899055,
      "rewards/rejected": 0.009460210800170898,
      "step": 58
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 6.682127952575684,
      "learning_rate": 6.545454545454545e-08,
      "logits/chosen": 1.045554518699646,
      "logits/rejected": 1.2351491451263428,
      "logps/chosen": -38.81959533691406,
      "logps/rejected": -53.824893951416016,
      "loss": 0.6871,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009807944297790527,
      "rewards/margins": 0.012290977872908115,
      "rewards/rejected": -0.0024830340407788754,
      "step": 59
    },
    {
      "epoch": 4.64,
      "grad_norm": 6.161900043487549,
      "learning_rate": 6.454545454545455e-08,
      "logits/chosen": 1.2939268350601196,
      "logits/rejected": 1.3825528621673584,
      "logps/chosen": -41.1781120300293,
      "logps/rejected": -44.91048812866211,
      "loss": 0.6945,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010208511725068092,
      "rewards/margins": -0.002582835964858532,
      "rewards/rejected": 0.012791348621249199,
      "step": 60
    },
    {
      "epoch": 4.72,
      "grad_norm": 8.209402084350586,
      "learning_rate": 6.363636363636363e-08,
      "logits/chosen": 1.020667552947998,
      "logits/rejected": 1.1572765111923218,
      "logps/chosen": -44.33797836303711,
      "logps/rejected": -46.56229782104492,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0025655508507043123,
      "rewards/margins": -0.0026096582878381014,
      "rewards/rejected": 0.005175209138542414,
      "step": 61
    },
    {
      "epoch": 4.8,
      "grad_norm": 7.02775239944458,
      "learning_rate": 6.272727272727273e-08,
      "logits/chosen": 1.0521836280822754,
      "logits/rejected": 1.1175265312194824,
      "logps/chosen": -35.90869903564453,
      "logps/rejected": -45.258888244628906,
      "loss": 0.6861,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005275368690490723,
      "rewards/margins": 0.014335704036056995,
      "rewards/rejected": -0.009060335345566273,
      "step": 62
    },
    {
      "epoch": 4.88,
      "grad_norm": 5.485253810882568,
      "learning_rate": 6.181818181818181e-08,
      "logits/chosen": 1.3201287984848022,
      "logits/rejected": 1.3249092102050781,
      "logps/chosen": -39.590850830078125,
      "logps/rejected": -40.3880615234375,
      "loss": 0.6937,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.007462429814040661,
      "rewards/margins": -0.0009801385458558798,
      "rewards/rejected": -0.006482291501015425,
      "step": 63
    },
    {
      "epoch": 4.96,
      "grad_norm": 7.177944660186768,
      "learning_rate": 6.090909090909091e-08,
      "logits/chosen": 1.2603890895843506,
      "logits/rejected": 1.3629653453826904,
      "logps/chosen": -40.080589294433594,
      "logps/rejected": -42.93303680419922,
      "loss": 0.6896,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008929348550736904,
      "rewards/margins": 0.0073226215317845345,
      "rewards/rejected": 0.001606726786121726,
      "step": 64
    },
    {
      "epoch": 5.0,
      "grad_norm": 10.2296724319458,
      "learning_rate": 6e-08,
      "logits/chosen": 1.0010366439819336,
      "logits/rejected": 1.4525859355926514,
      "logps/chosen": -42.129276275634766,
      "logps/rejected": -51.40764617919922,
      "loss": 0.6956,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.0011424063704907894,
      "rewards/margins": -0.004795361310243607,
      "rewards/rejected": 0.005937767215073109,
      "step": 65
    },
    {
      "epoch": 5.0,
      "eval_logits/chosen": 1.0654324293136597,
      "eval_logits/rejected": 1.096815824508667,
      "eval_logps/chosen": -37.89502716064453,
      "eval_logps/rejected": -43.92398452758789,
      "eval_loss": 0.6921131610870361,
      "eval_rewards/accuracies": 0.5899999737739563,
      "eval_rewards/chosen": 0.002298241015523672,
      "eval_rewards/margins": 0.00216601206921041,
      "eval_rewards/rejected": 0.0001322288444498554,
      "eval_runtime": 2.7711,
      "eval_samples_per_second": 36.087,
      "eval_steps_per_second": 18.043,
      "step": 65
    },
    {
      "epoch": 5.08,
      "grad_norm": 6.8072919845581055,
      "learning_rate": 5.909090909090909e-08,
      "logits/chosen": 1.3296854496002197,
      "logits/rejected": 1.3953526020050049,
      "logps/chosen": -40.096649169921875,
      "logps/rejected": -43.394439697265625,
      "loss": 0.6911,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006697320844978094,
      "rewards/margins": 0.004408502019941807,
      "rewards/rejected": 0.0022888185922056437,
      "step": 66
    },
    {
      "epoch": 5.16,
      "grad_norm": 6.367744445800781,
      "learning_rate": 5.8181818181818176e-08,
      "logits/chosen": 1.2513370513916016,
      "logits/rejected": 1.1121857166290283,
      "logps/chosen": -41.9703369140625,
      "logps/rejected": -44.49635314941406,
      "loss": 0.6891,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00855183694511652,
      "rewards/margins": 0.008337020874023438,
      "rewards/rejected": 0.00021481490693986416,
      "step": 67
    },
    {
      "epoch": 5.24,
      "grad_norm": 6.430971622467041,
      "learning_rate": 5.727272727272727e-08,
      "logits/chosen": 1.0149497985839844,
      "logits/rejected": 1.1980924606323242,
      "logps/chosen": -35.68224334716797,
      "logps/rejected": -47.54068374633789,
      "loss": 0.6919,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005711746402084827,
      "rewards/margins": 0.002586912829428911,
      "rewards/rejected": 0.0031248333398252726,
      "step": 68
    },
    {
      "epoch": 5.32,
      "grad_norm": 5.736401081085205,
      "learning_rate": 5.636363636363636e-08,
      "logits/chosen": 1.101784110069275,
      "logits/rejected": 1.1933215856552124,
      "logps/chosen": -36.8239860534668,
      "logps/rejected": -38.9938850402832,
      "loss": 0.6932,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003679203800857067,
      "rewards/margins": -1.764355693012476e-05,
      "rewards/rejected": 0.00369684724137187,
      "step": 69
    },
    {
      "epoch": 5.4,
      "grad_norm": 7.442526340484619,
      "learning_rate": 5.5454545454545454e-08,
      "logits/chosen": 1.1101675033569336,
      "logits/rejected": 1.4663090705871582,
      "logps/chosen": -43.16001892089844,
      "logps/rejected": -41.53095245361328,
      "loss": 0.6815,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02376541867852211,
      "rewards/margins": 0.023405956104397774,
      "rewards/rejected": 0.00035946350544691086,
      "step": 70
    },
    {
      "epoch": 5.48,
      "grad_norm": 6.69984769821167,
      "learning_rate": 5.454545454545454e-08,
      "logits/chosen": 1.1344709396362305,
      "logits/rejected": 1.063314437866211,
      "logps/chosen": -39.26066970825195,
      "logps/rejected": -46.14412307739258,
      "loss": 0.6816,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009427309036254883,
      "rewards/margins": 0.023394061252474785,
      "rewards/rejected": -0.013966752216219902,
      "step": 71
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 6.4890241622924805,
      "learning_rate": 5.3636363636363635e-08,
      "logits/chosen": 1.019049882888794,
      "logits/rejected": 1.48154616355896,
      "logps/chosen": -36.08876037597656,
      "logps/rejected": -46.477699279785156,
      "loss": 0.6868,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 6.976118311285973e-05,
      "rewards/margins": 0.012879658490419388,
      "rewards/rejected": -0.012809895910322666,
      "step": 72
    },
    {
      "epoch": 5.64,
      "grad_norm": 6.892837047576904,
      "learning_rate": 5.272727272727272e-08,
      "logits/chosen": 1.155697226524353,
      "logits/rejected": 1.3187360763549805,
      "logps/chosen": -37.863948822021484,
      "logps/rejected": -45.91493225097656,
      "loss": 0.6915,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003794264979660511,
      "rewards/margins": 0.003365015611052513,
      "rewards/rejected": 0.0004292489029467106,
      "step": 73
    },
    {
      "epoch": 5.72,
      "grad_norm": 7.985025882720947,
      "learning_rate": 5.1818181818181817e-08,
      "logits/chosen": 1.0243533849716187,
      "logits/rejected": 1.3884392976760864,
      "logps/chosen": -39.5598030090332,
      "logps/rejected": -47.60582733154297,
      "loss": 0.688,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.012384319677948952,
      "rewards/margins": 0.010439921170473099,
      "rewards/rejected": 0.0019443989731371403,
      "step": 74
    },
    {
      "epoch": 5.8,
      "grad_norm": 6.971113204956055,
      "learning_rate": 5.09090909090909e-08,
      "logits/chosen": 0.8891642093658447,
      "logits/rejected": 1.3346045017242432,
      "logps/chosen": -37.458778381347656,
      "logps/rejected": -41.30842590332031,
      "loss": 0.6943,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0036277538165450096,
      "rewards/margins": -0.00207679346203804,
      "rewards/rejected": -0.001550960587337613,
      "step": 75
    },
    {
      "epoch": 5.88,
      "grad_norm": 6.938117504119873,
      "learning_rate": 5e-08,
      "logits/chosen": 1.2866787910461426,
      "logits/rejected": 1.2047383785247803,
      "logps/chosen": -41.67980194091797,
      "logps/rejected": -45.00141906738281,
      "loss": 0.6963,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0009243483655154705,
      "rewards/margins": -0.006162690464407206,
      "rewards/rejected": 0.007087039761245251,
      "step": 76
    },
    {
      "epoch": 5.96,
      "grad_norm": 6.776516437530518,
      "learning_rate": 4.909090909090909e-08,
      "logits/chosen": 1.0465892553329468,
      "logits/rejected": 1.125701904296875,
      "logps/chosen": -36.70245361328125,
      "logps/rejected": -46.171051025390625,
      "loss": 0.6914,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005886459723114967,
      "rewards/margins": 0.003633785294368863,
      "rewards/rejected": 0.0022526741959154606,
      "step": 77
    },
    {
      "epoch": 6.0,
      "grad_norm": 10.145530700683594,
      "learning_rate": 4.818181818181818e-08,
      "logits/chosen": 1.5088272094726562,
      "logits/rejected": 1.2395622730255127,
      "logps/chosen": -46.51300811767578,
      "logps/rejected": -43.42918014526367,
      "loss": 0.7025,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.010445022955536842,
      "rewards/margins": -0.018540287390351295,
      "rewards/rejected": 0.008095264434814453,
      "step": 78
    },
    {
      "epoch": 6.0,
      "eval_logits/chosen": 1.0655356645584106,
      "eval_logits/rejected": 1.0956439971923828,
      "eval_logps/chosen": -37.871700286865234,
      "eval_logps/rejected": -43.931034088134766,
      "eval_loss": 0.69060879945755,
      "eval_rewards/accuracies": 0.5600000023841858,
      "eval_rewards/chosen": 0.004630615469068289,
      "eval_rewards/margins": 0.005204328801482916,
      "eval_rewards/rejected": -0.0005737130995839834,
      "eval_runtime": 2.7768,
      "eval_samples_per_second": 36.013,
      "eval_steps_per_second": 18.006,
      "step": 78
    }
  ],
  "logging_steps": 1,
  "max_steps": 130,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
