{
  "best_global_step": 559,
  "best_metric": 0.6713243126869202,
  "best_model_checkpoint": "/scratch/user/chuanhsin0110/LLMRec-Labs/unintentional-unalignment/outputs/Goodreads_test/ches_score_top100_epoch100/checkpoint-559",
  "epoch": 43.0,
  "eval_steps": 500,
  "global_step": 559,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 7.832798957824707,
      "learning_rate": 0.0,
      "logits/chosen": 1.3310693502426147,
      "logits/rejected": 1.2552515268325806,
      "logps/chosen": -38.18364715576172,
      "logps/rejected": -53.132118225097656,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.555120468139648,
      "learning_rate": 5e-09,
      "logits/chosen": 1.3258908987045288,
      "logits/rejected": 1.1168854236602783,
      "logps/chosen": -32.30229568481445,
      "logps/rejected": -54.77543640136719,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.326971054077148,
      "learning_rate": 1e-08,
      "logits/chosen": 1.2177958488464355,
      "logits/rejected": 1.1807693243026733,
      "logps/chosen": -35.597328186035156,
      "logps/rejected": -50.93684387207031,
      "loss": 0.6964,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.01171581819653511,
      "rewards/margins": -0.006390690803527832,
      "rewards/rejected": -0.005325126927345991,
      "step": 3
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.755810737609863,
      "learning_rate": 1.5e-08,
      "logits/chosen": 1.1827309131622314,
      "logits/rejected": 1.1037817001342773,
      "logps/chosen": -30.644683837890625,
      "logps/rejected": -58.49082946777344,
      "loss": 0.6916,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003853177884593606,
      "rewards/margins": 0.0030944820027798414,
      "rewards/rejected": 0.0007586957653984427,
      "step": 4
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.317534923553467,
      "learning_rate": 2e-08,
      "logits/chosen": 1.066528558731079,
      "logits/rejected": 1.3527010679244995,
      "logps/chosen": -29.525938034057617,
      "logps/rejected": -49.92799377441406,
      "loss": 0.6971,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.002061915583908558,
      "rewards/margins": -0.00782702025026083,
      "rewards/rejected": 0.005765104666352272,
      "step": 5
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.883938789367676,
      "learning_rate": 2.5e-08,
      "logits/chosen": 1.3096948862075806,
      "logits/rejected": 1.297282099723816,
      "logps/chosen": -36.401607513427734,
      "logps/rejected": -57.76664733886719,
      "loss": 0.6918,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0008435966446995735,
      "rewards/margins": 0.0028887984808534384,
      "rewards/rejected": -0.0020452020689845085,
      "step": 6
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.805821418762207,
      "learning_rate": 3e-08,
      "logits/chosen": 1.2441807985305786,
      "logits/rejected": 1.236514925956726,
      "logps/chosen": -34.795223236083984,
      "logps/rejected": -60.896095275878906,
      "loss": 0.6967,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.0017276285216212273,
      "rewards/margins": -0.006986856460571289,
      "rewards/rejected": 0.008714484982192516,
      "step": 7
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.372105121612549,
      "learning_rate": 3.4999999999999996e-08,
      "logits/chosen": 1.2159578800201416,
      "logits/rejected": 1.1956720352172852,
      "logps/chosen": -31.36081314086914,
      "logps/rejected": -48.767852783203125,
      "loss": 0.6902,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0027017120737582445,
      "rewards/margins": 0.005945777986198664,
      "rewards/rejected": -0.0032440663781017065,
      "step": 8
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.48534870147705,
      "learning_rate": 4e-08,
      "logits/chosen": 1.4350812435150146,
      "logits/rejected": 1.2775585651397705,
      "logps/chosen": -38.03495788574219,
      "logps/rejected": -53.87250518798828,
      "loss": 0.6968,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.006321048829704523,
      "rewards/margins": -0.007340145297348499,
      "rewards/rejected": 0.0010190964676439762,
      "step": 9
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.338312149047852,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.3126327991485596,
      "logits/rejected": 1.3534767627716064,
      "logps/chosen": -29.522003173828125,
      "logps/rejected": -51.50434875488281,
      "loss": 0.6899,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.003760624211281538,
      "rewards/margins": 0.006600713822990656,
      "rewards/rejected": -0.010361338034272194,
      "step": 10
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.874818801879883,
      "learning_rate": 5e-08,
      "logits/chosen": 1.4245519638061523,
      "logits/rejected": 1.111140251159668,
      "logps/chosen": -34.91636276245117,
      "logps/rejected": -57.692047119140625,
      "loss": 0.6953,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.004565763287246227,
      "rewards/margins": -0.0043249609880149364,
      "rewards/rejected": -0.00024080276489257812,
      "step": 11
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.164686679840088,
      "learning_rate": 5.5e-08,
      "logits/chosen": 1.36062753200531,
      "logits/rejected": 1.539231538772583,
      "logps/chosen": -39.918434143066406,
      "logps/rejected": -62.54383850097656,
      "loss": 0.6865,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0034180404618382454,
      "rewards/margins": 0.013546586036682129,
      "rewards/rejected": -0.010128545574843884,
      "step": 12
    },
    {
      "epoch": 1.0,
      "grad_norm": 11.479731559753418,
      "learning_rate": 6e-08,
      "logits/chosen": 1.386464238166809,
      "logits/rejected": 1.4492965936660767,
      "logps/chosen": -33.343143463134766,
      "logps/rejected": -51.052711486816406,
      "loss": 0.6903,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.006881380919367075,
      "rewards/margins": 0.005849790293723345,
      "rewards/rejected": 0.0010315896943211555,
      "step": 13
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 1.3043532371520996,
      "eval_logits/rejected": 1.1982649564743042,
      "eval_logps/chosen": -34.48662185668945,
      "eval_logps/rejected": -46.985050201416016,
      "eval_loss": 0.6933651566505432,
      "eval_rewards/accuracies": 0.550000011920929,
      "eval_rewards/chosen": 0.0012892206432297826,
      "eval_rewards/margins": -0.00032449723221361637,
      "eval_rewards/rejected": 0.001613717875443399,
      "eval_runtime": 2.7063,
      "eval_samples_per_second": 36.951,
      "eval_steps_per_second": 18.476,
      "step": 13
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.259261608123779,
      "learning_rate": 6.5e-08,
      "logits/chosen": 1.4839285612106323,
      "logits/rejected": 1.354259729385376,
      "logps/chosen": -30.18348503112793,
      "logps/rejected": -55.727684020996094,
      "loss": 0.695,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004667353816330433,
      "rewards/margins": -0.0037104368675500154,
      "rewards/rejected": 0.008377790451049805,
      "step": 14
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.788173675537109,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.1996264457702637,
      "logits/rejected": 1.359665870666504,
      "logps/chosen": -34.235923767089844,
      "logps/rejected": -55.484840393066406,
      "loss": 0.6946,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0032537938095629215,
      "rewards/margins": -0.0028334143571555614,
      "rewards/rejected": 0.006087208166718483,
      "step": 15
    },
    {
      "epoch": 1.24,
      "grad_norm": 8.592458724975586,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.1669740676879883,
      "logits/rejected": 0.9790306091308594,
      "logps/chosen": -31.886474609375,
      "logps/rejected": -49.787818908691406,
      "loss": 0.6909,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0034445524215698242,
      "rewards/margins": 0.00465354835614562,
      "rewards/rejected": -0.008098102174699306,
      "step": 16
    },
    {
      "epoch": 1.32,
      "grad_norm": 7.594528675079346,
      "learning_rate": 8e-08,
      "logits/chosen": 1.4092696905136108,
      "logits/rejected": 1.2833776473999023,
      "logps/chosen": -31.400001525878906,
      "logps/rejected": -58.165313720703125,
      "loss": 0.6895,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0023637772537767887,
      "rewards/margins": 0.007442951668053865,
      "rewards/rejected": -0.009806728921830654,
      "step": 17
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.379502773284912,
      "learning_rate": 8.5e-08,
      "logits/chosen": 1.3043955564498901,
      "logits/rejected": 1.3449150323867798,
      "logps/chosen": -36.073726654052734,
      "logps/rejected": -50.96331024169922,
      "loss": 0.6945,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005463766865432262,
      "rewards/margins": -0.002680992940440774,
      "rewards/rejected": 0.008144760504364967,
      "step": 18
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.734749794006348,
      "learning_rate": 9e-08,
      "logits/chosen": 1.1753181219100952,
      "logits/rejected": 1.0464363098144531,
      "logps/chosen": -34.865760803222656,
      "logps/rejected": -56.000831604003906,
      "loss": 0.6985,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.006457519717514515,
      "rewards/margins": -0.010711289010941982,
      "rewards/rejected": 0.004253769293427467,
      "step": 19
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.842024326324463,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.2154470682144165,
      "logits/rejected": 1.3275396823883057,
      "logps/chosen": -34.30143737792969,
      "logps/rejected": -60.64790344238281,
      "loss": 0.6941,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0018848180770874023,
      "rewards/margins": -0.0017590755596756935,
      "rewards/rejected": -0.00012574251741170883,
      "step": 20
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 8.086492538452148,
      "learning_rate": 1e-07,
      "logits/chosen": 1.3706283569335938,
      "logits/rejected": 1.0959497690200806,
      "logps/chosen": -33.55364990234375,
      "logps/rejected": -49.00587463378906,
      "loss": 0.6901,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.005014157388359308,
      "rewards/margins": 0.0062645673751831055,
      "rewards/rejected": -0.011278724297881126,
      "step": 21
    },
    {
      "epoch": 1.72,
      "grad_norm": 8.915935516357422,
      "learning_rate": 9.9921875e-08,
      "logits/chosen": 1.2908437252044678,
      "logits/rejected": 1.2470676898956299,
      "logps/chosen": -39.2299690246582,
      "logps/rejected": -56.64617156982422,
      "loss": 0.6939,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0021555188577622175,
      "rewards/margins": -0.001451039919629693,
      "rewards/rejected": -0.0007044791709631681,
      "step": 22
    },
    {
      "epoch": 1.8,
      "grad_norm": 8.61536693572998,
      "learning_rate": 9.984375e-08,
      "logits/chosen": 1.3004131317138672,
      "logits/rejected": 1.2637791633605957,
      "logps/chosen": -34.29813766479492,
      "logps/rejected": -55.41741180419922,
      "loss": 0.6872,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004701661877334118,
      "rewards/margins": 0.01209259033203125,
      "rewards/rejected": -0.007390928454697132,
      "step": 23
    },
    {
      "epoch": 1.88,
      "grad_norm": 6.974838733673096,
      "learning_rate": 9.9765625e-08,
      "logits/chosen": 1.3190423250198364,
      "logits/rejected": 1.3792725801467896,
      "logps/chosen": -33.09275436401367,
      "logps/rejected": -48.83880615234375,
      "loss": 0.6957,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.0004973887698724866,
      "rewards/margins": -0.00505332974717021,
      "rewards/rejected": 0.005550718866288662,
      "step": 24
    },
    {
      "epoch": 1.96,
      "grad_norm": 6.951394081115723,
      "learning_rate": 9.968749999999999e-08,
      "logits/chosen": 1.3511537313461304,
      "logits/rejected": 1.2982616424560547,
      "logps/chosen": -36.84638214111328,
      "logps/rejected": -63.71232223510742,
      "loss": 0.6906,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -3.57629032805562e-05,
      "rewards/margins": 0.005186367314308882,
      "rewards/rejected": -0.005222129635512829,
      "step": 25
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.944988250732422,
      "learning_rate": 9.9609375e-08,
      "logits/chosen": 1.1522213220596313,
      "logits/rejected": 1.421953558921814,
      "logps/chosen": -35.55683898925781,
      "logps/rejected": -50.68988800048828,
      "loss": 0.6836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010015727020800114,
      "rewards/margins": 0.01919856108725071,
      "rewards/rejected": -0.009182834066450596,
      "step": 26
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 1.305213212966919,
      "eval_logits/rejected": 1.1975308656692505,
      "eval_logps/chosen": -34.495296478271484,
      "eval_logps/rejected": -46.99305725097656,
      "eval_loss": 0.6933919787406921,
      "eval_rewards/accuracies": 0.49000000953674316,
      "eval_rewards/chosen": 0.0004218274261802435,
      "eval_rewards/margins": -0.0003913022519554943,
      "eval_rewards/rejected": 0.0008131294744089246,
      "eval_runtime": 2.7043,
      "eval_samples_per_second": 36.977,
      "eval_steps_per_second": 18.489,
      "step": 26
    },
    {
      "epoch": 2.08,
      "grad_norm": 7.482143402099609,
      "learning_rate": 9.953125e-08,
      "logits/chosen": 1.3517324924468994,
      "logits/rejected": 1.2937976121902466,
      "logps/chosen": -34.78208923339844,
      "logps/rejected": -54.62517166137695,
      "loss": 0.6959,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.007262253202497959,
      "rewards/margins": -0.005304408259689808,
      "rewards/rejected": -0.001957845874130726,
      "step": 27
    },
    {
      "epoch": 2.16,
      "grad_norm": 8.226454734802246,
      "learning_rate": 9.945312499999999e-08,
      "logits/chosen": 1.2495787143707275,
      "logits/rejected": 1.1970769166946411,
      "logps/chosen": -35.75505828857422,
      "logps/rejected": -56.549835205078125,
      "loss": 0.6957,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005588436499238014,
      "rewards/margins": -0.0051389699801802635,
      "rewards/rejected": -0.0004494664608500898,
      "step": 28
    },
    {
      "epoch": 2.24,
      "grad_norm": 7.437453746795654,
      "learning_rate": 9.9375e-08,
      "logits/chosen": 1.2912694215774536,
      "logits/rejected": 1.308596134185791,
      "logps/chosen": -35.818458557128906,
      "logps/rejected": -51.169315338134766,
      "loss": 0.6971,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010291481390595436,
      "rewards/margins": -0.007739591877907515,
      "rewards/rejected": -0.002551889047026634,
      "step": 29
    },
    {
      "epoch": 2.32,
      "grad_norm": 6.683032512664795,
      "learning_rate": 9.929687499999999e-08,
      "logits/chosen": 1.3621160984039307,
      "logits/rejected": 1.1512962579727173,
      "logps/chosen": -34.98652267456055,
      "logps/rejected": -52.77524948120117,
      "loss": 0.6927,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006467938423156738,
      "rewards/margins": 0.0010292289080098271,
      "rewards/rejected": 0.005438709631562233,
      "step": 30
    },
    {
      "epoch": 2.4,
      "grad_norm": 6.765615940093994,
      "learning_rate": 9.921874999999999e-08,
      "logits/chosen": 1.272133708000183,
      "logits/rejected": 1.355900526046753,
      "logps/chosen": -30.574996948242188,
      "logps/rejected": -53.959861755371094,
      "loss": 0.6977,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0009823085274547338,
      "rewards/margins": -0.009043479338288307,
      "rewards/rejected": 0.00806117057800293,
      "step": 31
    },
    {
      "epoch": 2.48,
      "grad_norm": 8.440461158752441,
      "learning_rate": 9.9140625e-08,
      "logits/chosen": 1.2344934940338135,
      "logits/rejected": 1.1582117080688477,
      "logps/chosen": -30.186784744262695,
      "logps/rejected": -53.87934494018555,
      "loss": 0.6849,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.002262831199914217,
      "rewards/margins": 0.016542674973607063,
      "rewards/rejected": -0.014279843308031559,
      "step": 32
    },
    {
      "epoch": 2.56,
      "grad_norm": 7.887796878814697,
      "learning_rate": 9.906249999999999e-08,
      "logits/chosen": 1.3459224700927734,
      "logits/rejected": 1.351119875907898,
      "logps/chosen": -35.72117233276367,
      "logps/rejected": -49.61790084838867,
      "loss": 0.6854,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01255948655307293,
      "rewards/margins": 0.015752293169498444,
      "rewards/rejected": -0.0031928063835948706,
      "step": 33
    },
    {
      "epoch": 2.64,
      "grad_norm": 9.705853462219238,
      "learning_rate": 9.898437499999999e-08,
      "logits/chosen": 1.455370306968689,
      "logits/rejected": 1.2128318548202515,
      "logps/chosen": -39.54311752319336,
      "logps/rejected": -61.78209686279297,
      "loss": 0.6921,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00849685724824667,
      "rewards/margins": 0.0021396162919700146,
      "rewards/rejected": 0.006357240490615368,
      "step": 34
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 6.678696155548096,
      "learning_rate": 9.890624999999999e-08,
      "logits/chosen": 1.1875299215316772,
      "logits/rejected": 1.133289098739624,
      "logps/chosen": -30.611907958984375,
      "logps/rejected": -54.29505920410156,
      "loss": 0.6953,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0036580325104296207,
      "rewards/margins": -0.004166817758232355,
      "rewards/rejected": 0.007824850268661976,
      "step": 35
    },
    {
      "epoch": 2.8,
      "grad_norm": 9.022202491760254,
      "learning_rate": 9.8828125e-08,
      "logits/chosen": 1.2180671691894531,
      "logits/rejected": 1.2372254133224487,
      "logps/chosen": -31.936004638671875,
      "logps/rejected": -53.95703125,
      "loss": 0.6928,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.006165338214486837,
      "rewards/margins": 0.0007980584632605314,
      "rewards/rejected": -0.006963396444916725,
      "step": 36
    },
    {
      "epoch": 2.88,
      "grad_norm": 7.285675048828125,
      "learning_rate": 9.875e-08,
      "logits/chosen": 1.3450326919555664,
      "logits/rejected": 1.3146288394927979,
      "logps/chosen": -34.283782958984375,
      "logps/rejected": -58.32658004760742,
      "loss": 0.6971,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0010262730065733194,
      "rewards/margins": -0.007704806048423052,
      "rewards/rejected": 0.008731079287827015,
      "step": 37
    },
    {
      "epoch": 2.96,
      "grad_norm": 7.753377437591553,
      "learning_rate": 9.8671875e-08,
      "logits/chosen": 1.2866556644439697,
      "logits/rejected": 1.2057313919067383,
      "logps/chosen": -36.14362335205078,
      "logps/rejected": -60.402164459228516,
      "loss": 0.6966,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.006308579817414284,
      "rewards/margins": -0.006580710411071777,
      "rewards/rejected": 0.0002721310593187809,
      "step": 38
    },
    {
      "epoch": 3.0,
      "grad_norm": 10.277792930603027,
      "learning_rate": 9.859375e-08,
      "logits/chosen": 1.2584210634231567,
      "logits/rejected": 1.4492090940475464,
      "logps/chosen": -34.664268493652344,
      "logps/rejected": -48.499393463134766,
      "loss": 0.7001,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0045740604400634766,
      "rewards/margins": -0.013718366622924805,
      "rewards/rejected": 0.009144306182861328,
      "step": 39
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": 1.304010033607483,
      "eval_logits/rejected": 1.198239803314209,
      "eval_logps/chosen": -34.48177719116211,
      "eval_logps/rejected": -47.03013229370117,
      "eval_loss": 0.6908591985702515,
      "eval_rewards/accuracies": 0.6600000262260437,
      "eval_rewards/chosen": 0.0017739124596118927,
      "eval_rewards/margins": 0.004668531473726034,
      "eval_rewards/rejected": -0.0028946194797754288,
      "eval_runtime": 2.7071,
      "eval_samples_per_second": 36.94,
      "eval_steps_per_second": 18.47,
      "step": 39
    },
    {
      "epoch": 3.08,
      "grad_norm": 9.236026763916016,
      "learning_rate": 9.8515625e-08,
      "logits/chosen": 1.4257968664169312,
      "logits/rejected": 1.2615035772323608,
      "logps/chosen": -37.34517288208008,
      "logps/rejected": -68.66419219970703,
      "loss": 0.6962,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.008835411630570889,
      "rewards/margins": -0.005959128960967064,
      "rewards/rejected": -0.0028762815054506063,
      "step": 40
    },
    {
      "epoch": 3.16,
      "grad_norm": 5.982080459594727,
      "learning_rate": 9.84375e-08,
      "logits/chosen": 1.3243610858917236,
      "logits/rejected": 1.3690495491027832,
      "logps/chosen": -35.99791717529297,
      "logps/rejected": -47.275115966796875,
      "loss": 0.6943,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0050074574537575245,
      "rewards/margins": -0.002263976028189063,
      "rewards/rejected": -0.002743482356891036,
      "step": 41
    },
    {
      "epoch": 3.24,
      "grad_norm": 6.951827049255371,
      "learning_rate": 9.8359375e-08,
      "logits/chosen": 1.405524492263794,
      "logits/rejected": 1.2856991291046143,
      "logps/chosen": -32.56797409057617,
      "logps/rejected": -58.75117874145508,
      "loss": 0.692,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00035779469180852175,
      "rewards/margins": 0.00231020525097847,
      "rewards/rejected": -0.0026679993607103825,
      "step": 42
    },
    {
      "epoch": 3.32,
      "grad_norm": 7.44862174987793,
      "learning_rate": 9.828125e-08,
      "logits/chosen": 1.1238605976104736,
      "logits/rejected": 1.3926165103912354,
      "logps/chosen": -30.23744010925293,
      "logps/rejected": -56.904476165771484,
      "loss": 0.6948,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.006517315283417702,
      "rewards/margins": -0.003019047901034355,
      "rewards/rejected": -0.0034982680808752775,
      "step": 43
    },
    {
      "epoch": 3.4,
      "grad_norm": 7.731142044067383,
      "learning_rate": 9.8203125e-08,
      "logits/chosen": 1.2823855876922607,
      "logits/rejected": 1.15843665599823,
      "logps/chosen": -32.84834289550781,
      "logps/rejected": -49.74429702758789,
      "loss": 0.6932,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.011795854195952415,
      "rewards/margins": 0.00012860307469964027,
      "rewards/rejected": -0.011924457736313343,
      "step": 44
    },
    {
      "epoch": 3.48,
      "grad_norm": 8.812846183776855,
      "learning_rate": 9.812499999999999e-08,
      "logits/chosen": 1.355675220489502,
      "logits/rejected": 1.165937900543213,
      "logps/chosen": -32.92424774169922,
      "logps/rejected": -43.95237731933594,
      "loss": 0.6869,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0018025159370154142,
      "rewards/margins": 0.01255042664706707,
      "rewards/rejected": -0.010747909545898438,
      "step": 45
    },
    {
      "epoch": 3.56,
      "grad_norm": 8.808919906616211,
      "learning_rate": 9.8046875e-08,
      "logits/chosen": 1.224490761756897,
      "logits/rejected": 1.1412529945373535,
      "logps/chosen": -32.71175003051758,
      "logps/rejected": -58.56663513183594,
      "loss": 0.6934,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006749414838850498,
      "rewards/margins": -0.00044052605517208576,
      "rewards/rejected": 0.007189941126853228,
      "step": 46
    },
    {
      "epoch": 3.64,
      "grad_norm": 7.543618202209473,
      "learning_rate": 9.796875e-08,
      "logits/chosen": 1.1668248176574707,
      "logits/rejected": 1.082930326461792,
      "logps/chosen": -34.746673583984375,
      "logps/rejected": -55.978919982910156,
      "loss": 0.69,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0007205248111858964,
      "rewards/margins": 0.006332707591354847,
      "rewards/rejected": -0.007053232751786709,
      "step": 47
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 7.342947483062744,
      "learning_rate": 9.789062499999999e-08,
      "logits/chosen": 1.235737919807434,
      "logits/rejected": 1.2271051406860352,
      "logps/chosen": -36.8045654296875,
      "logps/rejected": -60.275535583496094,
      "loss": 0.6862,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008952546864748001,
      "rewards/margins": 0.014116312377154827,
      "rewards/rejected": -0.005163764581084251,
      "step": 48
    },
    {
      "epoch": 3.8,
      "grad_norm": 7.227224826812744,
      "learning_rate": 9.78125e-08,
      "logits/chosen": 1.196224570274353,
      "logits/rejected": 1.0653502941131592,
      "logps/chosen": -30.619665145874023,
      "logps/rejected": -47.382843017578125,
      "loss": 0.6977,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010038424283266068,
      "rewards/margins": -0.00890259724110365,
      "rewards/rejected": -0.0011358262272551656,
      "step": 49
    },
    {
      "epoch": 3.88,
      "grad_norm": 7.545997619628906,
      "learning_rate": 9.773437499999999e-08,
      "logits/chosen": 1.2705329656600952,
      "logits/rejected": 1.486989140510559,
      "logps/chosen": -32.008914947509766,
      "logps/rejected": -58.39278030395508,
      "loss": 0.6926,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0013377905124798417,
      "rewards/margins": 0.0011677980655804276,
      "rewards/rejected": -0.0025055883452296257,
      "step": 50
    },
    {
      "epoch": 3.96,
      "grad_norm": 7.807016849517822,
      "learning_rate": 9.765624999999999e-08,
      "logits/chosen": 1.6170234680175781,
      "logits/rejected": 1.4134862422943115,
      "logps/chosen": -40.89461898803711,
      "logps/rejected": -57.59765625,
      "loss": 0.6923,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.005145764444023371,
      "rewards/margins": 0.001769280876033008,
      "rewards/rejected": 0.003376483917236328,
      "step": 51
    },
    {
      "epoch": 4.0,
      "grad_norm": 10.26676082611084,
      "learning_rate": 9.7578125e-08,
      "logits/chosen": 1.2761813402175903,
      "logits/rejected": 1.3833987712860107,
      "logps/chosen": -36.37372970581055,
      "logps/rejected": -45.25617218017578,
      "loss": 0.6965,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0015019417041912675,
      "rewards/margins": -0.006551075726747513,
      "rewards/rejected": 0.00504913367331028,
      "step": 52
    },
    {
      "epoch": 4.0,
      "eval_logits/chosen": 1.3035423755645752,
      "eval_logits/rejected": 1.197189211845398,
      "eval_logps/chosen": -34.48448944091797,
      "eval_logps/rejected": -46.9848747253418,
      "eval_loss": 0.6932636499404907,
      "eval_rewards/accuracies": 0.5,
      "eval_rewards/chosen": 0.0015023653395473957,
      "eval_rewards/margins": -0.00012902099115308374,
      "eval_rewards/rejected": 0.0016313859960064292,
      "eval_runtime": 2.7128,
      "eval_samples_per_second": 36.863,
      "eval_steps_per_second": 18.431,
      "step": 52
    },
    {
      "epoch": 4.08,
      "grad_norm": 8.077439308166504,
      "learning_rate": 9.749999999999999e-08,
      "logits/chosen": 1.1519553661346436,
      "logits/rejected": 1.12236487865448,
      "logps/chosen": -34.61963653564453,
      "logps/rejected": -48.45476531982422,
      "loss": 0.7007,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.002928734291344881,
      "rewards/margins": -0.014988996088504791,
      "rewards/rejected": 0.012060260400176048,
      "step": 53
    },
    {
      "epoch": 4.16,
      "grad_norm": 9.522790908813477,
      "learning_rate": 9.7421875e-08,
      "logits/chosen": 1.3063870668411255,
      "logits/rejected": 1.1330499649047852,
      "logps/chosen": -31.32805633544922,
      "logps/rejected": -50.47982406616211,
      "loss": 0.6965,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.008323860354721546,
      "rewards/margins": -0.006608057301491499,
      "rewards/rejected": -0.0017158035188913345,
      "step": 54
    },
    {
      "epoch": 4.24,
      "grad_norm": 6.605930328369141,
      "learning_rate": 9.734375e-08,
      "logits/chosen": 1.407303810119629,
      "logits/rejected": 1.3746907711029053,
      "logps/chosen": -41.588401794433594,
      "logps/rejected": -58.997276306152344,
      "loss": 0.6928,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.009450244717299938,
      "rewards/margins": 0.0007877354510128498,
      "rewards/rejected": -0.010237980633974075,
      "step": 55
    },
    {
      "epoch": 4.32,
      "grad_norm": 7.599425315856934,
      "learning_rate": 9.7265625e-08,
      "logits/chosen": 1.1388475894927979,
      "logits/rejected": 1.3288965225219727,
      "logps/chosen": -32.60577392578125,
      "logps/rejected": -57.21119689941406,
      "loss": 0.6893,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0003147600218653679,
      "rewards/margins": 0.007746362127363682,
      "rewards/rejected": -0.007431602105498314,
      "step": 56
    },
    {
      "epoch": 4.4,
      "grad_norm": 6.841515064239502,
      "learning_rate": 9.71875e-08,
      "logits/chosen": 1.3366097211837769,
      "logits/rejected": 1.3160384893417358,
      "logps/chosen": -37.511985778808594,
      "logps/rejected": -61.238731384277344,
      "loss": 0.6864,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.003011775203049183,
      "rewards/margins": 0.013708282262086868,
      "rewards/rejected": -0.016720056533813477,
      "step": 57
    },
    {
      "epoch": 4.48,
      "grad_norm": 7.757526397705078,
      "learning_rate": 9.7109375e-08,
      "logits/chosen": 1.2464637756347656,
      "logits/rejected": 1.063014268875122,
      "logps/chosen": -34.27224349975586,
      "logps/rejected": -45.744789123535156,
      "loss": 0.6897,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0035839322954416275,
      "rewards/margins": 0.006952500902116299,
      "rewards/rejected": -0.003368568606674671,
      "step": 58
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 8.858298301696777,
      "learning_rate": 9.703125e-08,
      "logits/chosen": 1.2311573028564453,
      "logits/rejected": 1.2914341688156128,
      "logps/chosen": -37.59563446044922,
      "logps/rejected": -65.62933349609375,
      "loss": 0.6877,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00651443051174283,
      "rewards/margins": 0.011117959395051003,
      "rewards/rejected": -0.004603528883308172,
      "step": 59
    },
    {
      "epoch": 4.64,
      "grad_norm": 7.127862453460693,
      "learning_rate": 9.695312499999998e-08,
      "logits/chosen": 1.4359025955200195,
      "logits/rejected": 1.408874273300171,
      "logps/chosen": -34.21762466430664,
      "logps/rejected": -57.074485778808594,
      "loss": 0.685,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0035534619819372892,
      "rewards/margins": 0.016505742445588112,
      "rewards/rejected": -0.012952280230820179,
      "step": 60
    },
    {
      "epoch": 4.72,
      "grad_norm": 7.967607021331787,
      "learning_rate": 9.6875e-08,
      "logits/chosen": 1.3984676599502563,
      "logits/rejected": 1.301060676574707,
      "logps/chosen": -34.15336608886719,
      "logps/rejected": -49.649723052978516,
      "loss": 0.6915,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.001099372049793601,
      "rewards/margins": 0.0033768420107662678,
      "rewards/rejected": -0.004476213827729225,
      "step": 61
    },
    {
      "epoch": 4.8,
      "grad_norm": 8.505511283874512,
      "learning_rate": 9.6796875e-08,
      "logits/chosen": 1.4457776546478271,
      "logits/rejected": 1.1880944967269897,
      "logps/chosen": -32.005271911621094,
      "logps/rejected": -54.93663024902344,
      "loss": 0.6917,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005947566125541925,
      "rewards/margins": 0.002918028738349676,
      "rewards/rejected": 0.0030295371543616056,
      "step": 62
    },
    {
      "epoch": 4.88,
      "grad_norm": 6.83784818649292,
      "learning_rate": 9.671874999999999e-08,
      "logits/chosen": 1.3075225353240967,
      "logits/rejected": 1.308008074760437,
      "logps/chosen": -30.370220184326172,
      "logps/rejected": -51.36241912841797,
      "loss": 0.6886,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010284590534865856,
      "rewards/margins": 0.009281945414841175,
      "rewards/rejected": 0.0010026455856859684,
      "step": 63
    },
    {
      "epoch": 4.96,
      "grad_norm": 6.958853244781494,
      "learning_rate": 9.6640625e-08,
      "logits/chosen": 1.2564617395401,
      "logits/rejected": 1.232116460800171,
      "logps/chosen": -33.25114822387695,
      "logps/rejected": -59.603450775146484,
      "loss": 0.6923,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0033980607986450195,
      "rewards/margins": 0.0018823868595063686,
      "rewards/rejected": 0.0015156744047999382,
      "step": 64
    },
    {
      "epoch": 5.0,
      "grad_norm": 10.761595726013184,
      "learning_rate": 9.656249999999999e-08,
      "logits/chosen": 1.1290384531021118,
      "logits/rejected": 1.3149762153625488,
      "logps/chosen": -27.952274322509766,
      "logps/rejected": -51.6113395690918,
      "loss": 0.6912,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008192396722733974,
      "rewards/margins": 0.00398068455979228,
      "rewards/rejected": 0.004211712628602982,
      "step": 65
    },
    {
      "epoch": 5.0,
      "eval_logits/chosen": 1.3039053678512573,
      "eval_logits/rejected": 1.1989319324493408,
      "eval_logps/chosen": -34.45012283325195,
      "eval_logps/rejected": -46.95795440673828,
      "eval_loss": 0.6928899884223938,
      "eval_rewards/accuracies": 0.5199999809265137,
      "eval_rewards/chosen": 0.004939315840601921,
      "eval_rewards/margins": 0.0006158087635412812,
      "eval_rewards/rejected": 0.004323507659137249,
      "eval_runtime": 2.7153,
      "eval_samples_per_second": 36.828,
      "eval_steps_per_second": 18.414,
      "step": 65
    },
    {
      "epoch": 5.08,
      "grad_norm": 8.507393836975098,
      "learning_rate": 9.648437499999999e-08,
      "logits/chosen": 1.2040969133377075,
      "logits/rejected": 1.3143510818481445,
      "logps/chosen": -34.73176956176758,
      "logps/rejected": -54.32247543334961,
      "loss": 0.6911,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0040367366746068,
      "rewards/margins": 0.004068207927048206,
      "rewards/rejected": -3.147125244140625e-05,
      "step": 66
    },
    {
      "epoch": 5.16,
      "grad_norm": 8.031421661376953,
      "learning_rate": 9.640625e-08,
      "logits/chosen": 1.253151535987854,
      "logits/rejected": 1.2033675909042358,
      "logps/chosen": -34.17063903808594,
      "logps/rejected": -49.22089767456055,
      "loss": 0.6903,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0111243249848485,
      "rewards/margins": 0.005785751156508923,
      "rewards/rejected": 0.005338573362678289,
      "step": 67
    },
    {
      "epoch": 5.24,
      "grad_norm": 8.308528900146484,
      "learning_rate": 9.632812499999999e-08,
      "logits/chosen": 1.4493968486785889,
      "logits/rejected": 1.3021888732910156,
      "logps/chosen": -39.76043701171875,
      "logps/rejected": -54.43330383300781,
      "loss": 0.6943,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0008351802825927734,
      "rewards/margins": -0.002229977399110794,
      "rewards/rejected": 0.0013947966508567333,
      "step": 68
    },
    {
      "epoch": 5.32,
      "grad_norm": 7.519227027893066,
      "learning_rate": 9.624999999999999e-08,
      "logits/chosen": 1.3947844505310059,
      "logits/rejected": 1.370129942893982,
      "logps/chosen": -35.12544631958008,
      "logps/rejected": -57.88005065917969,
      "loss": 0.6941,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0010788440704345703,
      "rewards/margins": -0.0018950463272631168,
      "rewards/rejected": 0.0008162020239979029,
      "step": 69
    },
    {
      "epoch": 5.4,
      "grad_norm": 7.282973289489746,
      "learning_rate": 9.617187499999999e-08,
      "logits/chosen": 1.219101905822754,
      "logits/rejected": 1.1634724140167236,
      "logps/chosen": -33.38330078125,
      "logps/rejected": -55.4354133605957,
      "loss": 0.6902,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005169153679162264,
      "rewards/margins": 0.005926799960434437,
      "rewards/rejected": -0.0007576467469334602,
      "step": 70
    },
    {
      "epoch": 5.48,
      "grad_norm": 7.468265056610107,
      "learning_rate": 9.609374999999999e-08,
      "logits/chosen": 1.1703788042068481,
      "logits/rejected": 1.2995502948760986,
      "logps/chosen": -30.072458267211914,
      "logps/rejected": -55.71460723876953,
      "loss": 0.697,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0037136320024728775,
      "rewards/margins": -0.007662272080779076,
      "rewards/rejected": 0.011375904083251953,
      "step": 71
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 7.409971237182617,
      "learning_rate": 9.6015625e-08,
      "logits/chosen": 1.3099130392074585,
      "logits/rejected": 1.103298544883728,
      "logps/chosen": -35.46250534057617,
      "logps/rejected": -53.382362365722656,
      "loss": 0.6892,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.011772704310715199,
      "rewards/margins": 0.008023333735764027,
      "rewards/rejected": 0.003749370574951172,
      "step": 72
    },
    {
      "epoch": 5.64,
      "grad_norm": 7.591115951538086,
      "learning_rate": 9.59375e-08,
      "logits/chosen": 1.2739717960357666,
      "logits/rejected": 1.2600739002227783,
      "logps/chosen": -32.848976135253906,
      "logps/rejected": -49.93111038208008,
      "loss": 0.6871,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 6.222748197615147e-06,
      "rewards/margins": 0.012128520756959915,
      "rewards/rejected": -0.012122297659516335,
      "step": 73
    },
    {
      "epoch": 5.72,
      "grad_norm": 6.86074161529541,
      "learning_rate": 9.5859375e-08,
      "logits/chosen": 1.5234057903289795,
      "logits/rejected": 1.3688000440597534,
      "logps/chosen": -31.707117080688477,
      "logps/rejected": -49.573062896728516,
      "loss": 0.6868,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011764789000153542,
      "rewards/margins": 0.012830615043640137,
      "rewards/rejected": -0.0010658265091478825,
      "step": 74
    },
    {
      "epoch": 5.8,
      "grad_norm": 7.89826774597168,
      "learning_rate": 9.578125e-08,
      "logits/chosen": 1.235503911972046,
      "logits/rejected": 1.331023931503296,
      "logps/chosen": -34.032405853271484,
      "logps/rejected": -59.21869659423828,
      "loss": 0.6911,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002413224894553423,
      "rewards/margins": 0.004142975900322199,
      "rewards/rejected": -0.0017297507729381323,
      "step": 75
    },
    {
      "epoch": 5.88,
      "grad_norm": 8.15034294128418,
      "learning_rate": 9.5703125e-08,
      "logits/chosen": 1.2201244831085205,
      "logits/rejected": 1.2520678043365479,
      "logps/chosen": -34.830867767333984,
      "logps/rejected": -60.330894470214844,
      "loss": 0.69,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.012929702177643776,
      "rewards/margins": 0.006357788573950529,
      "rewards/rejected": -0.019287489354610443,
      "step": 76
    },
    {
      "epoch": 5.96,
      "grad_norm": 7.88216495513916,
      "learning_rate": 9.5625e-08,
      "logits/chosen": 1.3023245334625244,
      "logits/rejected": 1.1607685089111328,
      "logps/chosen": -34.5366325378418,
      "logps/rejected": -63.53958511352539,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005203485954552889,
      "rewards/margins": 0.010524367913603783,
      "rewards/rejected": -0.005320882890373468,
      "step": 77
    },
    {
      "epoch": 6.0,
      "grad_norm": 8.344645500183105,
      "learning_rate": 9.5546875e-08,
      "logits/chosen": 1.1412979364395142,
      "logits/rejected": 1.1747605800628662,
      "logps/chosen": -33.42749786376953,
      "logps/rejected": -45.79444885253906,
      "loss": 0.6927,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003191280411556363,
      "rewards/margins": 0.0009902953170239925,
      "rewards/rejected": -0.004181575961410999,
      "step": 78
    },
    {
      "epoch": 6.0,
      "eval_logits/chosen": 1.3051238059997559,
      "eval_logits/rejected": 1.1980105638504028,
      "eval_logps/chosen": -34.4913444519043,
      "eval_logps/rejected": -47.019309997558594,
      "eval_loss": 0.6918836832046509,
      "eval_rewards/accuracies": 0.5,
      "eval_rewards/chosen": 0.0008176423143595457,
      "eval_rewards/margins": 0.0026300218887627125,
      "eval_rewards/rejected": -0.0018123798072338104,
      "eval_runtime": 2.7106,
      "eval_samples_per_second": 36.892,
      "eval_steps_per_second": 18.446,
      "step": 78
    },
    {
      "epoch": 6.08,
      "grad_norm": 7.907571792602539,
      "learning_rate": 9.546875e-08,
      "logits/chosen": 1.2739663124084473,
      "logits/rejected": 1.3327597379684448,
      "logps/chosen": -31.897201538085938,
      "logps/rejected": -47.68449401855469,
      "loss": 0.6982,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.004066396038979292,
      "rewards/margins": -0.009844374842941761,
      "rewards/rejected": 0.005777978803962469,
      "step": 79
    },
    {
      "epoch": 6.16,
      "grad_norm": 7.359317779541016,
      "learning_rate": 9.539062499999999e-08,
      "logits/chosen": 1.3292499780654907,
      "logits/rejected": 1.3876368999481201,
      "logps/chosen": -36.83709716796875,
      "logps/rejected": -60.33894348144531,
      "loss": 0.6898,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0014073369093239307,
      "rewards/margins": 0.006686735432595015,
      "rewards/rejected": -0.008094072341918945,
      "step": 80
    },
    {
      "epoch": 6.24,
      "grad_norm": 6.232259273529053,
      "learning_rate": 9.53125e-08,
      "logits/chosen": 1.1926422119140625,
      "logits/rejected": 1.210015058517456,
      "logps/chosen": -31.797985076904297,
      "logps/rejected": -46.48344421386719,
      "loss": 0.6844,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0066332342103123665,
      "rewards/margins": 0.017713451758027077,
      "rewards/rejected": -0.01108021754771471,
      "step": 81
    },
    {
      "epoch": 6.32,
      "grad_norm": 9.286623001098633,
      "learning_rate": 9.5234375e-08,
      "logits/chosen": 1.1971933841705322,
      "logits/rejected": 1.1534188985824585,
      "logps/chosen": -30.095197677612305,
      "logps/rejected": -59.1193733215332,
      "loss": 0.6895,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004652571864426136,
      "rewards/margins": 0.007404637522995472,
      "rewards/rejected": -0.0027520654257386923,
      "step": 82
    },
    {
      "epoch": 6.4,
      "grad_norm": 7.843479633331299,
      "learning_rate": 9.515624999999999e-08,
      "logits/chosen": 1.447794795036316,
      "logits/rejected": 1.3428239822387695,
      "logps/chosen": -35.6939582824707,
      "logps/rejected": -52.867431640625,
      "loss": 0.6916,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0032042742241173983,
      "rewards/margins": 0.00333387847058475,
      "rewards/rejected": -0.0001296042464673519,
      "step": 83
    },
    {
      "epoch": 6.48,
      "grad_norm": 7.581516742706299,
      "learning_rate": 9.5078125e-08,
      "logits/chosen": 1.154929518699646,
      "logits/rejected": 1.0635669231414795,
      "logps/chosen": -32.07890319824219,
      "logps/rejected": -51.67390441894531,
      "loss": 0.6976,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0002561095170676708,
      "rewards/margins": -0.00874023512005806,
      "rewards/rejected": 0.008484125137329102,
      "step": 84
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 8.77212905883789,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.4909324645996094,
      "logits/rejected": 1.1017558574676514,
      "logps/chosen": -40.65016174316406,
      "logps/rejected": -49.45806884765625,
      "loss": 0.6952,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0019713877700269222,
      "rewards/margins": -0.00411305483430624,
      "rewards/rejected": 0.00608444306999445,
      "step": 85
    },
    {
      "epoch": 6.64,
      "grad_norm": 6.193762302398682,
      "learning_rate": 9.492187499999999e-08,
      "logits/chosen": 1.2641149759292603,
      "logits/rejected": 1.4971508979797363,
      "logps/chosen": -31.854185104370117,
      "logps/rejected": -50.24237823486328,
      "loss": 0.6901,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0049977065064013,
      "rewards/margins": 0.0062508350238204,
      "rewards/rejected": -0.0012531275860965252,
      "step": 86
    },
    {
      "epoch": 6.72,
      "grad_norm": 8.433917045593262,
      "learning_rate": 9.484375e-08,
      "logits/chosen": 1.5011849403381348,
      "logits/rejected": 1.2273080348968506,
      "logps/chosen": -38.79720687866211,
      "logps/rejected": -57.08285903930664,
      "loss": 0.6927,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.001690077711828053,
      "rewards/margins": 0.0010830636601895094,
      "rewards/rejected": 0.0006070142844691873,
      "step": 87
    },
    {
      "epoch": 6.8,
      "grad_norm": 6.921027660369873,
      "learning_rate": 9.476562499999999e-08,
      "logits/chosen": 1.306880235671997,
      "logits/rejected": 1.360090732574463,
      "logps/chosen": -31.831378936767578,
      "logps/rejected": -59.787384033203125,
      "loss": 0.6921,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0020879267249256372,
      "rewards/margins": 0.00232119532302022,
      "rewards/rejected": -0.004409122280776501,
      "step": 88
    },
    {
      "epoch": 6.88,
      "grad_norm": 6.756122589111328,
      "learning_rate": 9.46875e-08,
      "logits/chosen": 1.2043356895446777,
      "logits/rejected": 1.242497205734253,
      "logps/chosen": -35.09823989868164,
      "logps/rejected": -60.59819793701172,
      "loss": 0.6908,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0037723782006651163,
      "rewards/margins": 0.004831957630813122,
      "rewards/rejected": -0.008604336529970169,
      "step": 89
    },
    {
      "epoch": 6.96,
      "grad_norm": 8.07632827758789,
      "learning_rate": 9.4609375e-08,
      "logits/chosen": 1.1780247688293457,
      "logits/rejected": 1.2090898752212524,
      "logps/chosen": -32.73401641845703,
      "logps/rejected": -60.32231903076172,
      "loss": 0.6923,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006710815243422985,
      "rewards/margins": 0.0018527987413108349,
      "rewards/rejected": 0.0048580169677734375,
      "step": 90
    },
    {
      "epoch": 7.0,
      "grad_norm": 10.300239562988281,
      "learning_rate": 9.453125e-08,
      "logits/chosen": 1.3068488836288452,
      "logits/rejected": 1.2151124477386475,
      "logps/chosen": -36.316558837890625,
      "logps/rejected": -60.4509391784668,
      "loss": 0.6855,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0005774497985839844,
      "rewards/margins": 0.015424154698848724,
      "rewards/rejected": -0.01484670676290989,
      "step": 91
    },
    {
      "epoch": 7.0,
      "eval_logits/chosen": 1.3030898571014404,
      "eval_logits/rejected": 1.1964200735092163,
      "eval_logps/chosen": -34.46707534790039,
      "eval_logps/rejected": -47.01984405517578,
      "eval_loss": 0.6906469464302063,
      "eval_rewards/accuracies": 0.6200000047683716,
      "eval_rewards/chosen": 0.0032440379727631807,
      "eval_rewards/margins": 0.005109873600304127,
      "eval_rewards/rejected": -0.0018658350454643369,
      "eval_runtime": 2.7141,
      "eval_samples_per_second": 36.845,
      "eval_steps_per_second": 18.423,
      "step": 91
    },
    {
      "epoch": 7.08,
      "grad_norm": 7.124684810638428,
      "learning_rate": 9.4453125e-08,
      "logits/chosen": 1.3903316259384155,
      "logits/rejected": 1.4727492332458496,
      "logps/chosen": -31.851234436035156,
      "logps/rejected": -52.85973358154297,
      "loss": 0.6917,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0007925032405182719,
      "rewards/margins": 0.002955531934276223,
      "rewards/rejected": -0.0037480355240404606,
      "step": 92
    },
    {
      "epoch": 7.16,
      "grad_norm": 8.050592422485352,
      "learning_rate": 9.4375e-08,
      "logits/chosen": 1.0975185632705688,
      "logits/rejected": 1.2802804708480835,
      "logps/chosen": -32.31549835205078,
      "logps/rejected": -55.58733367919922,
      "loss": 0.6886,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0007605075370520353,
      "rewards/margins": 0.00926957093179226,
      "rewards/rejected": -0.008509064093232155,
      "step": 93
    },
    {
      "epoch": 7.24,
      "grad_norm": 8.166927337646484,
      "learning_rate": 9.4296875e-08,
      "logits/chosen": 1.1488137245178223,
      "logits/rejected": 1.056098222732544,
      "logps/chosen": -31.7196044921875,
      "logps/rejected": -49.08454132080078,
      "loss": 0.6934,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009374022483825684,
      "rewards/margins": -0.00036804680712521076,
      "rewards/rejected": 0.009742069989442825,
      "step": 94
    },
    {
      "epoch": 7.32,
      "grad_norm": 8.344744682312012,
      "learning_rate": 9.421875e-08,
      "logits/chosen": 1.2001351118087769,
      "logits/rejected": 1.1989022493362427,
      "logps/chosen": -35.02604293823242,
      "logps/rejected": -58.4326171875,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0028781418222934008,
      "rewards/margins": 0.00627632113173604,
      "rewards/rejected": -0.0033981800079345703,
      "step": 95
    },
    {
      "epoch": 7.4,
      "grad_norm": 8.075819969177246,
      "learning_rate": 9.4140625e-08,
      "logits/chosen": 1.5314655303955078,
      "logits/rejected": 1.1323862075805664,
      "logps/chosen": -35.123268127441406,
      "logps/rejected": -51.92420959472656,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0074967145919799805,
      "rewards/margins": 0.010370994918048382,
      "rewards/rejected": -0.002874279161915183,
      "step": 96
    },
    {
      "epoch": 7.48,
      "grad_norm": 7.087543964385986,
      "learning_rate": 9.40625e-08,
      "logits/chosen": 1.331816554069519,
      "logits/rejected": 1.4338703155517578,
      "logps/chosen": -32.78190231323242,
      "logps/rejected": -50.806644439697266,
      "loss": 0.6879,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.004465436562895775,
      "rewards/margins": 0.010667514987289906,
      "rewards/rejected": -0.015132952481508255,
      "step": 97
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 7.750010013580322,
      "learning_rate": 9.3984375e-08,
      "logits/chosen": 1.7039309740066528,
      "logits/rejected": 1.6082717180252075,
      "logps/chosen": -36.40869903564453,
      "logps/rejected": -60.748199462890625,
      "loss": 0.7,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.005480313673615456,
      "rewards/margins": -0.013618971221148968,
      "rewards/rejected": 0.008138656616210938,
      "step": 98
    },
    {
      "epoch": 7.64,
      "grad_norm": 7.086890697479248,
      "learning_rate": 9.390625e-08,
      "logits/chosen": 1.3729513883590698,
      "logits/rejected": 1.1421095132827759,
      "logps/chosen": -32.983489990234375,
      "logps/rejected": -50.287620544433594,
      "loss": 0.6879,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003156519029289484,
      "rewards/margins": 0.010584210976958275,
      "rewards/rejected": -0.007427691947668791,
      "step": 99
    },
    {
      "epoch": 7.72,
      "grad_norm": 9.2261962890625,
      "learning_rate": 9.382812499999999e-08,
      "logits/chosen": 1.2111711502075195,
      "logits/rejected": 1.0458983182907104,
      "logps/chosen": -35.2000617980957,
      "logps/rejected": -61.44794464111328,
      "loss": 0.6896,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00907993409782648,
      "rewards/margins": 0.007337665650993586,
      "rewards/rejected": 0.0017422670498490334,
      "step": 100
    },
    {
      "epoch": 7.8,
      "grad_norm": 7.4866533279418945,
      "learning_rate": 9.375e-08,
      "logits/chosen": 1.3238643407821655,
      "logits/rejected": 1.2845664024353027,
      "logps/chosen": -36.012264251708984,
      "logps/rejected": -52.0887451171875,
      "loss": 0.6828,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010210085660219193,
      "rewards/margins": 0.02090177685022354,
      "rewards/rejected": -0.010691691190004349,
      "step": 101
    },
    {
      "epoch": 7.88,
      "grad_norm": 7.6338019371032715,
      "learning_rate": 9.3671875e-08,
      "logits/chosen": 1.2164608240127563,
      "logits/rejected": 1.2267334461212158,
      "logps/chosen": -36.67218780517578,
      "logps/rejected": -61.435543060302734,
      "loss": 0.6866,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.011685752309858799,
      "rewards/margins": 0.013137053698301315,
      "rewards/rejected": -0.00145130162127316,
      "step": 102
    },
    {
      "epoch": 7.96,
      "grad_norm": 7.5409464836120605,
      "learning_rate": 9.359374999999999e-08,
      "logits/chosen": 1.0513286590576172,
      "logits/rejected": 1.111921787261963,
      "logps/chosen": -31.928377151489258,
      "logps/rejected": -51.76798629760742,
      "loss": 0.6851,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.00014667508366983384,
      "rewards/margins": 0.016214990988373756,
      "rewards/rejected": -0.016361666843295097,
      "step": 103
    },
    {
      "epoch": 8.0,
      "grad_norm": 9.555595397949219,
      "learning_rate": 9.351562499999999e-08,
      "logits/chosen": 1.1153311729431152,
      "logits/rejected": 1.3761863708496094,
      "logps/chosen": -38.374549865722656,
      "logps/rejected": -59.35482406616211,
      "loss": 0.6891,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.012991858646273613,
      "rewards/margins": 0.008049249649047852,
      "rewards/rejected": 0.004942608065903187,
      "step": 104
    },
    {
      "epoch": 8.0,
      "eval_logits/chosen": 1.3026214838027954,
      "eval_logits/rejected": 1.1966865062713623,
      "eval_logps/chosen": -34.45497131347656,
      "eval_logps/rejected": -46.99673843383789,
      "eval_loss": 0.6911866664886475,
      "eval_rewards/accuracies": 0.5699999928474426,
      "eval_rewards/chosen": 0.004454614594578743,
      "eval_rewards/margins": 0.004010064993053675,
      "eval_rewards/rejected": 0.00044454948510974646,
      "eval_runtime": 2.7192,
      "eval_samples_per_second": 36.775,
      "eval_steps_per_second": 18.387,
      "step": 104
    },
    {
      "epoch": 8.08,
      "grad_norm": 9.173569679260254,
      "learning_rate": 9.343749999999999e-08,
      "logits/chosen": 1.4911130666732788,
      "logits/rejected": 1.2544478178024292,
      "logps/chosen": -38.717594146728516,
      "logps/rejected": -54.30902862548828,
      "loss": 0.6927,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.001789689064025879,
      "rewards/margins": 0.0012161023914813995,
      "rewards/rejected": 0.0005735871382057667,
      "step": 105
    },
    {
      "epoch": 8.16,
      "grad_norm": 7.119881629943848,
      "learning_rate": 9.335937499999999e-08,
      "logits/chosen": 1.2733632326126099,
      "logits/rejected": 1.2956879138946533,
      "logps/chosen": -30.9166202545166,
      "logps/rejected": -51.529579162597656,
      "loss": 0.6906,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003246140666306019,
      "rewards/margins": 0.005187154281884432,
      "rewards/rejected": -0.0019410133827477694,
      "step": 106
    },
    {
      "epoch": 8.24,
      "grad_norm": 7.902161121368408,
      "learning_rate": 9.328125e-08,
      "logits/chosen": 1.1679620742797852,
      "logits/rejected": 1.4284168481826782,
      "logps/chosen": -33.57509994506836,
      "logps/rejected": -60.224830627441406,
      "loss": 0.6895,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.011287499219179153,
      "rewards/margins": 0.007296514697372913,
      "rewards/rejected": -0.018584012985229492,
      "step": 107
    },
    {
      "epoch": 8.32,
      "grad_norm": 8.146379470825195,
      "learning_rate": 9.3203125e-08,
      "logits/chosen": 1.1668636798858643,
      "logits/rejected": 1.0442215204238892,
      "logps/chosen": -29.53513526916504,
      "logps/rejected": -48.05052947998047,
      "loss": 0.6882,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009161877445876598,
      "rewards/margins": 0.010002684779465199,
      "rewards/rejected": -0.0008408069843426347,
      "step": 108
    },
    {
      "epoch": 8.4,
      "grad_norm": 6.590439796447754,
      "learning_rate": 9.3125e-08,
      "logits/chosen": 1.2604529857635498,
      "logits/rejected": 1.280278205871582,
      "logps/chosen": -33.15561294555664,
      "logps/rejected": -53.49259948730469,
      "loss": 0.6875,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01026856992393732,
      "rewards/margins": 0.011407876387238503,
      "rewards/rejected": -0.0011393073946237564,
      "step": 109
    },
    {
      "epoch": 8.48,
      "grad_norm": 7.949906826019287,
      "learning_rate": 9.3046875e-08,
      "logits/chosen": 1.1124353408813477,
      "logits/rejected": 1.4092742204666138,
      "logps/chosen": -40.664730072021484,
      "logps/rejected": -64.97877502441406,
      "loss": 0.6874,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.002750587183982134,
      "rewards/margins": 0.011587000451982021,
      "rewards/rejected": -0.014337587170302868,
      "step": 110
    },
    {
      "epoch": 8.56,
      "grad_norm": 6.800430774688721,
      "learning_rate": 9.296875e-08,
      "logits/chosen": 1.4548556804656982,
      "logits/rejected": 1.2494745254516602,
      "logps/chosen": -32.37144088745117,
      "logps/rejected": -55.67129135131836,
      "loss": 0.6894,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005829525180160999,
      "rewards/margins": 0.007548618596047163,
      "rewards/rejected": -0.0017190936487168074,
      "step": 111
    },
    {
      "epoch": 8.64,
      "grad_norm": 8.066383361816406,
      "learning_rate": 9.2890625e-08,
      "logits/chosen": 1.2372801303863525,
      "logits/rejected": 1.2533535957336426,
      "logps/chosen": -35.221275329589844,
      "logps/rejected": -60.15143585205078,
      "loss": 0.6931,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.011499524116516113,
      "rewards/margins": 0.00018784997519105673,
      "rewards/rejected": 0.011311674490571022,
      "step": 112
    },
    {
      "epoch": 8.72,
      "grad_norm": 7.290645122528076,
      "learning_rate": 9.28125e-08,
      "logits/chosen": 1.2076880931854248,
      "logits/rejected": 1.2730168104171753,
      "logps/chosen": -35.54037094116211,
      "logps/rejected": -66.2259292602539,
      "loss": 0.6873,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006191539578139782,
      "rewards/margins": 0.011813306249678135,
      "rewards/rejected": -0.005621766671538353,
      "step": 113
    },
    {
      "epoch": 8.8,
      "grad_norm": 6.923037052154541,
      "learning_rate": 9.2734375e-08,
      "logits/chosen": 1.2882599830627441,
      "logits/rejected": 1.3359687328338623,
      "logps/chosen": -32.31707763671875,
      "logps/rejected": -45.76509475708008,
      "loss": 0.6841,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006466221995651722,
      "rewards/margins": 0.018306516110897064,
      "rewards/rejected": -0.011840295046567917,
      "step": 114
    },
    {
      "epoch": 8.88,
      "grad_norm": 7.706272602081299,
      "learning_rate": 9.265624999999999e-08,
      "logits/chosen": 1.4039032459259033,
      "logits/rejected": 1.115307092666626,
      "logps/chosen": -33.95524978637695,
      "logps/rejected": -51.87559509277344,
      "loss": 0.6869,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.013340448960661888,
      "rewards/margins": 0.012582564726471901,
      "rewards/rejected": 0.0007578853983432055,
      "step": 115
    },
    {
      "epoch": 8.96,
      "grad_norm": 7.810317039489746,
      "learning_rate": 9.2578125e-08,
      "logits/chosen": 1.4293625354766846,
      "logits/rejected": 1.1281328201293945,
      "logps/chosen": -35.74794006347656,
      "logps/rejected": -49.42671203613281,
      "loss": 0.6842,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.011664653196930885,
      "rewards/margins": 0.018090272322297096,
      "rewards/rejected": -0.006425619125366211,
      "step": 116
    },
    {
      "epoch": 9.0,
      "grad_norm": 9.030330657958984,
      "learning_rate": 9.25e-08,
      "logits/chosen": 1.3941367864608765,
      "logits/rejected": 1.1928515434265137,
      "logps/chosen": -30.59490203857422,
      "logps/rejected": -48.99076843261719,
      "loss": 0.6832,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0022184846457093954,
      "rewards/margins": 0.020100068300962448,
      "rewards/rejected": -0.022318555042147636,
      "step": 117
    },
    {
      "epoch": 9.0,
      "eval_logits/chosen": 1.3049018383026123,
      "eval_logits/rejected": 1.1967371702194214,
      "eval_logps/chosen": -34.403709411621094,
      "eval_logps/rejected": -46.992130279541016,
      "eval_loss": 0.6888763308525085,
      "eval_rewards/accuracies": 0.6600000262260437,
      "eval_rewards/chosen": 0.009580687619745731,
      "eval_rewards/margins": 0.008675134740769863,
      "eval_rewards/rejected": 0.0009055520058609545,
      "eval_runtime": 2.7298,
      "eval_samples_per_second": 36.633,
      "eval_steps_per_second": 18.316,
      "step": 117
    },
    {
      "epoch": 9.08,
      "grad_norm": 8.449271202087402,
      "learning_rate": 9.242187499999999e-08,
      "logits/chosen": 1.5590405464172363,
      "logits/rejected": 1.1506341695785522,
      "logps/chosen": -38.66082763671875,
      "logps/rejected": -56.390350341796875,
      "loss": 0.6882,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008097982965409756,
      "rewards/margins": 0.010016060434281826,
      "rewards/rejected": -0.0019180778181180358,
      "step": 118
    },
    {
      "epoch": 9.16,
      "grad_norm": 9.168283462524414,
      "learning_rate": 9.234375e-08,
      "logits/chosen": 1.0860620737075806,
      "logits/rejected": 1.1038621664047241,
      "logps/chosen": -31.03508758544922,
      "logps/rejected": -60.70368957519531,
      "loss": 0.6889,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004416704177856445,
      "rewards/margins": 0.008583832532167435,
      "rewards/rejected": -0.004167127422988415,
      "step": 119
    },
    {
      "epoch": 9.24,
      "grad_norm": 7.180488109588623,
      "learning_rate": 9.226562499999999e-08,
      "logits/chosen": 1.4327741861343384,
      "logits/rejected": 1.266445279121399,
      "logps/chosen": -34.82432556152344,
      "logps/rejected": -50.45824432373047,
      "loss": 0.684,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.004396914970129728,
      "rewards/margins": 0.018536042422056198,
      "rewards/rejected": -0.014139128848910332,
      "step": 120
    },
    {
      "epoch": 9.32,
      "grad_norm": 7.229279518127441,
      "learning_rate": 9.218749999999999e-08,
      "logits/chosen": 1.2924809455871582,
      "logits/rejected": 1.3464624881744385,
      "logps/chosen": -32.62507247924805,
      "logps/rejected": -49.19683837890625,
      "loss": 0.6839,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01477739866822958,
      "rewards/margins": 0.01871335506439209,
      "rewards/rejected": -0.003935956861823797,
      "step": 121
    },
    {
      "epoch": 9.4,
      "grad_norm": 6.862542152404785,
      "learning_rate": 9.2109375e-08,
      "logits/chosen": 1.2578028440475464,
      "logits/rejected": 1.290401816368103,
      "logps/chosen": -33.86405944824219,
      "logps/rejected": -53.92655944824219,
      "loss": 0.6874,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0004125119303353131,
      "rewards/margins": 0.011735773645341396,
      "rewards/rejected": -0.012148285284638405,
      "step": 122
    },
    {
      "epoch": 9.48,
      "grad_norm": 9.190960884094238,
      "learning_rate": 9.203124999999999e-08,
      "logits/chosen": 1.3200976848602295,
      "logits/rejected": 1.0113714933395386,
      "logps/chosen": -32.640254974365234,
      "logps/rejected": -51.10390853881836,
      "loss": 0.6878,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.007307005114853382,
      "rewards/margins": 0.010717535391449928,
      "rewards/rejected": -0.0034105300437659025,
      "step": 123
    },
    {
      "epoch": 9.56,
      "grad_norm": 7.159995079040527,
      "learning_rate": 9.195312499999999e-08,
      "logits/chosen": 1.3680493831634521,
      "logits/rejected": 1.187286138534546,
      "logps/chosen": -34.21858596801758,
      "logps/rejected": -54.899871826171875,
      "loss": 0.6889,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.005415916442871094,
      "rewards/margins": 0.008674383163452148,
      "rewards/rejected": -0.0032584669534116983,
      "step": 124
    },
    {
      "epoch": 9.64,
      "grad_norm": 8.192536354064941,
      "learning_rate": 9.1875e-08,
      "logits/chosen": 1.2425570487976074,
      "logits/rejected": 1.2184052467346191,
      "logps/chosen": -35.7696647644043,
      "logps/rejected": -71.02963256835938,
      "loss": 0.6884,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0022385360207408667,
      "rewards/margins": 0.009614348411560059,
      "rewards/rejected": -0.007375813089311123,
      "step": 125
    },
    {
      "epoch": 9.72,
      "grad_norm": 7.112046718597412,
      "learning_rate": 9.1796875e-08,
      "logits/chosen": 1.1218292713165283,
      "logits/rejected": 1.157401442527771,
      "logps/chosen": -30.562400817871094,
      "logps/rejected": -47.97205352783203,
      "loss": 0.6786,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012858271598815918,
      "rewards/margins": 0.029407383874058723,
      "rewards/rejected": -0.016549110412597656,
      "step": 126
    },
    {
      "epoch": 9.8,
      "grad_norm": 6.825537204742432,
      "learning_rate": 9.171875e-08,
      "logits/chosen": 1.2680013179779053,
      "logits/rejected": 1.3552346229553223,
      "logps/chosen": -32.03205871582031,
      "logps/rejected": -56.132041931152344,
      "loss": 0.6876,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0034189943689852953,
      "rewards/margins": 0.011182429268956184,
      "rewards/rejected": -0.007763433735817671,
      "step": 127
    },
    {
      "epoch": 9.88,
      "grad_norm": 6.292837142944336,
      "learning_rate": 9.1640625e-08,
      "logits/chosen": 1.352628231048584,
      "logits/rejected": 1.4638078212738037,
      "logps/chosen": -37.76320266723633,
      "logps/rejected": -51.2769889831543,
      "loss": 0.6902,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0028079990297555923,
      "rewards/margins": 0.006007385440170765,
      "rewards/rejected": -0.008815382607281208,
      "step": 128
    },
    {
      "epoch": 9.96,
      "grad_norm": 7.75413703918457,
      "learning_rate": 9.15625e-08,
      "logits/chosen": 1.120680570602417,
      "logits/rejected": 1.3576055765151978,
      "logps/chosen": -33.78936004638672,
      "logps/rejected": -61.63410186767578,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005178332328796387,
      "rewards/margins": 0.006407617591321468,
      "rewards/rejected": -0.0012292859610170126,
      "step": 129
    },
    {
      "epoch": 10.0,
      "grad_norm": 9.374214172363281,
      "learning_rate": 9.1484375e-08,
      "logits/chosen": 1.5148062705993652,
      "logits/rejected": 1.6374168395996094,
      "logps/chosen": -38.487152099609375,
      "logps/rejected": -43.64501190185547,
      "loss": 0.6824,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0034006598871201277,
      "rewards/margins": 0.021717406809329987,
      "rewards/rejected": -0.01831674575805664,
      "step": 130
    },
    {
      "epoch": 10.0,
      "eval_logits/chosen": 1.3035081624984741,
      "eval_logits/rejected": 1.1977133750915527,
      "eval_logps/chosen": -34.414302825927734,
      "eval_logps/rejected": -46.99907302856445,
      "eval_loss": 0.6890516877174377,
      "eval_rewards/accuracies": 0.6200000047683716,
      "eval_rewards/chosen": 0.008520878851413727,
      "eval_rewards/margins": 0.008309164084494114,
      "eval_rewards/rejected": 0.0002117157564498484,
      "eval_runtime": 2.7225,
      "eval_samples_per_second": 36.731,
      "eval_steps_per_second": 18.366,
      "step": 130
    },
    {
      "epoch": 10.08,
      "grad_norm": 8.403594970703125,
      "learning_rate": 9.140625e-08,
      "logits/chosen": 1.2183996438980103,
      "logits/rejected": 1.0212037563323975,
      "logps/chosen": -31.68474769592285,
      "logps/rejected": -48.49424362182617,
      "loss": 0.6867,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008852267637848854,
      "rewards/margins": 0.01299436204135418,
      "rewards/rejected": -0.004142094869166613,
      "step": 131
    },
    {
      "epoch": 10.16,
      "grad_norm": 7.198458194732666,
      "learning_rate": 9.1328125e-08,
      "logits/chosen": 1.429377794265747,
      "logits/rejected": 1.207654595375061,
      "logps/chosen": -33.3533935546875,
      "logps/rejected": -51.692161560058594,
      "loss": 0.6862,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013083338737487793,
      "rewards/margins": 0.013946175575256348,
      "rewards/rejected": -0.0008628367795608938,
      "step": 132
    },
    {
      "epoch": 10.24,
      "grad_norm": 6.987757682800293,
      "learning_rate": 9.125e-08,
      "logits/chosen": 1.2851581573486328,
      "logits/rejected": 1.483060359954834,
      "logps/chosen": -33.375308990478516,
      "logps/rejected": -55.33061599731445,
      "loss": 0.6968,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.001133251003921032,
      "rewards/margins": -0.007151890080422163,
      "rewards/rejected": 0.008285141550004482,
      "step": 133
    },
    {
      "epoch": 10.32,
      "grad_norm": 7.639895915985107,
      "learning_rate": 9.1171875e-08,
      "logits/chosen": 1.0732816457748413,
      "logits/rejected": 1.138580322265625,
      "logps/chosen": -34.676753997802734,
      "logps/rejected": -64.26908111572266,
      "loss": 0.6865,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0017613411182537675,
      "rewards/margins": 0.013449573889374733,
      "rewards/rejected": -0.011688232421875,
      "step": 134
    },
    {
      "epoch": 10.4,
      "grad_norm": 9.004441261291504,
      "learning_rate": 9.109374999999999e-08,
      "logits/chosen": 1.5075594186782837,
      "logits/rejected": 1.2592694759368896,
      "logps/chosen": -44.221160888671875,
      "logps/rejected": -64.77015686035156,
      "loss": 0.679,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00754094123840332,
      "rewards/margins": 0.02865137904882431,
      "rewards/rejected": -0.02111043967306614,
      "step": 135
    },
    {
      "epoch": 10.48,
      "grad_norm": 8.07844352722168,
      "learning_rate": 9.1015625e-08,
      "logits/chosen": 1.501526951789856,
      "logits/rejected": 1.3821609020233154,
      "logps/chosen": -33.868629455566406,
      "logps/rejected": -61.07816696166992,
      "loss": 0.6878,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003636598587036133,
      "rewards/margins": 0.010763406753540039,
      "rewards/rejected": -0.007126808166503906,
      "step": 136
    },
    {
      "epoch": 10.56,
      "grad_norm": 6.909247398376465,
      "learning_rate": 9.09375e-08,
      "logits/chosen": 1.2585405111312866,
      "logits/rejected": 1.4329683780670166,
      "logps/chosen": -33.897308349609375,
      "logps/rejected": -48.777183532714844,
      "loss": 0.6884,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00037262472324073315,
      "rewards/margins": 0.009747432544827461,
      "rewards/rejected": -0.009374809451401234,
      "step": 137
    },
    {
      "epoch": 10.64,
      "grad_norm": 8.037155151367188,
      "learning_rate": 9.085937499999999e-08,
      "logits/chosen": 1.4332226514816284,
      "logits/rejected": 1.1227328777313232,
      "logps/chosen": -30.399330139160156,
      "logps/rejected": -53.500389099121094,
      "loss": 0.6897,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0003146412782371044,
      "rewards/margins": 0.0071187252178788185,
      "rewards/rejected": -0.006804084870964289,
      "step": 138
    },
    {
      "epoch": 10.72,
      "grad_norm": 7.87470006942749,
      "learning_rate": 9.078125e-08,
      "logits/chosen": 1.1004246473312378,
      "logits/rejected": 1.1882551908493042,
      "logps/chosen": -31.438600540161133,
      "logps/rejected": -57.3450927734375,
      "loss": 0.6777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.003558564465492964,
      "rewards/margins": 0.031176067888736725,
      "rewards/rejected": -0.027617502957582474,
      "step": 139
    },
    {
      "epoch": 10.8,
      "grad_norm": 8.238734245300293,
      "learning_rate": 9.070312499999999e-08,
      "logits/chosen": 1.2123783826828003,
      "logits/rejected": 1.2167460918426514,
      "logps/chosen": -36.23622131347656,
      "logps/rejected": -54.535423278808594,
      "loss": 0.6821,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003895687870681286,
      "rewards/margins": 0.022388862445950508,
      "rewards/rejected": -0.018493175506591797,
      "step": 140
    },
    {
      "epoch": 10.88,
      "grad_norm": 6.742201805114746,
      "learning_rate": 9.062499999999999e-08,
      "logits/chosen": 1.511466145515442,
      "logits/rejected": 1.4582206010818481,
      "logps/chosen": -34.67167663574219,
      "logps/rejected": -52.67755889892578,
      "loss": 0.6918,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00409324187785387,
      "rewards/margins": 0.0028747322503477335,
      "rewards/rejected": 0.001218509627506137,
      "step": 141
    },
    {
      "epoch": 10.96,
      "grad_norm": 6.02468204498291,
      "learning_rate": 9.0546875e-08,
      "logits/chosen": 1.1737170219421387,
      "logits/rejected": 1.093931794166565,
      "logps/chosen": -33.015106201171875,
      "logps/rejected": -46.018619537353516,
      "loss": 0.6845,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005648111924529076,
      "rewards/margins": 0.01742875576019287,
      "rewards/rejected": -0.01178064290434122,
      "step": 142
    },
    {
      "epoch": 11.0,
      "grad_norm": 8.682947158813477,
      "learning_rate": 9.046875e-08,
      "logits/chosen": 1.295836091041565,
      "logits/rejected": 1.441523790359497,
      "logps/chosen": -32.568294525146484,
      "logps/rejected": -56.347694396972656,
      "loss": 0.6833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016800308600068092,
      "rewards/margins": 0.019931457936763763,
      "rewards/rejected": -0.0031311509665101767,
      "step": 143
    },
    {
      "epoch": 11.0,
      "eval_logits/chosen": 1.3048882484436035,
      "eval_logits/rejected": 1.1989821195602417,
      "eval_logps/chosen": -34.410560607910156,
      "eval_logps/rejected": -47.03269958496094,
      "eval_loss": 0.6871910095214844,
      "eval_rewards/accuracies": 0.7799999713897705,
      "eval_rewards/chosen": 0.008895765990018845,
      "eval_rewards/margins": 0.012047583237290382,
      "eval_rewards/rejected": -0.0031518172472715378,
      "eval_runtime": 2.7211,
      "eval_samples_per_second": 36.749,
      "eval_steps_per_second": 18.375,
      "step": 143
    },
    {
      "epoch": 11.08,
      "grad_norm": 7.493975639343262,
      "learning_rate": 9.0390625e-08,
      "logits/chosen": 0.9626868963241577,
      "logits/rejected": 1.2317394018173218,
      "logps/chosen": -32.98351287841797,
      "logps/rejected": -53.51544952392578,
      "loss": 0.689,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.006218623835593462,
      "rewards/margins": 0.008506011217832565,
      "rewards/rejected": -0.0022873878479003906,
      "step": 144
    },
    {
      "epoch": 11.16,
      "grad_norm": 7.585102558135986,
      "learning_rate": 9.03125e-08,
      "logits/chosen": 1.2922955751419067,
      "logits/rejected": 1.3894401788711548,
      "logps/chosen": -33.41468811035156,
      "logps/rejected": -58.53316879272461,
      "loss": 0.6909,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0014265775680541992,
      "rewards/margins": 0.004688382148742676,
      "rewards/rejected": -0.0061149587854743,
      "step": 145
    },
    {
      "epoch": 11.24,
      "grad_norm": 7.685290813446045,
      "learning_rate": 9.0234375e-08,
      "logits/chosen": 1.2232184410095215,
      "logits/rejected": 1.5949840545654297,
      "logps/chosen": -39.6796875,
      "logps/rejected": -71.36518096923828,
      "loss": 0.6843,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.001970004988834262,
      "rewards/margins": 0.01796107366681099,
      "rewards/rejected": -0.01993107795715332,
      "step": 146
    },
    {
      "epoch": 11.32,
      "grad_norm": 6.976325035095215,
      "learning_rate": 9.015625e-08,
      "logits/chosen": 1.26365327835083,
      "logits/rejected": 1.096797227859497,
      "logps/chosen": -31.3422908782959,
      "logps/rejected": -44.715824127197266,
      "loss": 0.684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.012658238410949707,
      "rewards/margins": 0.018547464162111282,
      "rewards/rejected": -0.005889225285500288,
      "step": 147
    },
    {
      "epoch": 11.4,
      "grad_norm": 8.3836088180542,
      "learning_rate": 9.0078125e-08,
      "logits/chosen": 1.5049676895141602,
      "logits/rejected": 1.2995097637176514,
      "logps/chosen": -35.253475189208984,
      "logps/rejected": -59.12382125854492,
      "loss": 0.689,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010774684138596058,
      "rewards/margins": 0.00837175827473402,
      "rewards/rejected": 0.0024029258638620377,
      "step": 148
    },
    {
      "epoch": 11.48,
      "grad_norm": 9.521425247192383,
      "learning_rate": 9e-08,
      "logits/chosen": 1.442784309387207,
      "logits/rejected": 1.111660361289978,
      "logps/chosen": -32.55039978027344,
      "logps/rejected": -55.46928024291992,
      "loss": 0.6842,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0116738798096776,
      "rewards/margins": 0.018123865127563477,
      "rewards/rejected": -0.00644998624920845,
      "step": 149
    },
    {
      "epoch": 11.56,
      "grad_norm": 7.239161968231201,
      "learning_rate": 8.992187499999999e-08,
      "logits/chosen": 1.1284129619598389,
      "logits/rejected": 0.983782172203064,
      "logps/chosen": -30.640655517578125,
      "logps/rejected": -51.60444259643555,
      "loss": 0.6793,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010270286351442337,
      "rewards/margins": 0.028040815144777298,
      "rewards/rejected": -0.01777052879333496,
      "step": 150
    },
    {
      "epoch": 11.64,
      "grad_norm": 6.804056167602539,
      "learning_rate": 8.984375e-08,
      "logits/chosen": 1.419779658317566,
      "logits/rejected": 1.4112573862075806,
      "logps/chosen": -35.17352294921875,
      "logps/rejected": -56.50162124633789,
      "loss": 0.6848,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013667751103639603,
      "rewards/margins": 0.01678650453686714,
      "rewards/rejected": -0.003118753433227539,
      "step": 151
    },
    {
      "epoch": 11.72,
      "grad_norm": 6.972949504852295,
      "learning_rate": 8.9765625e-08,
      "logits/chosen": 1.5076693296432495,
      "logits/rejected": 1.3245673179626465,
      "logps/chosen": -38.43302917480469,
      "logps/rejected": -48.25810241699219,
      "loss": 0.6889,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008221150375902653,
      "rewards/margins": 0.008748460561037064,
      "rewards/rejected": -0.0005273106507956982,
      "step": 152
    },
    {
      "epoch": 11.8,
      "grad_norm": 7.575134754180908,
      "learning_rate": 8.968749999999999e-08,
      "logits/chosen": 1.436945915222168,
      "logits/rejected": 1.2373830080032349,
      "logps/chosen": -33.759517669677734,
      "logps/rejected": -49.76884841918945,
      "loss": 0.6866,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0008570672944188118,
      "rewards/margins": 0.013145350851118565,
      "rewards/rejected": -0.014002419076859951,
      "step": 153
    },
    {
      "epoch": 11.88,
      "grad_norm": 7.578639030456543,
      "learning_rate": 8.9609375e-08,
      "logits/chosen": 1.180066704750061,
      "logits/rejected": 1.2705633640289307,
      "logps/chosen": -35.222755432128906,
      "logps/rejected": -67.47850036621094,
      "loss": 0.6819,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0015308617148548365,
      "rewards/margins": 0.022730041295289993,
      "rewards/rejected": -0.024260902777314186,
      "step": 154
    },
    {
      "epoch": 11.96,
      "grad_norm": 6.92464542388916,
      "learning_rate": 8.953124999999999e-08,
      "logits/chosen": 1.229550838470459,
      "logits/rejected": 1.171811819076538,
      "logps/chosen": -31.8143310546875,
      "logps/rejected": -45.442054748535156,
      "loss": 0.6836,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01160042267292738,
      "rewards/margins": 0.01929647848010063,
      "rewards/rejected": -0.007696056738495827,
      "step": 155
    },
    {
      "epoch": 12.0,
      "grad_norm": 8.786327362060547,
      "learning_rate": 8.945312499999999e-08,
      "logits/chosen": 1.3494362831115723,
      "logits/rejected": 1.3359808921813965,
      "logps/chosen": -32.98321533203125,
      "logps/rejected": -49.96072769165039,
      "loss": 0.6825,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006525707431137562,
      "rewards/margins": 0.021385954692959785,
      "rewards/rejected": -0.014860248193144798,
      "step": 156
    },
    {
      "epoch": 12.0,
      "eval_logits/chosen": 1.3035153150558472,
      "eval_logits/rejected": 1.197971224784851,
      "eval_logps/chosen": -34.40998077392578,
      "eval_logps/rejected": -47.0095100402832,
      "eval_loss": 0.6883389353752136,
      "eval_rewards/accuracies": 0.6499999761581421,
      "eval_rewards/chosen": 0.008953454904258251,
      "eval_rewards/margins": 0.009785802103579044,
      "eval_rewards/rejected": -0.0008323460351675749,
      "eval_runtime": 2.7253,
      "eval_samples_per_second": 36.693,
      "eval_steps_per_second": 18.346,
      "step": 156
    },
    {
      "epoch": 12.08,
      "grad_norm": 8.079911231994629,
      "learning_rate": 8.9375e-08,
      "logits/chosen": 1.2750670909881592,
      "logits/rejected": 0.9946823120117188,
      "logps/chosen": -31.89269256591797,
      "logps/rejected": -52.216514587402344,
      "loss": 0.6793,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01064908504486084,
      "rewards/margins": 0.028405454009771347,
      "rewards/rejected": -0.017756367102265358,
      "step": 157
    },
    {
      "epoch": 12.16,
      "grad_norm": 8.05543327331543,
      "learning_rate": 8.929687499999999e-08,
      "logits/chosen": 1.4595637321472168,
      "logits/rejected": 1.2290184497833252,
      "logps/chosen": -37.69374084472656,
      "logps/rejected": -53.94086456298828,
      "loss": 0.6815,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010511255823075771,
      "rewards/margins": 0.02360682561993599,
      "rewards/rejected": -0.013095569796860218,
      "step": 158
    },
    {
      "epoch": 12.24,
      "grad_norm": 6.8923115730285645,
      "learning_rate": 8.921874999999999e-08,
      "logits/chosen": 1.45723557472229,
      "logits/rejected": 1.5408639907836914,
      "logps/chosen": -35.865455627441406,
      "logps/rejected": -60.438663482666016,
      "loss": 0.684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008951997384428978,
      "rewards/margins": 0.018468046560883522,
      "rewards/rejected": -0.009516049176454544,
      "step": 159
    },
    {
      "epoch": 12.32,
      "grad_norm": 7.325297832489014,
      "learning_rate": 8.9140625e-08,
      "logits/chosen": 1.2416844367980957,
      "logits/rejected": 1.2012220621109009,
      "logps/chosen": -33.00698471069336,
      "logps/rejected": -55.1898307800293,
      "loss": 0.6903,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.002345896326005459,
      "rewards/margins": 0.005770516581833363,
      "rewards/rejected": -0.003424620721489191,
      "step": 160
    },
    {
      "epoch": 12.4,
      "grad_norm": 8.496565818786621,
      "learning_rate": 8.90625e-08,
      "logits/chosen": 1.3504244089126587,
      "logits/rejected": 1.118758201599121,
      "logps/chosen": -32.195465087890625,
      "logps/rejected": -51.07276153564453,
      "loss": 0.685,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005656337831169367,
      "rewards/margins": 0.016484977677464485,
      "rewards/rejected": -0.010828638449311256,
      "step": 161
    },
    {
      "epoch": 12.48,
      "grad_norm": 6.948427677154541,
      "learning_rate": 8.8984375e-08,
      "logits/chosen": 1.2223447561264038,
      "logits/rejected": 1.2679359912872314,
      "logps/chosen": -32.80788040161133,
      "logps/rejected": -56.74555206298828,
      "loss": 0.6829,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007120251655578613,
      "rewards/margins": 0.020576883107423782,
      "rewards/rejected": -0.013456631451845169,
      "step": 162
    },
    {
      "epoch": 12.56,
      "grad_norm": 8.325413703918457,
      "learning_rate": 8.890625e-08,
      "logits/chosen": 1.1818842887878418,
      "logits/rejected": 1.2753609418869019,
      "logps/chosen": -34.46753692626953,
      "logps/rejected": -64.30363464355469,
      "loss": 0.686,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0005308387335389853,
      "rewards/margins": 0.014453578740358353,
      "rewards/rejected": -0.013922740705311298,
      "step": 163
    },
    {
      "epoch": 12.64,
      "grad_norm": 7.0789055824279785,
      "learning_rate": 8.8828125e-08,
      "logits/chosen": 1.4416656494140625,
      "logits/rejected": 1.314785361289978,
      "logps/chosen": -37.446617126464844,
      "logps/rejected": -51.020721435546875,
      "loss": 0.6856,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0021609070245176554,
      "rewards/margins": 0.01528480090200901,
      "rewards/rejected": -0.013123894110321999,
      "step": 164
    },
    {
      "epoch": 12.72,
      "grad_norm": 8.18398380279541,
      "learning_rate": 8.875e-08,
      "logits/chosen": 1.1434345245361328,
      "logits/rejected": 1.2481696605682373,
      "logps/chosen": -29.68883514404297,
      "logps/rejected": -53.97892761230469,
      "loss": 0.6863,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.013071632012724876,
      "rewards/margins": 0.013898467645049095,
      "rewards/rejected": -0.0008268355159088969,
      "step": 165
    },
    {
      "epoch": 12.8,
      "grad_norm": 8.181241035461426,
      "learning_rate": 8.8671875e-08,
      "logits/chosen": 1.3802766799926758,
      "logits/rejected": 1.3750016689300537,
      "logps/chosen": -37.03910827636719,
      "logps/rejected": -49.645423889160156,
      "loss": 0.6792,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.00013630383182317019,
      "rewards/margins": 0.02817518636584282,
      "rewards/rejected": -0.02831149287521839,
      "step": 166
    },
    {
      "epoch": 12.88,
      "grad_norm": 8.57199764251709,
      "learning_rate": 8.859375e-08,
      "logits/chosen": 1.066310167312622,
      "logits/rejected": 1.0522921085357666,
      "logps/chosen": -32.93598175048828,
      "logps/rejected": -53.1522216796875,
      "loss": 0.6791,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.004692005924880505,
      "rewards/margins": 0.028489375486969948,
      "rewards/rejected": -0.023797370493412018,
      "step": 167
    },
    {
      "epoch": 12.96,
      "grad_norm": 7.2808122634887695,
      "learning_rate": 8.8515625e-08,
      "logits/chosen": 1.401111125946045,
      "logits/rejected": 1.4622799158096313,
      "logps/chosen": -38.022789001464844,
      "logps/rejected": -60.70038604736328,
      "loss": 0.6847,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010669470764696598,
      "rewards/margins": 0.017125893384218216,
      "rewards/rejected": -0.006456422619521618,
      "step": 168
    },
    {
      "epoch": 13.0,
      "grad_norm": 8.577930450439453,
      "learning_rate": 8.84375e-08,
      "logits/chosen": 1.2017731666564941,
      "logits/rejected": 1.2682209014892578,
      "logps/chosen": -27.43587875366211,
      "logps/rejected": -49.6202278137207,
      "loss": 0.6805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01630888134241104,
      "rewards/margins": 0.025548839941620827,
      "rewards/rejected": -0.00923995953053236,
      "step": 169
    },
    {
      "epoch": 13.0,
      "eval_logits/chosen": 1.3057361841201782,
      "eval_logits/rejected": 1.1987791061401367,
      "eval_logps/chosen": -34.38860321044922,
      "eval_logps/rejected": -47.000308990478516,
      "eval_loss": 0.6877242922782898,
      "eval_rewards/accuracies": 0.6899999976158142,
      "eval_rewards/chosen": 0.011091269552707672,
      "eval_rewards/margins": 0.011003116145730019,
      "eval_rewards/rejected": 8.815198816591874e-05,
      "eval_runtime": 2.7973,
      "eval_samples_per_second": 35.748,
      "eval_steps_per_second": 17.874,
      "step": 169
    },
    {
      "epoch": 13.08,
      "grad_norm": 7.784671783447266,
      "learning_rate": 8.835937499999999e-08,
      "logits/chosen": 1.2081706523895264,
      "logits/rejected": 1.131005048751831,
      "logps/chosen": -34.42744445800781,
      "logps/rejected": -55.75196075439453,
      "loss": 0.6831,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010544109158217907,
      "rewards/margins": 0.02019643783569336,
      "rewards/rejected": -0.009652327746152878,
      "step": 170
    },
    {
      "epoch": 13.16,
      "grad_norm": 6.3703155517578125,
      "learning_rate": 8.828125e-08,
      "logits/chosen": 1.1506677865982056,
      "logits/rejected": 1.2440847158432007,
      "logps/chosen": -32.415977478027344,
      "logps/rejected": -52.44577407836914,
      "loss": 0.6812,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013641953468322754,
      "rewards/margins": 0.024178195744752884,
      "rewards/rejected": -0.01053624227643013,
      "step": 171
    },
    {
      "epoch": 13.24,
      "grad_norm": 7.1576151847839355,
      "learning_rate": 8.8203125e-08,
      "logits/chosen": 1.3904566764831543,
      "logits/rejected": 1.2547242641448975,
      "logps/chosen": -33.371097564697266,
      "logps/rejected": -51.07892608642578,
      "loss": 0.6855,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0014737844467163086,
      "rewards/margins": 0.01556103304028511,
      "rewards/rejected": -0.014087248593568802,
      "step": 172
    },
    {
      "epoch": 13.32,
      "grad_norm": 7.421108245849609,
      "learning_rate": 8.812499999999999e-08,
      "logits/chosen": 1.340988039970398,
      "logits/rejected": 1.3235864639282227,
      "logps/chosen": -37.65484619140625,
      "logps/rejected": -61.580867767333984,
      "loss": 0.6859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009561920538544655,
      "rewards/margins": 0.014483499340713024,
      "rewards/rejected": -0.004921579733490944,
      "step": 173
    },
    {
      "epoch": 13.4,
      "grad_norm": 7.2007317543029785,
      "learning_rate": 8.8046875e-08,
      "logits/chosen": 1.3112199306488037,
      "logits/rejected": 1.2117481231689453,
      "logps/chosen": -31.929222106933594,
      "logps/rejected": -56.0388069152832,
      "loss": 0.6845,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.009958767332136631,
      "rewards/margins": 0.01763753779232502,
      "rewards/rejected": -0.0076787713915109634,
      "step": 174
    },
    {
      "epoch": 13.48,
      "grad_norm": 7.827630519866943,
      "learning_rate": 8.796874999999999e-08,
      "logits/chosen": 1.2693206071853638,
      "logits/rejected": 1.1375802755355835,
      "logps/chosen": -34.212371826171875,
      "logps/rejected": -53.312957763671875,
      "loss": 0.6824,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005662202835083008,
      "rewards/margins": 0.02176680415868759,
      "rewards/rejected": -0.016104603186249733,
      "step": 175
    },
    {
      "epoch": 13.56,
      "grad_norm": 7.63427209854126,
      "learning_rate": 8.789062499999999e-08,
      "logits/chosen": 1.3570270538330078,
      "logits/rejected": 1.4516539573669434,
      "logps/chosen": -34.333106994628906,
      "logps/rejected": -50.81604766845703,
      "loss": 0.6817,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012923001311719418,
      "rewards/margins": 0.023060083389282227,
      "rewards/rejected": -0.010137081146240234,
      "step": 176
    },
    {
      "epoch": 13.64,
      "grad_norm": 7.599148273468018,
      "learning_rate": 8.78125e-08,
      "logits/chosen": 1.552796483039856,
      "logits/rejected": 1.3721346855163574,
      "logps/chosen": -32.927730560302734,
      "logps/rejected": -52.54401397705078,
      "loss": 0.6867,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01094882469624281,
      "rewards/margins": 0.013071511872112751,
      "rewards/rejected": -0.0021226878743618727,
      "step": 177
    },
    {
      "epoch": 13.72,
      "grad_norm": 7.650221347808838,
      "learning_rate": 8.7734375e-08,
      "logits/chosen": 1.1115671396255493,
      "logits/rejected": 1.1937092542648315,
      "logps/chosen": -33.99525833129883,
      "logps/rejected": -56.23514175415039,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002237295964732766,
      "rewards/margins": 0.010449577122926712,
      "rewards/rejected": -0.008212280459702015,
      "step": 178
    },
    {
      "epoch": 13.8,
      "grad_norm": 7.6566009521484375,
      "learning_rate": 8.765625e-08,
      "logits/chosen": 1.3979159593582153,
      "logits/rejected": 1.1733571290969849,
      "logps/chosen": -38.207767486572266,
      "logps/rejected": -50.254539489746094,
      "loss": 0.6828,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006287693046033382,
      "rewards/margins": 0.02092616632580757,
      "rewards/rejected": -0.014638472348451614,
      "step": 179
    },
    {
      "epoch": 13.88,
      "grad_norm": 9.212800979614258,
      "learning_rate": 8.7578125e-08,
      "logits/chosen": 1.520357608795166,
      "logits/rejected": 1.2653732299804688,
      "logps/chosen": -34.105777740478516,
      "logps/rejected": -50.25970458984375,
      "loss": 0.6733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020411111414432526,
      "rewards/margins": 0.04022216796875,
      "rewards/rejected": -0.019811058416962624,
      "step": 180
    },
    {
      "epoch": 13.96,
      "grad_norm": 8.984652519226074,
      "learning_rate": 8.75e-08,
      "logits/chosen": 1.1924469470977783,
      "logits/rejected": 1.2270586490631104,
      "logps/chosen": -32.808135986328125,
      "logps/rejected": -64.25298309326172,
      "loss": 0.6827,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.002093601506203413,
      "rewards/margins": 0.021129561588168144,
      "rewards/rejected": -0.019035959616303444,
      "step": 181
    },
    {
      "epoch": 14.0,
      "grad_norm": 9.415550231933594,
      "learning_rate": 8.7421875e-08,
      "logits/chosen": 1.1900758743286133,
      "logits/rejected": 1.4733091592788696,
      "logps/chosen": -32.32262420654297,
      "logps/rejected": -64.81907653808594,
      "loss": 0.6843,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009788132272660732,
      "rewards/margins": 0.017888735979795456,
      "rewards/rejected": -0.008100605569779873,
      "step": 182
    },
    {
      "epoch": 14.0,
      "eval_logits/chosen": 1.305528998374939,
      "eval_logits/rejected": 1.1979584693908691,
      "eval_logps/chosen": -34.41804122924805,
      "eval_logps/rejected": -47.019222259521484,
      "eval_loss": 0.6882481575012207,
      "eval_rewards/accuracies": 0.6700000166893005,
      "eval_rewards/chosen": 0.008147608488798141,
      "eval_rewards/margins": 0.00995129905641079,
      "eval_rewards/rejected": -0.00180369196459651,
      "eval_runtime": 2.7345,
      "eval_samples_per_second": 36.569,
      "eval_steps_per_second": 18.285,
      "step": 182
    },
    {
      "epoch": 14.08,
      "grad_norm": 7.376296043395996,
      "learning_rate": 8.734375e-08,
      "logits/chosen": 1.3409005403518677,
      "logits/rejected": 1.1721715927124023,
      "logps/chosen": -32.48366165161133,
      "logps/rejected": -55.61290740966797,
      "loss": 0.6851,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0018794299103319645,
      "rewards/margins": 0.01624133810400963,
      "rewards/rejected": -0.014361906796693802,
      "step": 183
    },
    {
      "epoch": 14.16,
      "grad_norm": 7.993503093719482,
      "learning_rate": 8.7265625e-08,
      "logits/chosen": 1.330312967300415,
      "logits/rejected": 1.3501079082489014,
      "logps/chosen": -34.906089782714844,
      "logps/rejected": -56.226654052734375,
      "loss": 0.6827,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009782696142792702,
      "rewards/margins": 0.02107696607708931,
      "rewards/rejected": -0.011294269934296608,
      "step": 184
    },
    {
      "epoch": 14.24,
      "grad_norm": 6.5654449462890625,
      "learning_rate": 8.718749999999999e-08,
      "logits/chosen": 1.3648149967193604,
      "logits/rejected": 1.2577072381973267,
      "logps/chosen": -34.72467803955078,
      "logps/rejected": -48.28911590576172,
      "loss": 0.6828,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011872291564941406,
      "rewards/margins": 0.020913027226924896,
      "rewards/rejected": -0.00904073752462864,
      "step": 185
    },
    {
      "epoch": 14.32,
      "grad_norm": 8.165816307067871,
      "learning_rate": 8.7109375e-08,
      "logits/chosen": 1.4215905666351318,
      "logits/rejected": 1.2759103775024414,
      "logps/chosen": -35.78303527832031,
      "logps/rejected": -48.84778594970703,
      "loss": 0.6844,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013162994757294655,
      "rewards/margins": 0.017799902707338333,
      "rewards/rejected": -0.004636907950043678,
      "step": 186
    },
    {
      "epoch": 14.4,
      "grad_norm": 7.800466060638428,
      "learning_rate": 8.703125e-08,
      "logits/chosen": 1.1485754251480103,
      "logits/rejected": 1.1332645416259766,
      "logps/chosen": -34.263633728027344,
      "logps/rejected": -58.03091812133789,
      "loss": 0.6775,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009424377232789993,
      "rewards/margins": 0.03183157742023468,
      "rewards/rejected": -0.022407198324799538,
      "step": 187
    },
    {
      "epoch": 14.48,
      "grad_norm": 8.005745887756348,
      "learning_rate": 8.695312499999999e-08,
      "logits/chosen": 1.3483927249908447,
      "logits/rejected": 1.4304498434066772,
      "logps/chosen": -29.72460174560547,
      "logps/rejected": -50.04191589355469,
      "loss": 0.6756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011731982231140137,
      "rewards/margins": 0.035414956510066986,
      "rewards/rejected": -0.023682976141572,
      "step": 188
    },
    {
      "epoch": 14.56,
      "grad_norm": 7.111694812774658,
      "learning_rate": 8.6875e-08,
      "logits/chosen": 1.179500699043274,
      "logits/rejected": 1.27742600440979,
      "logps/chosen": -34.207977294921875,
      "logps/rejected": -52.89763641357422,
      "loss": 0.6845,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007780647370964289,
      "rewards/margins": 0.01750652864575386,
      "rewards/rejected": -0.009725880809128284,
      "step": 189
    },
    {
      "epoch": 14.64,
      "grad_norm": 6.871847629547119,
      "learning_rate": 8.679687499999999e-08,
      "logits/chosen": 1.180045485496521,
      "logits/rejected": 1.3092479705810547,
      "logps/chosen": -36.463897705078125,
      "logps/rejected": -59.05433654785156,
      "loss": 0.6759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010228538885712624,
      "rewards/margins": 0.03482051193714142,
      "rewards/rejected": -0.024591971188783646,
      "step": 190
    },
    {
      "epoch": 14.72,
      "grad_norm": 7.622663974761963,
      "learning_rate": 8.671874999999999e-08,
      "logits/chosen": 1.3641221523284912,
      "logits/rejected": 1.2281601428985596,
      "logps/chosen": -33.44314193725586,
      "logps/rejected": -54.686256408691406,
      "loss": 0.6878,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0069676171988248825,
      "rewards/margins": 0.010917164385318756,
      "rewards/rejected": -0.003949547186493874,
      "step": 191
    },
    {
      "epoch": 14.8,
      "grad_norm": 7.360219955444336,
      "learning_rate": 8.6640625e-08,
      "logits/chosen": 1.350523591041565,
      "logits/rejected": 1.3596618175506592,
      "logps/chosen": -34.69713592529297,
      "logps/rejected": -66.73040771484375,
      "loss": 0.6887,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0015587570378556848,
      "rewards/margins": 0.00896608829498291,
      "rewards/rejected": -0.01052484568208456,
      "step": 192
    },
    {
      "epoch": 14.88,
      "grad_norm": 7.592655181884766,
      "learning_rate": 8.656249999999999e-08,
      "logits/chosen": 1.3180674314498901,
      "logits/rejected": 1.153974175453186,
      "logps/chosen": -35.38463592529297,
      "logps/rejected": -50.066410064697266,
      "loss": 0.6841,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008157659322023392,
      "rewards/margins": 0.01829516887664795,
      "rewards/rejected": -0.010137510485947132,
      "step": 193
    },
    {
      "epoch": 14.96,
      "grad_norm": 7.66126012802124,
      "learning_rate": 8.648437499999999e-08,
      "logits/chosen": 1.3529942035675049,
      "logits/rejected": 1.157901644706726,
      "logps/chosen": -33.80888748168945,
      "logps/rejected": -55.0234260559082,
      "loss": 0.6704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014606237411499023,
      "rewards/margins": 0.04615302383899689,
      "rewards/rejected": -0.031546782702207565,
      "step": 194
    },
    {
      "epoch": 15.0,
      "grad_norm": 12.180668830871582,
      "learning_rate": 8.640624999999999e-08,
      "logits/chosen": 1.1643236875534058,
      "logits/rejected": 1.11661696434021,
      "logps/chosen": -33.67884826660156,
      "logps/rejected": -63.61057662963867,
      "loss": 0.6837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.007394265849143267,
      "rewards/margins": 0.019094038754701614,
      "rewards/rejected": -0.026488304138183594,
      "step": 195
    },
    {
      "epoch": 15.0,
      "eval_logits/chosen": 1.3032909631729126,
      "eval_logits/rejected": 1.1990187168121338,
      "eval_logps/chosen": -34.403995513916016,
      "eval_logps/rejected": -47.019168853759766,
      "eval_loss": 0.6875436902046204,
      "eval_rewards/accuracies": 0.6800000071525574,
      "eval_rewards/chosen": 0.009552089497447014,
      "eval_rewards/margins": 0.011350398883223534,
      "eval_rewards/rejected": -0.0017983093857765198,
      "eval_runtime": 2.7603,
      "eval_samples_per_second": 36.227,
      "eval_steps_per_second": 18.114,
      "step": 195
    },
    {
      "epoch": 15.08,
      "grad_norm": 6.675019264221191,
      "learning_rate": 8.6328125e-08,
      "logits/chosen": 1.4131059646606445,
      "logits/rejected": 1.3721892833709717,
      "logps/chosen": -32.65882110595703,
      "logps/rejected": -42.918190002441406,
      "loss": 0.6888,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0032980921678245068,
      "rewards/margins": 0.008761263452470303,
      "rewards/rejected": -0.005463171284645796,
      "step": 196
    },
    {
      "epoch": 15.16,
      "grad_norm": 6.373348712921143,
      "learning_rate": 8.625e-08,
      "logits/chosen": 1.4659805297851562,
      "logits/rejected": 1.4560643434524536,
      "logps/chosen": -38.95060729980469,
      "logps/rejected": -44.81367492675781,
      "loss": 0.6829,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0008062602719292045,
      "rewards/margins": 0.020588040351867676,
      "rewards/rejected": -0.02139430120587349,
      "step": 197
    },
    {
      "epoch": 15.24,
      "grad_norm": 7.9864091873168945,
      "learning_rate": 8.6171875e-08,
      "logits/chosen": 1.3914258480072021,
      "logits/rejected": 1.4784647226333618,
      "logps/chosen": -35.290184020996094,
      "logps/rejected": -56.350502014160156,
      "loss": 0.6831,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003975606523454189,
      "rewards/margins": 0.0205003023147583,
      "rewards/rejected": -0.016524698585271835,
      "step": 198
    },
    {
      "epoch": 15.32,
      "grad_norm": 7.859752655029297,
      "learning_rate": 8.609375e-08,
      "logits/chosen": 1.024963140487671,
      "logits/rejected": 1.1435657739639282,
      "logps/chosen": -38.26487350463867,
      "logps/rejected": -56.41980743408203,
      "loss": 0.6786,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008931731805205345,
      "rewards/margins": 0.029520656913518906,
      "rewards/rejected": -0.02058892324566841,
      "step": 199
    },
    {
      "epoch": 15.4,
      "grad_norm": 7.78318452835083,
      "learning_rate": 8.6015625e-08,
      "logits/chosen": 1.181574821472168,
      "logits/rejected": 1.1794673204421997,
      "logps/chosen": -31.528255462646484,
      "logps/rejected": -57.403099060058594,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01396184042096138,
      "rewards/margins": 0.010358096100389957,
      "rewards/rejected": 0.0036037443205714226,
      "step": 200
    },
    {
      "epoch": 15.48,
      "grad_norm": 8.813932418823242,
      "learning_rate": 8.59375e-08,
      "logits/chosen": 1.1809974908828735,
      "logits/rejected": 1.2828606367111206,
      "logps/chosen": -34.262550354003906,
      "logps/rejected": -57.330047607421875,
      "loss": 0.6829,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010759185999631882,
      "rewards/margins": 0.02067134529352188,
      "rewards/rejected": -0.00991215743124485,
      "step": 201
    },
    {
      "epoch": 15.56,
      "grad_norm": 6.944619178771973,
      "learning_rate": 8.5859375e-08,
      "logits/chosen": 1.208148717880249,
      "logits/rejected": 1.286537528038025,
      "logps/chosen": -33.2569580078125,
      "logps/rejected": -56.726409912109375,
      "loss": 0.6781,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013138199225068092,
      "rewards/margins": 0.0305512435734272,
      "rewards/rejected": -0.017413044348359108,
      "step": 202
    },
    {
      "epoch": 15.64,
      "grad_norm": 7.640780448913574,
      "learning_rate": 8.578125e-08,
      "logits/chosen": 1.238863468170166,
      "logits/rejected": 1.3594363927841187,
      "logps/chosen": -34.023101806640625,
      "logps/rejected": -57.665584564208984,
      "loss": 0.6814,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00657656230032444,
      "rewards/margins": 0.023737741634249687,
      "rewards/rejected": -0.017161179333925247,
      "step": 203
    },
    {
      "epoch": 15.72,
      "grad_norm": 9.15446949005127,
      "learning_rate": 8.5703125e-08,
      "logits/chosen": 1.4062976837158203,
      "logits/rejected": 1.0921604633331299,
      "logps/chosen": -33.59539031982422,
      "logps/rejected": -48.189762115478516,
      "loss": 0.6841,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.017494987696409225,
      "rewards/margins": 0.018350768834352493,
      "rewards/rejected": -0.0008557792752981186,
      "step": 204
    },
    {
      "epoch": 15.8,
      "grad_norm": 7.042207717895508,
      "learning_rate": 8.562499999999999e-08,
      "logits/chosen": 1.435730218887329,
      "logits/rejected": 1.1670711040496826,
      "logps/chosen": -34.94331741333008,
      "logps/rejected": -57.16962814331055,
      "loss": 0.6843,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.004664826672524214,
      "rewards/margins": 0.01784832589328289,
      "rewards/rejected": -0.022513151168823242,
      "step": 205
    },
    {
      "epoch": 15.88,
      "grad_norm": 8.223671913146973,
      "learning_rate": 8.5546875e-08,
      "logits/chosen": 1.2779929637908936,
      "logits/rejected": 1.0149881839752197,
      "logps/chosen": -30.174034118652344,
      "logps/rejected": -56.17328643798828,
      "loss": 0.6731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013690424151718616,
      "rewards/margins": 0.0406549908220768,
      "rewards/rejected": -0.026964571326971054,
      "step": 206
    },
    {
      "epoch": 15.96,
      "grad_norm": 7.9711222648620605,
      "learning_rate": 8.546875e-08,
      "logits/chosen": 1.2401994466781616,
      "logits/rejected": 1.2225149869918823,
      "logps/chosen": -33.51054763793945,
      "logps/rejected": -68.33920288085938,
      "loss": 0.6731,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013070940971374512,
      "rewards/margins": 0.040784385055303574,
      "rewards/rejected": -0.027713444083929062,
      "step": 207
    },
    {
      "epoch": 16.0,
      "grad_norm": 9.27137279510498,
      "learning_rate": 8.539062499999999e-08,
      "logits/chosen": 1.4873712062835693,
      "logits/rejected": 1.354040265083313,
      "logps/chosen": -32.18711853027344,
      "logps/rejected": -56.07170867919922,
      "loss": 0.6675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027240417897701263,
      "rewards/margins": 0.05201869085431099,
      "rewards/rejected": -0.024778271093964577,
      "step": 208
    },
    {
      "epoch": 16.0,
      "eval_logits/chosen": 1.306907057762146,
      "eval_logits/rejected": 1.19902503490448,
      "eval_logps/chosen": -34.4035758972168,
      "eval_logps/rejected": -47.020301818847656,
      "eval_loss": 0.6874593496322632,
      "eval_rewards/accuracies": 0.6899999976158142,
      "eval_rewards/chosen": 0.009594272822141647,
      "eval_rewards/margins": 0.011505934409797192,
      "eval_rewards/rejected": -0.0019116613548249006,
      "eval_runtime": 2.7295,
      "eval_samples_per_second": 36.636,
      "eval_steps_per_second": 18.318,
      "step": 208
    },
    {
      "epoch": 16.08,
      "grad_norm": 7.65212869644165,
      "learning_rate": 8.53125e-08,
      "logits/chosen": 1.3920778036117554,
      "logits/rejected": 1.3447710275650024,
      "logps/chosen": -45.751800537109375,
      "logps/rejected": -56.65234375,
      "loss": 0.6834,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006090117152780294,
      "rewards/margins": 0.019647266715765,
      "rewards/rejected": -0.013557148166000843,
      "step": 209
    },
    {
      "epoch": 16.16,
      "grad_norm": 8.574590682983398,
      "learning_rate": 8.523437499999999e-08,
      "logits/chosen": 1.2397946119308472,
      "logits/rejected": 1.1859387159347534,
      "logps/chosen": -34.815826416015625,
      "logps/rejected": -58.42320251464844,
      "loss": 0.6863,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0030520204454660416,
      "rewards/margins": 0.013829780742526054,
      "rewards/rejected": -0.010777760297060013,
      "step": 210
    },
    {
      "epoch": 16.24,
      "grad_norm": 8.137663841247559,
      "learning_rate": 8.515624999999999e-08,
      "logits/chosen": 1.4035086631774902,
      "logits/rejected": 1.0624864101409912,
      "logps/chosen": -29.688222885131836,
      "logps/rejected": -51.270606994628906,
      "loss": 0.6752,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014371657744050026,
      "rewards/margins": 0.036455512046813965,
      "rewards/rejected": -0.022083856165409088,
      "step": 211
    },
    {
      "epoch": 16.32,
      "grad_norm": 7.533499717712402,
      "learning_rate": 8.5078125e-08,
      "logits/chosen": 1.2624545097351074,
      "logits/rejected": 1.3716487884521484,
      "logps/chosen": -33.10034942626953,
      "logps/rejected": -53.76982879638672,
      "loss": 0.6744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010388708673417568,
      "rewards/margins": 0.03798728063702583,
      "rewards/rejected": -0.02759857103228569,
      "step": 212
    },
    {
      "epoch": 16.4,
      "grad_norm": 7.35308837890625,
      "learning_rate": 8.5e-08,
      "logits/chosen": 1.436874270439148,
      "logits/rejected": 1.3859621286392212,
      "logps/chosen": -34.8463249206543,
      "logps/rejected": -59.482688903808594,
      "loss": 0.6811,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007485128007829189,
      "rewards/margins": 0.024393439292907715,
      "rewards/rejected": -0.0169083122164011,
      "step": 213
    },
    {
      "epoch": 16.48,
      "grad_norm": 7.355845928192139,
      "learning_rate": 8.4921875e-08,
      "logits/chosen": 1.0008370876312256,
      "logits/rejected": 1.1466437578201294,
      "logps/chosen": -30.90652847290039,
      "logps/rejected": -47.20338821411133,
      "loss": 0.6756,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012920570559799671,
      "rewards/margins": 0.03561573103070259,
      "rewards/rejected": -0.022695161402225494,
      "step": 214
    },
    {
      "epoch": 16.56,
      "grad_norm": 6.481489181518555,
      "learning_rate": 8.484375e-08,
      "logits/chosen": 1.4120361804962158,
      "logits/rejected": 1.2835447788238525,
      "logps/chosen": -34.956275939941406,
      "logps/rejected": -56.570213317871094,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0049142357893288136,
      "rewards/margins": 0.006358242128044367,
      "rewards/rejected": -0.0014440059894695878,
      "step": 215
    },
    {
      "epoch": 16.64,
      "grad_norm": 7.132805347442627,
      "learning_rate": 8.4765625e-08,
      "logits/chosen": 1.3555419445037842,
      "logits/rejected": 1.2101675271987915,
      "logps/chosen": -34.304439544677734,
      "logps/rejected": -55.60110855102539,
      "loss": 0.6858,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005053472705185413,
      "rewards/margins": 0.014864111319184303,
      "rewards/rejected": -0.00981063861399889,
      "step": 216
    },
    {
      "epoch": 16.72,
      "grad_norm": 7.2744460105896,
      "learning_rate": 8.46875e-08,
      "logits/chosen": 1.2454018592834473,
      "logits/rejected": 1.3086671829223633,
      "logps/chosen": -31.3221492767334,
      "logps/rejected": -54.661109924316406,
      "loss": 0.6836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00363407121039927,
      "rewards/margins": 0.019252920523285866,
      "rewards/rejected": -0.01561884954571724,
      "step": 217
    },
    {
      "epoch": 16.8,
      "grad_norm": 7.803454875946045,
      "learning_rate": 8.4609375e-08,
      "logits/chosen": 1.2286994457244873,
      "logits/rejected": 1.2965787649154663,
      "logps/chosen": -34.79943084716797,
      "logps/rejected": -62.34593963623047,
      "loss": 0.6713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01658327504992485,
      "rewards/margins": 0.04437363147735596,
      "rewards/rejected": -0.027790354564785957,
      "step": 218
    },
    {
      "epoch": 16.88,
      "grad_norm": 7.407208442687988,
      "learning_rate": 8.453125e-08,
      "logits/chosen": 1.2753844261169434,
      "logits/rejected": 1.4396189451217651,
      "logps/chosen": -32.10309982299805,
      "logps/rejected": -51.0184326171875,
      "loss": 0.686,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0013794421683996916,
      "rewards/margins": 0.014449691399931908,
      "rewards/rejected": -0.013070249930024147,
      "step": 219
    },
    {
      "epoch": 16.96,
      "grad_norm": 8.342097282409668,
      "learning_rate": 8.445312499999999e-08,
      "logits/chosen": 1.2712607383728027,
      "logits/rejected": 1.0136696100234985,
      "logps/chosen": -32.56729507446289,
      "logps/rejected": -49.29144287109375,
      "loss": 0.6747,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015547705814242363,
      "rewards/margins": 0.03744964674115181,
      "rewards/rejected": -0.021901939064264297,
      "step": 220
    },
    {
      "epoch": 17.0,
      "grad_norm": 8.663926124572754,
      "learning_rate": 8.4375e-08,
      "logits/chosen": 1.23255455493927,
      "logits/rejected": 1.3714581727981567,
      "logps/chosen": -35.12614822387695,
      "logps/rejected": -62.75702667236328,
      "loss": 0.6918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00902872160077095,
      "rewards/margins": 0.0027831075713038445,
      "rewards/rejected": -0.01181182824075222,
      "step": 221
    },
    {
      "epoch": 17.0,
      "eval_logits/chosen": 1.3080840110778809,
      "eval_logits/rejected": 1.2004330158233643,
      "eval_logps/chosen": -34.386085510253906,
      "eval_logps/rejected": -47.01902389526367,
      "eval_loss": 0.6866550445556641,
      "eval_rewards/accuracies": 0.7599999904632568,
      "eval_rewards/chosen": 0.011343229562044144,
      "eval_rewards/margins": 0.013127058744430542,
      "eval_rewards/rejected": -0.0017838286003097892,
      "eval_runtime": 2.7255,
      "eval_samples_per_second": 36.691,
      "eval_steps_per_second": 18.345,
      "step": 221
    },
    {
      "epoch": 17.08,
      "grad_norm": 9.281266212463379,
      "learning_rate": 8.4296875e-08,
      "logits/chosen": 1.344268560409546,
      "logits/rejected": 1.0244137048721313,
      "logps/chosen": -32.951622009277344,
      "logps/rejected": -55.7742805480957,
      "loss": 0.6821,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00770196970552206,
      "rewards/margins": 0.02249450795352459,
      "rewards/rejected": -0.01479253824800253,
      "step": 222
    },
    {
      "epoch": 17.16,
      "grad_norm": 6.910304069519043,
      "learning_rate": 8.421874999999999e-08,
      "logits/chosen": 1.2796238660812378,
      "logits/rejected": 1.459326148033142,
      "logps/chosen": -35.55626678466797,
      "logps/rejected": -48.55952453613281,
      "loss": 0.6756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012006497010588646,
      "rewards/margins": 0.03552229329943657,
      "rewards/rejected": -0.023515796288847923,
      "step": 223
    },
    {
      "epoch": 17.24,
      "grad_norm": 7.5389509201049805,
      "learning_rate": 8.4140625e-08,
      "logits/chosen": 1.2725507020950317,
      "logits/rejected": 1.235302448272705,
      "logps/chosen": -35.10710906982422,
      "logps/rejected": -55.81306076049805,
      "loss": 0.6787,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016462016850709915,
      "rewards/margins": 0.029210304841399193,
      "rewards/rejected": -0.012748288922011852,
      "step": 224
    },
    {
      "epoch": 17.32,
      "grad_norm": 7.409352779388428,
      "learning_rate": 8.406249999999999e-08,
      "logits/chosen": 1.348474383354187,
      "logits/rejected": 1.3418281078338623,
      "logps/chosen": -32.823143005371094,
      "logps/rejected": -59.78968048095703,
      "loss": 0.6794,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00888810120522976,
      "rewards/margins": 0.02780909463763237,
      "rewards/rejected": -0.01892099529504776,
      "step": 225
    },
    {
      "epoch": 17.4,
      "grad_norm": 6.212700366973877,
      "learning_rate": 8.398437499999999e-08,
      "logits/chosen": 1.6380925178527832,
      "logits/rejected": 1.447859287261963,
      "logps/chosen": -36.266273498535156,
      "logps/rejected": -55.07726287841797,
      "loss": 0.6911,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0006931545212864876,
      "rewards/margins": 0.0042137387208640575,
      "rewards/rejected": -0.004906893242150545,
      "step": 226
    },
    {
      "epoch": 17.48,
      "grad_norm": 8.164852142333984,
      "learning_rate": 8.390625e-08,
      "logits/chosen": 1.3486542701721191,
      "logits/rejected": 1.2639378309249878,
      "logps/chosen": -36.891090393066406,
      "logps/rejected": -58.651371002197266,
      "loss": 0.6794,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0009624715894460678,
      "rewards/margins": 0.02784597873687744,
      "rewards/rejected": -0.026883509010076523,
      "step": 227
    },
    {
      "epoch": 17.56,
      "grad_norm": 7.386984825134277,
      "learning_rate": 8.382812499999999e-08,
      "logits/chosen": 1.147969365119934,
      "logits/rejected": 1.2281303405761719,
      "logps/chosen": -34.120330810546875,
      "logps/rejected": -63.04521942138672,
      "loss": 0.6784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006404065992683172,
      "rewards/margins": 0.029743194580078125,
      "rewards/rejected": -0.023339128121733665,
      "step": 228
    },
    {
      "epoch": 17.64,
      "grad_norm": 7.879123687744141,
      "learning_rate": 8.374999999999999e-08,
      "logits/chosen": 1.1794127225875854,
      "logits/rejected": 1.2268385887145996,
      "logps/chosen": -33.70869445800781,
      "logps/rejected": -53.085662841796875,
      "loss": 0.6806,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01606116257607937,
      "rewards/margins": 0.02541956678032875,
      "rewards/rejected": -0.009358406066894531,
      "step": 229
    },
    {
      "epoch": 17.72,
      "grad_norm": 7.775365829467773,
      "learning_rate": 8.367187499999999e-08,
      "logits/chosen": 1.4764283895492554,
      "logits/rejected": 1.4229727983474731,
      "logps/chosen": -33.3127555847168,
      "logps/rejected": -52.51020431518555,
      "loss": 0.675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01666555367410183,
      "rewards/margins": 0.036895085126161575,
      "rewards/rejected": -0.020229529589414597,
      "step": 230
    },
    {
      "epoch": 17.8,
      "grad_norm": 7.401878833770752,
      "learning_rate": 8.359375e-08,
      "logits/chosen": 1.2062429189682007,
      "logits/rejected": 0.9086906313896179,
      "logps/chosen": -31.013315200805664,
      "logps/rejected": -45.32595443725586,
      "loss": 0.6773,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.005968976765871048,
      "rewards/margins": 0.032125331461429596,
      "rewards/rejected": -0.026156354695558548,
      "step": 231
    },
    {
      "epoch": 17.88,
      "grad_norm": 8.045510292053223,
      "learning_rate": 8.3515625e-08,
      "logits/chosen": 1.3734710216522217,
      "logits/rejected": 1.2842501401901245,
      "logps/chosen": -33.776763916015625,
      "logps/rejected": -60.130584716796875,
      "loss": 0.6777,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012620760127902031,
      "rewards/margins": 0.031217360869050026,
      "rewards/rejected": -0.018596602603793144,
      "step": 232
    },
    {
      "epoch": 17.96,
      "grad_norm": 7.330270767211914,
      "learning_rate": 8.34375e-08,
      "logits/chosen": 1.2428312301635742,
      "logits/rejected": 1.223965048789978,
      "logps/chosen": -34.78388977050781,
      "logps/rejected": -50.96477127075195,
      "loss": 0.679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012222790159285069,
      "rewards/margins": 0.02865426614880562,
      "rewards/rejected": -0.016431473195552826,
      "step": 233
    },
    {
      "epoch": 18.0,
      "grad_norm": 10.24630355834961,
      "learning_rate": 8.3359375e-08,
      "logits/chosen": 0.8839156627655029,
      "logits/rejected": 1.4362982511520386,
      "logps/chosen": -32.28530502319336,
      "logps/rejected": -58.30134582519531,
      "loss": 0.686,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0002641204046085477,
      "rewards/margins": 0.014630556106567383,
      "rewards/rejected": -0.014366435818374157,
      "step": 234
    },
    {
      "epoch": 18.0,
      "eval_logits/chosen": 1.3062374591827393,
      "eval_logits/rejected": 1.2001092433929443,
      "eval_logps/chosen": -34.36387252807617,
      "eval_logps/rejected": -47.04232406616211,
      "eval_loss": 0.6844048500061035,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.013564378954470158,
      "eval_rewards/margins": 0.01767801307141781,
      "eval_rewards/rejected": -0.004113634582608938,
      "eval_runtime": 2.7354,
      "eval_samples_per_second": 36.558,
      "eval_steps_per_second": 18.279,
      "step": 234
    },
    {
      "epoch": 18.08,
      "grad_norm": 7.3560566902160645,
      "learning_rate": 8.328125e-08,
      "logits/chosen": 1.103515386581421,
      "logits/rejected": 1.3035550117492676,
      "logps/chosen": -34.708438873291016,
      "logps/rejected": -57.04522705078125,
      "loss": 0.6848,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0035614967346191406,
      "rewards/margins": 0.01681814156472683,
      "rewards/rejected": -0.013256644830107689,
      "step": 235
    },
    {
      "epoch": 18.16,
      "grad_norm": 7.5115251541137695,
      "learning_rate": 8.3203125e-08,
      "logits/chosen": 1.2875287532806396,
      "logits/rejected": 1.181999921798706,
      "logps/chosen": -33.7008056640625,
      "logps/rejected": -53.870262145996094,
      "loss": 0.6751,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005767941474914551,
      "rewards/margins": 0.0366164930164814,
      "rewards/rejected": -0.03084855154156685,
      "step": 236
    },
    {
      "epoch": 18.24,
      "grad_norm": 6.803830146789551,
      "learning_rate": 8.3125e-08,
      "logits/chosen": 1.257629632949829,
      "logits/rejected": 1.4552805423736572,
      "logps/chosen": -32.40470886230469,
      "logps/rejected": -56.310646057128906,
      "loss": 0.6806,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014416838064789772,
      "rewards/margins": 0.025375843048095703,
      "rewards/rejected": -0.01095900684595108,
      "step": 237
    },
    {
      "epoch": 18.32,
      "grad_norm": 8.27979564666748,
      "learning_rate": 8.3046875e-08,
      "logits/chosen": 1.2452058792114258,
      "logits/rejected": 1.327467679977417,
      "logps/chosen": -41.15192413330078,
      "logps/rejected": -77.49468231201172,
      "loss": 0.6852,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007660103030502796,
      "rewards/margins": 0.015946388244628906,
      "rewards/rejected": -0.00828628521412611,
      "step": 238
    },
    {
      "epoch": 18.4,
      "grad_norm": 7.623510837554932,
      "learning_rate": 8.296875e-08,
      "logits/chosen": 1.3766493797302246,
      "logits/rejected": 1.421128273010254,
      "logps/chosen": -33.895233154296875,
      "logps/rejected": -46.8647575378418,
      "loss": 0.6838,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012689090333878994,
      "rewards/margins": 0.01876223273575306,
      "rewards/rejected": -0.0060731410048902035,
      "step": 239
    },
    {
      "epoch": 18.48,
      "grad_norm": 7.8743205070495605,
      "learning_rate": 8.289062499999999e-08,
      "logits/chosen": 1.4622818231582642,
      "logits/rejected": 1.3980282545089722,
      "logps/chosen": -35.141151428222656,
      "logps/rejected": -48.81266784667969,
      "loss": 0.6766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015940379351377487,
      "rewards/margins": 0.0333922877907753,
      "rewards/rejected": -0.017451906576752663,
      "step": 240
    },
    {
      "epoch": 18.56,
      "grad_norm": 7.065310478210449,
      "learning_rate": 8.28125e-08,
      "logits/chosen": 1.472548484802246,
      "logits/rejected": 1.2052785158157349,
      "logps/chosen": -33.63286590576172,
      "logps/rejected": -51.09616470336914,
      "loss": 0.6821,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.000479245325550437,
      "rewards/margins": 0.022396253421902657,
      "rewards/rejected": -0.022875498980283737,
      "step": 241
    },
    {
      "epoch": 18.64,
      "grad_norm": 7.302058219909668,
      "learning_rate": 8.2734375e-08,
      "logits/chosen": 1.4663152694702148,
      "logits/rejected": 1.4801292419433594,
      "logps/chosen": -31.59241485595703,
      "logps/rejected": -53.21854782104492,
      "loss": 0.6767,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016519593074917793,
      "rewards/margins": 0.03329124301671982,
      "rewards/rejected": -0.016771649941802025,
      "step": 242
    },
    {
      "epoch": 18.72,
      "grad_norm": 8.042011260986328,
      "learning_rate": 8.265624999999999e-08,
      "logits/chosen": 1.1833640336990356,
      "logits/rejected": 1.1190369129180908,
      "logps/chosen": -31.74892234802246,
      "logps/rejected": -53.597434997558594,
      "loss": 0.6711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01885509304702282,
      "rewards/margins": 0.04470887407660484,
      "rewards/rejected": -0.025853777304291725,
      "step": 243
    },
    {
      "epoch": 18.8,
      "grad_norm": 8.547659873962402,
      "learning_rate": 8.2578125e-08,
      "logits/chosen": 1.3635172843933105,
      "logits/rejected": 1.0516575574874878,
      "logps/chosen": -32.880645751953125,
      "logps/rejected": -60.34808349609375,
      "loss": 0.6726,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01739180088043213,
      "rewards/margins": 0.041704632341861725,
      "rewards/rejected": -0.024312831461429596,
      "step": 244
    },
    {
      "epoch": 18.88,
      "grad_norm": 8.202082633972168,
      "learning_rate": 8.249999999999999e-08,
      "logits/chosen": 1.3781152963638306,
      "logits/rejected": 1.067677617073059,
      "logps/chosen": -37.914024353027344,
      "logps/rejected": -58.45926284790039,
      "loss": 0.6743,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012950420379638672,
      "rewards/margins": 0.03819608688354492,
      "rewards/rejected": -0.0252456683665514,
      "step": 245
    },
    {
      "epoch": 18.96,
      "grad_norm": 7.511923313140869,
      "learning_rate": 8.242187499999999e-08,
      "logits/chosen": 0.9694297313690186,
      "logits/rejected": 1.0447994470596313,
      "logps/chosen": -30.47208023071289,
      "logps/rejected": -48.41550827026367,
      "loss": 0.6794,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.004095172509551048,
      "rewards/margins": 0.027814675122499466,
      "rewards/rejected": -0.023719502612948418,
      "step": 246
    },
    {
      "epoch": 19.0,
      "grad_norm": 9.117405891418457,
      "learning_rate": 8.234375e-08,
      "logits/chosen": 1.418654203414917,
      "logits/rejected": 1.3292992115020752,
      "logps/chosen": -34.29452896118164,
      "logps/rejected": -44.81721496582031,
      "loss": 0.6854,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006483554840087891,
      "rewards/margins": 0.015637969598174095,
      "rewards/rejected": -0.009154414758086205,
      "step": 247
    },
    {
      "epoch": 19.0,
      "eval_logits/chosen": 1.3067293167114258,
      "eval_logits/rejected": 1.2009257078170776,
      "eval_logps/chosen": -34.363529205322266,
      "eval_logps/rejected": -47.039588928222656,
      "eval_loss": 0.6845265030860901,
      "eval_rewards/accuracies": 0.7900000214576721,
      "eval_rewards/chosen": 0.013598492369055748,
      "eval_rewards/margins": 0.017439112067222595,
      "eval_rewards/rejected": -0.003840619930997491,
      "eval_runtime": 2.7323,
      "eval_samples_per_second": 36.6,
      "eval_steps_per_second": 18.3,
      "step": 247
    },
    {
      "epoch": 19.08,
      "grad_norm": 9.310342788696289,
      "learning_rate": 8.226562499999999e-08,
      "logits/chosen": 1.242138385772705,
      "logits/rejected": 1.3152483701705933,
      "logps/chosen": -34.58877182006836,
      "logps/rejected": -62.640995025634766,
      "loss": 0.6674,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01743016391992569,
      "rewards/margins": 0.05275345593690872,
      "rewards/rejected": -0.035323284566402435,
      "step": 248
    },
    {
      "epoch": 19.16,
      "grad_norm": 8.106834411621094,
      "learning_rate": 8.21875e-08,
      "logits/chosen": 1.0832021236419678,
      "logits/rejected": 1.0472750663757324,
      "logps/chosen": -28.363386154174805,
      "logps/rejected": -48.825599670410156,
      "loss": 0.6766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013073778711259365,
      "rewards/margins": 0.03343849256634712,
      "rewards/rejected": -0.020364712923765182,
      "step": 249
    },
    {
      "epoch": 19.24,
      "grad_norm": 7.689756870269775,
      "learning_rate": 8.2109375e-08,
      "logits/chosen": 1.257386565208435,
      "logits/rejected": 1.2172232866287231,
      "logps/chosen": -37.283203125,
      "logps/rejected": -57.07640838623047,
      "loss": 0.677,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009080029092729092,
      "rewards/margins": 0.03261213377118111,
      "rewards/rejected": -0.02353210374712944,
      "step": 250
    },
    {
      "epoch": 19.32,
      "grad_norm": 8.193053245544434,
      "learning_rate": 8.203125e-08,
      "logits/chosen": 1.2319655418395996,
      "logits/rejected": 0.9840977191925049,
      "logps/chosen": -29.737045288085938,
      "logps/rejected": -45.98439407348633,
      "loss": 0.676,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0032292131800204515,
      "rewards/margins": 0.03479301929473877,
      "rewards/rejected": -0.031563807278871536,
      "step": 251
    },
    {
      "epoch": 19.4,
      "grad_norm": 8.09206771850586,
      "learning_rate": 8.1953125e-08,
      "logits/chosen": 1.3264598846435547,
      "logits/rejected": 1.3960835933685303,
      "logps/chosen": -42.739288330078125,
      "logps/rejected": -60.674957275390625,
      "loss": 0.6849,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.003164243884384632,
      "rewards/margins": 0.016784142702817917,
      "rewards/rejected": -0.019948387518525124,
      "step": 252
    },
    {
      "epoch": 19.48,
      "grad_norm": 7.498716354370117,
      "learning_rate": 8.1875e-08,
      "logits/chosen": 1.4700151681900024,
      "logits/rejected": 1.1631172895431519,
      "logps/chosen": -32.6004524230957,
      "logps/rejected": -57.557682037353516,
      "loss": 0.6788,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01539929024875164,
      "rewards/margins": 0.028974082320928574,
      "rewards/rejected": -0.013574791140854359,
      "step": 253
    },
    {
      "epoch": 19.56,
      "grad_norm": 8.02535629272461,
      "learning_rate": 8.1796875e-08,
      "logits/chosen": 1.1585843563079834,
      "logits/rejected": 1.2410567998886108,
      "logps/chosen": -29.12781524658203,
      "logps/rejected": -56.033775329589844,
      "loss": 0.6759,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01378166675567627,
      "rewards/margins": 0.03514402359724045,
      "rewards/rejected": -0.02136235311627388,
      "step": 254
    },
    {
      "epoch": 19.64,
      "grad_norm": 6.979736328125,
      "learning_rate": 8.171875e-08,
      "logits/chosen": 1.164735198020935,
      "logits/rejected": 1.3132539987564087,
      "logps/chosen": -32.15369415283203,
      "logps/rejected": -58.53804397583008,
      "loss": 0.6788,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015920137986540794,
      "rewards/margins": 0.02884533628821373,
      "rewards/rejected": -0.012925195507705212,
      "step": 255
    },
    {
      "epoch": 19.72,
      "grad_norm": 6.421550750732422,
      "learning_rate": 8.1640625e-08,
      "logits/chosen": 1.2981305122375488,
      "logits/rejected": 1.3236684799194336,
      "logps/chosen": -34.833106994628906,
      "logps/rejected": -48.53609848022461,
      "loss": 0.6792,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011556602083146572,
      "rewards/margins": 0.028148580342531204,
      "rewards/rejected": -0.016591979190707207,
      "step": 256
    },
    {
      "epoch": 19.8,
      "grad_norm": 7.1809492111206055,
      "learning_rate": 8.15625e-08,
      "logits/chosen": 1.2553995847702026,
      "logits/rejected": 1.351557970046997,
      "logps/chosen": -31.928165435791016,
      "logps/rejected": -52.459320068359375,
      "loss": 0.6745,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013905596919357777,
      "rewards/margins": 0.037659481167793274,
      "rewards/rejected": -0.023753881454467773,
      "step": 257
    },
    {
      "epoch": 19.88,
      "grad_norm": 7.962432861328125,
      "learning_rate": 8.1484375e-08,
      "logits/chosen": 1.4406952857971191,
      "logits/rejected": 1.3414556980133057,
      "logps/chosen": -38.21162414550781,
      "logps/rejected": -52.252708435058594,
      "loss": 0.676,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01165633276104927,
      "rewards/margins": 0.034827373921871185,
      "rewards/rejected": -0.023171043023467064,
      "step": 258
    },
    {
      "epoch": 19.96,
      "grad_norm": 6.782118797302246,
      "learning_rate": 8.140625e-08,
      "logits/chosen": 1.4555668830871582,
      "logits/rejected": 1.3595945835113525,
      "logps/chosen": -36.619197845458984,
      "logps/rejected": -56.32006072998047,
      "loss": 0.6812,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005195808596909046,
      "rewards/margins": 0.024068117141723633,
      "rewards/rejected": -0.01887230947613716,
      "step": 259
    },
    {
      "epoch": 20.0,
      "grad_norm": 9.57235336303711,
      "learning_rate": 8.132812499999999e-08,
      "logits/chosen": 1.4661858081817627,
      "logits/rejected": 1.4491682052612305,
      "logps/chosen": -36.27888488769531,
      "logps/rejected": -62.67161178588867,
      "loss": 0.683,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.013016700744628906,
      "rewards/margins": 0.020838070660829544,
      "rewards/rejected": -0.007821369916200638,
      "step": 260
    },
    {
      "epoch": 20.0,
      "eval_logits/chosen": 1.3109508752822876,
      "eval_logits/rejected": 1.203978419303894,
      "eval_logps/chosen": -34.3824577331543,
      "eval_logps/rejected": -47.060951232910156,
      "eval_loss": 0.6844019889831543,
      "eval_rewards/accuracies": 0.7799999713897705,
      "eval_rewards/chosen": 0.011706113815307617,
      "eval_rewards/margins": 0.01768258586525917,
      "eval_rewards/rejected": -0.005976472981274128,
      "eval_runtime": 2.7355,
      "eval_samples_per_second": 36.557,
      "eval_steps_per_second": 18.278,
      "step": 260
    },
    {
      "epoch": 20.08,
      "grad_norm": 8.451781272888184,
      "learning_rate": 8.124999999999999e-08,
      "logits/chosen": 1.3739078044891357,
      "logits/rejected": 1.3560783863067627,
      "logps/chosen": -35.35533905029297,
      "logps/rejected": -52.0906867980957,
      "loss": 0.6755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01654357835650444,
      "rewards/margins": 0.03581695258617401,
      "rewards/rejected": -0.01927337795495987,
      "step": 261
    },
    {
      "epoch": 20.16,
      "grad_norm": 7.7334747314453125,
      "learning_rate": 8.1171875e-08,
      "logits/chosen": 1.318117380142212,
      "logits/rejected": 1.2802783250808716,
      "logps/chosen": -31.5904483795166,
      "logps/rejected": -50.8458137512207,
      "loss": 0.6724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015740346163511276,
      "rewards/margins": 0.04195699840784073,
      "rewards/rejected": -0.026216652244329453,
      "step": 262
    },
    {
      "epoch": 20.24,
      "grad_norm": 7.148143291473389,
      "learning_rate": 8.109374999999999e-08,
      "logits/chosen": 1.1911742687225342,
      "logits/rejected": 1.234262228012085,
      "logps/chosen": -35.563720703125,
      "logps/rejected": -56.055152893066406,
      "loss": 0.6764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004220723640173674,
      "rewards/margins": 0.03393011540174484,
      "rewards/rejected": -0.029709387570619583,
      "step": 263
    },
    {
      "epoch": 20.32,
      "grad_norm": 8.472674369812012,
      "learning_rate": 8.101562499999999e-08,
      "logits/chosen": 1.224551796913147,
      "logits/rejected": 1.3951935768127441,
      "logps/chosen": -35.19163513183594,
      "logps/rejected": -61.53861618041992,
      "loss": 0.6764,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011256623081862926,
      "rewards/margins": 0.03389165550470352,
      "rewards/rejected": -0.02263503149151802,
      "step": 264
    },
    {
      "epoch": 20.4,
      "grad_norm": 6.439034938812256,
      "learning_rate": 8.093749999999999e-08,
      "logits/chosen": 1.462147831916809,
      "logits/rejected": 1.2705066204071045,
      "logps/chosen": -36.99546432495117,
      "logps/rejected": -55.25986862182617,
      "loss": 0.6787,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007853317074477673,
      "rewards/margins": 0.029106996953487396,
      "rewards/rejected": -0.021253682672977448,
      "step": 265
    },
    {
      "epoch": 20.48,
      "grad_norm": 8.683249473571777,
      "learning_rate": 8.0859375e-08,
      "logits/chosen": 1.0143245458602905,
      "logits/rejected": 1.01662015914917,
      "logps/chosen": -29.285863876342773,
      "logps/rejected": -56.614707946777344,
      "loss": 0.6795,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010890364646911621,
      "rewards/margins": 0.027765631675720215,
      "rewards/rejected": -0.016875267028808594,
      "step": 266
    },
    {
      "epoch": 20.56,
      "grad_norm": 7.06927490234375,
      "learning_rate": 8.078125e-08,
      "logits/chosen": 1.6114981174468994,
      "logits/rejected": 1.4384015798568726,
      "logps/chosen": -36.4322509765625,
      "logps/rejected": -61.1822395324707,
      "loss": 0.6781,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.017740393057465553,
      "rewards/margins": 0.03047626093029976,
      "rewards/rejected": -0.012735867872834206,
      "step": 267
    },
    {
      "epoch": 20.64,
      "grad_norm": 7.451966762542725,
      "learning_rate": 8.0703125e-08,
      "logits/chosen": 1.3287615776062012,
      "logits/rejected": 1.136481761932373,
      "logps/chosen": -32.91832733154297,
      "logps/rejected": -47.26782989501953,
      "loss": 0.6793,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004166126251220703,
      "rewards/margins": 0.0280301570892334,
      "rewards/rejected": -0.023864030838012695,
      "step": 268
    },
    {
      "epoch": 20.72,
      "grad_norm": 6.92356538772583,
      "learning_rate": 8.0625e-08,
      "logits/chosen": 1.352059245109558,
      "logits/rejected": 1.2581253051757812,
      "logps/chosen": -32.55438232421875,
      "logps/rejected": -50.671485900878906,
      "loss": 0.6781,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010074066929519176,
      "rewards/margins": 0.03061993047595024,
      "rewards/rejected": -0.02054586447775364,
      "step": 269
    },
    {
      "epoch": 20.8,
      "grad_norm": 7.347165584564209,
      "learning_rate": 8.0546875e-08,
      "logits/chosen": 1.1156237125396729,
      "logits/rejected": 1.2604625225067139,
      "logps/chosen": -34.79289245605469,
      "logps/rejected": -54.18212890625,
      "loss": 0.6767,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016799308359622955,
      "rewards/margins": 0.033227112144231796,
      "rewards/rejected": -0.01642780378460884,
      "step": 270
    },
    {
      "epoch": 20.88,
      "grad_norm": 7.672338962554932,
      "learning_rate": 8.046875e-08,
      "logits/chosen": 1.225143313407898,
      "logits/rejected": 1.2347115278244019,
      "logps/chosen": -30.795270919799805,
      "logps/rejected": -52.01202392578125,
      "loss": 0.6723,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012671804055571556,
      "rewards/margins": 0.04228372871875763,
      "rewards/rejected": -0.029611922800540924,
      "step": 271
    },
    {
      "epoch": 20.96,
      "grad_norm": 8.115195274353027,
      "learning_rate": 8.0390625e-08,
      "logits/chosen": 1.2827651500701904,
      "logits/rejected": 1.1330454349517822,
      "logps/chosen": -33.04747772216797,
      "logps/rejected": -58.17637252807617,
      "loss": 0.6767,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012786675244569778,
      "rewards/margins": 0.03323817253112793,
      "rewards/rejected": -0.02045149728655815,
      "step": 272
    },
    {
      "epoch": 21.0,
      "grad_norm": 11.030317306518555,
      "learning_rate": 8.03125e-08,
      "logits/chosen": 1.3605589866638184,
      "logits/rejected": 1.4499092102050781,
      "logps/chosen": -43.377540588378906,
      "logps/rejected": -65.11506652832031,
      "loss": 0.6809,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.006474971771240234,
      "rewards/margins": 0.02459268644452095,
      "rewards/rejected": -0.031067658215761185,
      "step": 273
    },
    {
      "epoch": 21.0,
      "eval_logits/chosen": 1.3077020645141602,
      "eval_logits/rejected": 1.201769232749939,
      "eval_logps/chosen": -34.36953353881836,
      "eval_logps/rejected": -47.10302734375,
      "eval_loss": 0.6816775798797607,
      "eval_rewards/accuracies": 0.8999999761581421,
      "eval_rewards/chosen": 0.01299799419939518,
      "eval_rewards/margins": 0.023182637989521027,
      "eval_rewards/rejected": -0.010184642858803272,
      "eval_runtime": 2.7363,
      "eval_samples_per_second": 36.546,
      "eval_steps_per_second": 18.273,
      "step": 273
    },
    {
      "epoch": 21.08,
      "grad_norm": 8.47016429901123,
      "learning_rate": 8.0234375e-08,
      "logits/chosen": 0.9188203811645508,
      "logits/rejected": 1.0186501741409302,
      "logps/chosen": -30.79645538330078,
      "logps/rejected": -53.463661193847656,
      "loss": 0.665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025015592575073242,
      "rewards/margins": 0.05737161636352539,
      "rewards/rejected": -0.03235602378845215,
      "step": 274
    },
    {
      "epoch": 21.16,
      "grad_norm": 7.35019588470459,
      "learning_rate": 8.015624999999999e-08,
      "logits/chosen": 1.4800348281860352,
      "logits/rejected": 1.240797519683838,
      "logps/chosen": -39.01799011230469,
      "logps/rejected": -51.04469299316406,
      "loss": 0.6726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018692422658205032,
      "rewards/margins": 0.04173152521252632,
      "rewards/rejected": -0.02303910255432129,
      "step": 275
    },
    {
      "epoch": 21.24,
      "grad_norm": 7.520223140716553,
      "learning_rate": 8.0078125e-08,
      "logits/chosen": 1.324083685874939,
      "logits/rejected": 1.3227168321609497,
      "logps/chosen": -32.69922637939453,
      "logps/rejected": -57.24489212036133,
      "loss": 0.6655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02835371531546116,
      "rewards/margins": 0.056219909340143204,
      "rewards/rejected": -0.027866195887327194,
      "step": 276
    },
    {
      "epoch": 21.32,
      "grad_norm": 7.301128387451172,
      "learning_rate": 8e-08,
      "logits/chosen": 1.3634425401687622,
      "logits/rejected": 1.135915756225586,
      "logps/chosen": -35.05528259277344,
      "logps/rejected": -52.605072021484375,
      "loss": 0.6743,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01013572234660387,
      "rewards/margins": 0.03806197643280029,
      "rewards/rejected": -0.027926255017518997,
      "step": 277
    },
    {
      "epoch": 21.4,
      "grad_norm": 8.526556968688965,
      "learning_rate": 7.992187499999999e-08,
      "logits/chosen": 1.1978139877319336,
      "logits/rejected": 1.299214482307434,
      "logps/chosen": -31.28309440612793,
      "logps/rejected": -60.584625244140625,
      "loss": 0.68,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01711719110608101,
      "rewards/margins": 0.02644198015332222,
      "rewards/rejected": -0.009324789047241211,
      "step": 278
    },
    {
      "epoch": 21.48,
      "grad_norm": 7.185222148895264,
      "learning_rate": 7.984375e-08,
      "logits/chosen": 1.3210848569869995,
      "logits/rejected": 1.1385364532470703,
      "logps/chosen": -34.788490295410156,
      "logps/rejected": -56.56258773803711,
      "loss": 0.6792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007360601797699928,
      "rewards/margins": 0.0281571876257658,
      "rewards/rejected": -0.020796585828065872,
      "step": 279
    },
    {
      "epoch": 21.56,
      "grad_norm": 6.88630485534668,
      "learning_rate": 7.976562499999999e-08,
      "logits/chosen": 1.358919382095337,
      "logits/rejected": 1.5828726291656494,
      "logps/chosen": -33.96788024902344,
      "logps/rejected": -51.845741271972656,
      "loss": 0.6722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01583712175488472,
      "rewards/margins": 0.042377591133117676,
      "rewards/rejected": -0.026540469378232956,
      "step": 280
    },
    {
      "epoch": 21.64,
      "grad_norm": 7.051046848297119,
      "learning_rate": 7.968749999999999e-08,
      "logits/chosen": 1.5368825197219849,
      "logits/rejected": 1.448021650314331,
      "logps/chosen": -37.45035934448242,
      "logps/rejected": -54.69603729248047,
      "loss": 0.6773,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0016122099477797747,
      "rewards/margins": 0.03200504928827286,
      "rewards/rejected": -0.033617258071899414,
      "step": 281
    },
    {
      "epoch": 21.72,
      "grad_norm": 8.067105293273926,
      "learning_rate": 7.9609375e-08,
      "logits/chosen": 1.276949167251587,
      "logits/rejected": 1.2149784564971924,
      "logps/chosen": -33.45981979370117,
      "logps/rejected": -51.71112060546875,
      "loss": 0.6772,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01632061041891575,
      "rewards/margins": 0.03253769874572754,
      "rewards/rejected": -0.01621709018945694,
      "step": 282
    },
    {
      "epoch": 21.8,
      "grad_norm": 6.798429012298584,
      "learning_rate": 7.953124999999999e-08,
      "logits/chosen": 1.3517463207244873,
      "logits/rejected": 1.3619499206542969,
      "logps/chosen": -33.02876281738281,
      "logps/rejected": -58.55405807495117,
      "loss": 0.6744,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011065030470490456,
      "rewards/margins": 0.03802216425538063,
      "rewards/rejected": -0.026957131922245026,
      "step": 283
    },
    {
      "epoch": 21.88,
      "grad_norm": 7.264212131500244,
      "learning_rate": 7.9453125e-08,
      "logits/chosen": 1.2747652530670166,
      "logits/rejected": 1.2271391153335571,
      "logps/chosen": -35.11289596557617,
      "logps/rejected": -54.138023376464844,
      "loss": 0.6798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010412430390715599,
      "rewards/margins": 0.026909852400422096,
      "rewards/rejected": -0.016497422009706497,
      "step": 284
    },
    {
      "epoch": 21.96,
      "grad_norm": 8.284327507019043,
      "learning_rate": 7.9375e-08,
      "logits/chosen": 1.1800382137298584,
      "logits/rejected": 1.3513996601104736,
      "logps/chosen": -32.681251525878906,
      "logps/rejected": -59.24608612060547,
      "loss": 0.6668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02154085598886013,
      "rewards/margins": 0.053626276552677155,
      "rewards/rejected": -0.032085418701171875,
      "step": 285
    },
    {
      "epoch": 22.0,
      "grad_norm": 11.162018775939941,
      "learning_rate": 7.9296875e-08,
      "logits/chosen": 1.170287847518921,
      "logits/rejected": 1.0843632221221924,
      "logps/chosen": -32.97076416015625,
      "logps/rejected": -54.08211135864258,
      "loss": 0.6712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006989813409745693,
      "rewards/margins": 0.04451413452625275,
      "rewards/rejected": -0.03752432018518448,
      "step": 286
    },
    {
      "epoch": 22.0,
      "eval_logits/chosen": 1.3097665309906006,
      "eval_logits/rejected": 1.2024623155593872,
      "eval_logps/chosen": -34.363929748535156,
      "eval_logps/rejected": -47.07233428955078,
      "eval_loss": 0.6829289197921753,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.01355854794383049,
      "eval_rewards/margins": 0.020673487335443497,
      "eval_rewards/rejected": -0.007114939857274294,
      "eval_runtime": 2.7485,
      "eval_samples_per_second": 36.384,
      "eval_steps_per_second": 18.192,
      "step": 286
    },
    {
      "epoch": 22.08,
      "grad_norm": 8.148597717285156,
      "learning_rate": 7.921875e-08,
      "logits/chosen": 1.4216594696044922,
      "logits/rejected": 1.2711260318756104,
      "logps/chosen": -32.56791687011719,
      "logps/rejected": -66.29161071777344,
      "loss": 0.6751,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008339596912264824,
      "rewards/margins": 0.03650236129760742,
      "rewards/rejected": -0.028162766247987747,
      "step": 287
    },
    {
      "epoch": 22.16,
      "grad_norm": 7.292220115661621,
      "learning_rate": 7.9140625e-08,
      "logits/chosen": 1.399799108505249,
      "logits/rejected": 1.2900598049163818,
      "logps/chosen": -33.216678619384766,
      "logps/rejected": -60.386287689208984,
      "loss": 0.6771,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012258648872375488,
      "rewards/margins": 0.03233625739812851,
      "rewards/rejected": -0.02007761225104332,
      "step": 288
    },
    {
      "epoch": 22.24,
      "grad_norm": 6.740784645080566,
      "learning_rate": 7.90625e-08,
      "logits/chosen": 1.3541502952575684,
      "logits/rejected": 1.4906578063964844,
      "logps/chosen": -38.00136184692383,
      "logps/rejected": -52.838783264160156,
      "loss": 0.6785,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0024453396908938885,
      "rewards/margins": 0.029774978756904602,
      "rewards/rejected": -0.03222031891345978,
      "step": 289
    },
    {
      "epoch": 22.32,
      "grad_norm": 7.433019161224365,
      "learning_rate": 7.8984375e-08,
      "logits/chosen": 1.2892082929611206,
      "logits/rejected": 1.3169842958450317,
      "logps/chosen": -31.795513153076172,
      "logps/rejected": -58.818092346191406,
      "loss": 0.6659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017727995291352272,
      "rewards/margins": 0.05528445541858673,
      "rewards/rejected": -0.03755645453929901,
      "step": 290
    },
    {
      "epoch": 22.4,
      "grad_norm": 7.117403030395508,
      "learning_rate": 7.890625e-08,
      "logits/chosen": 1.3427358865737915,
      "logits/rejected": 1.4573297500610352,
      "logps/chosen": -31.633255004882812,
      "logps/rejected": -52.22901153564453,
      "loss": 0.6777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011774969287216663,
      "rewards/margins": 0.031313467770814896,
      "rewards/rejected": -0.019538497552275658,
      "step": 291
    },
    {
      "epoch": 22.48,
      "grad_norm": 7.171273231506348,
      "learning_rate": 7.8828125e-08,
      "logits/chosen": 1.3488050699234009,
      "logits/rejected": 1.1781905889511108,
      "logps/chosen": -35.14033126831055,
      "logps/rejected": -50.91143798828125,
      "loss": 0.6777,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00589723652228713,
      "rewards/margins": 0.03138537332415581,
      "rewards/rejected": -0.02548813819885254,
      "step": 292
    },
    {
      "epoch": 22.56,
      "grad_norm": 6.923815727233887,
      "learning_rate": 7.875e-08,
      "logits/chosen": 1.3013113737106323,
      "logits/rejected": 1.1070152521133423,
      "logps/chosen": -32.56785202026367,
      "logps/rejected": -46.780887603759766,
      "loss": 0.6821,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.021485114470124245,
      "rewards/margins": 0.022260451689362526,
      "rewards/rejected": -0.0007753372192382812,
      "step": 293
    },
    {
      "epoch": 22.64,
      "grad_norm": 7.639817714691162,
      "learning_rate": 7.8671875e-08,
      "logits/chosen": 1.3915324211120605,
      "logits/rejected": 1.2670331001281738,
      "logps/chosen": -32.4181022644043,
      "logps/rejected": -46.256473541259766,
      "loss": 0.6756,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012033558450639248,
      "rewards/margins": 0.035482119768857956,
      "rewards/rejected": -0.023448564112186432,
      "step": 294
    },
    {
      "epoch": 22.72,
      "grad_norm": 9.129403114318848,
      "learning_rate": 7.859374999999999e-08,
      "logits/chosen": 0.9948270916938782,
      "logits/rejected": 1.1558343172073364,
      "logps/chosen": -30.783090591430664,
      "logps/rejected": -57.07636260986328,
      "loss": 0.6655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023564839735627174,
      "rewards/margins": 0.05622541904449463,
      "rewards/rejected": -0.032660581171512604,
      "step": 295
    },
    {
      "epoch": 22.8,
      "grad_norm": 8.134455680847168,
      "learning_rate": 7.8515625e-08,
      "logits/chosen": 1.464681625366211,
      "logits/rejected": 1.1624406576156616,
      "logps/chosen": -42.603660583496094,
      "logps/rejected": -61.5108757019043,
      "loss": 0.6675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019879817962646484,
      "rewards/margins": 0.05210580676794052,
      "rewards/rejected": -0.032225992530584335,
      "step": 296
    },
    {
      "epoch": 22.88,
      "grad_norm": 7.339440822601318,
      "learning_rate": 7.84375e-08,
      "logits/chosen": 1.1129260063171387,
      "logits/rejected": 1.2708487510681152,
      "logps/chosen": -35.09639358520508,
      "logps/rejected": -57.33617401123047,
      "loss": 0.6726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013326669111847878,
      "rewards/margins": 0.04163840040564537,
      "rewards/rejected": -0.028311729431152344,
      "step": 297
    },
    {
      "epoch": 22.96,
      "grad_norm": 8.233671188354492,
      "learning_rate": 7.835937499999999e-08,
      "logits/chosen": 1.1240237951278687,
      "logits/rejected": 1.0835750102996826,
      "logps/chosen": -31.31362533569336,
      "logps/rejected": -50.832496643066406,
      "loss": 0.6704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016141295433044434,
      "rewards/margins": 0.046782467514276505,
      "rewards/rejected": -0.03064117580652237,
      "step": 298
    },
    {
      "epoch": 23.0,
      "grad_norm": 12.40018081665039,
      "learning_rate": 7.828125e-08,
      "logits/chosen": 1.324317216873169,
      "logits/rejected": 1.330033302307129,
      "logps/chosen": -37.79690170288086,
      "logps/rejected": -55.231590270996094,
      "loss": 0.6756,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0014976501697674394,
      "rewards/margins": 0.035610005259513855,
      "rewards/rejected": -0.03710765764117241,
      "step": 299
    },
    {
      "epoch": 23.0,
      "eval_logits/chosen": 1.3065690994262695,
      "eval_logits/rejected": 1.2009711265563965,
      "eval_logps/chosen": -34.414329528808594,
      "eval_logps/rejected": -47.119834899902344,
      "eval_loss": 0.6830708384513855,
      "eval_rewards/accuracies": 0.800000011920929,
      "eval_rewards/chosen": 0.008518815971910954,
      "eval_rewards/margins": 0.02038397081196308,
      "eval_rewards/rejected": -0.011865154840052128,
      "eval_runtime": 2.7424,
      "eval_samples_per_second": 36.465,
      "eval_steps_per_second": 18.233,
      "step": 299
    },
    {
      "epoch": 23.08,
      "grad_norm": 6.967366695404053,
      "learning_rate": 7.820312499999999e-08,
      "logits/chosen": 1.424708366394043,
      "logits/rejected": 1.3047066926956177,
      "logps/chosen": -35.15037536621094,
      "logps/rejected": -60.139404296875,
      "loss": 0.6769,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01158811990171671,
      "rewards/margins": 0.032827164977788925,
      "rewards/rejected": -0.02123904414474964,
      "step": 300
    },
    {
      "epoch": 23.16,
      "grad_norm": 7.835017204284668,
      "learning_rate": 7.812499999999999e-08,
      "logits/chosen": 1.537284016609192,
      "logits/rejected": 1.2837059497833252,
      "logps/chosen": -31.481197357177734,
      "logps/rejected": -55.93023681640625,
      "loss": 0.6778,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02297511324286461,
      "rewards/margins": 0.03108053281903267,
      "rewards/rejected": -0.00810542143881321,
      "step": 301
    },
    {
      "epoch": 23.24,
      "grad_norm": 7.9571852684021,
      "learning_rate": 7.804687500000001e-08,
      "logits/chosen": 1.0261051654815674,
      "logits/rejected": 1.3370373249053955,
      "logps/chosen": -28.043174743652344,
      "logps/rejected": -53.11798858642578,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012151956558227539,
      "rewards/margins": 0.03390679508447647,
      "rewards/rejected": -0.021754836663603783,
      "step": 302
    },
    {
      "epoch": 23.32,
      "grad_norm": 8.106115341186523,
      "learning_rate": 7.796875e-08,
      "logits/chosen": 1.442935585975647,
      "logits/rejected": 1.0502326488494873,
      "logps/chosen": -34.75621032714844,
      "logps/rejected": -53.872154235839844,
      "loss": 0.6671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015773631632328033,
      "rewards/margins": 0.052889205515384674,
      "rewards/rejected": -0.03711557388305664,
      "step": 303
    },
    {
      "epoch": 23.4,
      "grad_norm": 7.126482963562012,
      "learning_rate": 7.7890625e-08,
      "logits/chosen": 1.4303863048553467,
      "logits/rejected": 1.2409298419952393,
      "logps/chosen": -33.886009216308594,
      "logps/rejected": -47.41521453857422,
      "loss": 0.6754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008675075136125088,
      "rewards/margins": 0.03594005107879639,
      "rewards/rejected": -0.027264976873993874,
      "step": 304
    },
    {
      "epoch": 23.48,
      "grad_norm": 8.244352340698242,
      "learning_rate": 7.78125e-08,
      "logits/chosen": 1.2718383073806763,
      "logits/rejected": 1.3858803510665894,
      "logps/chosen": -33.48275375366211,
      "logps/rejected": -55.430877685546875,
      "loss": 0.6696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01744067668914795,
      "rewards/margins": 0.04762975871562958,
      "rewards/rejected": -0.030189085751771927,
      "step": 305
    },
    {
      "epoch": 23.56,
      "grad_norm": 8.055062294006348,
      "learning_rate": 7.7734375e-08,
      "logits/chosen": 1.2544424533843994,
      "logits/rejected": 1.2626242637634277,
      "logps/chosen": -35.63395309448242,
      "logps/rejected": -50.17359924316406,
      "loss": 0.6818,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.00039184093475341797,
      "rewards/margins": 0.02301933988928795,
      "rewards/rejected": -0.023411180824041367,
      "step": 306
    },
    {
      "epoch": 23.64,
      "grad_norm": 7.457353115081787,
      "learning_rate": 7.765625e-08,
      "logits/chosen": 1.2996338605880737,
      "logits/rejected": 1.336745023727417,
      "logps/chosen": -37.91614532470703,
      "logps/rejected": -56.939422607421875,
      "loss": 0.6753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013636350631713867,
      "rewards/margins": 0.035964012145996094,
      "rewards/rejected": -0.022327661514282227,
      "step": 307
    },
    {
      "epoch": 23.72,
      "grad_norm": 7.947406768798828,
      "learning_rate": 7.7578125e-08,
      "logits/chosen": 1.4028502702713013,
      "logits/rejected": 1.293464183807373,
      "logps/chosen": -32.22108840942383,
      "logps/rejected": -49.636844635009766,
      "loss": 0.6689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020406676456332207,
      "rewards/margins": 0.04935412481427193,
      "rewards/rejected": -0.02894744835793972,
      "step": 308
    },
    {
      "epoch": 23.8,
      "grad_norm": 7.005395889282227,
      "learning_rate": 7.75e-08,
      "logits/chosen": 1.0111526250839233,
      "logits/rejected": 1.01529860496521,
      "logps/chosen": -34.54259490966797,
      "logps/rejected": -51.364112854003906,
      "loss": 0.6775,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012579846195876598,
      "rewards/margins": 0.031729720532894135,
      "rewards/rejected": -0.01914987713098526,
      "step": 309
    },
    {
      "epoch": 23.88,
      "grad_norm": 6.8152055740356445,
      "learning_rate": 7.742187499999999e-08,
      "logits/chosen": 1.2551730871200562,
      "logits/rejected": 1.4104650020599365,
      "logps/chosen": -35.998878479003906,
      "logps/rejected": -56.690216064453125,
      "loss": 0.6787,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009501338005065918,
      "rewards/margins": 0.02937161922454834,
      "rewards/rejected": -0.01987028308212757,
      "step": 310
    },
    {
      "epoch": 23.96,
      "grad_norm": 9.116558074951172,
      "learning_rate": 7.734375e-08,
      "logits/chosen": 1.135192632675171,
      "logits/rejected": 1.1416741609573364,
      "logps/chosen": -33.674041748046875,
      "logps/rejected": -62.167179107666016,
      "loss": 0.6738,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008664751425385475,
      "rewards/margins": 0.039676811546087265,
      "rewards/rejected": -0.03101205825805664,
      "step": 311
    },
    {
      "epoch": 24.0,
      "grad_norm": 11.401654243469238,
      "learning_rate": 7.7265625e-08,
      "logits/chosen": 1.3583554029464722,
      "logits/rejected": 1.3080813884735107,
      "logps/chosen": -38.459144592285156,
      "logps/rejected": -71.73558044433594,
      "loss": 0.669,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.013918543234467506,
      "rewards/margins": 0.049214888364076614,
      "rewards/rejected": -0.03529634699225426,
      "step": 312
    },
    {
      "epoch": 24.0,
      "eval_logits/chosen": 1.3087338209152222,
      "eval_logits/rejected": 1.2014487981796265,
      "eval_logps/chosen": -34.362674713134766,
      "eval_logps/rejected": -47.05860900878906,
      "eval_loss": 0.6835561990737915,
      "eval_rewards/accuracies": 0.800000011920929,
      "eval_rewards/chosen": 0.013684401288628578,
      "eval_rewards/margins": 0.019426563754677773,
      "eval_rewards/rejected": -0.005742161069065332,
      "eval_runtime": 2.7417,
      "eval_samples_per_second": 36.474,
      "eval_steps_per_second": 18.237,
      "step": 312
    },
    {
      "epoch": 24.08,
      "grad_norm": 8.664237976074219,
      "learning_rate": 7.718749999999999e-08,
      "logits/chosen": 1.182861089706421,
      "logits/rejected": 0.9723268747329712,
      "logps/chosen": -33.07990264892578,
      "logps/rejected": -55.10125732421875,
      "loss": 0.6608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02604539506137371,
      "rewards/margins": 0.06604793667793274,
      "rewards/rejected": -0.04000253975391388,
      "step": 313
    },
    {
      "epoch": 24.16,
      "grad_norm": 8.774872779846191,
      "learning_rate": 7.7109375e-08,
      "logits/chosen": 1.2811598777770996,
      "logits/rejected": 1.33926522731781,
      "logps/chosen": -30.112751007080078,
      "logps/rejected": -58.314247131347656,
      "loss": 0.6676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027479220181703568,
      "rewards/margins": 0.051764726638793945,
      "rewards/rejected": -0.024285506457090378,
      "step": 314
    },
    {
      "epoch": 24.24,
      "grad_norm": 6.798287391662598,
      "learning_rate": 7.703124999999999e-08,
      "logits/chosen": 1.3279989957809448,
      "logits/rejected": 1.3263568878173828,
      "logps/chosen": -32.87242889404297,
      "logps/rejected": -54.86388397216797,
      "loss": 0.6691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01588132418692112,
      "rewards/margins": 0.04884045198559761,
      "rewards/rejected": -0.03295912593603134,
      "step": 315
    },
    {
      "epoch": 24.32,
      "grad_norm": 6.91154670715332,
      "learning_rate": 7.695312499999999e-08,
      "logits/chosen": 1.4560977220535278,
      "logits/rejected": 1.209725022315979,
      "logps/chosen": -31.423248291015625,
      "logps/rejected": -52.74630355834961,
      "loss": 0.6698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013145159929990768,
      "rewards/margins": 0.04745025560259819,
      "rewards/rejected": -0.03430509939789772,
      "step": 316
    },
    {
      "epoch": 24.4,
      "grad_norm": 8.003209114074707,
      "learning_rate": 7.6875e-08,
      "logits/chosen": 1.1726233959197998,
      "logits/rejected": 1.2719768285751343,
      "logps/chosen": -35.495670318603516,
      "logps/rejected": -54.69404602050781,
      "loss": 0.6751,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019027305766940117,
      "rewards/margins": 0.03655693680047989,
      "rewards/rejected": -0.017529629170894623,
      "step": 317
    },
    {
      "epoch": 24.48,
      "grad_norm": 8.065120697021484,
      "learning_rate": 7.679687499999999e-08,
      "logits/chosen": 1.4819223880767822,
      "logits/rejected": 1.2135642766952515,
      "logps/chosen": -41.48918151855469,
      "logps/rejected": -55.0948371887207,
      "loss": 0.6764,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003973603248596191,
      "rewards/margins": 0.034079864621162415,
      "rewards/rejected": -0.030106259509921074,
      "step": 318
    },
    {
      "epoch": 24.56,
      "grad_norm": 6.835409164428711,
      "learning_rate": 7.671875e-08,
      "logits/chosen": 1.3065769672393799,
      "logits/rejected": 1.2677850723266602,
      "logps/chosen": -33.69170379638672,
      "logps/rejected": -53.5816650390625,
      "loss": 0.6703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021503066644072533,
      "rewards/margins": 0.04634683206677437,
      "rewards/rejected": -0.024843763560056686,
      "step": 319
    },
    {
      "epoch": 24.64,
      "grad_norm": 8.196078300476074,
      "learning_rate": 7.6640625e-08,
      "logits/chosen": 1.244724988937378,
      "logits/rejected": 1.2030872106552124,
      "logps/chosen": -29.810314178466797,
      "logps/rejected": -60.98084259033203,
      "loss": 0.6764,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007332181558012962,
      "rewards/margins": 0.033947087824344635,
      "rewards/rejected": -0.026614904403686523,
      "step": 320
    },
    {
      "epoch": 24.72,
      "grad_norm": 8.038503646850586,
      "learning_rate": 7.65625e-08,
      "logits/chosen": 1.022533655166626,
      "logits/rejected": 1.283149242401123,
      "logps/chosen": -28.445880889892578,
      "logps/rejected": -59.111732482910156,
      "loss": 0.6649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02562718465924263,
      "rewards/margins": 0.05745859071612358,
      "rewards/rejected": -0.03183140605688095,
      "step": 321
    },
    {
      "epoch": 24.8,
      "grad_norm": 7.129213809967041,
      "learning_rate": 7.6484375e-08,
      "logits/chosen": 1.486791729927063,
      "logits/rejected": 1.269194483757019,
      "logps/chosen": -39.300052642822266,
      "logps/rejected": -49.16094207763672,
      "loss": 0.6713,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006729030515998602,
      "rewards/margins": 0.04445777088403702,
      "rewards/rejected": -0.03772874176502228,
      "step": 322
    },
    {
      "epoch": 24.88,
      "grad_norm": 6.397057056427002,
      "learning_rate": 7.640625e-08,
      "logits/chosen": 1.3324998617172241,
      "logits/rejected": 1.4069485664367676,
      "logps/chosen": -33.40650177001953,
      "logps/rejected": -54.53624725341797,
      "loss": 0.6808,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.017279982566833496,
      "rewards/margins": 0.025040553882718086,
      "rewards/rejected": -0.007760573178529739,
      "step": 323
    },
    {
      "epoch": 24.96,
      "grad_norm": 6.970788955688477,
      "learning_rate": 7.6328125e-08,
      "logits/chosen": 1.3941316604614258,
      "logits/rejected": 1.312990665435791,
      "logps/chosen": -40.11634826660156,
      "logps/rejected": -51.7279167175293,
      "loss": 0.6794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004161262419074774,
      "rewards/margins": 0.027827929705381393,
      "rewards/rejected": -0.02366666868329048,
      "step": 324
    },
    {
      "epoch": 25.0,
      "grad_norm": 11.841768264770508,
      "learning_rate": 7.625e-08,
      "logits/chosen": 1.1334009170532227,
      "logits/rejected": 1.405841588973999,
      "logps/chosen": -32.95320510864258,
      "logps/rejected": -58.55793762207031,
      "loss": 0.6709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007508611306548119,
      "rewards/margins": 0.04512534290552139,
      "rewards/rejected": -0.037616729736328125,
      "step": 325
    },
    {
      "epoch": 25.0,
      "eval_logits/chosen": 1.3104071617126465,
      "eval_logits/rejected": 1.203970193862915,
      "eval_logps/chosen": -34.353885650634766,
      "eval_logps/rejected": -47.093475341796875,
      "eval_loss": 0.6813883781433105,
      "eval_rewards/accuracies": 0.8700000047683716,
      "eval_rewards/chosen": 0.014562809839844704,
      "eval_rewards/margins": 0.023791566491127014,
      "eval_rewards/rejected": -0.00922875851392746,
      "eval_runtime": 2.7378,
      "eval_samples_per_second": 36.526,
      "eval_steps_per_second": 18.263,
      "step": 325
    },
    {
      "epoch": 25.08,
      "grad_norm": 6.497636318206787,
      "learning_rate": 7.6171875e-08,
      "logits/chosen": 1.1976025104522705,
      "logits/rejected": 1.3456621170043945,
      "logps/chosen": -35.967159271240234,
      "logps/rejected": -54.709251403808594,
      "loss": 0.6793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007601690478622913,
      "rewards/margins": 0.028025580570101738,
      "rewards/rejected": -0.02042388916015625,
      "step": 326
    },
    {
      "epoch": 25.16,
      "grad_norm": 7.545188903808594,
      "learning_rate": 7.609375e-08,
      "logits/chosen": 1.3387839794158936,
      "logits/rejected": 1.2477924823760986,
      "logps/chosen": -34.87313461303711,
      "logps/rejected": -60.838645935058594,
      "loss": 0.6778,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013045573607087135,
      "rewards/margins": 0.031018422916531563,
      "rewards/rejected": -0.017972851172089577,
      "step": 327
    },
    {
      "epoch": 25.24,
      "grad_norm": 7.156572341918945,
      "learning_rate": 7.6015625e-08,
      "logits/chosen": 1.3353022336959839,
      "logits/rejected": 1.2970529794692993,
      "logps/chosen": -33.785430908203125,
      "logps/rejected": -64.10623931884766,
      "loss": 0.6731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022666478529572487,
      "rewards/margins": 0.040483877062797546,
      "rewards/rejected": -0.017817404121160507,
      "step": 328
    },
    {
      "epoch": 25.32,
      "grad_norm": 7.378665447235107,
      "learning_rate": 7.59375e-08,
      "logits/chosen": 1.1160929203033447,
      "logits/rejected": 0.958191454410553,
      "logps/chosen": -30.55287742614746,
      "logps/rejected": -55.778846740722656,
      "loss": 0.6777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01121459063142538,
      "rewards/margins": 0.031268976628780365,
      "rewards/rejected": -0.02005438692867756,
      "step": 329
    },
    {
      "epoch": 25.4,
      "grad_norm": 7.468541145324707,
      "learning_rate": 7.585937499999999e-08,
      "logits/chosen": 1.4217175245285034,
      "logits/rejected": 1.3396331071853638,
      "logps/chosen": -34.45042419433594,
      "logps/rejected": -50.107444763183594,
      "loss": 0.6626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03307681158185005,
      "rewards/margins": 0.062203146517276764,
      "rewards/rejected": -0.029126334935426712,
      "step": 330
    },
    {
      "epoch": 25.48,
      "grad_norm": 7.593552589416504,
      "learning_rate": 7.578125e-08,
      "logits/chosen": 1.386116623878479,
      "logits/rejected": 1.0550689697265625,
      "logps/chosen": -37.80033493041992,
      "logps/rejected": -54.647918701171875,
      "loss": 0.6737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.001329517224803567,
      "rewards/margins": 0.039461564272642136,
      "rewards/rejected": -0.03813204914331436,
      "step": 331
    },
    {
      "epoch": 25.56,
      "grad_norm": 6.892310619354248,
      "learning_rate": 7.5703125e-08,
      "logits/chosen": 1.301027536392212,
      "logits/rejected": 1.3486065864562988,
      "logps/chosen": -34.71262741088867,
      "logps/rejected": -58.524200439453125,
      "loss": 0.6751,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006795192137360573,
      "rewards/margins": 0.036601901054382324,
      "rewards/rejected": -0.02980670891702175,
      "step": 332
    },
    {
      "epoch": 25.64,
      "grad_norm": 7.0085368156433105,
      "learning_rate": 7.562499999999999e-08,
      "logits/chosen": 1.2693606615066528,
      "logits/rejected": 1.3011221885681152,
      "logps/chosen": -33.472007751464844,
      "logps/rejected": -47.94346237182617,
      "loss": 0.671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02587873861193657,
      "rewards/margins": 0.044936586171388626,
      "rewards/rejected": -0.019057845696806908,
      "step": 333
    },
    {
      "epoch": 25.72,
      "grad_norm": 6.64458703994751,
      "learning_rate": 7.5546875e-08,
      "logits/chosen": 1.3494250774383545,
      "logits/rejected": 1.2936984300613403,
      "logps/chosen": -31.3470458984375,
      "logps/rejected": -52.87162780761719,
      "loss": 0.6727,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02048955112695694,
      "rewards/margins": 0.041544102132320404,
      "rewards/rejected": -0.021054554730653763,
      "step": 334
    },
    {
      "epoch": 25.8,
      "grad_norm": 9.535665512084961,
      "learning_rate": 7.546874999999999e-08,
      "logits/chosen": 1.130975604057312,
      "logits/rejected": 1.0520015954971313,
      "logps/chosen": -32.22136306762695,
      "logps/rejected": -53.1322021484375,
      "loss": 0.6667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010768222622573376,
      "rewards/margins": 0.05374889075756073,
      "rewards/rejected": -0.04298067092895508,
      "step": 335
    },
    {
      "epoch": 25.88,
      "grad_norm": 9.609747886657715,
      "learning_rate": 7.539062499999999e-08,
      "logits/chosen": 1.2449383735656738,
      "logits/rejected": 1.3207266330718994,
      "logps/chosen": -31.710941314697266,
      "logps/rejected": -59.63203430175781,
      "loss": 0.6594,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026773668825626373,
      "rewards/margins": 0.06942126154899597,
      "rewards/rejected": -0.042647600173950195,
      "step": 336
    },
    {
      "epoch": 25.96,
      "grad_norm": 7.420476913452148,
      "learning_rate": 7.531250000000001e-08,
      "logits/chosen": 1.447831153869629,
      "logits/rejected": 1.392183542251587,
      "logps/chosen": -38.16929244995117,
      "logps/rejected": -53.708343505859375,
      "loss": 0.6671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01446621399372816,
      "rewards/margins": 0.052838824689388275,
      "rewards/rejected": -0.03837261348962784,
      "step": 337
    },
    {
      "epoch": 26.0,
      "grad_norm": 8.943191528320312,
      "learning_rate": 7.5234375e-08,
      "logits/chosen": 1.5431896448135376,
      "logits/rejected": 1.6660525798797607,
      "logps/chosen": -33.26127243041992,
      "logps/rejected": -46.43732452392578,
      "loss": 0.6752,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010507297702133656,
      "rewards/margins": 0.036550525575876236,
      "rewards/rejected": -0.026043225079774857,
      "step": 338
    },
    {
      "epoch": 26.0,
      "eval_logits/chosen": 1.313144564628601,
      "eval_logits/rejected": 1.205348014831543,
      "eval_logps/chosen": -34.330352783203125,
      "eval_logps/rejected": -47.083160400390625,
      "eval_loss": 0.6807330846786499,
      "eval_rewards/accuracies": 0.8299999833106995,
      "eval_rewards/chosen": 0.01691659353673458,
      "eval_rewards/margins": 0.025114107877016068,
      "eval_rewards/rejected": -0.008197513408958912,
      "eval_runtime": 2.7378,
      "eval_samples_per_second": 36.525,
      "eval_steps_per_second": 18.263,
      "step": 338
    },
    {
      "epoch": 26.08,
      "grad_norm": 7.508876323699951,
      "learning_rate": 7.515625e-08,
      "logits/chosen": 1.240071415901184,
      "logits/rejected": 1.121392011642456,
      "logps/chosen": -31.110748291015625,
      "logps/rejected": -48.43217086791992,
      "loss": 0.6733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019191550090909004,
      "rewards/margins": 0.04013343155384064,
      "rewards/rejected": -0.020941877737641335,
      "step": 339
    },
    {
      "epoch": 26.16,
      "grad_norm": 8.287761688232422,
      "learning_rate": 7.5078125e-08,
      "logits/chosen": 1.4012812376022339,
      "logits/rejected": 1.22862708568573,
      "logps/chosen": -37.27268981933594,
      "logps/rejected": -54.94477844238281,
      "loss": 0.6699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0129631282761693,
      "rewards/margins": 0.04719097912311554,
      "rewards/rejected": -0.034227851778268814,
      "step": 340
    },
    {
      "epoch": 26.24,
      "grad_norm": 9.112067222595215,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.3413282632827759,
      "logits/rejected": 1.1410690546035767,
      "logps/chosen": -36.35684585571289,
      "logps/rejected": -65.58137512207031,
      "loss": 0.6676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014616535976529121,
      "rewards/margins": 0.05188317596912384,
      "rewards/rejected": -0.03726663812994957,
      "step": 341
    },
    {
      "epoch": 26.32,
      "grad_norm": 8.228462219238281,
      "learning_rate": 7.4921875e-08,
      "logits/chosen": 1.2063121795654297,
      "logits/rejected": 1.3874579668045044,
      "logps/chosen": -30.217790603637695,
      "logps/rejected": -54.412261962890625,
      "loss": 0.6643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030029725283384323,
      "rewards/margins": 0.0586271733045578,
      "rewards/rejected": -0.028597451746463776,
      "step": 342
    },
    {
      "epoch": 26.4,
      "grad_norm": 7.824013710021973,
      "learning_rate": 7.484375e-08,
      "logits/chosen": 1.3354504108428955,
      "logits/rejected": 1.2293497323989868,
      "logps/chosen": -32.25423812866211,
      "logps/rejected": -50.06168746948242,
      "loss": 0.6566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019525719806551933,
      "rewards/margins": 0.07493916153907776,
      "rewards/rejected": -0.055413439869880676,
      "step": 343
    },
    {
      "epoch": 26.48,
      "grad_norm": 6.477793216705322,
      "learning_rate": 7.4765625e-08,
      "logits/chosen": 1.300100326538086,
      "logits/rejected": 1.1811919212341309,
      "logps/chosen": -33.757080078125,
      "logps/rejected": -47.04827880859375,
      "loss": 0.6749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017812490463256836,
      "rewards/margins": 0.03710537031292915,
      "rewards/rejected": -0.01929287798702717,
      "step": 344
    },
    {
      "epoch": 26.56,
      "grad_norm": 7.886685848236084,
      "learning_rate": 7.468749999999999e-08,
      "logits/chosen": 1.2585408687591553,
      "logits/rejected": 1.095663070678711,
      "logps/chosen": -32.94753646850586,
      "logps/rejected": -51.288787841796875,
      "loss": 0.6643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014579200185835361,
      "rewards/margins": 0.05881467089056969,
      "rewards/rejected": -0.0442354679107666,
      "step": 345
    },
    {
      "epoch": 26.64,
      "grad_norm": 7.073910713195801,
      "learning_rate": 7.4609375e-08,
      "logits/chosen": 1.290839433670044,
      "logits/rejected": 1.3371376991271973,
      "logps/chosen": -34.69056701660156,
      "logps/rejected": -56.23257827758789,
      "loss": 0.6673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02870316430926323,
      "rewards/margins": 0.052559711039066315,
      "rewards/rejected": -0.023856544867157936,
      "step": 346
    },
    {
      "epoch": 26.72,
      "grad_norm": 7.553911209106445,
      "learning_rate": 7.453125e-08,
      "logits/chosen": 1.3282465934753418,
      "logits/rejected": 1.4234907627105713,
      "logps/chosen": -36.116119384765625,
      "logps/rejected": -61.320884704589844,
      "loss": 0.6671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01571338064968586,
      "rewards/margins": 0.052917931228876114,
      "rewards/rejected": -0.0372045524418354,
      "step": 347
    },
    {
      "epoch": 26.8,
      "grad_norm": 6.864935874938965,
      "learning_rate": 7.445312499999999e-08,
      "logits/chosen": 1.2757463455200195,
      "logits/rejected": 1.2283979654312134,
      "logps/chosen": -35.566307067871094,
      "logps/rejected": -51.94107437133789,
      "loss": 0.6793,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.005396032240241766,
      "rewards/margins": 0.028075028210878372,
      "rewards/rejected": -0.02267899550497532,
      "step": 348
    },
    {
      "epoch": 26.88,
      "grad_norm": 7.469357967376709,
      "learning_rate": 7.4375e-08,
      "logits/chosen": 1.119362711906433,
      "logits/rejected": 1.3694097995758057,
      "logps/chosen": -30.385061264038086,
      "logps/rejected": -61.46422576904297,
      "loss": 0.6651,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019205976277589798,
      "rewards/margins": 0.0570484884083271,
      "rewards/rejected": -0.037842512130737305,
      "step": 349
    },
    {
      "epoch": 26.96,
      "grad_norm": 6.747773170471191,
      "learning_rate": 7.429687499999999e-08,
      "logits/chosen": 1.4450445175170898,
      "logits/rejected": 1.3901140689849854,
      "logps/chosen": -39.216583251953125,
      "logps/rejected": -59.640541076660156,
      "loss": 0.6773,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007286691572517157,
      "rewards/margins": 0.03213391453027725,
      "rewards/rejected": -0.02484722062945366,
      "step": 350
    },
    {
      "epoch": 27.0,
      "grad_norm": 9.568221092224121,
      "learning_rate": 7.421874999999999e-08,
      "logits/chosen": 1.4448182582855225,
      "logits/rejected": 1.3890433311462402,
      "logps/chosen": -31.464061737060547,
      "logps/rejected": -54.723838806152344,
      "loss": 0.6666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016812611371278763,
      "rewards/margins": 0.054143525660037994,
      "rewards/rejected": -0.03733091428875923,
      "step": 351
    },
    {
      "epoch": 27.0,
      "eval_logits/chosen": 1.3152233362197876,
      "eval_logits/rejected": 1.2054429054260254,
      "eval_logps/chosen": -34.369117736816406,
      "eval_logps/rejected": -47.085853576660156,
      "eval_loss": 0.6825127601623535,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.013040000572800636,
      "eval_rewards/margins": 0.021506553515791893,
      "eval_rewards/rejected": -0.008466552942991257,
      "eval_runtime": 2.7315,
      "eval_samples_per_second": 36.61,
      "eval_steps_per_second": 18.305,
      "step": 351
    },
    {
      "epoch": 27.08,
      "grad_norm": 7.884965896606445,
      "learning_rate": 7.4140625e-08,
      "logits/chosen": 1.3699836730957031,
      "logits/rejected": 1.2887067794799805,
      "logps/chosen": -30.663328170776367,
      "logps/rejected": -52.53234100341797,
      "loss": 0.6722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013403463177382946,
      "rewards/margins": 0.042443469166755676,
      "rewards/rejected": -0.029040005058050156,
      "step": 352
    },
    {
      "epoch": 27.16,
      "grad_norm": 7.377623558044434,
      "learning_rate": 7.406249999999999e-08,
      "logits/chosen": 1.2596478462219238,
      "logits/rejected": 1.3334718942642212,
      "logps/chosen": -29.632829666137695,
      "logps/rejected": -52.20854187011719,
      "loss": 0.6609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029531478881835938,
      "rewards/margins": 0.06583571434020996,
      "rewards/rejected": -0.03630423545837402,
      "step": 353
    },
    {
      "epoch": 27.24,
      "grad_norm": 7.373026371002197,
      "learning_rate": 7.398437499999999e-08,
      "logits/chosen": 1.3206695318222046,
      "logits/rejected": 1.2583253383636475,
      "logps/chosen": -31.573225021362305,
      "logps/rejected": -55.022911071777344,
      "loss": 0.6636,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025154948234558105,
      "rewards/margins": 0.06019475683569908,
      "rewards/rejected": -0.035039808601140976,
      "step": 354
    },
    {
      "epoch": 27.32,
      "grad_norm": 6.689345836639404,
      "learning_rate": 7.390625e-08,
      "logits/chosen": 1.224668264389038,
      "logits/rejected": 1.1836764812469482,
      "logps/chosen": -33.3587646484375,
      "logps/rejected": -54.36233139038086,
      "loss": 0.6722,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007716012187302113,
      "rewards/margins": 0.04274771362543106,
      "rewards/rejected": -0.03503170236945152,
      "step": 355
    },
    {
      "epoch": 27.4,
      "grad_norm": 7.594867706298828,
      "learning_rate": 7.3828125e-08,
      "logits/chosen": 1.288964867591858,
      "logits/rejected": 1.195258378982544,
      "logps/chosen": -39.236568450927734,
      "logps/rejected": -59.91425704956055,
      "loss": 0.6701,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01112136896699667,
      "rewards/margins": 0.04690132290124893,
      "rewards/rejected": -0.03577995300292969,
      "step": 356
    },
    {
      "epoch": 27.48,
      "grad_norm": 6.076754570007324,
      "learning_rate": 7.375e-08,
      "logits/chosen": 1.423012137413025,
      "logits/rejected": 1.417367696762085,
      "logps/chosen": -35.2578125,
      "logps/rejected": -54.265594482421875,
      "loss": 0.6711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034746505320072174,
      "rewards/margins": 0.044741153717041016,
      "rewards/rejected": -0.00999465025961399,
      "step": 357
    },
    {
      "epoch": 27.56,
      "grad_norm": 7.465908050537109,
      "learning_rate": 7.3671875e-08,
      "logits/chosen": 1.4425889253616333,
      "logits/rejected": 1.3220696449279785,
      "logps/chosen": -39.80403137207031,
      "logps/rejected": -58.39750289916992,
      "loss": 0.677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005616283509880304,
      "rewards/margins": 0.0326387882232666,
      "rewards/rejected": -0.027022503316402435,
      "step": 358
    },
    {
      "epoch": 27.64,
      "grad_norm": 8.131816864013672,
      "learning_rate": 7.359375e-08,
      "logits/chosen": 1.408414602279663,
      "logits/rejected": 1.3450062274932861,
      "logps/chosen": -36.09190368652344,
      "logps/rejected": -55.83344268798828,
      "loss": 0.6684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017612051218748093,
      "rewards/margins": 0.050282072275877,
      "rewards/rejected": -0.032670021057128906,
      "step": 359
    },
    {
      "epoch": 27.72,
      "grad_norm": 8.924802780151367,
      "learning_rate": 7.3515625e-08,
      "logits/chosen": 1.3157179355621338,
      "logits/rejected": 1.243472695350647,
      "logps/chosen": -34.59949493408203,
      "logps/rejected": -50.525238037109375,
      "loss": 0.6595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02607235684990883,
      "rewards/margins": 0.06887922435998917,
      "rewards/rejected": -0.04280686378479004,
      "step": 360
    },
    {
      "epoch": 27.8,
      "grad_norm": 7.6897873878479,
      "learning_rate": 7.34375e-08,
      "logits/chosen": 1.104457139968872,
      "logits/rejected": 1.1669223308563232,
      "logps/chosen": -32.402435302734375,
      "logps/rejected": -61.48757553100586,
      "loss": 0.6703,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008238124661147594,
      "rewards/margins": 0.046428535133600235,
      "rewards/rejected": -0.038190413266420364,
      "step": 361
    },
    {
      "epoch": 27.88,
      "grad_norm": 7.626198768615723,
      "learning_rate": 7.3359375e-08,
      "logits/chosen": 1.370113492012024,
      "logits/rejected": 1.2492889165878296,
      "logps/chosen": -36.56206512451172,
      "logps/rejected": -56.7542610168457,
      "loss": 0.6684,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015950871631503105,
      "rewards/margins": 0.050265122205019,
      "rewards/rejected": -0.03431425243616104,
      "step": 362
    },
    {
      "epoch": 27.96,
      "grad_norm": 6.853341102600098,
      "learning_rate": 7.328125e-08,
      "logits/chosen": 1.193223476409912,
      "logits/rejected": 1.3913853168487549,
      "logps/chosen": -28.648122787475586,
      "logps/rejected": -54.69548797607422,
      "loss": 0.6612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034987833350896835,
      "rewards/margins": 0.06516160815954208,
      "rewards/rejected": -0.030173778533935547,
      "step": 363
    },
    {
      "epoch": 28.0,
      "grad_norm": 11.279707908630371,
      "learning_rate": 7.3203125e-08,
      "logits/chosen": 1.3915667533874512,
      "logits/rejected": 0.9837230443954468,
      "logps/chosen": -35.213523864746094,
      "logps/rejected": -47.548927307128906,
      "loss": 0.6641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014936685562133789,
      "rewards/margins": 0.059318214654922485,
      "rewards/rejected": -0.0443815253674984,
      "step": 364
    },
    {
      "epoch": 28.0,
      "eval_logits/chosen": 1.3137699365615845,
      "eval_logits/rejected": 1.204217553138733,
      "eval_logps/chosen": -34.35585403442383,
      "eval_logps/rejected": -47.072715759277344,
      "eval_loss": 0.6825143694877625,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.01436614990234375,
      "eval_rewards/margins": 0.021518880501389503,
      "eval_rewards/rejected": -0.0071527305990457535,
      "eval_runtime": 2.7419,
      "eval_samples_per_second": 36.471,
      "eval_steps_per_second": 18.236,
      "step": 364
    },
    {
      "epoch": 28.08,
      "grad_norm": 7.3416900634765625,
      "learning_rate": 7.312499999999999e-08,
      "logits/chosen": 1.249819040298462,
      "logits/rejected": 1.3542592525482178,
      "logps/chosen": -37.93906021118164,
      "logps/rejected": -61.447776794433594,
      "loss": 0.6769,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015453482046723366,
      "rewards/margins": 0.03278326988220215,
      "rewards/rejected": -0.017329787835478783,
      "step": 365
    },
    {
      "epoch": 28.16,
      "grad_norm": 7.201632976531982,
      "learning_rate": 7.3046875e-08,
      "logits/chosen": 1.2320579290390015,
      "logits/rejected": 1.3198416233062744,
      "logps/chosen": -31.380592346191406,
      "logps/rejected": -55.56620407104492,
      "loss": 0.6722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026905346661806107,
      "rewards/margins": 0.04240603372454643,
      "rewards/rejected": -0.0155006879940629,
      "step": 366
    },
    {
      "epoch": 28.24,
      "grad_norm": 7.926521301269531,
      "learning_rate": 7.296875e-08,
      "logits/chosen": 1.521512508392334,
      "logits/rejected": 1.298538327217102,
      "logps/chosen": -35.72046661376953,
      "logps/rejected": -57.754737854003906,
      "loss": 0.6659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02384195476770401,
      "rewards/margins": 0.055413104593753815,
      "rewards/rejected": -0.031571149826049805,
      "step": 367
    },
    {
      "epoch": 28.32,
      "grad_norm": 5.776983261108398,
      "learning_rate": 7.289062499999999e-08,
      "logits/chosen": 1.1051867008209229,
      "logits/rejected": 1.2254425287246704,
      "logps/chosen": -34.093292236328125,
      "logps/rejected": -49.33746337890625,
      "loss": 0.6717,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009242295287549496,
      "rewards/margins": 0.04367544502019882,
      "rewards/rejected": -0.03443315252661705,
      "step": 368
    },
    {
      "epoch": 28.4,
      "grad_norm": 7.737083911895752,
      "learning_rate": 7.28125e-08,
      "logits/chosen": 1.3709381818771362,
      "logits/rejected": 1.3772823810577393,
      "logps/chosen": -34.715538024902344,
      "logps/rejected": -60.17499542236328,
      "loss": 0.6704,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011437177658081055,
      "rewards/margins": 0.04637785255908966,
      "rewards/rejected": -0.03494067117571831,
      "step": 369
    },
    {
      "epoch": 28.48,
      "grad_norm": 8.96133804321289,
      "learning_rate": 7.273437499999999e-08,
      "logits/chosen": 1.2183818817138672,
      "logits/rejected": 1.1179876327514648,
      "logps/chosen": -32.16400146484375,
      "logps/rejected": -52.200408935546875,
      "loss": 0.6591,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023175548762083054,
      "rewards/margins": 0.06981990486383438,
      "rewards/rejected": -0.04664435610175133,
      "step": 370
    },
    {
      "epoch": 28.56,
      "grad_norm": 8.120506286621094,
      "learning_rate": 7.265624999999999e-08,
      "logits/chosen": 1.5643792152404785,
      "logits/rejected": 1.068310260772705,
      "logps/chosen": -33.844642639160156,
      "logps/rejected": -49.801597595214844,
      "loss": 0.6587,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028593970462679863,
      "rewards/margins": 0.07032608985900879,
      "rewards/rejected": -0.041732121258974075,
      "step": 371
    },
    {
      "epoch": 28.64,
      "grad_norm": 8.143333435058594,
      "learning_rate": 7.2578125e-08,
      "logits/chosen": 1.3737304210662842,
      "logits/rejected": 1.3943084478378296,
      "logps/chosen": -33.52568817138672,
      "logps/rejected": -59.374019622802734,
      "loss": 0.6612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01910569705069065,
      "rewards/margins": 0.06517217308282852,
      "rewards/rejected": -0.04606647416949272,
      "step": 372
    },
    {
      "epoch": 28.72,
      "grad_norm": 7.440232276916504,
      "learning_rate": 7.25e-08,
      "logits/chosen": 1.187233805656433,
      "logits/rejected": 1.191892147064209,
      "logps/chosen": -33.028831481933594,
      "logps/rejected": -45.56366729736328,
      "loss": 0.6672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026155926287174225,
      "rewards/margins": 0.05279748886823654,
      "rewards/rejected": -0.02664155885577202,
      "step": 373
    },
    {
      "epoch": 28.8,
      "grad_norm": 8.430888175964355,
      "learning_rate": 7.2421875e-08,
      "logits/chosen": 1.2581841945648193,
      "logits/rejected": 1.1980568170547485,
      "logps/chosen": -33.454471588134766,
      "logps/rejected": -64.11957550048828,
      "loss": 0.6585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025371456518769264,
      "rewards/margins": 0.07069472968578339,
      "rewards/rejected": -0.04532327502965927,
      "step": 374
    },
    {
      "epoch": 28.88,
      "grad_norm": 6.898401737213135,
      "learning_rate": 7.234375e-08,
      "logits/chosen": 1.0827008485794067,
      "logits/rejected": 1.1775882244110107,
      "logps/chosen": -30.227890014648438,
      "logps/rejected": -51.093196868896484,
      "loss": 0.6695,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02529475837945938,
      "rewards/margins": 0.04801323264837265,
      "rewards/rejected": -0.022718477994203568,
      "step": 375
    },
    {
      "epoch": 28.96,
      "grad_norm": 6.8774309158325195,
      "learning_rate": 7.2265625e-08,
      "logits/chosen": 1.4102624654769897,
      "logits/rejected": 1.4674993753433228,
      "logps/chosen": -38.167945861816406,
      "logps/rejected": -59.575496673583984,
      "loss": 0.6763,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.005315042100846767,
      "rewards/margins": 0.03415372222661972,
      "rewards/rejected": -0.028838682919740677,
      "step": 376
    },
    {
      "epoch": 29.0,
      "grad_norm": 10.755170822143555,
      "learning_rate": 7.21875e-08,
      "logits/chosen": 1.2214654684066772,
      "logits/rejected": 1.1614378690719604,
      "logps/chosen": -33.92293930053711,
      "logps/rejected": -47.79758071899414,
      "loss": 0.6489,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.036457158625125885,
      "rewards/margins": 0.09063682705163956,
      "rewards/rejected": -0.05417966842651367,
      "step": 377
    },
    {
      "epoch": 29.0,
      "eval_logits/chosen": 1.3118433952331543,
      "eval_logits/rejected": 1.2035274505615234,
      "eval_logps/chosen": -34.342628479003906,
      "eval_logps/rejected": -47.081417083740234,
      "eval_loss": 0.6814384460449219,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.015688858926296234,
      "eval_rewards/margins": 0.023711424320936203,
      "eval_rewards/rejected": -0.008022565394639969,
      "eval_runtime": 2.7357,
      "eval_samples_per_second": 36.554,
      "eval_steps_per_second": 18.277,
      "step": 377
    },
    {
      "epoch": 29.08,
      "grad_norm": 8.086359024047852,
      "learning_rate": 7.2109375e-08,
      "logits/chosen": 1.5696983337402344,
      "logits/rejected": 1.3327871561050415,
      "logps/chosen": -42.82866668701172,
      "logps/rejected": -54.307823181152344,
      "loss": 0.6661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0103919031098485,
      "rewards/margins": 0.0551212802529335,
      "rewards/rejected": -0.04472937434911728,
      "step": 378
    },
    {
      "epoch": 29.16,
      "grad_norm": 7.298272132873535,
      "learning_rate": 7.203125e-08,
      "logits/chosen": 1.3517428636550903,
      "logits/rejected": 1.0154880285263062,
      "logps/chosen": -30.462234497070312,
      "logps/rejected": -52.160057067871094,
      "loss": 0.6684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026174044236540794,
      "rewards/margins": 0.05012734234333038,
      "rewards/rejected": -0.02395329438149929,
      "step": 379
    },
    {
      "epoch": 29.24,
      "grad_norm": 7.684864044189453,
      "learning_rate": 7.195312499999999e-08,
      "logits/chosen": 1.1263855695724487,
      "logits/rejected": 1.2004213333129883,
      "logps/chosen": -32.59175109863281,
      "logps/rejected": -54.01854705810547,
      "loss": 0.6655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00736424932256341,
      "rewards/margins": 0.05632669851183891,
      "rewards/rejected": -0.04896245151758194,
      "step": 380
    },
    {
      "epoch": 29.32,
      "grad_norm": 7.842283248901367,
      "learning_rate": 7.1875e-08,
      "logits/chosen": 1.4534772634506226,
      "logits/rejected": 1.2640254497528076,
      "logps/chosen": -32.730751037597656,
      "logps/rejected": -55.80845642089844,
      "loss": 0.6624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03190624713897705,
      "rewards/margins": 0.0626814141869545,
      "rewards/rejected": -0.030775167047977448,
      "step": 381
    },
    {
      "epoch": 29.4,
      "grad_norm": 6.364016532897949,
      "learning_rate": 7.1796875e-08,
      "logits/chosen": 1.3771573305130005,
      "logits/rejected": 1.3175199031829834,
      "logps/chosen": -35.29009246826172,
      "logps/rejected": -57.42271423339844,
      "loss": 0.6715,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.018948866054415703,
      "rewards/margins": 0.043857693672180176,
      "rewards/rejected": -0.024908829480409622,
      "step": 382
    },
    {
      "epoch": 29.48,
      "grad_norm": 7.365490913391113,
      "learning_rate": 7.171874999999999e-08,
      "logits/chosen": 1.2967060804367065,
      "logits/rejected": 1.3033177852630615,
      "logps/chosen": -35.8127555847168,
      "logps/rejected": -62.842342376708984,
      "loss": 0.6621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015444446355104446,
      "rewards/margins": 0.06324432045221329,
      "rewards/rejected": -0.04779987409710884,
      "step": 383
    },
    {
      "epoch": 29.56,
      "grad_norm": 7.292636394500732,
      "learning_rate": 7.1640625e-08,
      "logits/chosen": 1.296922206878662,
      "logits/rejected": 1.3053505420684814,
      "logps/chosen": -37.4749870300293,
      "logps/rejected": -54.09440612792969,
      "loss": 0.6705,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009897995740175247,
      "rewards/margins": 0.0462217815220356,
      "rewards/rejected": -0.03632378205657005,
      "step": 384
    },
    {
      "epoch": 29.64,
      "grad_norm": 7.495270729064941,
      "learning_rate": 7.156249999999999e-08,
      "logits/chosen": 1.2310714721679688,
      "logits/rejected": 1.5388970375061035,
      "logps/chosen": -32.20444107055664,
      "logps/rejected": -52.104393005371094,
      "loss": 0.6674,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02116391807794571,
      "rewards/margins": 0.05241658538579941,
      "rewards/rejected": -0.031252671033144,
      "step": 385
    },
    {
      "epoch": 29.72,
      "grad_norm": 7.533656120300293,
      "learning_rate": 7.148437499999999e-08,
      "logits/chosen": 1.371384859085083,
      "logits/rejected": 1.35120689868927,
      "logps/chosen": -29.978845596313477,
      "logps/rejected": -49.232337951660156,
      "loss": 0.6624,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.029458116739988327,
      "rewards/margins": 0.06278884410858154,
      "rewards/rejected": -0.033330727368593216,
      "step": 386
    },
    {
      "epoch": 29.8,
      "grad_norm": 8.671957015991211,
      "learning_rate": 7.140625e-08,
      "logits/chosen": 1.1956393718719482,
      "logits/rejected": 1.125212550163269,
      "logps/chosen": -35.869300842285156,
      "logps/rejected": -61.66499328613281,
      "loss": 0.6543,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025510670617222786,
      "rewards/margins": 0.08025133609771729,
      "rewards/rejected": -0.05474067106842995,
      "step": 387
    },
    {
      "epoch": 29.88,
      "grad_norm": 6.899652481079102,
      "learning_rate": 7.132812499999999e-08,
      "logits/chosen": 1.3458925485610962,
      "logits/rejected": 1.2011826038360596,
      "logps/chosen": -28.72168731689453,
      "logps/rejected": -45.255531311035156,
      "loss": 0.6618,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021691037341952324,
      "rewards/margins": 0.06395063549280167,
      "rewards/rejected": -0.04225960001349449,
      "step": 388
    },
    {
      "epoch": 29.96,
      "grad_norm": 7.905704975128174,
      "learning_rate": 7.124999999999999e-08,
      "logits/chosen": 1.3460643291473389,
      "logits/rejected": 1.3301455974578857,
      "logps/chosen": -34.72396469116211,
      "logps/rejected": -60.300537109375,
      "loss": 0.6767,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01716587506234646,
      "rewards/margins": 0.033493734896183014,
      "rewards/rejected": -0.016327857971191406,
      "step": 389
    },
    {
      "epoch": 30.0,
      "grad_norm": 10.726067543029785,
      "learning_rate": 7.1171875e-08,
      "logits/chosen": 0.914013147354126,
      "logits/rejected": 1.0391805171966553,
      "logps/chosen": -33.17698287963867,
      "logps/rejected": -61.60358428955078,
      "loss": 0.6685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008594561368227005,
      "rewards/margins": 0.05022845417261124,
      "rewards/rejected": -0.04163389280438423,
      "step": 390
    },
    {
      "epoch": 30.0,
      "eval_logits/chosen": 1.3142313957214355,
      "eval_logits/rejected": 1.2054578065872192,
      "eval_logps/chosen": -34.329288482666016,
      "eval_logps/rejected": -47.10918045043945,
      "eval_loss": 0.6794156432151794,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.01702301576733589,
      "eval_rewards/margins": 0.027821844443678856,
      "eval_rewards/rejected": -0.010798829607665539,
      "eval_runtime": 2.7443,
      "eval_samples_per_second": 36.439,
      "eval_steps_per_second": 18.22,
      "step": 390
    },
    {
      "epoch": 30.08,
      "grad_norm": 9.17463207244873,
      "learning_rate": 7.109375e-08,
      "logits/chosen": 1.4000535011291504,
      "logits/rejected": 1.1530953645706177,
      "logps/chosen": -34.16820526123047,
      "logps/rejected": -61.701778411865234,
      "loss": 0.6614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.035097409039735794,
      "rewards/margins": 0.06465268135070801,
      "rewards/rejected": -0.029555274173617363,
      "step": 391
    },
    {
      "epoch": 30.16,
      "grad_norm": 7.328595161437988,
      "learning_rate": 7.1015625e-08,
      "logits/chosen": 1.2749511003494263,
      "logits/rejected": 1.2097291946411133,
      "logps/chosen": -29.86942481994629,
      "logps/rejected": -60.598873138427734,
      "loss": 0.6689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028568197041749954,
      "rewards/margins": 0.04910576343536377,
      "rewards/rejected": -0.020537568256258965,
      "step": 392
    },
    {
      "epoch": 30.24,
      "grad_norm": 8.616415977478027,
      "learning_rate": 7.09375e-08,
      "logits/chosen": 1.3558735847473145,
      "logits/rejected": 0.9824967384338379,
      "logps/chosen": -29.41800308227539,
      "logps/rejected": -49.153831481933594,
      "loss": 0.6584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01654798910021782,
      "rewards/margins": 0.07132279872894287,
      "rewards/rejected": -0.05477480962872505,
      "step": 393
    },
    {
      "epoch": 30.32,
      "grad_norm": 7.488612174987793,
      "learning_rate": 7.0859375e-08,
      "logits/chosen": 1.2978599071502686,
      "logits/rejected": 1.3135738372802734,
      "logps/chosen": -36.62547302246094,
      "logps/rejected": -55.43284606933594,
      "loss": 0.6632,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.018166089430451393,
      "rewards/margins": 0.06139509752392769,
      "rewards/rejected": -0.043229006230831146,
      "step": 394
    },
    {
      "epoch": 30.4,
      "grad_norm": 8.04770278930664,
      "learning_rate": 7.078125e-08,
      "logits/chosen": 1.1925050020217896,
      "logits/rejected": 1.4264843463897705,
      "logps/chosen": -35.193294525146484,
      "logps/rejected": -60.09918212890625,
      "loss": 0.6546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026334214955568314,
      "rewards/margins": 0.07893631607294083,
      "rewards/rejected": -0.05260210111737251,
      "step": 395
    },
    {
      "epoch": 30.48,
      "grad_norm": 7.058897972106934,
      "learning_rate": 7.0703125e-08,
      "logits/chosen": 1.3796825408935547,
      "logits/rejected": 1.3854507207870483,
      "logps/chosen": -36.96406173706055,
      "logps/rejected": -53.86589050292969,
      "loss": 0.6634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024562694132328033,
      "rewards/margins": 0.060535334050655365,
      "rewards/rejected": -0.03597263991832733,
      "step": 396
    },
    {
      "epoch": 30.56,
      "grad_norm": 7.029977321624756,
      "learning_rate": 7.0625e-08,
      "logits/chosen": 1.1885194778442383,
      "logits/rejected": 1.2342708110809326,
      "logps/chosen": -29.46854019165039,
      "logps/rejected": -55.10395812988281,
      "loss": 0.6664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02769956737756729,
      "rewards/margins": 0.05436086654663086,
      "rewards/rejected": -0.026661301031708717,
      "step": 397
    },
    {
      "epoch": 30.64,
      "grad_norm": 6.837631702423096,
      "learning_rate": 7.0546875e-08,
      "logits/chosen": 1.2413880825042725,
      "logits/rejected": 1.3459328413009644,
      "logps/chosen": -38.59307861328125,
      "logps/rejected": -48.427398681640625,
      "loss": 0.6709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013429403305053711,
      "rewards/margins": 0.0452788844704628,
      "rewards/rejected": -0.03184948116540909,
      "step": 398
    },
    {
      "epoch": 30.72,
      "grad_norm": 7.480941295623779,
      "learning_rate": 7.046875e-08,
      "logits/chosen": 1.1301097869873047,
      "logits/rejected": 1.3118436336517334,
      "logps/chosen": -31.666357040405273,
      "logps/rejected": -54.958251953125,
      "loss": 0.6672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018511008471250534,
      "rewards/margins": 0.0527382418513298,
      "rewards/rejected": -0.03422722965478897,
      "step": 399
    },
    {
      "epoch": 30.8,
      "grad_norm": 7.8445634841918945,
      "learning_rate": 7.039062499999999e-08,
      "logits/chosen": 1.2855377197265625,
      "logits/rejected": 1.1732394695281982,
      "logps/chosen": -36.79723358154297,
      "logps/rejected": -56.47351837158203,
      "loss": 0.6632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015038896352052689,
      "rewards/margins": 0.06136641278862953,
      "rewards/rejected": -0.04632752016186714,
      "step": 400
    },
    {
      "epoch": 30.88,
      "grad_norm": 7.953109264373779,
      "learning_rate": 7.03125e-08,
      "logits/chosen": 1.4565459489822388,
      "logits/rejected": 1.3384382724761963,
      "logps/chosen": -35.705894470214844,
      "logps/rejected": -59.053001403808594,
      "loss": 0.6737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00986697617918253,
      "rewards/margins": 0.03935129567980766,
      "rewards/rejected": -0.029484320431947708,
      "step": 401
    },
    {
      "epoch": 30.96,
      "grad_norm": 6.710702419281006,
      "learning_rate": 7.0234375e-08,
      "logits/chosen": 1.3838474750518799,
      "logits/rejected": 1.2812268733978271,
      "logps/chosen": -35.61360549926758,
      "logps/rejected": -52.090213775634766,
      "loss": 0.6656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020826030522584915,
      "rewards/margins": 0.056098055094480515,
      "rewards/rejected": -0.0352720245718956,
      "step": 402
    },
    {
      "epoch": 31.0,
      "grad_norm": 8.557997703552246,
      "learning_rate": 7.015624999999999e-08,
      "logits/chosen": 1.210745930671692,
      "logits/rejected": 1.2738430500030518,
      "logps/chosen": -29.99135971069336,
      "logps/rejected": -46.59164810180664,
      "loss": 0.6766,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.012387276627123356,
      "rewards/margins": 0.03367166593670845,
      "rewards/rejected": -0.02128438837826252,
      "step": 403
    },
    {
      "epoch": 31.0,
      "eval_logits/chosen": 1.3145685195922852,
      "eval_logits/rejected": 1.2053970098495483,
      "eval_logps/chosen": -34.31262969970703,
      "eval_logps/rejected": -47.115501403808594,
      "eval_loss": 0.6782980561256409,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.01868860237300396,
      "eval_rewards/margins": 0.03012016974389553,
      "eval_rewards/rejected": -0.011431566439568996,
      "eval_runtime": 2.7375,
      "eval_samples_per_second": 36.529,
      "eval_steps_per_second": 18.265,
      "step": 403
    },
    {
      "epoch": 31.08,
      "grad_norm": 7.605563640594482,
      "learning_rate": 7.0078125e-08,
      "logits/chosen": 1.4592978954315186,
      "logits/rejected": 1.2240338325500488,
      "logps/chosen": -28.819164276123047,
      "logps/rejected": -49.966758728027344,
      "loss": 0.6705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016814684495329857,
      "rewards/margins": 0.04589240625500679,
      "rewards/rejected": -0.029077721759676933,
      "step": 404
    },
    {
      "epoch": 31.16,
      "grad_norm": 7.324702739715576,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.3103551864624023,
      "logits/rejected": 1.0734753608703613,
      "logps/chosen": -32.53624725341797,
      "logps/rejected": -57.56467056274414,
      "loss": 0.6696,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0030480141285806894,
      "rewards/margins": 0.048068881034851074,
      "rewards/rejected": -0.04502087086439133,
      "step": 405
    },
    {
      "epoch": 31.24,
      "grad_norm": 7.585947513580322,
      "learning_rate": 6.992187499999999e-08,
      "logits/chosen": 1.2591391801834106,
      "logits/rejected": 1.2620865106582642,
      "logps/chosen": -35.81463623046875,
      "logps/rejected": -63.213134765625,
      "loss": 0.6723,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004625153727829456,
      "rewards/margins": 0.042258381843566895,
      "rewards/rejected": -0.03763322904706001,
      "step": 406
    },
    {
      "epoch": 31.32,
      "grad_norm": 7.970963001251221,
      "learning_rate": 6.984375e-08,
      "logits/chosen": 1.281207799911499,
      "logits/rejected": 1.335424542427063,
      "logps/chosen": -38.500709533691406,
      "logps/rejected": -66.6947250366211,
      "loss": 0.676,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007862878032028675,
      "rewards/margins": 0.03497164696455002,
      "rewards/rejected": -0.02710876613855362,
      "step": 407
    },
    {
      "epoch": 31.4,
      "grad_norm": 8.339066505432129,
      "learning_rate": 6.9765625e-08,
      "logits/chosen": 1.2474110126495361,
      "logits/rejected": 1.2335249185562134,
      "logps/chosen": -34.1714973449707,
      "logps/rejected": -49.236961364746094,
      "loss": 0.661,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.019970441237092018,
      "rewards/margins": 0.06564202159643173,
      "rewards/rejected": -0.04567158222198486,
      "step": 408
    },
    {
      "epoch": 31.48,
      "grad_norm": 8.651510238647461,
      "learning_rate": 6.96875e-08,
      "logits/chosen": 1.1418688297271729,
      "logits/rejected": 1.2468165159225464,
      "logps/chosen": -33.46930694580078,
      "logps/rejected": -58.662559509277344,
      "loss": 0.655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.032325126230716705,
      "rewards/margins": 0.07818012684583664,
      "rewards/rejected": -0.045855000615119934,
      "step": 409
    },
    {
      "epoch": 31.56,
      "grad_norm": 7.3322954177856445,
      "learning_rate": 6.9609375e-08,
      "logits/chosen": 1.4487340450286865,
      "logits/rejected": 1.386229395866394,
      "logps/chosen": -32.205848693847656,
      "logps/rejected": -54.62187576293945,
      "loss": 0.6598,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03495974466204643,
      "rewards/margins": 0.06811018288135529,
      "rewards/rejected": -0.033150434494018555,
      "step": 410
    },
    {
      "epoch": 31.64,
      "grad_norm": 6.456846237182617,
      "learning_rate": 6.953125e-08,
      "logits/chosen": 1.4530689716339111,
      "logits/rejected": 1.3447459936141968,
      "logps/chosen": -33.730621337890625,
      "logps/rejected": -57.29511260986328,
      "loss": 0.6683,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0231703519821167,
      "rewards/margins": 0.05057895556092262,
      "rewards/rejected": -0.027408601716160774,
      "step": 411
    },
    {
      "epoch": 31.72,
      "grad_norm": 6.669605255126953,
      "learning_rate": 6.9453125e-08,
      "logits/chosen": 1.0366404056549072,
      "logits/rejected": 1.3765044212341309,
      "logps/chosen": -34.90974044799805,
      "logps/rejected": -58.376564025878906,
      "loss": 0.6758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007768202107399702,
      "rewards/margins": 0.03512921556830406,
      "rewards/rejected": -0.027361012995243073,
      "step": 412
    },
    {
      "epoch": 31.8,
      "grad_norm": 9.189570426940918,
      "learning_rate": 6.9375e-08,
      "logits/chosen": 1.1434392929077148,
      "logits/rejected": 1.1098456382751465,
      "logps/chosen": -32.311134338378906,
      "logps/rejected": -48.26872253417969,
      "loss": 0.6613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01660010777413845,
      "rewards/margins": 0.06484416127204895,
      "rewards/rejected": -0.04824404418468475,
      "step": 413
    },
    {
      "epoch": 31.88,
      "grad_norm": 7.020939350128174,
      "learning_rate": 6.9296875e-08,
      "logits/chosen": 1.3913180828094482,
      "logits/rejected": 1.3780086040496826,
      "logps/chosen": -36.275634765625,
      "logps/rejected": -47.75276184082031,
      "loss": 0.6634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019369030371308327,
      "rewards/margins": 0.0605347603559494,
      "rewards/rejected": -0.04116573557257652,
      "step": 414
    },
    {
      "epoch": 31.96,
      "grad_norm": 7.732224464416504,
      "learning_rate": 6.921875e-08,
      "logits/chosen": 1.511098027229309,
      "logits/rejected": 1.165769338607788,
      "logps/chosen": -34.048831939697266,
      "logps/rejected": -45.57819366455078,
      "loss": 0.6632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03159499168395996,
      "rewards/margins": 0.06105780601501465,
      "rewards/rejected": -0.02946281246840954,
      "step": 415
    },
    {
      "epoch": 32.0,
      "grad_norm": 11.76850414276123,
      "learning_rate": 6.9140625e-08,
      "logits/chosen": 1.5219228267669678,
      "logits/rejected": 1.2248491048812866,
      "logps/chosen": -36.9514045715332,
      "logps/rejected": -66.48347473144531,
      "loss": 0.6369,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03337531164288521,
      "rewards/margins": 0.1159212589263916,
      "rewards/rejected": -0.08254595100879669,
      "step": 416
    },
    {
      "epoch": 32.0,
      "eval_logits/chosen": 1.3134334087371826,
      "eval_logits/rejected": 1.2052100896835327,
      "eval_logps/chosen": -34.28541564941406,
      "eval_logps/rejected": -47.12324142456055,
      "eval_loss": 0.6765698790550232,
      "eval_rewards/accuracies": 0.8799999952316284,
      "eval_rewards/chosen": 0.02140996977686882,
      "eval_rewards/margins": 0.03361520171165466,
      "eval_rewards/rejected": -0.012205235660076141,
      "eval_runtime": 2.737,
      "eval_samples_per_second": 36.536,
      "eval_steps_per_second": 18.268,
      "step": 416
    },
    {
      "epoch": 32.08,
      "grad_norm": 5.9945149421691895,
      "learning_rate": 6.90625e-08,
      "logits/chosen": 1.2847803831100464,
      "logits/rejected": 1.3443140983581543,
      "logps/chosen": -37.05412292480469,
      "logps/rejected": -52.180145263671875,
      "loss": 0.6731,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014810776337981224,
      "rewards/margins": 0.040723156183958054,
      "rewards/rejected": -0.02591237984597683,
      "step": 417
    },
    {
      "epoch": 32.16,
      "grad_norm": 7.304105758666992,
      "learning_rate": 6.8984375e-08,
      "logits/chosen": 1.2545349597930908,
      "logits/rejected": 1.2392048835754395,
      "logps/chosen": -36.294227600097656,
      "logps/rejected": -58.685264587402344,
      "loss": 0.661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004923796746879816,
      "rewards/margins": 0.06584884971380234,
      "rewards/rejected": -0.06092505529522896,
      "step": 418
    },
    {
      "epoch": 32.24,
      "grad_norm": 7.731841564178467,
      "learning_rate": 6.890625e-08,
      "logits/chosen": 1.390171766281128,
      "logits/rejected": 1.3293510675430298,
      "logps/chosen": -34.96992874145508,
      "logps/rejected": -53.691898345947266,
      "loss": 0.6555,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03003695048391819,
      "rewards/margins": 0.07704202830791473,
      "rewards/rejected": -0.04700507968664169,
      "step": 419
    },
    {
      "epoch": 32.32,
      "grad_norm": 8.23258113861084,
      "learning_rate": 6.882812499999999e-08,
      "logits/chosen": 1.1503701210021973,
      "logits/rejected": 1.1821773052215576,
      "logps/chosen": -33.069435119628906,
      "logps/rejected": -64.49241638183594,
      "loss": 0.666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00591776380315423,
      "rewards/margins": 0.055202506482601166,
      "rewards/rejected": -0.04928474500775337,
      "step": 420
    },
    {
      "epoch": 32.4,
      "grad_norm": 8.379127502441406,
      "learning_rate": 6.875e-08,
      "logits/chosen": 1.4180344343185425,
      "logits/rejected": 1.3477474451065063,
      "logps/chosen": -35.098167419433594,
      "logps/rejected": -68.9798583984375,
      "loss": 0.6602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027853919193148613,
      "rewards/margins": 0.067205049097538,
      "rewards/rejected": -0.03935113176703453,
      "step": 421
    },
    {
      "epoch": 32.48,
      "grad_norm": 6.229736804962158,
      "learning_rate": 6.8671875e-08,
      "logits/chosen": 1.4723856449127197,
      "logits/rejected": 1.3589181900024414,
      "logps/chosen": -32.263916015625,
      "logps/rejected": -60.0313835144043,
      "loss": 0.6661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01953437365591526,
      "rewards/margins": 0.05496933311223984,
      "rewards/rejected": -0.03543496131896973,
      "step": 422
    },
    {
      "epoch": 32.56,
      "grad_norm": 8.762487411499023,
      "learning_rate": 6.859374999999999e-08,
      "logits/chosen": 1.2524853944778442,
      "logits/rejected": 1.1843189001083374,
      "logps/chosen": -29.97130012512207,
      "logps/rejected": -51.58900451660156,
      "loss": 0.6596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02069871313869953,
      "rewards/margins": 0.06833846867084503,
      "rewards/rejected": -0.04763974994421005,
      "step": 423
    },
    {
      "epoch": 32.64,
      "grad_norm": 7.3585124015808105,
      "learning_rate": 6.851562499999999e-08,
      "logits/chosen": 1.4374842643737793,
      "logits/rejected": 1.1226143836975098,
      "logps/chosen": -38.12564468383789,
      "logps/rejected": -47.837913513183594,
      "loss": 0.6646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010333322919905186,
      "rewards/margins": 0.05823533609509468,
      "rewards/rejected": -0.04790201410651207,
      "step": 424
    },
    {
      "epoch": 32.72,
      "grad_norm": 7.114125728607178,
      "learning_rate": 6.843749999999999e-08,
      "logits/chosen": 1.117455244064331,
      "logits/rejected": 1.3763068914413452,
      "logps/chosen": -28.57703399658203,
      "logps/rejected": -54.07353210449219,
      "loss": 0.6508,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03910376876592636,
      "rewards/margins": 0.08702810108661652,
      "rewards/rejected": -0.04792432487010956,
      "step": 425
    },
    {
      "epoch": 32.8,
      "grad_norm": 8.355945587158203,
      "learning_rate": 6.8359375e-08,
      "logits/chosen": 1.2844198942184448,
      "logits/rejected": 1.2507901191711426,
      "logps/chosen": -35.70555877685547,
      "logps/rejected": -59.917640686035156,
      "loss": 0.6486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03629279136657715,
      "rewards/margins": 0.09204979240894318,
      "rewards/rejected": -0.05575700104236603,
      "step": 426
    },
    {
      "epoch": 32.88,
      "grad_norm": 8.6890230178833,
      "learning_rate": 6.828125e-08,
      "logits/chosen": 1.3855177164077759,
      "logits/rejected": 1.0790081024169922,
      "logps/chosen": -35.161800384521484,
      "logps/rejected": -52.94989776611328,
      "loss": 0.6551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018762638792395592,
      "rewards/margins": 0.07852178066968918,
      "rewards/rejected": -0.05975914001464844,
      "step": 427
    },
    {
      "epoch": 32.96,
      "grad_norm": 6.678261756896973,
      "learning_rate": 6.8203125e-08,
      "logits/chosen": 1.3276199102401733,
      "logits/rejected": 1.3306113481521606,
      "logps/chosen": -35.16057586669922,
      "logps/rejected": -43.34693145751953,
      "loss": 0.6624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023655343800783157,
      "rewards/margins": 0.06261570751667023,
      "rewards/rejected": -0.03896036371588707,
      "step": 428
    },
    {
      "epoch": 33.0,
      "grad_norm": 9.420109748840332,
      "learning_rate": 6.8125e-08,
      "logits/chosen": 1.2753249406814575,
      "logits/rejected": 1.510566234588623,
      "logps/chosen": -27.27406120300293,
      "logps/rejected": -47.09627914428711,
      "loss": 0.6647,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03611450269818306,
      "rewards/margins": 0.057857707142829895,
      "rewards/rejected": -0.021743202582001686,
      "step": 429
    },
    {
      "epoch": 33.0,
      "eval_logits/chosen": 1.3137006759643555,
      "eval_logits/rejected": 1.2047476768493652,
      "eval_logps/chosen": -34.2960205078125,
      "eval_logps/rejected": -47.125831604003906,
      "eval_loss": 0.6769477128982544,
      "eval_rewards/accuracies": 0.8799999952316284,
      "eval_rewards/chosen": 0.020349230617284775,
      "eval_rewards/margins": 0.03281418979167938,
      "eval_rewards/rejected": -0.012464959174394608,
      "eval_runtime": 2.7375,
      "eval_samples_per_second": 36.53,
      "eval_steps_per_second": 18.265,
      "step": 429
    },
    {
      "epoch": 33.08,
      "grad_norm": 7.18523645401001,
      "learning_rate": 6.8046875e-08,
      "logits/chosen": 1.6238020658493042,
      "logits/rejected": 1.4196797609329224,
      "logps/chosen": -41.30558395385742,
      "logps/rejected": -54.2149543762207,
      "loss": 0.6622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.002451682463288307,
      "rewards/margins": 0.06303489208221436,
      "rewards/rejected": -0.06548658013343811,
      "step": 430
    },
    {
      "epoch": 33.16,
      "grad_norm": 8.448713302612305,
      "learning_rate": 6.796875e-08,
      "logits/chosen": 1.451847791671753,
      "logits/rejected": 1.1385754346847534,
      "logps/chosen": -30.878074645996094,
      "logps/rejected": -54.078948974609375,
      "loss": 0.6529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02781553380191326,
      "rewards/margins": 0.08252573013305664,
      "rewards/rejected": -0.05471019446849823,
      "step": 431
    },
    {
      "epoch": 33.24,
      "grad_norm": 7.663743495941162,
      "learning_rate": 6.7890625e-08,
      "logits/chosen": 1.3108651638031006,
      "logits/rejected": 1.2746179103851318,
      "logps/chosen": -39.14887619018555,
      "logps/rejected": -52.39755630493164,
      "loss": 0.6691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015946079045534134,
      "rewards/margins": 0.04873116314411163,
      "rewards/rejected": -0.0327850803732872,
      "step": 432
    },
    {
      "epoch": 33.32,
      "grad_norm": 7.254777431488037,
      "learning_rate": 6.78125e-08,
      "logits/chosen": 1.350494384765625,
      "logits/rejected": 1.2067985534667969,
      "logps/chosen": -37.335411071777344,
      "logps/rejected": -56.270355224609375,
      "loss": 0.6633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009967518039047718,
      "rewards/margins": 0.060724206268787384,
      "rewards/rejected": -0.05075669661164284,
      "step": 433
    },
    {
      "epoch": 33.4,
      "grad_norm": 7.587749481201172,
      "learning_rate": 6.7734375e-08,
      "logits/chosen": 1.388873815536499,
      "logits/rejected": 1.3319240808486938,
      "logps/chosen": -32.6411247253418,
      "logps/rejected": -56.56551742553711,
      "loss": 0.6605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03895476087927818,
      "rewards/margins": 0.06667092442512512,
      "rewards/rejected": -0.02771615795791149,
      "step": 434
    },
    {
      "epoch": 33.48,
      "grad_norm": 6.982511043548584,
      "learning_rate": 6.765624999999999e-08,
      "logits/chosen": 1.1847286224365234,
      "logits/rejected": 1.3888272047042847,
      "logps/chosen": -35.27091979980469,
      "logps/rejected": -60.57072067260742,
      "loss": 0.6631,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019562887027859688,
      "rewards/margins": 0.06122872605919838,
      "rewards/rejected": -0.04166584089398384,
      "step": 435
    },
    {
      "epoch": 33.56,
      "grad_norm": 7.222668170928955,
      "learning_rate": 6.7578125e-08,
      "logits/chosen": 1.0870875120162964,
      "logits/rejected": 1.1563149690628052,
      "logps/chosen": -31.468996047973633,
      "logps/rejected": -53.79595947265625,
      "loss": 0.6584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02815847471356392,
      "rewards/margins": 0.07075200229883194,
      "rewards/rejected": -0.04259352758526802,
      "step": 436
    },
    {
      "epoch": 33.64,
      "grad_norm": 8.18450927734375,
      "learning_rate": 6.75e-08,
      "logits/chosen": 1.1051719188690186,
      "logits/rejected": 1.1919522285461426,
      "logps/chosen": -32.587615966796875,
      "logps/rejected": -54.72174072265625,
      "loss": 0.6522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03314247354865074,
      "rewards/margins": 0.08378086239099503,
      "rewards/rejected": -0.05063839256763458,
      "step": 437
    },
    {
      "epoch": 33.72,
      "grad_norm": 7.667984962463379,
      "learning_rate": 6.742187499999999e-08,
      "logits/chosen": 1.193756341934204,
      "logits/rejected": 1.2007856369018555,
      "logps/chosen": -30.076555252075195,
      "logps/rejected": -57.029727935791016,
      "loss": 0.6692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024814464151859283,
      "rewards/margins": 0.048523664474487305,
      "rewards/rejected": -0.02370920218527317,
      "step": 438
    },
    {
      "epoch": 33.8,
      "grad_norm": 6.813406944274902,
      "learning_rate": 6.734375e-08,
      "logits/chosen": 1.195735216140747,
      "logits/rejected": 1.2673797607421875,
      "logps/chosen": -32.93894577026367,
      "logps/rejected": -43.785282135009766,
      "loss": 0.6568,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01424477156251669,
      "rewards/margins": 0.0741719976067543,
      "rewards/rejected": -0.05992722511291504,
      "step": 439
    },
    {
      "epoch": 33.88,
      "grad_norm": 6.749810218811035,
      "learning_rate": 6.726562499999999e-08,
      "logits/chosen": 1.4523347616195679,
      "logits/rejected": 1.3527884483337402,
      "logps/chosen": -32.71689224243164,
      "logps/rejected": -58.41621398925781,
      "loss": 0.6673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01895890384912491,
      "rewards/margins": 0.05256643518805504,
      "rewards/rejected": -0.03360753133893013,
      "step": 440
    },
    {
      "epoch": 33.96,
      "grad_norm": 9.20482349395752,
      "learning_rate": 6.718749999999999e-08,
      "logits/chosen": 1.2046353816986084,
      "logits/rejected": 1.1838449239730835,
      "logps/chosen": -32.03069305419922,
      "logps/rejected": -59.122406005859375,
      "loss": 0.6628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009400080889463425,
      "rewards/margins": 0.06204557418823242,
      "rewards/rejected": -0.052645493298769,
      "step": 441
    },
    {
      "epoch": 34.0,
      "grad_norm": 11.476346969604492,
      "learning_rate": 6.7109375e-08,
      "logits/chosen": 1.5266954898834229,
      "logits/rejected": 1.32060968875885,
      "logps/chosen": -33.51082229614258,
      "logps/rejected": -60.466461181640625,
      "loss": 0.6641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025017596781253815,
      "rewards/margins": 0.05905137211084366,
      "rewards/rejected": -0.034033775329589844,
      "step": 442
    },
    {
      "epoch": 34.0,
      "eval_logits/chosen": 1.3135075569152832,
      "eval_logits/rejected": 1.2066532373428345,
      "eval_logps/chosen": -34.29426574707031,
      "eval_logps/rejected": -47.11799240112305,
      "eval_loss": 0.6772584319114685,
      "eval_rewards/accuracies": 0.9100000262260437,
      "eval_rewards/chosen": 0.02052454464137554,
      "eval_rewards/margins": 0.03220539912581444,
      "eval_rewards/rejected": -0.011680854484438896,
      "eval_runtime": 2.7469,
      "eval_samples_per_second": 36.405,
      "eval_steps_per_second": 18.202,
      "step": 442
    },
    {
      "epoch": 34.08,
      "grad_norm": 8.220778465270996,
      "learning_rate": 6.703125e-08,
      "logits/chosen": 1.3079450130462646,
      "logits/rejected": 1.3001753091812134,
      "logps/chosen": -37.293548583984375,
      "logps/rejected": -54.14421844482422,
      "loss": 0.6666,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.017712904140353203,
      "rewards/margins": 0.054114796221256256,
      "rewards/rejected": -0.036401890218257904,
      "step": 443
    },
    {
      "epoch": 34.16,
      "grad_norm": 7.217661380767822,
      "learning_rate": 6.6953125e-08,
      "logits/chosen": 1.1819344758987427,
      "logits/rejected": 1.4473069906234741,
      "logps/chosen": -38.83961486816406,
      "logps/rejected": -65.59679412841797,
      "loss": 0.6701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025925733149051666,
      "rewards/margins": 0.0467924103140831,
      "rewards/rejected": -0.02086668089032173,
      "step": 444
    },
    {
      "epoch": 34.24,
      "grad_norm": 8.070107460021973,
      "learning_rate": 6.6875e-08,
      "logits/chosen": 1.2820357084274292,
      "logits/rejected": 1.2312040328979492,
      "logps/chosen": -35.44408416748047,
      "logps/rejected": -59.43716049194336,
      "loss": 0.6581,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022086145356297493,
      "rewards/margins": 0.07164016366004944,
      "rewards/rejected": -0.0495540127158165,
      "step": 445
    },
    {
      "epoch": 34.32,
      "grad_norm": 8.589019775390625,
      "learning_rate": 6.6796875e-08,
      "logits/chosen": 1.0902371406555176,
      "logits/rejected": 1.01372492313385,
      "logps/chosen": -30.88866424560547,
      "logps/rejected": -55.59736633300781,
      "loss": 0.6482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.036510493606328964,
      "rewards/margins": 0.09318573772907257,
      "rewards/rejected": -0.05667524039745331,
      "step": 446
    },
    {
      "epoch": 34.4,
      "grad_norm": 7.457690238952637,
      "learning_rate": 6.671875e-08,
      "logits/chosen": 1.395203709602356,
      "logits/rejected": 1.1224784851074219,
      "logps/chosen": -34.03355407714844,
      "logps/rejected": -43.97900390625,
      "loss": 0.6541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03466937690973282,
      "rewards/margins": 0.07996895164251328,
      "rewards/rejected": -0.045299578458070755,
      "step": 447
    },
    {
      "epoch": 34.48,
      "grad_norm": 7.534926891326904,
      "learning_rate": 6.6640625e-08,
      "logits/chosen": 1.2741880416870117,
      "logits/rejected": 1.1971919536590576,
      "logps/chosen": -30.8048152923584,
      "logps/rejected": -55.96346664428711,
      "loss": 0.6591,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018246959894895554,
      "rewards/margins": 0.06938999146223068,
      "rewards/rejected": -0.05114302784204483,
      "step": 448
    },
    {
      "epoch": 34.56,
      "grad_norm": 7.450250625610352,
      "learning_rate": 6.65625e-08,
      "logits/chosen": 1.3581056594848633,
      "logits/rejected": 1.2928975820541382,
      "logps/chosen": -36.04534149169922,
      "logps/rejected": -56.90543746948242,
      "loss": 0.6647,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019541168585419655,
      "rewards/margins": 0.05789261311292648,
      "rewards/rejected": -0.03835144266486168,
      "step": 449
    },
    {
      "epoch": 34.64,
      "grad_norm": 7.1246256828308105,
      "learning_rate": 6.6484375e-08,
      "logits/chosen": 1.614962100982666,
      "logits/rejected": 1.398313045501709,
      "logps/chosen": -33.37715148925781,
      "logps/rejected": -64.9561538696289,
      "loss": 0.6601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012157750315964222,
      "rewards/margins": 0.06751210987567902,
      "rewards/rejected": -0.05535436049103737,
      "step": 450
    },
    {
      "epoch": 34.72,
      "grad_norm": 6.3796491622924805,
      "learning_rate": 6.640625e-08,
      "logits/chosen": 1.1102702617645264,
      "logits/rejected": 1.3186204433441162,
      "logps/chosen": -33.9911994934082,
      "logps/rejected": -52.695472717285156,
      "loss": 0.6692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019176602363586426,
      "rewards/margins": 0.04880058765411377,
      "rewards/rejected": -0.029623985290527344,
      "step": 451
    },
    {
      "epoch": 34.8,
      "grad_norm": 8.088767051696777,
      "learning_rate": 6.6328125e-08,
      "logits/chosen": 1.2952524423599243,
      "logits/rejected": 1.2909986972808838,
      "logps/chosen": -33.66014862060547,
      "logps/rejected": -54.647117614746094,
      "loss": 0.6544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03439021110534668,
      "rewards/margins": 0.07939000427722931,
      "rewards/rejected": -0.04499978944659233,
      "step": 452
    },
    {
      "epoch": 34.88,
      "grad_norm": 6.936700820922852,
      "learning_rate": 6.625e-08,
      "logits/chosen": 1.459195613861084,
      "logits/rejected": 1.299594759941101,
      "logps/chosen": -33.4522590637207,
      "logps/rejected": -51.829185485839844,
      "loss": 0.657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02736828476190567,
      "rewards/margins": 0.07380979508161545,
      "rewards/rejected": -0.04644151031970978,
      "step": 453
    },
    {
      "epoch": 34.96,
      "grad_norm": 7.526405334472656,
      "learning_rate": 6.6171875e-08,
      "logits/chosen": 1.2763445377349854,
      "logits/rejected": 1.1461436748504639,
      "logps/chosen": -33.34716033935547,
      "logps/rejected": -52.249637603759766,
      "loss": 0.667,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013225174508988857,
      "rewards/margins": 0.05332031100988388,
      "rewards/rejected": -0.04009513929486275,
      "step": 454
    },
    {
      "epoch": 35.0,
      "grad_norm": 9.867684364318848,
      "learning_rate": 6.609374999999999e-08,
      "logits/chosen": 1.4720923900604248,
      "logits/rejected": 1.4591448307037354,
      "logps/chosen": -27.073915481567383,
      "logps/rejected": -46.18347930908203,
      "loss": 0.6518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.052542924880981445,
      "rewards/margins": 0.08454804867506027,
      "rewards/rejected": -0.03200511634349823,
      "step": 455
    },
    {
      "epoch": 35.0,
      "eval_logits/chosen": 1.3167500495910645,
      "eval_logits/rejected": 1.207638144493103,
      "eval_logps/chosen": -34.2980842590332,
      "eval_logps/rejected": -47.152618408203125,
      "eval_loss": 0.675759494304657,
      "eval_rewards/accuracies": 0.8999999761581421,
      "eval_rewards/chosen": 0.020142843946814537,
      "eval_rewards/margins": 0.03528592735528946,
      "eval_rewards/rejected": -0.015143079683184624,
      "eval_runtime": 2.744,
      "eval_samples_per_second": 36.443,
      "eval_steps_per_second": 18.221,
      "step": 455
    },
    {
      "epoch": 35.08,
      "grad_norm": 6.930986404418945,
      "learning_rate": 6.6015625e-08,
      "logits/chosen": 1.3219974040985107,
      "logits/rejected": 1.4523175954818726,
      "logps/chosen": -41.944007873535156,
      "logps/rejected": -62.36256408691406,
      "loss": 0.6666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010302592068910599,
      "rewards/margins": 0.053983353078365326,
      "rewards/rejected": -0.04368076100945473,
      "step": 456
    },
    {
      "epoch": 35.16,
      "grad_norm": 6.68194580078125,
      "learning_rate": 6.59375e-08,
      "logits/chosen": 1.3484669923782349,
      "logits/rejected": 1.250450849533081,
      "logps/chosen": -31.80664825439453,
      "logps/rejected": -47.679203033447266,
      "loss": 0.664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026875996962189674,
      "rewards/margins": 0.05930502712726593,
      "rewards/rejected": -0.03242902457714081,
      "step": 457
    },
    {
      "epoch": 35.24,
      "grad_norm": 8.003396034240723,
      "learning_rate": 6.585937499999999e-08,
      "logits/chosen": 1.3406710624694824,
      "logits/rejected": 1.1652438640594482,
      "logps/chosen": -36.62139129638672,
      "logps/rejected": -61.526123046875,
      "loss": 0.6566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01841292344033718,
      "rewards/margins": 0.07474928349256516,
      "rewards/rejected": -0.056336354464292526,
      "step": 458
    },
    {
      "epoch": 35.32,
      "grad_norm": 8.564201354980469,
      "learning_rate": 6.578125e-08,
      "logits/chosen": 1.4729511737823486,
      "logits/rejected": 1.2827980518341064,
      "logps/chosen": -33.349849700927734,
      "logps/rejected": -54.82809829711914,
      "loss": 0.6487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03416109085083008,
      "rewards/margins": 0.09105825424194336,
      "rewards/rejected": -0.05689716339111328,
      "step": 459
    },
    {
      "epoch": 35.4,
      "grad_norm": 8.216958045959473,
      "learning_rate": 6.570312499999999e-08,
      "logits/chosen": 1.4017747640609741,
      "logits/rejected": 1.1483745574951172,
      "logps/chosen": -32.57722473144531,
      "logps/rejected": -53.45829772949219,
      "loss": 0.6496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027245117351412773,
      "rewards/margins": 0.0894622653722763,
      "rewards/rejected": -0.06221713870763779,
      "step": 460
    },
    {
      "epoch": 35.48,
      "grad_norm": 7.363307476043701,
      "learning_rate": 6.5625e-08,
      "logits/chosen": 1.268888235092163,
      "logits/rejected": 1.129799246788025,
      "logps/chosen": -32.7777214050293,
      "logps/rejected": -51.5303955078125,
      "loss": 0.6647,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029421305283904076,
      "rewards/margins": 0.057849861681461334,
      "rewards/rejected": -0.02842855453491211,
      "step": 461
    },
    {
      "epoch": 35.56,
      "grad_norm": 7.0859174728393555,
      "learning_rate": 6.554687500000001e-08,
      "logits/chosen": 1.2722656726837158,
      "logits/rejected": 1.2373952865600586,
      "logps/chosen": -34.684410095214844,
      "logps/rejected": -50.6158332824707,
      "loss": 0.664,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012888002209365368,
      "rewards/margins": 0.05946941301226616,
      "rewards/rejected": -0.046581413596868515,
      "step": 462
    },
    {
      "epoch": 35.64,
      "grad_norm": 7.817688941955566,
      "learning_rate": 6.546875e-08,
      "logits/chosen": 1.2776777744293213,
      "logits/rejected": 1.1861708164215088,
      "logps/chosen": -32.42451477050781,
      "logps/rejected": -58.602684020996094,
      "loss": 0.6561,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.022174905985593796,
      "rewards/margins": 0.07626937329769135,
      "rewards/rejected": -0.054094456136226654,
      "step": 463
    },
    {
      "epoch": 35.72,
      "grad_norm": 7.2563934326171875,
      "learning_rate": 6.5390625e-08,
      "logits/chosen": 1.1661241054534912,
      "logits/rejected": 1.2308154106140137,
      "logps/chosen": -33.774085998535156,
      "logps/rejected": -58.332149505615234,
      "loss": 0.6604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01549835316836834,
      "rewards/margins": 0.06713223457336426,
      "rewards/rejected": -0.05163388326764107,
      "step": 464
    },
    {
      "epoch": 35.8,
      "grad_norm": 7.41710901260376,
      "learning_rate": 6.53125e-08,
      "logits/chosen": 1.360252022743225,
      "logits/rejected": 1.3140854835510254,
      "logps/chosen": -32.05281448364258,
      "logps/rejected": -54.16199493408203,
      "loss": 0.6625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02485065534710884,
      "rewards/margins": 0.06261815875768661,
      "rewards/rejected": -0.03776750713586807,
      "step": 465
    },
    {
      "epoch": 35.88,
      "grad_norm": 7.2992939949035645,
      "learning_rate": 6.5234375e-08,
      "logits/chosen": 1.2070640325546265,
      "logits/rejected": 1.336258888244629,
      "logps/chosen": -34.31184387207031,
      "logps/rejected": -63.029266357421875,
      "loss": 0.6604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028252480551600456,
      "rewards/margins": 0.06673260033130646,
      "rewards/rejected": -0.03848011791706085,
      "step": 466
    },
    {
      "epoch": 35.96,
      "grad_norm": 7.905913352966309,
      "learning_rate": 6.515625e-08,
      "logits/chosen": 1.3481290340423584,
      "logits/rejected": 1.6723490953445435,
      "logps/chosen": -32.447898864746094,
      "logps/rejected": -52.77498245239258,
      "loss": 0.6615,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020319271832704544,
      "rewards/margins": 0.06453647464513779,
      "rewards/rejected": -0.04421720653772354,
      "step": 467
    },
    {
      "epoch": 36.0,
      "grad_norm": 10.145078659057617,
      "learning_rate": 6.5078125e-08,
      "logits/chosen": 1.3906114101409912,
      "logits/rejected": 1.0742309093475342,
      "logps/chosen": -32.06339645385742,
      "logps/rejected": -44.915794372558594,
      "loss": 0.6521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.038527488708496094,
      "rewards/margins": 0.08386154472827911,
      "rewards/rejected": -0.04533405601978302,
      "step": 468
    },
    {
      "epoch": 36.0,
      "eval_logits/chosen": 1.3158578872680664,
      "eval_logits/rejected": 1.2067692279815674,
      "eval_logps/chosen": -34.28256607055664,
      "eval_logps/rejected": -47.13310623168945,
      "eval_loss": 0.6759704351425171,
      "eval_rewards/accuracies": 0.8999999761581421,
      "eval_rewards/chosen": 0.02169494889676571,
      "eval_rewards/margins": 0.0348869264125824,
      "eval_rewards/rejected": -0.013191979378461838,
      "eval_runtime": 2.7397,
      "eval_samples_per_second": 36.5,
      "eval_steps_per_second": 18.25,
      "step": 468
    },
    {
      "epoch": 36.08,
      "grad_norm": 6.988065719604492,
      "learning_rate": 6.5e-08,
      "logits/chosen": 1.2132147550582886,
      "logits/rejected": 1.2557493448257446,
      "logps/chosen": -38.531890869140625,
      "logps/rejected": -55.33313751220703,
      "loss": 0.6601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004139352589845657,
      "rewards/margins": 0.06751406192779541,
      "rewards/rejected": -0.06337471306324005,
      "step": 469
    },
    {
      "epoch": 36.16,
      "grad_norm": 7.992159366607666,
      "learning_rate": 6.492187499999999e-08,
      "logits/chosen": 1.2540558576583862,
      "logits/rejected": 1.072487473487854,
      "logps/chosen": -31.014942169189453,
      "logps/rejected": -44.304542541503906,
      "loss": 0.6595,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025240134447813034,
      "rewards/margins": 0.06880365312099457,
      "rewards/rejected": -0.04356350749731064,
      "step": 470
    },
    {
      "epoch": 36.24,
      "grad_norm": 8.85045051574707,
      "learning_rate": 6.484375e-08,
      "logits/chosen": 1.2066673040390015,
      "logits/rejected": 1.0400773286819458,
      "logps/chosen": -28.9932861328125,
      "logps/rejected": -54.49712371826172,
      "loss": 0.6523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02924163267016411,
      "rewards/margins": 0.08382828533649445,
      "rewards/rejected": -0.05458664894104004,
      "step": 471
    },
    {
      "epoch": 36.32,
      "grad_norm": 6.7257232666015625,
      "learning_rate": 6.4765625e-08,
      "logits/chosen": 1.199167251586914,
      "logits/rejected": 1.1158380508422852,
      "logps/chosen": -34.711402893066406,
      "logps/rejected": -49.56724166870117,
      "loss": 0.6576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0253206267952919,
      "rewards/margins": 0.0727272480726242,
      "rewards/rejected": -0.0474066287279129,
      "step": 472
    },
    {
      "epoch": 36.4,
      "grad_norm": 8.145695686340332,
      "learning_rate": 6.468749999999999e-08,
      "logits/chosen": 1.4789235591888428,
      "logits/rejected": 1.1280285120010376,
      "logps/chosen": -31.93286895751953,
      "logps/rejected": -62.08079528808594,
      "loss": 0.6547,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03773007169365883,
      "rewards/margins": 0.07851824909448624,
      "rewards/rejected": -0.04078817367553711,
      "step": 473
    },
    {
      "epoch": 36.48,
      "grad_norm": 7.6906046867370605,
      "learning_rate": 6.4609375e-08,
      "logits/chosen": 1.220781683921814,
      "logits/rejected": 1.4366470575332642,
      "logps/chosen": -35.196144104003906,
      "logps/rejected": -58.02507019042969,
      "loss": 0.6562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03534233570098877,
      "rewards/margins": 0.07541176676750183,
      "rewards/rejected": -0.04006943851709366,
      "step": 474
    },
    {
      "epoch": 36.56,
      "grad_norm": 7.917817115783691,
      "learning_rate": 6.453124999999999e-08,
      "logits/chosen": 1.3775696754455566,
      "logits/rejected": 1.2766880989074707,
      "logps/chosen": -34.114532470703125,
      "logps/rejected": -51.72147750854492,
      "loss": 0.6539,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.024290040135383606,
      "rewards/margins": 0.0808030217885971,
      "rewards/rejected": -0.0565129779279232,
      "step": 475
    },
    {
      "epoch": 36.64,
      "grad_norm": 8.327159881591797,
      "learning_rate": 6.445312499999999e-08,
      "logits/chosen": 1.2682287693023682,
      "logits/rejected": 1.3031435012817383,
      "logps/chosen": -33.76839828491211,
      "logps/rejected": -49.55010986328125,
      "loss": 0.6522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02100508287549019,
      "rewards/margins": 0.083875872194767,
      "rewards/rejected": -0.06287079304456711,
      "step": 476
    },
    {
      "epoch": 36.72,
      "grad_norm": 6.616943836212158,
      "learning_rate": 6.4375e-08,
      "logits/chosen": 1.5908631086349487,
      "logits/rejected": 1.4742075204849243,
      "logps/chosen": -37.251434326171875,
      "logps/rejected": -61.25102996826172,
      "loss": 0.6524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025504756718873978,
      "rewards/margins": 0.08364059776067734,
      "rewards/rejected": -0.05813584476709366,
      "step": 477
    },
    {
      "epoch": 36.8,
      "grad_norm": 6.546967029571533,
      "learning_rate": 6.429687499999999e-08,
      "logits/chosen": 1.2410311698913574,
      "logits/rejected": 1.2558293342590332,
      "logps/chosen": -30.54475212097168,
      "logps/rejected": -53.18360137939453,
      "loss": 0.6662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0208616741001606,
      "rewards/margins": 0.054880429059267044,
      "rewards/rejected": -0.034018754959106445,
      "step": 478
    },
    {
      "epoch": 36.88,
      "grad_norm": 7.830621719360352,
      "learning_rate": 6.421875e-08,
      "logits/chosen": 1.3228403329849243,
      "logits/rejected": 1.371989130973816,
      "logps/chosen": -33.47193145751953,
      "logps/rejected": -57.64558410644531,
      "loss": 0.6643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0235091932117939,
      "rewards/margins": 0.058803632855415344,
      "rewards/rejected": -0.035294435918331146,
      "step": 479
    },
    {
      "epoch": 36.96,
      "grad_norm": 6.7604193687438965,
      "learning_rate": 6.4140625e-08,
      "logits/chosen": 1.424631118774414,
      "logits/rejected": 1.5063889026641846,
      "logps/chosen": -34.308876037597656,
      "logps/rejected": -64.17121887207031,
      "loss": 0.6653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015570569783449173,
      "rewards/margins": 0.05686793476343155,
      "rewards/rejected": -0.041297364979982376,
      "step": 480
    },
    {
      "epoch": 37.0,
      "grad_norm": 11.460980415344238,
      "learning_rate": 6.40625e-08,
      "logits/chosen": 1.3505712747573853,
      "logits/rejected": 1.2396714687347412,
      "logps/chosen": -41.42967987060547,
      "logps/rejected": -60.56542205810547,
      "loss": 0.6392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.031714726239442825,
      "rewards/margins": 0.11102810502052307,
      "rewards/rejected": -0.07931337505578995,
      "step": 481
    },
    {
      "epoch": 37.0,
      "eval_logits/chosen": 1.3144066333770752,
      "eval_logits/rejected": 1.205741286277771,
      "eval_logps/chosen": -34.26189041137695,
      "eval_logps/rejected": -47.141212463378906,
      "eval_loss": 0.6745631694793701,
      "eval_rewards/accuracies": 0.8700000047683716,
      "eval_rewards/chosen": 0.02376263402402401,
      "eval_rewards/margins": 0.03776533529162407,
      "eval_rewards/rejected": -0.01400270126760006,
      "eval_runtime": 2.7395,
      "eval_samples_per_second": 36.503,
      "eval_steps_per_second": 18.252,
      "step": 481
    },
    {
      "epoch": 37.08,
      "grad_norm": 6.918969631195068,
      "learning_rate": 6.3984375e-08,
      "logits/chosen": 1.421557068824768,
      "logits/rejected": 1.4254952669143677,
      "logps/chosen": -34.71524429321289,
      "logps/rejected": -57.73504638671875,
      "loss": 0.656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0338604710996151,
      "rewards/margins": 0.07594998180866241,
      "rewards/rejected": -0.04208951070904732,
      "step": 482
    },
    {
      "epoch": 37.16,
      "grad_norm": 7.538917064666748,
      "learning_rate": 6.390625e-08,
      "logits/chosen": 1.2404356002807617,
      "logits/rejected": 1.2155704498291016,
      "logps/chosen": -35.072166442871094,
      "logps/rejected": -53.17815399169922,
      "loss": 0.665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02161874808371067,
      "rewards/margins": 0.057450488209724426,
      "rewards/rejected": -0.035831741988658905,
      "step": 483
    },
    {
      "epoch": 37.24,
      "grad_norm": 8.398475646972656,
      "learning_rate": 6.3828125e-08,
      "logits/chosen": 1.1415132284164429,
      "logits/rejected": 1.2269872426986694,
      "logps/chosen": -33.697147369384766,
      "logps/rejected": -59.66992950439453,
      "loss": 0.648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028959179297089577,
      "rewards/margins": 0.09367785602807999,
      "rewards/rejected": -0.06471867859363556,
      "step": 484
    },
    {
      "epoch": 37.32,
      "grad_norm": 8.543903350830078,
      "learning_rate": 6.375e-08,
      "logits/chosen": 1.2894772291183472,
      "logits/rejected": 1.4109153747558594,
      "logps/chosen": -31.145530700683594,
      "logps/rejected": -54.65021896362305,
      "loss": 0.6576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03197292983531952,
      "rewards/margins": 0.07268290221691132,
      "rewards/rejected": -0.0407099723815918,
      "step": 485
    },
    {
      "epoch": 37.4,
      "grad_norm": 6.609200954437256,
      "learning_rate": 6.3671875e-08,
      "logits/chosen": 1.4191092252731323,
      "logits/rejected": 1.4987664222717285,
      "logps/chosen": -34.11109924316406,
      "logps/rejected": -53.07947540283203,
      "loss": 0.6598,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.029793906956911087,
      "rewards/margins": 0.06829039752483368,
      "rewards/rejected": -0.03849649429321289,
      "step": 486
    },
    {
      "epoch": 37.48,
      "grad_norm": 7.665472984313965,
      "learning_rate": 6.359375e-08,
      "logits/chosen": 1.1826691627502441,
      "logits/rejected": 1.2483339309692383,
      "logps/chosen": -33.520790100097656,
      "logps/rejected": -53.98167419433594,
      "loss": 0.6598,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018308091908693314,
      "rewards/margins": 0.06800525635480881,
      "rewards/rejected": -0.049697160720825195,
      "step": 487
    },
    {
      "epoch": 37.56,
      "grad_norm": 7.285721778869629,
      "learning_rate": 6.3515625e-08,
      "logits/chosen": 1.33855140209198,
      "logits/rejected": 1.2787665128707886,
      "logps/chosen": -34.94084548950195,
      "logps/rejected": -63.64039611816406,
      "loss": 0.6616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01971275731921196,
      "rewards/margins": 0.06429941952228546,
      "rewards/rejected": -0.0445866584777832,
      "step": 488
    },
    {
      "epoch": 37.64,
      "grad_norm": 7.875067710876465,
      "learning_rate": 6.34375e-08,
      "logits/chosen": 1.3341020345687866,
      "logits/rejected": 1.0735331773757935,
      "logps/chosen": -31.599618911743164,
      "logps/rejected": -60.32445526123047,
      "loss": 0.6464,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03270426020026207,
      "rewards/margins": 0.09620872139930725,
      "rewards/rejected": -0.06350445747375488,
      "step": 489
    },
    {
      "epoch": 37.72,
      "grad_norm": 8.352462768554688,
      "learning_rate": 6.335937499999999e-08,
      "logits/chosen": 1.1699901819229126,
      "logits/rejected": 1.1414275169372559,
      "logps/chosen": -35.61754608154297,
      "logps/rejected": -60.82577896118164,
      "loss": 0.6475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022823262959718704,
      "rewards/margins": 0.09375312179327011,
      "rewards/rejected": -0.0709298625588417,
      "step": 490
    },
    {
      "epoch": 37.8,
      "grad_norm": 7.439938068389893,
      "learning_rate": 6.328125e-08,
      "logits/chosen": 1.4195631742477417,
      "logits/rejected": 1.2304353713989258,
      "logps/chosen": -32.43558883666992,
      "logps/rejected": -54.83720397949219,
      "loss": 0.6573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023931454867124557,
      "rewards/margins": 0.07350768893957138,
      "rewards/rejected": -0.04957623779773712,
      "step": 491
    },
    {
      "epoch": 37.88,
      "grad_norm": 6.810654640197754,
      "learning_rate": 6.3203125e-08,
      "logits/chosen": 1.1096794605255127,
      "logits/rejected": 1.1798509359359741,
      "logps/chosen": -32.35964584350586,
      "logps/rejected": -52.165802001953125,
      "loss": 0.6578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012791704386472702,
      "rewards/margins": 0.07242448627948761,
      "rewards/rejected": -0.05963278189301491,
      "step": 492
    },
    {
      "epoch": 37.96,
      "grad_norm": 6.889595985412598,
      "learning_rate": 6.312499999999999e-08,
      "logits/chosen": 1.3659021854400635,
      "logits/rejected": 1.3018893003463745,
      "logps/chosen": -38.34750747680664,
      "logps/rejected": -47.12356948852539,
      "loss": 0.6605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022245503962039948,
      "rewards/margins": 0.06670017540454865,
      "rewards/rejected": -0.0444546714425087,
      "step": 493
    },
    {
      "epoch": 38.0,
      "grad_norm": 8.598501205444336,
      "learning_rate": 6.3046875e-08,
      "logits/chosen": 1.6791577339172363,
      "logits/rejected": 1.2784699201583862,
      "logps/chosen": -34.14553451538086,
      "logps/rejected": -41.50531768798828,
      "loss": 0.6513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028870441019535065,
      "rewards/margins": 0.08576293289661407,
      "rewards/rejected": -0.05689249187707901,
      "step": 494
    },
    {
      "epoch": 38.0,
      "eval_logits/chosen": 1.3182154893875122,
      "eval_logits/rejected": 1.2083451747894287,
      "eval_logps/chosen": -34.277217864990234,
      "eval_logps/rejected": -47.14884948730469,
      "eval_loss": 0.6749551296234131,
      "eval_rewards/accuracies": 0.8999999761581421,
      "eval_rewards/chosen": 0.022229908034205437,
      "eval_rewards/margins": 0.03699585050344467,
      "eval_rewards/rejected": -0.01476594340056181,
      "eval_runtime": 2.7408,
      "eval_samples_per_second": 36.486,
      "eval_steps_per_second": 18.243,
      "step": 494
    },
    {
      "epoch": 38.08,
      "grad_norm": 8.085367202758789,
      "learning_rate": 6.296874999999999e-08,
      "logits/chosen": 1.6257529258728027,
      "logits/rejected": 1.2960636615753174,
      "logps/chosen": -42.50869369506836,
      "logps/rejected": -56.87008285522461,
      "loss": 0.6527,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014788818545639515,
      "rewards/margins": 0.0836850106716156,
      "rewards/rejected": -0.06889619678258896,
      "step": 495
    },
    {
      "epoch": 38.16,
      "grad_norm": 7.668026447296143,
      "learning_rate": 6.2890625e-08,
      "logits/chosen": 1.165009617805481,
      "logits/rejected": 1.3533986806869507,
      "logps/chosen": -37.04953384399414,
      "logps/rejected": -58.20307922363281,
      "loss": 0.6592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013656163588166237,
      "rewards/margins": 0.06929400563240051,
      "rewards/rejected": -0.05563783645629883,
      "step": 496
    },
    {
      "epoch": 38.24,
      "grad_norm": 6.978055000305176,
      "learning_rate": 6.281250000000001e-08,
      "logits/chosen": 1.3673675060272217,
      "logits/rejected": 1.1952916383743286,
      "logps/chosen": -32.67376708984375,
      "logps/rejected": -46.914215087890625,
      "loss": 0.654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014675164595246315,
      "rewards/margins": 0.07995688915252686,
      "rewards/rejected": -0.06528172641992569,
      "step": 497
    },
    {
      "epoch": 38.32,
      "grad_norm": 6.8081159591674805,
      "learning_rate": 6.2734375e-08,
      "logits/chosen": 1.1849467754364014,
      "logits/rejected": 0.9714795351028442,
      "logps/chosen": -31.80438995361328,
      "logps/rejected": -51.9588737487793,
      "loss": 0.6603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013792229816317558,
      "rewards/margins": 0.06702480465173721,
      "rewards/rejected": -0.053232576698064804,
      "step": 498
    },
    {
      "epoch": 38.4,
      "grad_norm": 8.74131965637207,
      "learning_rate": 6.265625e-08,
      "logits/chosen": 1.0256541967391968,
      "logits/rejected": 1.2465490102767944,
      "logps/chosen": -30.41573143005371,
      "logps/rejected": -50.39679718017578,
      "loss": 0.6509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03653226047754288,
      "rewards/margins": 0.08673600852489471,
      "rewards/rejected": -0.050203755497932434,
      "step": 499
    },
    {
      "epoch": 38.48,
      "grad_norm": 7.529178142547607,
      "learning_rate": 6.2578125e-08,
      "logits/chosen": 1.4258683919906616,
      "logits/rejected": 1.2592607736587524,
      "logps/chosen": -31.127647399902344,
      "logps/rejected": -56.51511764526367,
      "loss": 0.6496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028212452307343483,
      "rewards/margins": 0.08924289047718048,
      "rewards/rejected": -0.06103044003248215,
      "step": 500
    },
    {
      "epoch": 38.56,
      "grad_norm": 6.999652862548828,
      "learning_rate": 6.25e-08,
      "logits/chosen": 1.2054567337036133,
      "logits/rejected": 1.4509572982788086,
      "logps/chosen": -32.13899230957031,
      "logps/rejected": -57.12828063964844,
      "loss": 0.6582,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019150568172335625,
      "rewards/margins": 0.07175014913082123,
      "rewards/rejected": -0.052599579095840454,
      "step": 501
    },
    {
      "epoch": 38.64,
      "grad_norm": 7.676937580108643,
      "learning_rate": 6.2421875e-08,
      "logits/chosen": 1.5971958637237549,
      "logits/rejected": 1.3993998765945435,
      "logps/chosen": -32.53431701660156,
      "logps/rejected": -54.878536224365234,
      "loss": 0.6587,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.021623993292450905,
      "rewards/margins": 0.07041049003601074,
      "rewards/rejected": -0.04878649488091469,
      "step": 502
    },
    {
      "epoch": 38.72,
      "grad_norm": 8.490344047546387,
      "learning_rate": 6.234375e-08,
      "logits/chosen": 1.2156376838684082,
      "logits/rejected": 1.1745479106903076,
      "logps/chosen": -31.36250114440918,
      "logps/rejected": -64.98200988769531,
      "loss": 0.6475,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03547036647796631,
      "rewards/margins": 0.09537437558174133,
      "rewards/rejected": -0.059904009103775024,
      "step": 503
    },
    {
      "epoch": 38.8,
      "grad_norm": 7.059032917022705,
      "learning_rate": 6.2265625e-08,
      "logits/chosen": 1.3347300291061401,
      "logits/rejected": 1.316579818725586,
      "logps/chosen": -34.9066047668457,
      "logps/rejected": -51.255332946777344,
      "loss": 0.6515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03198826313018799,
      "rewards/margins": 0.08571246266365051,
      "rewards/rejected": -0.05372419208288193,
      "step": 504
    },
    {
      "epoch": 38.88,
      "grad_norm": 7.466157913208008,
      "learning_rate": 6.218749999999999e-08,
      "logits/chosen": 1.2907772064208984,
      "logits/rejected": 1.38278067111969,
      "logps/chosen": -39.291019439697266,
      "logps/rejected": -64.77445220947266,
      "loss": 0.6612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014783740043640137,
      "rewards/margins": 0.06536953896284103,
      "rewards/rejected": -0.0505857951939106,
      "step": 505
    },
    {
      "epoch": 38.96,
      "grad_norm": 7.318035125732422,
      "learning_rate": 6.2109375e-08,
      "logits/chosen": 1.255528211593628,
      "logits/rejected": 1.0672744512557983,
      "logps/chosen": -33.666221618652344,
      "logps/rejected": -49.51917266845703,
      "loss": 0.6519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.041350699961185455,
      "rewards/margins": 0.08443837612867355,
      "rewards/rejected": -0.0430876761674881,
      "step": 506
    },
    {
      "epoch": 39.0,
      "grad_norm": 8.69411563873291,
      "learning_rate": 6.203125e-08,
      "logits/chosen": 1.3748576641082764,
      "logits/rejected": 1.369042158126831,
      "logps/chosen": -30.347126007080078,
      "logps/rejected": -57.8454475402832,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029928207397460938,
      "rewards/margins": 0.056344032287597656,
      "rewards/rejected": -0.02641582489013672,
      "step": 507
    },
    {
      "epoch": 39.0,
      "eval_logits/chosen": 1.3194656372070312,
      "eval_logits/rejected": 1.2105414867401123,
      "eval_logps/chosen": -34.27477264404297,
      "eval_logps/rejected": -47.19267272949219,
      "eval_loss": 0.6726769804954529,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.022474179044365883,
      "eval_rewards/margins": 0.041622743010520935,
      "eval_rewards/rejected": -0.019148562103509903,
      "eval_runtime": 2.7421,
      "eval_samples_per_second": 36.468,
      "eval_steps_per_second": 18.234,
      "step": 507
    },
    {
      "epoch": 39.08,
      "grad_norm": 6.946188926696777,
      "learning_rate": 6.195312499999999e-08,
      "logits/chosen": 1.3683850765228271,
      "logits/rejected": 1.3571172952651978,
      "logps/chosen": -36.69757080078125,
      "logps/rejected": -49.67744064331055,
      "loss": 0.6619,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026699615642428398,
      "rewards/margins": 0.06377717852592468,
      "rewards/rejected": -0.03707757219672203,
      "step": 508
    },
    {
      "epoch": 39.16,
      "grad_norm": 7.550082206726074,
      "learning_rate": 6.1875e-08,
      "logits/chosen": 1.4026821851730347,
      "logits/rejected": 1.1989996433258057,
      "logps/chosen": -37.538330078125,
      "logps/rejected": -58.66381072998047,
      "loss": 0.6613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006112431176006794,
      "rewards/margins": 0.06515255570411682,
      "rewards/rejected": -0.059040118008852005,
      "step": 509
    },
    {
      "epoch": 39.24,
      "grad_norm": 7.464168548583984,
      "learning_rate": 6.179687499999999e-08,
      "logits/chosen": 1.461029052734375,
      "logits/rejected": 1.2282623052597046,
      "logps/chosen": -30.008798599243164,
      "logps/rejected": -52.82495880126953,
      "loss": 0.6583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017894936725497246,
      "rewards/margins": 0.0709514170885086,
      "rewards/rejected": -0.05305647850036621,
      "step": 510
    },
    {
      "epoch": 39.32,
      "grad_norm": 7.0258965492248535,
      "learning_rate": 6.171874999999999e-08,
      "logits/chosen": 1.0222967863082886,
      "logits/rejected": 1.0387686491012573,
      "logps/chosen": -31.74081802368164,
      "logps/rejected": -54.08211898803711,
      "loss": 0.6608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004718828480690718,
      "rewards/margins": 0.06611161679029465,
      "rewards/rejected": -0.06139278784394264,
      "step": 511
    },
    {
      "epoch": 39.4,
      "grad_norm": 7.983788013458252,
      "learning_rate": 6.1640625e-08,
      "logits/chosen": 1.2365312576293945,
      "logits/rejected": 1.4263743162155151,
      "logps/chosen": -30.38652229309082,
      "logps/rejected": -53.00638961791992,
      "loss": 0.6515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03548276424407959,
      "rewards/margins": 0.08542678505182266,
      "rewards/rejected": -0.04994402080774307,
      "step": 512
    },
    {
      "epoch": 39.48,
      "grad_norm": 7.926121711730957,
      "learning_rate": 6.156249999999999e-08,
      "logits/chosen": 1.5155181884765625,
      "logits/rejected": 1.2489358186721802,
      "logps/chosen": -30.082731246948242,
      "logps/rejected": -48.36796569824219,
      "loss": 0.6478,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.042269062250852585,
      "rewards/margins": 0.09311933815479279,
      "rewards/rejected": -0.0508502721786499,
      "step": 513
    },
    {
      "epoch": 39.56,
      "grad_norm": 7.212852478027344,
      "learning_rate": 6.1484375e-08,
      "logits/chosen": 1.495441198348999,
      "logits/rejected": 1.189876675605774,
      "logps/chosen": -33.85593032836914,
      "logps/rejected": -46.941612243652344,
      "loss": 0.6542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.031358957290649414,
      "rewards/margins": 0.07989001274108887,
      "rewards/rejected": -0.04853105545043945,
      "step": 514
    },
    {
      "epoch": 39.64,
      "grad_norm": 7.568109035491943,
      "learning_rate": 6.140625e-08,
      "logits/chosen": 1.0087454319000244,
      "logits/rejected": 1.3915300369262695,
      "logps/chosen": -35.40629959106445,
      "logps/rejected": -59.73208999633789,
      "loss": 0.6572,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028162121772766113,
      "rewards/margins": 0.0734025239944458,
      "rewards/rejected": -0.04524040222167969,
      "step": 515
    },
    {
      "epoch": 39.72,
      "grad_norm": 7.10251522064209,
      "learning_rate": 6.1328125e-08,
      "logits/chosen": 1.2905910015106201,
      "logits/rejected": 1.2564460039138794,
      "logps/chosen": -33.295753479003906,
      "logps/rejected": -51.868682861328125,
      "loss": 0.6648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006919408217072487,
      "rewards/margins": 0.05794256180524826,
      "rewards/rejected": -0.051023151725530624,
      "step": 516
    },
    {
      "epoch": 39.8,
      "grad_norm": 7.245423793792725,
      "learning_rate": 6.125e-08,
      "logits/chosen": 1.3266091346740723,
      "logits/rejected": 1.4471135139465332,
      "logps/chosen": -35.58338928222656,
      "logps/rejected": -63.11845397949219,
      "loss": 0.6636,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025397516787052155,
      "rewards/margins": 0.060289166867733,
      "rewards/rejected": -0.034891653805971146,
      "step": 517
    },
    {
      "epoch": 39.88,
      "grad_norm": 11.24264144897461,
      "learning_rate": 6.1171875e-08,
      "logits/chosen": 1.3810018301010132,
      "logits/rejected": 1.0816341638565063,
      "logps/chosen": -39.28681945800781,
      "logps/rejected": -62.492164611816406,
      "loss": 0.6341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015938330441713333,
      "rewards/margins": 0.12280145287513733,
      "rewards/rejected": -0.1068631187081337,
      "step": 518
    },
    {
      "epoch": 39.96,
      "grad_norm": 8.077198028564453,
      "learning_rate": 6.109375e-08,
      "logits/chosen": 1.169678807258606,
      "logits/rejected": 1.2860445976257324,
      "logps/chosen": -33.337432861328125,
      "logps/rejected": -62.445621490478516,
      "loss": 0.654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026890158653259277,
      "rewards/margins": 0.0803057923913002,
      "rewards/rejected": -0.053415633738040924,
      "step": 519
    },
    {
      "epoch": 40.0,
      "grad_norm": 8.099069595336914,
      "learning_rate": 6.1015625e-08,
      "logits/chosen": 1.5323312282562256,
      "logits/rejected": 1.5053399801254272,
      "logps/chosen": -35.260154724121094,
      "logps/rejected": -58.08219528198242,
      "loss": 0.6646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0234269630163908,
      "rewards/margins": 0.05799422413110733,
      "rewards/rejected": -0.03456725925207138,
      "step": 520
    },
    {
      "epoch": 40.0,
      "eval_logits/chosen": 1.3198537826538086,
      "eval_logits/rejected": 1.2089253664016724,
      "eval_logps/chosen": -34.2555046081543,
      "eval_logps/rejected": -47.15483093261719,
      "eval_loss": 0.6736122369766235,
      "eval_rewards/accuracies": 0.8600000143051147,
      "eval_rewards/chosen": 0.024401122704148293,
      "eval_rewards/margins": 0.039765167981386185,
      "eval_rewards/rejected": -0.015364043414592743,
      "eval_runtime": 2.7331,
      "eval_samples_per_second": 36.588,
      "eval_steps_per_second": 18.294,
      "step": 520
    },
    {
      "epoch": 40.08,
      "grad_norm": 7.758838176727295,
      "learning_rate": 6.09375e-08,
      "logits/chosen": 1.3769886493682861,
      "logits/rejected": 1.2983962297439575,
      "logps/chosen": -34.97807693481445,
      "logps/rejected": -58.96815490722656,
      "loss": 0.6476,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.031334925442934036,
      "rewards/margins": 0.09481815993785858,
      "rewards/rejected": -0.06348323822021484,
      "step": 521
    },
    {
      "epoch": 40.16,
      "grad_norm": 7.458619117736816,
      "learning_rate": 6.0859375e-08,
      "logits/chosen": 1.5869544744491577,
      "logits/rejected": 1.3408092260360718,
      "logps/chosen": -36.85997009277344,
      "logps/rejected": -51.27495574951172,
      "loss": 0.6642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0039234403520822525,
      "rewards/margins": 0.05899389088153839,
      "rewards/rejected": -0.05507044866681099,
      "step": 522
    },
    {
      "epoch": 40.24,
      "grad_norm": 6.985169410705566,
      "learning_rate": 6.078125e-08,
      "logits/chosen": 1.242178201675415,
      "logits/rejected": 1.339263916015625,
      "logps/chosen": -33.36231994628906,
      "logps/rejected": -63.746803283691406,
      "loss": 0.648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023829126730561256,
      "rewards/margins": 0.0927911251783371,
      "rewards/rejected": -0.06896200031042099,
      "step": 523
    },
    {
      "epoch": 40.32,
      "grad_norm": 8.130535125732422,
      "learning_rate": 6.0703125e-08,
      "logits/chosen": 1.0477389097213745,
      "logits/rejected": 1.16707444190979,
      "logps/chosen": -32.145111083984375,
      "logps/rejected": -57.84974670410156,
      "loss": 0.6469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0312667153775692,
      "rewards/margins": 0.09488456696271896,
      "rewards/rejected": -0.06361784785985947,
      "step": 524
    },
    {
      "epoch": 40.4,
      "grad_norm": 7.311985015869141,
      "learning_rate": 6.062499999999999e-08,
      "logits/chosen": 1.4047213792800903,
      "logits/rejected": 1.2681435346603394,
      "logps/chosen": -36.64041519165039,
      "logps/rejected": -48.987056732177734,
      "loss": 0.6619,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024815868586301804,
      "rewards/margins": 0.06356189399957657,
      "rewards/rejected": -0.038746025413274765,
      "step": 525
    },
    {
      "epoch": 40.48,
      "grad_norm": 7.676743030548096,
      "learning_rate": 6.0546875e-08,
      "logits/chosen": 1.3992960453033447,
      "logits/rejected": 1.3471331596374512,
      "logps/chosen": -39.9211311340332,
      "logps/rejected": -65.30596923828125,
      "loss": 0.6583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0001750707160681486,
      "rewards/margins": 0.07125494629144669,
      "rewards/rejected": -0.07107987254858017,
      "step": 526
    },
    {
      "epoch": 40.56,
      "grad_norm": 7.501766204833984,
      "learning_rate": 6.046875e-08,
      "logits/chosen": 1.2417200803756714,
      "logits/rejected": 1.2065889835357666,
      "logps/chosen": -29.469985961914062,
      "logps/rejected": -51.325523376464844,
      "loss": 0.6471,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03997178003191948,
      "rewards/margins": 0.09454698860645294,
      "rewards/rejected": -0.054575204849243164,
      "step": 527
    },
    {
      "epoch": 40.64,
      "grad_norm": 7.87395715713501,
      "learning_rate": 6.039062499999999e-08,
      "logits/chosen": 1.3026423454284668,
      "logits/rejected": 1.3198801279067993,
      "logps/chosen": -32.18450164794922,
      "logps/rejected": -59.69877243041992,
      "loss": 0.6396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03833957016468048,
      "rewards/margins": 0.11035819351673126,
      "rewards/rejected": -0.07201862335205078,
      "step": 528
    },
    {
      "epoch": 40.72,
      "grad_norm": 7.5686869621276855,
      "learning_rate": 6.03125e-08,
      "logits/chosen": 1.3626890182495117,
      "logits/rejected": 1.1995043754577637,
      "logps/chosen": -36.23606491088867,
      "logps/rejected": -51.48062515258789,
      "loss": 0.6486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020092202350497246,
      "rewards/margins": 0.09134797751903534,
      "rewards/rejected": -0.07125578075647354,
      "step": 529
    },
    {
      "epoch": 40.8,
      "grad_norm": 8.200336456298828,
      "learning_rate": 6.023437499999999e-08,
      "logits/chosen": 1.2261849641799927,
      "logits/rejected": 1.2425334453582764,
      "logps/chosen": -29.701446533203125,
      "logps/rejected": -53.191978454589844,
      "loss": 0.6497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04160737991333008,
      "rewards/margins": 0.08932504802942276,
      "rewards/rejected": -0.04771766811609268,
      "step": 530
    },
    {
      "epoch": 40.88,
      "grad_norm": 7.470337390899658,
      "learning_rate": 6.015624999999999e-08,
      "logits/chosen": 1.2188063859939575,
      "logits/rejected": 1.2385250329971313,
      "logps/chosen": -33.556365966796875,
      "logps/rejected": -52.094482421875,
      "loss": 0.655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0236436128616333,
      "rewards/margins": 0.07811768352985382,
      "rewards/rejected": -0.05447406694293022,
      "step": 531
    },
    {
      "epoch": 40.96,
      "grad_norm": 7.775904178619385,
      "learning_rate": 6.007812500000001e-08,
      "logits/chosen": 1.323328971862793,
      "logits/rejected": 1.3162072896957397,
      "logps/chosen": -31.300992965698242,
      "logps/rejected": -53.62529754638672,
      "loss": 0.6501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03633110597729683,
      "rewards/margins": 0.08818371593952179,
      "rewards/rejected": -0.05185260996222496,
      "step": 532
    },
    {
      "epoch": 41.0,
      "grad_norm": 9.80588436126709,
      "learning_rate": 6e-08,
      "logits/chosen": 1.1544944047927856,
      "logits/rejected": 1.1339197158813477,
      "logps/chosen": -35.99738311767578,
      "logps/rejected": -50.803863525390625,
      "loss": 0.6597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02390904538333416,
      "rewards/margins": 0.06819634139537811,
      "rewards/rejected": -0.0442873015999794,
      "step": 533
    },
    {
      "epoch": 41.0,
      "eval_logits/chosen": 1.319914698600769,
      "eval_logits/rejected": 1.2103267908096313,
      "eval_logps/chosen": -34.270965576171875,
      "eval_logps/rejected": -47.19951629638672,
      "eval_loss": 0.6721806526184082,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.02285473607480526,
      "eval_rewards/margins": 0.04268778860569,
      "eval_rewards/rejected": -0.019833052530884743,
      "eval_runtime": 2.7319,
      "eval_samples_per_second": 36.605,
      "eval_steps_per_second": 18.303,
      "step": 533
    },
    {
      "epoch": 41.08,
      "grad_norm": 7.399885654449463,
      "learning_rate": 5.9921875e-08,
      "logits/chosen": 1.3811129331588745,
      "logits/rejected": 1.3281186819076538,
      "logps/chosen": -37.41798400878906,
      "logps/rejected": -53.30225372314453,
      "loss": 0.6479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03220710903406143,
      "rewards/margins": 0.09283442795276642,
      "rewards/rejected": -0.06062731891870499,
      "step": 534
    },
    {
      "epoch": 41.16,
      "grad_norm": 7.276308536529541,
      "learning_rate": 5.984375e-08,
      "logits/chosen": 1.520649790763855,
      "logits/rejected": 1.1596653461456299,
      "logps/chosen": -31.332199096679688,
      "logps/rejected": -56.584102630615234,
      "loss": 0.6542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017381763085722923,
      "rewards/margins": 0.07975678890943527,
      "rewards/rejected": -0.0623750202357769,
      "step": 535
    },
    {
      "epoch": 41.24,
      "grad_norm": 7.061758041381836,
      "learning_rate": 5.9765625e-08,
      "logits/chosen": 1.3502005338668823,
      "logits/rejected": 1.1414225101470947,
      "logps/chosen": -31.98697280883789,
      "logps/rejected": -55.27900695800781,
      "loss": 0.6583,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014613439328968525,
      "rewards/margins": 0.07125063240528107,
      "rewards/rejected": -0.05663719028234482,
      "step": 536
    },
    {
      "epoch": 41.32,
      "grad_norm": 7.323317527770996,
      "learning_rate": 5.96875e-08,
      "logits/chosen": 1.288145899772644,
      "logits/rejected": 1.3153564929962158,
      "logps/chosen": -33.51286315917969,
      "logps/rejected": -50.78715133666992,
      "loss": 0.6457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03936755657196045,
      "rewards/margins": 0.09766576439142227,
      "rewards/rejected": -0.05829820781946182,
      "step": 537
    },
    {
      "epoch": 41.4,
      "grad_norm": 8.45263385772705,
      "learning_rate": 5.9609375e-08,
      "logits/chosen": 1.5384068489074707,
      "logits/rejected": 1.2168660163879395,
      "logps/chosen": -34.893531799316406,
      "logps/rejected": -57.54795837402344,
      "loss": 0.6494,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00888833962380886,
      "rewards/margins": 0.0898451879620552,
      "rewards/rejected": -0.0809568390250206,
      "step": 538
    },
    {
      "epoch": 41.48,
      "grad_norm": 7.575125694274902,
      "learning_rate": 5.953125e-08,
      "logits/chosen": 1.22282075881958,
      "logits/rejected": 1.1616994142532349,
      "logps/chosen": -36.531280517578125,
      "logps/rejected": -49.13349151611328,
      "loss": 0.6527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030073165893554688,
      "rewards/margins": 0.0827544778585434,
      "rewards/rejected": -0.05268130451440811,
      "step": 539
    },
    {
      "epoch": 41.56,
      "grad_norm": 7.480551242828369,
      "learning_rate": 5.945312499999999e-08,
      "logits/chosen": 1.198103427886963,
      "logits/rejected": 1.3336797952651978,
      "logps/chosen": -31.68997573852539,
      "logps/rejected": -57.63514709472656,
      "loss": 0.6549,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029407860711216927,
      "rewards/margins": 0.07840169221162796,
      "rewards/rejected": -0.048993825912475586,
      "step": 540
    },
    {
      "epoch": 41.64,
      "grad_norm": 8.49543571472168,
      "learning_rate": 5.9375e-08,
      "logits/chosen": 1.052739143371582,
      "logits/rejected": 1.363353967666626,
      "logps/chosen": -28.486122131347656,
      "logps/rejected": -56.08041763305664,
      "loss": 0.6424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.045635294169187546,
      "rewards/margins": 0.10441486537456512,
      "rewards/rejected": -0.05877957493066788,
      "step": 541
    },
    {
      "epoch": 41.72,
      "grad_norm": 8.236678123474121,
      "learning_rate": 5.9296875e-08,
      "logits/chosen": 1.4985328912734985,
      "logits/rejected": 1.2681894302368164,
      "logps/chosen": -38.62400817871094,
      "logps/rejected": -57.088829040527344,
      "loss": 0.6477,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029805732890963554,
      "rewards/margins": 0.09349821507930756,
      "rewards/rejected": -0.06369247287511826,
      "step": 542
    },
    {
      "epoch": 41.8,
      "grad_norm": 6.229948997497559,
      "learning_rate": 5.9218749999999996e-08,
      "logits/chosen": 1.2748804092407227,
      "logits/rejected": 1.2989283800125122,
      "logps/chosen": -35.77403259277344,
      "logps/rejected": -53.19285583496094,
      "loss": 0.662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020800519734621048,
      "rewards/margins": 0.06350186467170715,
      "rewards/rejected": -0.04270134121179581,
      "step": 543
    },
    {
      "epoch": 41.88,
      "grad_norm": 9.105314254760742,
      "learning_rate": 5.9140624999999996e-08,
      "logits/chosen": 1.2275679111480713,
      "logits/rejected": 1.1221848726272583,
      "logps/chosen": -31.2950382232666,
      "logps/rejected": -58.562095642089844,
      "loss": 0.6429,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03240857273340225,
      "rewards/margins": 0.10446944832801819,
      "rewards/rejected": -0.07206087559461594,
      "step": 544
    },
    {
      "epoch": 41.96,
      "grad_norm": 6.858238220214844,
      "learning_rate": 5.906249999999999e-08,
      "logits/chosen": 1.2588943243026733,
      "logits/rejected": 1.4185945987701416,
      "logps/chosen": -34.05546188354492,
      "logps/rejected": -57.58027648925781,
      "loss": 0.6624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023616790771484375,
      "rewards/margins": 0.06307894736528397,
      "rewards/rejected": -0.03946216404438019,
      "step": 545
    },
    {
      "epoch": 42.0,
      "grad_norm": 9.216362953186035,
      "learning_rate": 5.8984375e-08,
      "logits/chosen": 1.1392465829849243,
      "logits/rejected": 1.4544744491577148,
      "logps/chosen": -37.63927459716797,
      "logps/rejected": -60.33805847167969,
      "loss": 0.6639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0119492057710886,
      "rewards/margins": 0.05953851342201233,
      "rewards/rejected": -0.04758930206298828,
      "step": 546
    },
    {
      "epoch": 42.0,
      "eval_logits/chosen": 1.318742275238037,
      "eval_logits/rejected": 1.20792818069458,
      "eval_logps/chosen": -34.25679397583008,
      "eval_logps/rejected": -47.192039489746094,
      "eval_loss": 0.6718528866767883,
      "eval_rewards/accuracies": 0.8799999952316284,
      "eval_rewards/chosen": 0.02427203580737114,
      "eval_rewards/margins": 0.04335740581154823,
      "eval_rewards/rejected": -0.019085366278886795,
      "eval_runtime": 2.7465,
      "eval_samples_per_second": 36.41,
      "eval_steps_per_second": 18.205,
      "step": 546
    },
    {
      "epoch": 42.08,
      "grad_norm": 7.922475337982178,
      "learning_rate": 5.890625e-08,
      "logits/chosen": 1.2312153577804565,
      "logits/rejected": 1.4628286361694336,
      "logps/chosen": -28.721141815185547,
      "logps/rejected": -49.088462829589844,
      "loss": 0.6372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05813467875123024,
      "rewards/margins": 0.11564982682466507,
      "rewards/rejected": -0.05751514434814453,
      "step": 547
    },
    {
      "epoch": 42.16,
      "grad_norm": 7.109045505523682,
      "learning_rate": 5.882812499999999e-08,
      "logits/chosen": 1.1665971279144287,
      "logits/rejected": 1.290835976600647,
      "logps/chosen": -33.4113655090332,
      "logps/rejected": -59.51985549926758,
      "loss": 0.6612,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014514804817736149,
      "rewards/margins": 0.0651080384850502,
      "rewards/rejected": -0.05059323459863663,
      "step": 548
    },
    {
      "epoch": 42.24,
      "grad_norm": 8.477423667907715,
      "learning_rate": 5.875e-08,
      "logits/chosen": 1.321424961090088,
      "logits/rejected": 1.025965929031372,
      "logps/chosen": -32.75202178955078,
      "logps/rejected": -57.73977279663086,
      "loss": 0.6382,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.031051088124513626,
      "rewards/margins": 0.1134009137749672,
      "rewards/rejected": -0.08234982192516327,
      "step": 549
    },
    {
      "epoch": 42.32,
      "grad_norm": 7.678946018218994,
      "learning_rate": 5.8671874999999994e-08,
      "logits/chosen": 1.315006971359253,
      "logits/rejected": 1.352308750152588,
      "logps/chosen": -29.178722381591797,
      "logps/rejected": -47.437744140625,
      "loss": 0.6505,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04258885607123375,
      "rewards/margins": 0.08748960494995117,
      "rewards/rejected": -0.04490075260400772,
      "step": 550
    },
    {
      "epoch": 42.4,
      "grad_norm": 6.755233287811279,
      "learning_rate": 5.8593749999999995e-08,
      "logits/chosen": 1.2334938049316406,
      "logits/rejected": 1.3079077005386353,
      "logps/chosen": -33.179725646972656,
      "logps/rejected": -55.623191833496094,
      "loss": 0.6534,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.035898566246032715,
      "rewards/margins": 0.08154217898845673,
      "rewards/rejected": -0.04564361646771431,
      "step": 551
    },
    {
      "epoch": 42.48,
      "grad_norm": 7.566048622131348,
      "learning_rate": 5.8515625e-08,
      "logits/chosen": 1.403281569480896,
      "logits/rejected": 1.3927801847457886,
      "logps/chosen": -33.21952819824219,
      "logps/rejected": -53.75545883178711,
      "loss": 0.6498,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02882223203778267,
      "rewards/margins": 0.0888979434967041,
      "rewards/rejected": -0.06007571518421173,
      "step": 552
    },
    {
      "epoch": 42.56,
      "grad_norm": 7.402221202850342,
      "learning_rate": 5.8437499999999996e-08,
      "logits/chosen": 1.2665033340454102,
      "logits/rejected": 1.07161545753479,
      "logps/chosen": -32.00743103027344,
      "logps/rejected": -54.879051208496094,
      "loss": 0.6572,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02978501468896866,
      "rewards/margins": 0.07378330081701279,
      "rewards/rejected": -0.04399828612804413,
      "step": 553
    },
    {
      "epoch": 42.64,
      "grad_norm": 8.458291053771973,
      "learning_rate": 5.8359375e-08,
      "logits/chosen": 1.3405652046203613,
      "logits/rejected": 1.2445533275604248,
      "logps/chosen": -38.15874481201172,
      "logps/rejected": -64.57057189941406,
      "loss": 0.6557,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014289045706391335,
      "rewards/margins": 0.07669982314109802,
      "rewards/rejected": -0.062410783022642136,
      "step": 554
    },
    {
      "epoch": 42.72,
      "grad_norm": 6.7991132736206055,
      "learning_rate": 5.828124999999999e-08,
      "logits/chosen": 1.3774148225784302,
      "logits/rejected": 1.296480417251587,
      "logps/chosen": -35.59834671020508,
      "logps/rejected": -60.940452575683594,
      "loss": 0.6518,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026039889082312584,
      "rewards/margins": 0.08490706235170364,
      "rewards/rejected": -0.05886716768145561,
      "step": 555
    },
    {
      "epoch": 42.8,
      "grad_norm": 7.691030502319336,
      "learning_rate": 5.8203125e-08,
      "logits/chosen": 1.552485704421997,
      "logits/rejected": 1.2465641498565674,
      "logps/chosen": -37.22454833984375,
      "logps/rejected": -49.97291946411133,
      "loss": 0.6511,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02878263033926487,
      "rewards/margins": 0.0863964855670929,
      "rewards/rejected": -0.05761384963989258,
      "step": 556
    },
    {
      "epoch": 42.88,
      "grad_norm": 6.736451148986816,
      "learning_rate": 5.8125e-08,
      "logits/chosen": 1.2803335189819336,
      "logits/rejected": 1.3241944313049316,
      "logps/chosen": -39.243019104003906,
      "logps/rejected": -57.799041748046875,
      "loss": 0.6562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006702566519379616,
      "rewards/margins": 0.07569718360900879,
      "rewards/rejected": -0.06899461895227432,
      "step": 557
    },
    {
      "epoch": 42.96,
      "grad_norm": 8.388099670410156,
      "learning_rate": 5.8046874999999993e-08,
      "logits/chosen": 1.2328280210494995,
      "logits/rejected": 1.1117706298828125,
      "logps/chosen": -33.33871078491211,
      "logps/rejected": -57.64265060424805,
      "loss": 0.6417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03162346035242081,
      "rewards/margins": 0.1067904531955719,
      "rewards/rejected": -0.0751669853925705,
      "step": 558
    },
    {
      "epoch": 43.0,
      "grad_norm": 10.597084045410156,
      "learning_rate": 5.796875e-08,
      "logits/chosen": 1.0671333074569702,
      "logits/rejected": 1.384901762008667,
      "logps/chosen": -36.051700592041016,
      "logps/rejected": -48.08979797363281,
      "loss": 0.6563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015294646844267845,
      "rewards/margins": 0.0751689001917839,
      "rewards/rejected": -0.05987425148487091,
      "step": 559
    },
    {
      "epoch": 43.0,
      "eval_logits/chosen": 1.321018099784851,
      "eval_logits/rejected": 1.2082139253616333,
      "eval_logps/chosen": -34.221614837646484,
      "eval_logps/rejected": -47.16777038574219,
      "eval_loss": 0.6713243126869202,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.027790196239948273,
      "eval_rewards/margins": 0.04444831982254982,
      "eval_rewards/rejected": -0.016658121719956398,
      "eval_runtime": 2.7335,
      "eval_samples_per_second": 36.583,
      "eval_steps_per_second": 18.291,
      "step": 559
    }
  ],
  "logging_steps": 1,
  "max_steps": 1300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
