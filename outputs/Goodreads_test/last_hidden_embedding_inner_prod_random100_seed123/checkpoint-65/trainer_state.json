{
  "best_global_step": 65,
  "best_metric": 0.6923895478248596,
  "best_model_checkpoint": "/scratch/user/chuanhsin0110/LLMRec-Labs/unintentional-unalignment/outputs/Goodreads_test/last_hidden_embedding_inner_prod_random100_seed123/checkpoint-65",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 65,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 6.374134540557861,
      "learning_rate": 0.0,
      "logits/chosen": 1.2612364292144775,
      "logits/rejected": 1.1921188831329346,
      "logps/chosen": -39.18479919433594,
      "logps/rejected": -32.571189880371094,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.697031497955322,
      "learning_rate": 5e-09,
      "logits/chosen": 1.1266672611236572,
      "logits/rejected": 1.3085578680038452,
      "logps/chosen": -32.81430435180664,
      "logps/rejected": -36.93833923339844,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.782289981842041,
      "learning_rate": 1e-08,
      "logits/chosen": 1.35579514503479,
      "logits/rejected": 1.3279218673706055,
      "logps/chosen": -32.30202865600586,
      "logps/rejected": -48.15401840209961,
      "loss": 0.6906,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.003946566488593817,
      "rewards/margins": 0.005097461398690939,
      "rewards/rejected": -0.009044027887284756,
      "step": 3
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.010339260101318,
      "learning_rate": 1.5e-08,
      "logits/chosen": 1.3061630725860596,
      "logits/rejected": 1.446200966835022,
      "logps/chosen": -35.52410888671875,
      "logps/rejected": -45.17461013793945,
      "loss": 0.692,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0025673629716038704,
      "rewards/margins": 0.002348184585571289,
      "rewards/rejected": 0.00021917838603258133,
      "step": 4
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.633256435394287,
      "learning_rate": 2e-08,
      "logits/chosen": 1.0641745328903198,
      "logits/rejected": 1.375917911529541,
      "logps/chosen": -34.50688171386719,
      "logps/rejected": -49.04056930541992,
      "loss": 0.6921,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00044558034278452396,
      "rewards/margins": 0.0021722796373069286,
      "rewards/rejected": -0.001726699061691761,
      "step": 5
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.331296443939209,
      "learning_rate": 2.5e-08,
      "logits/chosen": 1.2896724939346313,
      "logits/rejected": 1.3760199546813965,
      "logps/chosen": -36.289398193359375,
      "logps/rejected": -42.974891662597656,
      "loss": 0.6941,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0028621437959372997,
      "rewards/margins": -0.0018397091189399362,
      "rewards/rejected": -0.0010224342113360763,
      "step": 6
    },
    {
      "epoch": 0.56,
      "grad_norm": 7.195899963378906,
      "learning_rate": 3e-08,
      "logits/chosen": 0.9915685653686523,
      "logits/rejected": 1.2463241815567017,
      "logps/chosen": -39.661155700683594,
      "logps/rejected": -44.69219207763672,
      "loss": 0.6951,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.005847120191901922,
      "rewards/margins": -0.003856587689369917,
      "rewards/rejected": 0.00970370788127184,
      "step": 7
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.019843578338623,
      "learning_rate": 3.4999999999999996e-08,
      "logits/chosen": 1.2524654865264893,
      "logits/rejected": 0.9270095825195312,
      "logps/chosen": -33.53221130371094,
      "logps/rejected": -34.37825393676758,
      "loss": 0.6962,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.006654787342995405,
      "rewards/margins": -0.00593645591288805,
      "rewards/rejected": -0.0007183314301073551,
      "step": 8
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.584136962890625,
      "learning_rate": 4e-08,
      "logits/chosen": 1.0252628326416016,
      "logits/rejected": 1.2671074867248535,
      "logps/chosen": -41.445526123046875,
      "logps/rejected": -45.80717468261719,
      "loss": 0.6937,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.013043737970292568,
      "rewards/margins": -0.0011451009195297956,
      "rewards/rejected": 0.014188838191330433,
      "step": 9
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.803971290588379,
      "learning_rate": 4.5e-08,
      "logits/chosen": 0.9674299955368042,
      "logits/rejected": 1.3963350057601929,
      "logps/chosen": -37.93708801269531,
      "logps/rejected": -40.12145233154297,
      "loss": 0.6917,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008902858942747116,
      "rewards/margins": 0.0030007599852979183,
      "rewards/rejected": 0.00590210035443306,
      "step": 10
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.948394775390625,
      "learning_rate": 5e-08,
      "logits/chosen": 1.2040084600448608,
      "logits/rejected": 1.0775476694107056,
      "logps/chosen": -37.409339904785156,
      "logps/rejected": -31.545917510986328,
      "loss": 0.6878,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010123610496520996,
      "rewards/margins": 0.010852313600480556,
      "rewards/rejected": -0.0007287025218829513,
      "step": 11
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.697490692138672,
      "learning_rate": 5.5e-08,
      "logits/chosen": 0.9221689701080322,
      "logits/rejected": 1.2438420057296753,
      "logps/chosen": -50.632225036621094,
      "logps/rejected": -35.06250762939453,
      "loss": 0.6947,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0015742300311103463,
      "rewards/margins": -0.0031084069050848484,
      "rewards/rejected": 0.004682636354118586,
      "step": 12
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.25040054321289,
      "learning_rate": 6e-08,
      "logits/chosen": 1.236384630203247,
      "logits/rejected": 1.496445655822754,
      "logps/chosen": -38.80718994140625,
      "logps/rejected": -35.81172180175781,
      "loss": 0.6921,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008108234964311123,
      "rewards/margins": 0.0020785334054380655,
      "rewards/rejected": 0.006029701326042414,
      "step": 13
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 1.2031668424606323,
      "eval_logits/rejected": 1.1918694972991943,
      "eval_logps/chosen": -36.62403869628906,
      "eval_logps/rejected": -42.793617248535156,
      "eval_loss": 0.6930963397026062,
      "eval_rewards/accuracies": 0.49000000953674316,
      "eval_rewards/chosen": 0.0006285952986218035,
      "eval_rewards/margins": 0.0001895943278213963,
      "eval_rewards/rejected": 0.00043900107266381383,
      "eval_runtime": 2.7816,
      "eval_samples_per_second": 35.95,
      "eval_steps_per_second": 17.975,
      "step": 13
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.861460208892822,
      "learning_rate": 6.5e-08,
      "logits/chosen": 0.9940751791000366,
      "logits/rejected": 1.4595370292663574,
      "logps/chosen": -32.64995574951172,
      "logps/rejected": -40.592124938964844,
      "loss": 0.694,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.003582168137654662,
      "rewards/margins": -0.0016388180665671825,
      "rewards/rejected": -0.001943349838256836,
      "step": 14
    },
    {
      "epoch": 1.16,
      "grad_norm": 5.068225383758545,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.329507827758789,
      "logits/rejected": 1.4317598342895508,
      "logps/chosen": -32.568458557128906,
      "logps/rejected": -38.366031646728516,
      "loss": 0.6916,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.003514814656227827,
      "rewards/margins": 0.0032335282303392887,
      "rewards/rejected": -0.0067483424209058285,
      "step": 15
    },
    {
      "epoch": 1.24,
      "grad_norm": 6.9491376876831055,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.426612138748169,
      "logits/rejected": 1.2059322595596313,
      "logps/chosen": -40.36582946777344,
      "logps/rejected": -42.39636993408203,
      "loss": 0.6941,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.005705284886062145,
      "rewards/margins": -0.001839280128479004,
      "rewards/rejected": -0.003866004990413785,
      "step": 16
    },
    {
      "epoch": 1.32,
      "grad_norm": 6.112132549285889,
      "learning_rate": 8e-08,
      "logits/chosen": 1.149780511856079,
      "logits/rejected": 1.370590329170227,
      "logps/chosen": -42.961063385009766,
      "logps/rejected": -42.51318359375,
      "loss": 0.6881,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.012721038423478603,
      "rewards/margins": 0.010322429239749908,
      "rewards/rejected": 0.0023986101150512695,
      "step": 17
    },
    {
      "epoch": 1.4,
      "grad_norm": 5.946016788482666,
      "learning_rate": 8.5e-08,
      "logits/chosen": 1.1747064590454102,
      "logits/rejected": 1.1377431154251099,
      "logps/chosen": -35.06977081298828,
      "logps/rejected": -34.97899627685547,
      "loss": 0.6897,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006723643280565739,
      "rewards/margins": 0.006957029923796654,
      "rewards/rejected": -0.00023338780738413334,
      "step": 18
    },
    {
      "epoch": 1.48,
      "grad_norm": 5.722586154937744,
      "learning_rate": 9e-08,
      "logits/chosen": 1.3785823583602905,
      "logits/rejected": 1.2454956769943237,
      "logps/chosen": -39.783504486083984,
      "logps/rejected": -42.37177276611328,
      "loss": 0.6903,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00039465446025133133,
      "rewards/margins": 0.005686306394636631,
      "rewards/rejected": -0.00608096132054925,
      "step": 19
    },
    {
      "epoch": 1.56,
      "grad_norm": 6.755873680114746,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 0.9063644409179688,
      "logits/rejected": 1.464009404182434,
      "logps/chosen": -37.01454162597656,
      "logps/rejected": -47.07289505004883,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0016944174421951175,
      "rewards/margins": -0.002568173687905073,
      "rewards/rejected": 0.0008737565367482603,
      "step": 20
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 7.496662616729736,
      "learning_rate": 1e-07,
      "logits/chosen": 1.0989117622375488,
      "logits/rejected": 1.0070420503616333,
      "logps/chosen": -35.65927505493164,
      "logps/rejected": -39.742794036865234,
      "loss": 0.6943,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.0018811228219419718,
      "rewards/margins": -0.0021941422019153833,
      "rewards/rejected": 0.004075264558196068,
      "step": 21
    },
    {
      "epoch": 1.72,
      "grad_norm": 5.918618202209473,
      "learning_rate": 9.909090909090909e-08,
      "logits/chosen": 1.2787600755691528,
      "logits/rejected": 1.413151741027832,
      "logps/chosen": -41.455360412597656,
      "logps/rejected": -38.41951370239258,
      "loss": 0.6949,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.005851078778505325,
      "rewards/margins": -0.0034241441171616316,
      "rewards/rejected": -0.00242693442851305,
      "step": 22
    },
    {
      "epoch": 1.8,
      "grad_norm": 5.943953990936279,
      "learning_rate": 9.818181818181818e-08,
      "logits/chosen": 0.9462764859199524,
      "logits/rejected": 1.0982935428619385,
      "logps/chosen": -37.04020690917969,
      "logps/rejected": -33.41801071166992,
      "loss": 0.6886,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008602714166045189,
      "rewards/margins": 0.009345006197690964,
      "rewards/rejected": -0.0007422922644764185,
      "step": 23
    },
    {
      "epoch": 1.88,
      "grad_norm": 6.899826526641846,
      "learning_rate": 9.727272727272727e-08,
      "logits/chosen": 1.2195323705673218,
      "logits/rejected": 0.9494748115539551,
      "logps/chosen": -47.53070831298828,
      "logps/rejected": -37.101783752441406,
      "loss": 0.6956,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00274658203125,
      "rewards/margins": -0.00485541857779026,
      "rewards/rejected": 0.007601999677717686,
      "step": 24
    },
    {
      "epoch": 1.96,
      "grad_norm": 7.0067620277404785,
      "learning_rate": 9.636363636363636e-08,
      "logits/chosen": 0.9589955806732178,
      "logits/rejected": 1.3682211637496948,
      "logps/chosen": -31.563243865966797,
      "logps/rejected": -51.38086700439453,
      "loss": 0.6912,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01261904276907444,
      "rewards/margins": 0.003938841633498669,
      "rewards/rejected": 0.008680200204253197,
      "step": 25
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.352473735809326,
      "learning_rate": 9.545454545454546e-08,
      "logits/chosen": 0.9912229776382446,
      "logits/rejected": 1.2691459655761719,
      "logps/chosen": -34.10544967651367,
      "logps/rejected": -32.37428283691406,
      "loss": 0.6954,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.00011911382898688316,
      "rewards/margins": -0.004545259289443493,
      "rewards/rejected": 0.004426145926117897,
      "step": 26
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 1.2031599283218384,
      "eval_logits/rejected": 1.1919770240783691,
      "eval_logps/chosen": -36.6373176574707,
      "eval_logps/rejected": -42.811492919921875,
      "eval_loss": 0.6928683519363403,
      "eval_rewards/accuracies": 0.5099999904632568,
      "eval_rewards/chosen": -0.000699317897669971,
      "eval_rewards/margins": 0.0006495951674878597,
      "eval_rewards/rejected": -0.0013489132979884744,
      "eval_runtime": 2.7061,
      "eval_samples_per_second": 36.954,
      "eval_steps_per_second": 18.477,
      "step": 26
    },
    {
      "epoch": 2.08,
      "grad_norm": 6.34814453125,
      "learning_rate": 9.454545454545454e-08,
      "logits/chosen": 1.0352718830108643,
      "logits/rejected": 1.3233373165130615,
      "logps/chosen": -36.01239013671875,
      "logps/rejected": -40.169700622558594,
      "loss": 0.6903,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004501724615693092,
      "rewards/margins": 0.005780243780463934,
      "rewards/rejected": -0.001278519630432129,
      "step": 27
    },
    {
      "epoch": 2.16,
      "grad_norm": 6.13068151473999,
      "learning_rate": 9.363636363636364e-08,
      "logits/chosen": 1.2766059637069702,
      "logits/rejected": 1.4749467372894287,
      "logps/chosen": -38.648563385009766,
      "logps/rejected": -50.129486083984375,
      "loss": 0.6975,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.00587460957467556,
      "rewards/margins": -0.008670400828123093,
      "rewards/rejected": 0.00279579171910882,
      "step": 28
    },
    {
      "epoch": 2.24,
      "grad_norm": 5.739200592041016,
      "learning_rate": 9.272727272727272e-08,
      "logits/chosen": 1.3398756980895996,
      "logits/rejected": 1.3496812582015991,
      "logps/chosen": -33.445167541503906,
      "logps/rejected": -38.00746536254883,
      "loss": 0.702,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.015457700937986374,
      "rewards/margins": -0.017506098374724388,
      "rewards/rejected": 0.002048396971076727,
      "step": 29
    },
    {
      "epoch": 2.32,
      "grad_norm": 5.651331901550293,
      "learning_rate": 9.181818181818182e-08,
      "logits/chosen": 1.1559191942214966,
      "logits/rejected": 1.3968952894210815,
      "logps/chosen": -41.22405242919922,
      "logps/rejected": -44.16936492919922,
      "loss": 0.6972,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004979515448212624,
      "rewards/margins": -0.007938504219055176,
      "rewards/rejected": 0.0129180196672678,
      "step": 30
    },
    {
      "epoch": 2.4,
      "grad_norm": 6.406694412231445,
      "learning_rate": 9.09090909090909e-08,
      "logits/chosen": 0.9128541946411133,
      "logits/rejected": 1.160447120666504,
      "logps/chosen": -34.67447280883789,
      "logps/rejected": -33.820457458496094,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.002562332432717085,
      "rewards/margins": -0.0026780366897583008,
      "rewards/rejected": 0.00011570448987185955,
      "step": 31
    },
    {
      "epoch": 2.48,
      "grad_norm": 6.5479512214660645,
      "learning_rate": 9e-08,
      "logits/chosen": 1.215378999710083,
      "logits/rejected": 1.1869338750839233,
      "logps/chosen": -44.16565704345703,
      "logps/rejected": -43.14118957519531,
      "loss": 0.6959,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0005563024897128344,
      "rewards/margins": -0.005307126324623823,
      "rewards/rejected": 0.0047508240677416325,
      "step": 32
    },
    {
      "epoch": 2.56,
      "grad_norm": 6.902541637420654,
      "learning_rate": 8.909090909090908e-08,
      "logits/chosen": 1.2719120979309082,
      "logits/rejected": 0.8556908369064331,
      "logps/chosen": -29.265113830566406,
      "logps/rejected": -40.47328186035156,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006929659750312567,
      "rewards/margins": 0.006504559889435768,
      "rewards/rejected": 0.00042509986087679863,
      "step": 33
    },
    {
      "epoch": 2.64,
      "grad_norm": 6.004189968109131,
      "learning_rate": 8.818181818181818e-08,
      "logits/chosen": 1.0808550119400024,
      "logits/rejected": 1.2630211114883423,
      "logps/chosen": -38.81559371948242,
      "logps/rejected": -37.59114074707031,
      "loss": 0.6974,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.002052498050034046,
      "rewards/margins": -0.008507013320922852,
      "rewards/rejected": 0.006454515736550093,
      "step": 34
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 5.877448558807373,
      "learning_rate": 8.727272727272726e-08,
      "logits/chosen": 1.1371371746063232,
      "logits/rejected": 1.4337009191513062,
      "logps/chosen": -39.77696990966797,
      "logps/rejected": -40.97730255126953,
      "loss": 0.6928,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.001308607985265553,
      "rewards/margins": 0.0007264850428327918,
      "rewards/rejected": -0.002035093028098345,
      "step": 35
    },
    {
      "epoch": 2.8,
      "grad_norm": 7.954182147979736,
      "learning_rate": 8.636363636363636e-08,
      "logits/chosen": 0.9091907739639282,
      "logits/rejected": 1.1250190734863281,
      "logps/chosen": -32.48855972290039,
      "logps/rejected": -40.218528747558594,
      "loss": 0.6915,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004896164406090975,
      "rewards/margins": 0.0035099745728075504,
      "rewards/rejected": 0.0013861898332834244,
      "step": 36
    },
    {
      "epoch": 2.88,
      "grad_norm": 5.819096565246582,
      "learning_rate": 8.545454545454544e-08,
      "logits/chosen": 1.1836717128753662,
      "logits/rejected": 1.4932153224945068,
      "logps/chosen": -35.93299102783203,
      "logps/rejected": -41.7647705078125,
      "loss": 0.6917,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0009083510376513004,
      "rewards/margins": 0.002945113927125931,
      "rewards/rejected": -0.002036762423813343,
      "step": 37
    },
    {
      "epoch": 2.96,
      "grad_norm": 5.3652119636535645,
      "learning_rate": 8.454545454545454e-08,
      "logits/chosen": 1.2799150943756104,
      "logits/rejected": 1.2040283679962158,
      "logps/chosen": -33.43128967285156,
      "logps/rejected": -36.536476135253906,
      "loss": 0.6929,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.006727719213813543,
      "rewards/margins": 0.0005342481890693307,
      "rewards/rejected": 0.0061934711411595345,
      "step": 38
    },
    {
      "epoch": 3.0,
      "grad_norm": 11.619318008422852,
      "learning_rate": 8.363636363636363e-08,
      "logits/chosen": 1.1763094663619995,
      "logits/rejected": 1.0983747243881226,
      "logps/chosen": -66.15311431884766,
      "logps/rejected": -34.53376007080078,
      "loss": 0.6991,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003511809976771474,
      "rewards/margins": -0.01170430239289999,
      "rewards/rejected": 0.00819249264895916,
      "step": 39
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": 1.203386664390564,
      "eval_logits/rejected": 1.1915905475616455,
      "eval_logps/chosen": -36.60808181762695,
      "eval_logps/rejected": -42.781517028808594,
      "eval_loss": 0.6929177641868591,
      "eval_rewards/accuracies": 0.5199999809265137,
      "eval_rewards/chosen": 0.0022241915576159954,
      "eval_rewards/margins": 0.0005752221331931651,
      "eval_rewards/rejected": 0.0016489694826304913,
      "eval_runtime": 2.7091,
      "eval_samples_per_second": 36.913,
      "eval_steps_per_second": 18.457,
      "step": 39
    },
    {
      "epoch": 3.08,
      "grad_norm": 7.959442138671875,
      "learning_rate": 8.272727272727272e-08,
      "logits/chosen": 0.8599169850349426,
      "logits/rejected": 1.3191428184509277,
      "logps/chosen": -39.49042510986328,
      "logps/rejected": -56.298336029052734,
      "loss": 0.6907,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.002941942773759365,
      "rewards/margins": 0.004875039216130972,
      "rewards/rejected": -0.00781698152422905,
      "step": 40
    },
    {
      "epoch": 3.16,
      "grad_norm": 5.6438307762146,
      "learning_rate": 8.181818181818182e-08,
      "logits/chosen": 1.086678385734558,
      "logits/rejected": 1.4696357250213623,
      "logps/chosen": -45.667015075683594,
      "logps/rejected": -35.26637268066406,
      "loss": 0.6973,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0024304864928126335,
      "rewards/margins": -0.008205866441130638,
      "rewards/rejected": 0.005775380413979292,
      "step": 41
    },
    {
      "epoch": 3.24,
      "grad_norm": 6.13469934463501,
      "learning_rate": 8.09090909090909e-08,
      "logits/chosen": 1.1405727863311768,
      "logits/rejected": 1.2149927616119385,
      "logps/chosen": -45.92341613769531,
      "logps/rejected": -38.82704544067383,
      "loss": 0.6916,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.009153008460998535,
      "rewards/margins": 0.003242683596909046,
      "rewards/rejected": 0.005910325795412064,
      "step": 42
    },
    {
      "epoch": 3.32,
      "grad_norm": 5.860279083251953,
      "learning_rate": 8e-08,
      "logits/chosen": 1.247285008430481,
      "logits/rejected": 1.239366054534912,
      "logps/chosen": -38.50377655029297,
      "logps/rejected": -37.72407531738281,
      "loss": 0.692,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0023022405803203583,
      "rewards/margins": 0.0024472950026392937,
      "rewards/rejected": -0.0047495365142822266,
      "step": 43
    },
    {
      "epoch": 3.4,
      "grad_norm": 7.291507720947266,
      "learning_rate": 7.909090909090909e-08,
      "logits/chosen": 1.0454763174057007,
      "logits/rejected": 1.4353001117706299,
      "logps/chosen": -32.481807708740234,
      "logps/rejected": -41.39268493652344,
      "loss": 0.695,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.009086108766496181,
      "rewards/margins": -0.003585600294172764,
      "rewards/rejected": 0.012671709060668945,
      "step": 44
    },
    {
      "epoch": 3.48,
      "grad_norm": 4.951364040374756,
      "learning_rate": 7.818181818181818e-08,
      "logits/chosen": 1.2929022312164307,
      "logits/rejected": 1.1185070276260376,
      "logps/chosen": -33.39114761352539,
      "logps/rejected": -36.435447692871094,
      "loss": 0.698,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.002841615816578269,
      "rewards/margins": -0.009636688977479935,
      "rewards/rejected": 0.006795072928071022,
      "step": 45
    },
    {
      "epoch": 3.56,
      "grad_norm": 6.0996246337890625,
      "learning_rate": 7.727272727272727e-08,
      "logits/chosen": 1.4050856828689575,
      "logits/rejected": 1.1767768859863281,
      "logps/chosen": -37.0592155456543,
      "logps/rejected": -41.19673156738281,
      "loss": 0.6966,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0044287205673754215,
      "rewards/margins": -0.006781006697565317,
      "rewards/rejected": 0.0023522854316979647,
      "step": 46
    },
    {
      "epoch": 3.64,
      "grad_norm": 5.632574558258057,
      "learning_rate": 7.636363636363636e-08,
      "logits/chosen": 1.1858506202697754,
      "logits/rejected": 1.3264261484146118,
      "logps/chosen": -34.161277770996094,
      "logps/rejected": -40.44023895263672,
      "loss": 0.6964,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 4.184269346296787e-05,
      "rewards/margins": -0.006358337588608265,
      "rewards/rejected": 0.006400180049240589,
      "step": 47
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 6.254282474517822,
      "learning_rate": 7.545454545454545e-08,
      "logits/chosen": 1.1025292873382568,
      "logits/rejected": 1.425100326538086,
      "logps/chosen": -32.73381042480469,
      "logps/rejected": -45.05099868774414,
      "loss": 0.6956,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0003180503845214844,
      "rewards/margins": -0.004846930503845215,
      "rewards/rejected": 0.004528879653662443,
      "step": 48
    },
    {
      "epoch": 3.8,
      "grad_norm": 6.4957051277160645,
      "learning_rate": 7.454545454545455e-08,
      "logits/chosen": 1.2252907752990723,
      "logits/rejected": 1.0310851335525513,
      "logps/chosen": -35.20683670043945,
      "logps/rejected": -44.68004608154297,
      "loss": 0.6911,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005068302154541016,
      "rewards/margins": 0.0042122602462768555,
      "rewards/rejected": 0.000856042024679482,
      "step": 49
    },
    {
      "epoch": 3.88,
      "grad_norm": 6.240015029907227,
      "learning_rate": 7.363636363636363e-08,
      "logits/chosen": 0.9830682277679443,
      "logits/rejected": 1.084326148033142,
      "logps/chosen": -38.78738784790039,
      "logps/rejected": -33.02320861816406,
      "loss": 0.6965,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.009445954114198685,
      "rewards/margins": -0.006703615188598633,
      "rewards/rejected": -0.0027423379942774773,
      "step": 50
    },
    {
      "epoch": 3.96,
      "grad_norm": 5.057881832122803,
      "learning_rate": 7.272727272727273e-08,
      "logits/chosen": 1.1333190202713013,
      "logits/rejected": 1.2384026050567627,
      "logps/chosen": -36.25130844116211,
      "logps/rejected": -34.34326934814453,
      "loss": 0.6954,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003176569938659668,
      "rewards/margins": -0.004465246107429266,
      "rewards/rejected": 0.0012886764016002417,
      "step": 51
    },
    {
      "epoch": 4.0,
      "grad_norm": 8.269505500793457,
      "learning_rate": 7.181818181818181e-08,
      "logits/chosen": 1.3253073692321777,
      "logits/rejected": 1.3999407291412354,
      "logps/chosen": -42.537139892578125,
      "logps/rejected": -39.11924743652344,
      "loss": 0.695,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00031261472031474113,
      "rewards/margins": -0.0036341671366244555,
      "rewards/rejected": 0.003946781624108553,
      "step": 52
    },
    {
      "epoch": 4.0,
      "eval_logits/chosen": 1.2020020484924316,
      "eval_logits/rejected": 1.189494252204895,
      "eval_logps/chosen": -36.635337829589844,
      "eval_logps/rejected": -42.78831100463867,
      "eval_loss": 0.6939395070075989,
      "eval_rewards/accuracies": 0.5299999713897705,
      "eval_rewards/chosen": -0.0005010433960705996,
      "eval_rewards/margins": -0.0014703556662425399,
      "eval_rewards/rejected": 0.0009693127940408885,
      "eval_runtime": 2.7136,
      "eval_samples_per_second": 36.851,
      "eval_steps_per_second": 18.425,
      "step": 52
    },
    {
      "epoch": 4.08,
      "grad_norm": 6.609297752380371,
      "learning_rate": 7.090909090909091e-08,
      "logits/chosen": 1.1905608177185059,
      "logits/rejected": 1.1415717601776123,
      "logps/chosen": -31.17475128173828,
      "logps/rejected": -42.56402587890625,
      "loss": 0.6957,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0006469246000051498,
      "rewards/margins": -0.005095792002975941,
      "rewards/rejected": 0.0057427166029810905,
      "step": 53
    },
    {
      "epoch": 4.16,
      "grad_norm": 6.765017509460449,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 0.9635235667228699,
      "logits/rejected": 1.1734458208084106,
      "logps/chosen": -33.760093688964844,
      "logps/rejected": -44.76398849487305,
      "loss": 0.6991,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.008825517259538174,
      "rewards/margins": -0.011734843254089355,
      "rewards/rejected": 0.0029093266930431128,
      "step": 54
    },
    {
      "epoch": 4.24,
      "grad_norm": 5.681632041931152,
      "learning_rate": 6.909090909090909e-08,
      "logits/chosen": 1.1910988092422485,
      "logits/rejected": 1.5046247243881226,
      "logps/chosen": -39.193424224853516,
      "logps/rejected": -42.042213439941406,
      "loss": 0.6929,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.003422427223995328,
      "rewards/margins": 0.0005987881449982524,
      "rewards/rejected": 0.0028236389625817537,
      "step": 55
    },
    {
      "epoch": 4.32,
      "grad_norm": 8.6602783203125,
      "learning_rate": 6.818181818181817e-08,
      "logits/chosen": 1.1516064405441284,
      "logits/rejected": 1.1376763582229614,
      "logps/chosen": -53.53923797607422,
      "logps/rejected": -39.62635040283203,
      "loss": 0.6922,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0012926339404657483,
      "rewards/margins": 0.002083349507302046,
      "rewards/rejected": -0.0007907156832516193,
      "step": 56
    },
    {
      "epoch": 4.4,
      "grad_norm": 6.752065181732178,
      "learning_rate": 6.727272727272727e-08,
      "logits/chosen": 0.8817541599273682,
      "logits/rejected": 1.28602135181427,
      "logps/chosen": -32.47856903076172,
      "logps/rejected": -40.50098419189453,
      "loss": 0.6939,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0049849748611450195,
      "rewards/margins": -0.0014288423117250204,
      "rewards/rejected": 0.006413816940039396,
      "step": 57
    },
    {
      "epoch": 4.48,
      "grad_norm": 5.334300994873047,
      "learning_rate": 6.636363636363637e-08,
      "logits/chosen": 1.0675437450408936,
      "logits/rejected": 1.3710534572601318,
      "logps/chosen": -36.57356643676758,
      "logps/rejected": -36.28133773803711,
      "loss": 0.6898,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002643156098201871,
      "rewards/margins": 0.006755542941391468,
      "rewards/rejected": -0.004112387076020241,
      "step": 58
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 5.708319187164307,
      "learning_rate": 6.545454545454545e-08,
      "logits/chosen": 1.1956688165664673,
      "logits/rejected": 1.4655282497406006,
      "logps/chosen": -35.56943893432617,
      "logps/rejected": -38.60441589355469,
      "loss": 0.6894,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01086053904145956,
      "rewards/margins": 0.007587408181279898,
      "rewards/rejected": 0.0032731296960264444,
      "step": 59
    },
    {
      "epoch": 4.64,
      "grad_norm": 5.868063449859619,
      "learning_rate": 6.454545454545455e-08,
      "logits/chosen": 1.120802879333496,
      "logits/rejected": 1.4120761156082153,
      "logps/chosen": -38.69218444824219,
      "logps/rejected": -44.805320739746094,
      "loss": 0.695,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0001244068844243884,
      "rewards/margins": -0.0035437820479273796,
      "rewards/rejected": 0.00366818904876709,
      "step": 60
    },
    {
      "epoch": 4.72,
      "grad_norm": 6.010902404785156,
      "learning_rate": 6.363636363636363e-08,
      "logits/chosen": 1.1732591390609741,
      "logits/rejected": 1.4213701486587524,
      "logps/chosen": -30.861534118652344,
      "logps/rejected": -40.406341552734375,
      "loss": 0.6956,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0043184044770896435,
      "rewards/margins": -0.004805207252502441,
      "rewards/rejected": 0.0004868030082434416,
      "step": 61
    },
    {
      "epoch": 4.8,
      "grad_norm": 5.874751091003418,
      "learning_rate": 6.272727272727273e-08,
      "logits/chosen": 1.30158269405365,
      "logits/rejected": 1.0636205673217773,
      "logps/chosen": -44.97877883911133,
      "logps/rejected": -40.82699966430664,
      "loss": 0.691,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0003048896323889494,
      "rewards/margins": 0.004344868939369917,
      "rewards/rejected": -0.004649758338928223,
      "step": 62
    },
    {
      "epoch": 4.88,
      "grad_norm": 5.540100574493408,
      "learning_rate": 6.181818181818181e-08,
      "logits/chosen": 1.2701048851013184,
      "logits/rejected": 1.1929818391799927,
      "logps/chosen": -34.62054443359375,
      "logps/rejected": -40.19648742675781,
      "loss": 0.6991,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.007592583075165749,
      "rewards/margins": -0.011731838807463646,
      "rewards/rejected": 0.004139256663620472,
      "step": 63
    },
    {
      "epoch": 4.96,
      "grad_norm": 6.001725196838379,
      "learning_rate": 6.090909090909091e-08,
      "logits/chosen": 1.3279101848602295,
      "logits/rejected": 1.2583363056182861,
      "logps/chosen": -40.12506103515625,
      "logps/rejected": -35.837547302246094,
      "loss": 0.6988,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.005181861110031605,
      "rewards/margins": -0.011056972667574883,
      "rewards/rejected": 0.005875110160559416,
      "step": 64
    },
    {
      "epoch": 5.0,
      "grad_norm": 8.933469772338867,
      "learning_rate": 6e-08,
      "logits/chosen": 1.295105218887329,
      "logits/rejected": 1.107787847518921,
      "logps/chosen": -39.04867172241211,
      "logps/rejected": -35.744956970214844,
      "loss": 0.693,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.002110767411068082,
      "rewards/margins": 0.00022888206876814365,
      "rewards/rejected": -0.002339649247005582,
      "step": 65
    },
    {
      "epoch": 5.0,
      "eval_logits/chosen": 1.2024096250534058,
      "eval_logits/rejected": 1.191442847251892,
      "eval_logps/chosen": -36.59190368652344,
      "eval_logps/rejected": -42.77582550048828,
      "eval_loss": 0.6923895478248596,
      "eval_rewards/accuracies": 0.5299999713897705,
      "eval_rewards/chosen": 0.0038422164507210255,
      "eval_rewards/margins": 0.0016238901298493147,
      "eval_rewards/rejected": 0.0022183265537023544,
      "eval_runtime": 2.7171,
      "eval_samples_per_second": 36.804,
      "eval_steps_per_second": 18.402,
      "step": 65
    }
  ],
  "logging_steps": 1,
  "max_steps": 130,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
