{
  "best_global_step": 611,
  "best_metric": 0.6775261759757996,
  "best_model_checkpoint": "/scratch/user/chuanhsin0110/LLMRec-Labs/unintentional-unalignment/outputs/Goodreads_test/ches_score_top100_epoch50/checkpoint-611",
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 650,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 7.912317276000977,
      "learning_rate": 0.0,
      "logits/chosen": 1.3310693502426147,
      "logits/rejected": 1.2552515268325806,
      "logps/chosen": -38.18364715576172,
      "logps/rejected": -53.132118225097656,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.589303016662598,
      "learning_rate": 5e-09,
      "logits/chosen": 1.3258908987045288,
      "logits/rejected": 1.1168854236602783,
      "logps/chosen": -32.30229568481445,
      "logps/rejected": -54.77543640136719,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 2
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.287254810333252,
      "learning_rate": 1e-08,
      "logits/chosen": 1.2153717279434204,
      "logits/rejected": 1.180932879447937,
      "logps/chosen": -35.4702262878418,
      "logps/rejected": -50.87117004394531,
      "loss": 0.6933,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0009946345817297697,
      "rewards/margins": -0.00024769268929958344,
      "rewards/rejected": 0.0012423276202753186,
      "step": 3
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.795101642608643,
      "learning_rate": 1.5e-08,
      "logits/chosen": 1.1783382892608643,
      "logits/rejected": 1.1035207509994507,
      "logps/chosen": -30.70616912841797,
      "logps/rejected": -58.59922790527344,
      "loss": 0.6893,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0022952791769057512,
      "rewards/margins": 0.007786298170685768,
      "rewards/rejected": -0.01008157804608345,
      "step": 4
    },
    {
      "epoch": 0.4,
      "grad_norm": 7.37426233291626,
      "learning_rate": 2e-08,
      "logits/chosen": 1.0653727054595947,
      "logits/rejected": 1.352402925491333,
      "logps/chosen": -29.515016555786133,
      "logps/rejected": -49.94809341430664,
      "loss": 0.6955,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0009697194909676909,
      "rewards/margins": -0.004725003615021706,
      "rewards/rejected": 0.0037552830763161182,
      "step": 5
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.930150032043457,
      "learning_rate": 2.5e-08,
      "logits/chosen": 1.3039259910583496,
      "logits/rejected": 1.2979851961135864,
      "logps/chosen": -36.44289779663086,
      "logps/rejected": -57.790870666503906,
      "loss": 0.6926,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0032855989411473274,
      "rewards/margins": 0.001182174775749445,
      "rewards/rejected": -0.004467773251235485,
      "step": 6
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.894197463989258,
      "learning_rate": 3e-08,
      "logits/chosen": 1.2402422428131104,
      "logits/rejected": 1.2336227893829346,
      "logps/chosen": -34.8067741394043,
      "logps/rejected": -60.94792556762695,
      "loss": 0.6947,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0005726097151637077,
      "rewards/margins": -0.0029593235813081264,
      "rewards/rejected": 0.0035319330636411905,
      "step": 7
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.443088531494141,
      "learning_rate": 3.4999999999999996e-08,
      "logits/chosen": 1.2155896425247192,
      "logits/rejected": 1.196808099746704,
      "logps/chosen": -31.382699966430664,
      "logps/rejected": -48.62493896484375,
      "loss": 0.6984,
      "rewards/accuracies": 0.125,
      "rewards/chosen": 0.0005131246289238334,
      "rewards/margins": -0.010534144006669521,
      "rewards/rejected": 0.01104726828634739,
      "step": 8
    },
    {
      "epoch": 0.72,
      "grad_norm": 8.573447227478027,
      "learning_rate": 4e-08,
      "logits/chosen": 1.4391638040542603,
      "logits/rejected": 1.2754144668579102,
      "logps/chosen": -38.053375244140625,
      "logps/rejected": -53.8907470703125,
      "loss": 0.6969,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.008162975311279297,
      "rewards/margins": -0.007357502356171608,
      "rewards/rejected": -0.0008054734207689762,
      "step": 9
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.370125770568848,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.3156317472457886,
      "logits/rejected": 1.3524988889694214,
      "logps/chosen": -29.490589141845703,
      "logps/rejected": -51.354698181152344,
      "loss": 0.6958,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0006191253196448088,
      "rewards/margins": -0.005222988780587912,
      "rewards/rejected": 0.004603863228112459,
      "step": 10
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.868659973144531,
      "learning_rate": 5e-08,
      "logits/chosen": 1.426473617553711,
      "logits/rejected": 1.1081560850143433,
      "logps/chosen": -34.85114288330078,
      "logps/rejected": -57.69574737548828,
      "loss": 0.6919,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0019558430649340153,
      "rewards/margins": 0.0025662421248853207,
      "rewards/rejected": -0.0006103990599513054,
      "step": 11
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.168028354644775,
      "learning_rate": 5.5e-08,
      "logits/chosen": 1.3644590377807617,
      "logits/rejected": 1.538978099822998,
      "logps/chosen": -39.97705078125,
      "logps/rejected": -62.48909378051758,
      "loss": 0.6922,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.00244328984990716,
      "rewards/margins": 0.002210736507549882,
      "rewards/rejected": -0.004654026590287685,
      "step": 12
    },
    {
      "epoch": 1.0,
      "grad_norm": 11.509532928466797,
      "learning_rate": 6e-08,
      "logits/chosen": 1.3843412399291992,
      "logits/rejected": 1.450859546661377,
      "logps/chosen": -33.34332275390625,
      "logps/rejected": -51.165977478027344,
      "loss": 0.6847,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0068634990602731705,
      "rewards/margins": 0.01715870015323162,
      "rewards/rejected": -0.010295199230313301,
      "step": 13
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 1.3029224872589111,
      "eval_logits/rejected": 1.1972578763961792,
      "eval_logps/chosen": -34.4760627746582,
      "eval_logps/rejected": -46.98942947387695,
      "eval_loss": 0.6926182508468628,
      "eval_rewards/accuracies": 0.5,
      "eval_rewards/chosen": 0.002345310291275382,
      "eval_rewards/margins": 0.0011694926070049405,
      "eval_rewards/rejected": 0.0011758176842704415,
      "eval_runtime": 2.7184,
      "eval_samples_per_second": 36.787,
      "eval_steps_per_second": 18.393,
      "step": 13
    },
    {
      "epoch": 1.08,
      "grad_norm": 7.274550437927246,
      "learning_rate": 6.5e-08,
      "logits/chosen": 1.4831119775772095,
      "logits/rejected": 1.3517465591430664,
      "logps/chosen": -30.19500732421875,
      "logps/rejected": -55.751556396484375,
      "loss": 0.6945,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.003515196032822132,
      "rewards/margins": -0.002475070534273982,
      "rewards/rejected": 0.0059902663342654705,
      "step": 14
    },
    {
      "epoch": 1.16,
      "grad_norm": 7.941336154937744,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.1977519989013672,
      "logits/rejected": 1.358170509338379,
      "logps/chosen": -34.31591033935547,
      "logps/rejected": -55.5545654296875,
      "loss": 0.6951,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.004744672682136297,
      "rewards/margins": -0.003858709242194891,
      "rewards/rejected": -0.0008859633817337453,
      "step": 15
    },
    {
      "epoch": 1.24,
      "grad_norm": 8.59754753112793,
      "learning_rate": 7.5e-08,
      "logits/chosen": 1.169238567352295,
      "logits/rejected": 0.9834401607513428,
      "logps/chosen": -31.866195678710938,
      "logps/rejected": -49.778587341308594,
      "loss": 0.6903,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0014164925087243319,
      "rewards/margins": 0.005758858285844326,
      "rewards/rejected": -0.0071753510273993015,
      "step": 16
    },
    {
      "epoch": 1.32,
      "grad_norm": 7.58815860748291,
      "learning_rate": 8e-08,
      "logits/chosen": 1.4051672220230103,
      "logits/rejected": 1.2835512161254883,
      "logps/chosen": -31.383779525756836,
      "logps/rejected": -58.130409240722656,
      "loss": 0.6904,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0007415770087391138,
      "rewards/margins": 0.005575133021920919,
      "rewards/rejected": -0.006316710263490677,
      "step": 17
    },
    {
      "epoch": 1.4,
      "grad_norm": 6.3700337409973145,
      "learning_rate": 8.5e-08,
      "logits/chosen": 1.3031775951385498,
      "logits/rejected": 1.3473196029663086,
      "logps/chosen": -36.248268127441406,
      "logps/rejected": -51.19780731201172,
      "loss": 0.6916,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.011990380473434925,
      "rewards/margins": 0.003314375411719084,
      "rewards/rejected": -0.01530475728213787,
      "step": 18
    },
    {
      "epoch": 1.48,
      "grad_norm": 7.777618408203125,
      "learning_rate": 9e-08,
      "logits/chosen": 1.1781859397888184,
      "logits/rejected": 1.0472679138183594,
      "logps/chosen": -34.902076721191406,
      "logps/rejected": -55.960662841796875,
      "loss": 0.7025,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010088873095810413,
      "rewards/margins": -0.018359804525971413,
      "rewards/rejected": 0.008270931430161,
      "step": 19
    },
    {
      "epoch": 1.56,
      "grad_norm": 7.757184982299805,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.2116870880126953,
      "logits/rejected": 1.3248566389083862,
      "logps/chosen": -34.212684631347656,
      "logps/rejected": -60.75562286376953,
      "loss": 0.6843,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0069911242462694645,
      "rewards/margins": 0.017888952046632767,
      "rewards/rejected": -0.010897827334702015,
      "step": 20
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 8.196033477783203,
      "learning_rate": 1e-07,
      "logits/chosen": 1.3683406114578247,
      "logits/rejected": 1.0915207862854004,
      "logps/chosen": -33.4801025390625,
      "logps/rejected": -48.87120056152344,
      "loss": 0.6931,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.002340459730476141,
      "rewards/margins": 0.00015158671885728836,
      "rewards/rejected": 0.002188872778788209,
      "step": 21
    },
    {
      "epoch": 1.72,
      "grad_norm": 9.038294792175293,
      "learning_rate": 9.984126984126984e-08,
      "logits/chosen": 1.293218731880188,
      "logits/rejected": 1.2436439990997314,
      "logps/chosen": -39.22562026977539,
      "logps/rejected": -56.58060073852539,
      "loss": 0.697,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0017203806200996041,
      "rewards/margins": -0.007572459988296032,
      "rewards/rejected": 0.005852079950273037,
      "step": 22
    },
    {
      "epoch": 1.8,
      "grad_norm": 8.604475021362305,
      "learning_rate": 9.968253968253968e-08,
      "logits/chosen": 1.2979650497436523,
      "logits/rejected": 1.2670137882232666,
      "logps/chosen": -34.35459518432617,
      "logps/rejected": -55.35784149169922,
      "loss": 0.6929,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0009440421708859503,
      "rewards/margins": 0.0004899981431663036,
      "rewards/rejected": -0.0014340400230139494,
      "step": 23
    },
    {
      "epoch": 1.88,
      "grad_norm": 7.038559913635254,
      "learning_rate": 9.952380952380952e-08,
      "logits/chosen": 1.323025107383728,
      "logits/rejected": 1.3780744075775146,
      "logps/chosen": -33.04808807373047,
      "logps/rejected": -48.82676696777344,
      "loss": 0.6941,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004963946528732777,
      "rewards/margins": -0.0017910243477672338,
      "rewards/rejected": 0.006754971109330654,
      "step": 24
    },
    {
      "epoch": 1.96,
      "grad_norm": 6.976914405822754,
      "learning_rate": 9.936507936507936e-08,
      "logits/chosen": 1.356062889099121,
      "logits/rejected": 1.3026536703109741,
      "logps/chosen": -36.806434631347656,
      "logps/rejected": -63.70009994506836,
      "loss": 0.6892,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003958702087402344,
      "rewards/margins": 0.007958841510117054,
      "rewards/rejected": -0.00400013942271471,
      "step": 25
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.94445514678955,
      "learning_rate": 9.920634920634921e-08,
      "logits/chosen": 1.1567180156707764,
      "logits/rejected": 1.4238026142120361,
      "logps/chosen": -35.57698059082031,
      "logps/rejected": -50.50908660888672,
      "loss": 0.6936,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008001614362001419,
      "rewards/margins": -0.0008959765546023846,
      "rewards/rejected": 0.008897591382265091,
      "step": 26
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 1.3034710884094238,
      "eval_logits/rejected": 1.1984344720840454,
      "eval_logps/chosen": -34.52928161621094,
      "eval_logps/rejected": -47.003517150878906,
      "eval_loss": 0.6945757865905762,
      "eval_rewards/accuracies": 0.49000000953674316,
      "eval_rewards/chosen": -0.0029765625949949026,
      "eval_rewards/margins": -0.0027440490666776896,
      "eval_rewards/rejected": -0.000232513397349976,
      "eval_runtime": 2.7173,
      "eval_samples_per_second": 36.801,
      "eval_steps_per_second": 18.4,
      "step": 26
    },
    {
      "epoch": 2.08,
      "grad_norm": 7.509138107299805,
      "learning_rate": 9.904761904761905e-08,
      "logits/chosen": 1.3511277437210083,
      "logits/rejected": 1.2900052070617676,
      "logps/chosen": -34.820194244384766,
      "logps/rejected": -54.6517333984375,
      "loss": 0.6965,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.011073112487792969,
      "rewards/margins": -0.006458950228989124,
      "rewards/rejected": -0.0046141622588038445,
      "step": 27
    },
    {
      "epoch": 2.16,
      "grad_norm": 8.258333206176758,
      "learning_rate": 9.888888888888889e-08,
      "logits/chosen": 1.2570726871490479,
      "logits/rejected": 1.1989383697509766,
      "logps/chosen": -35.72299575805664,
      "logps/rejected": -56.64720153808594,
      "loss": 0.6893,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.002382302191108465,
      "rewards/margins": 0.0078036547638475895,
      "rewards/rejected": -0.010185956954956055,
      "step": 28
    },
    {
      "epoch": 2.24,
      "grad_norm": 7.420022964477539,
      "learning_rate": 9.873015873015873e-08,
      "logits/chosen": 1.291399359703064,
      "logits/rejected": 1.3090415000915527,
      "logps/chosen": -35.67629623413086,
      "logps/rejected": -51.14415740966797,
      "loss": 0.6912,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0039247749373316765,
      "rewards/margins": 0.0039608473889529705,
      "rewards/rejected": -3.6072684451937675e-05,
      "step": 29
    },
    {
      "epoch": 2.32,
      "grad_norm": 6.744539260864258,
      "learning_rate": 9.857142857142858e-08,
      "logits/chosen": 1.3578112125396729,
      "logits/rejected": 1.1476939916610718,
      "logps/chosen": -34.997711181640625,
      "logps/rejected": -52.75013732910156,
      "loss": 0.6945,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005349182989448309,
      "rewards/margins": -0.0026009324938058853,
      "rewards/rejected": 0.007950115948915482,
      "step": 30
    },
    {
      "epoch": 2.4,
      "grad_norm": 6.749225616455078,
      "learning_rate": 9.84126984126984e-08,
      "logits/chosen": 1.2733196020126343,
      "logits/rejected": 1.3597172498703003,
      "logps/chosen": -30.593910217285156,
      "logps/rejected": -54.060272216796875,
      "loss": 0.6937,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.002873850055038929,
      "rewards/margins": -0.0008942596614360809,
      "rewards/rejected": -0.0019795894622802734,
      "step": 31
    },
    {
      "epoch": 2.48,
      "grad_norm": 8.456583976745605,
      "learning_rate": 9.825396825396825e-08,
      "logits/chosen": 1.2310541868209839,
      "logits/rejected": 1.1565619707107544,
      "logps/chosen": -30.18548011779785,
      "logps/rejected": -53.7956657409668,
      "loss": 0.689,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.002393364906311035,
      "rewards/margins": 0.008305668830871582,
      "rewards/rejected": -0.005912304390221834,
      "step": 32
    },
    {
      "epoch": 2.56,
      "grad_norm": 7.934566974639893,
      "learning_rate": 9.809523809523809e-08,
      "logits/chosen": 1.3436439037322998,
      "logits/rejected": 1.3484811782836914,
      "logps/chosen": -35.8084716796875,
      "logps/rejected": -49.67949676513672,
      "loss": 0.6866,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0038298601284623146,
      "rewards/margins": 0.013182115741074085,
      "rewards/rejected": -0.00935225561261177,
      "step": 33
    },
    {
      "epoch": 2.64,
      "grad_norm": 9.775945663452148,
      "learning_rate": 9.793650793650793e-08,
      "logits/chosen": 1.4592376947402954,
      "logits/rejected": 1.2171741724014282,
      "logps/chosen": -39.50941467285156,
      "logps/rejected": -61.70500183105469,
      "loss": 0.6943,
      "rewards/accuracies": 0.25,
      "rewards/chosen": 0.011867142282426357,
      "rewards/margins": -0.0022000782191753387,
      "rewards/rejected": 0.014067220501601696,
      "step": 34
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 6.641319751739502,
      "learning_rate": 9.777777777777778e-08,
      "logits/chosen": 1.1929683685302734,
      "logits/rejected": 1.1311383247375488,
      "logps/chosen": -30.617097854614258,
      "logps/rejected": -54.45277404785156,
      "loss": 0.6877,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0031392816454172134,
      "rewards/margins": 0.01108634565025568,
      "rewards/rejected": -0.007947064004838467,
      "step": 35
    },
    {
      "epoch": 2.8,
      "grad_norm": 9.18194580078125,
      "learning_rate": 9.761904761904762e-08,
      "logits/chosen": 1.2202003002166748,
      "logits/rejected": 1.2325990200042725,
      "logps/chosen": -31.942203521728516,
      "logps/rejected": -53.94926071166992,
      "loss": 0.6936,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0067848446778953075,
      "rewards/margins": -0.0005981689319014549,
      "rewards/rejected": -0.006186675280332565,
      "step": 36
    },
    {
      "epoch": 2.88,
      "grad_norm": 7.300791263580322,
      "learning_rate": 9.746031746031746e-08,
      "logits/chosen": 1.3446882963180542,
      "logits/rejected": 1.3144245147705078,
      "logps/chosen": -34.24513244628906,
      "logps/rejected": -58.42039489746094,
      "loss": 0.6905,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004891419783234596,
      "rewards/margins": 0.005541682243347168,
      "rewards/rejected": -0.0006502628093585372,
      "step": 37
    },
    {
      "epoch": 2.96,
      "grad_norm": 7.744457721710205,
      "learning_rate": 9.730158730158729e-08,
      "logits/chosen": 1.293066382408142,
      "logits/rejected": 1.2081831693649292,
      "logps/chosen": -36.187225341796875,
      "logps/rejected": -60.45861053466797,
      "loss": 0.6959,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010668206959962845,
      "rewards/margins": -0.005295443814247847,
      "rewards/rejected": -0.005372762680053711,
      "step": 38
    },
    {
      "epoch": 3.0,
      "grad_norm": 10.377267837524414,
      "learning_rate": 9.714285714285713e-08,
      "logits/chosen": 1.2603586912155151,
      "logits/rejected": 1.4526994228363037,
      "logps/chosen": -34.74110412597656,
      "logps/rejected": -48.6111946105957,
      "loss": 0.6983,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.012257528491318226,
      "rewards/margins": -0.010221529752016068,
      "rewards/rejected": -0.0020359994377940893,
      "step": 39
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": 1.3020846843719482,
      "eval_logits/rejected": 1.195446491241455,
      "eval_logps/chosen": -34.52726745605469,
      "eval_logps/rejected": -47.006858825683594,
      "eval_loss": 0.6942940354347229,
      "eval_rewards/accuracies": 0.47999998927116394,
      "eval_rewards/chosen": -0.0027753813192248344,
      "eval_rewards/margins": -0.002208109013736248,
      "eval_rewards/rejected": -0.0005672723054885864,
      "eval_runtime": 2.7133,
      "eval_samples_per_second": 36.856,
      "eval_steps_per_second": 18.428,
      "step": 39
    },
    {
      "epoch": 3.08,
      "grad_norm": 9.212749481201172,
      "learning_rate": 9.698412698412697e-08,
      "logits/chosen": 1.4246416091918945,
      "logits/rejected": 1.2594552040100098,
      "logps/chosen": -37.2223014831543,
      "logps/rejected": -68.62015533447266,
      "loss": 0.6923,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003451419062912464,
      "rewards/margins": 0.0019233464263379574,
      "rewards/rejected": 0.0015280721709132195,
      "step": 40
    },
    {
      "epoch": 3.16,
      "grad_norm": 5.981501579284668,
      "learning_rate": 9.682539682539682e-08,
      "logits/chosen": 1.328678011894226,
      "logits/rejected": 1.3672893047332764,
      "logps/chosen": -35.92017364501953,
      "logps/rejected": -47.243927001953125,
      "loss": 0.692,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0027666091918945312,
      "rewards/margins": 0.0023915767669677734,
      "rewards/rejected": 0.0003750319592654705,
      "step": 41
    },
    {
      "epoch": 3.24,
      "grad_norm": 7.047969341278076,
      "learning_rate": 9.666666666666666e-08,
      "logits/chosen": 1.4006133079528809,
      "logits/rejected": 1.2827861309051514,
      "logps/chosen": -32.53205871582031,
      "logps/rejected": -58.68801498413086,
      "loss": 0.6934,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.003233623458072543,
      "rewards/margins": -0.00041432410944253206,
      "rewards/rejected": 0.0036479472182691097,
      "step": 42
    },
    {
      "epoch": 3.32,
      "grad_norm": 7.510355472564697,
      "learning_rate": 9.65079365079365e-08,
      "logits/chosen": 1.1171386241912842,
      "logits/rejected": 1.3894858360290527,
      "logps/chosen": -30.213544845581055,
      "logps/rejected": -56.906124114990234,
      "loss": 0.6935,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.004127741325646639,
      "rewards/margins": -0.0004648687317967415,
      "rewards/rejected": -0.0036628725938498974,
      "step": 43
    },
    {
      "epoch": 3.4,
      "grad_norm": 7.76370906829834,
      "learning_rate": 9.634920634920634e-08,
      "logits/chosen": 1.2813684940338135,
      "logits/rejected": 1.1514379978179932,
      "logps/chosen": -32.72855758666992,
      "logps/rejected": -49.759361267089844,
      "loss": 0.6865,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.000182796036824584,
      "rewards/margins": 0.013613392598927021,
      "rewards/rejected": -0.013430596329271793,
      "step": 44
    },
    {
      "epoch": 3.48,
      "grad_norm": 8.950040817260742,
      "learning_rate": 9.619047619047619e-08,
      "logits/chosen": 1.3521500825881958,
      "logits/rejected": 1.1612058877944946,
      "logps/chosen": -33.05779266357422,
      "logps/rejected": -44.00171661376953,
      "loss": 0.6911,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.011552095413208008,
      "rewards/margins": 0.00412979070097208,
      "rewards/rejected": -0.015681887045502663,
      "step": 45
    },
    {
      "epoch": 3.56,
      "grad_norm": 8.75224494934082,
      "learning_rate": 9.603174603174603e-08,
      "logits/chosen": 1.2263312339782715,
      "logits/rejected": 1.141724944114685,
      "logps/chosen": -32.702091217041016,
      "logps/rejected": -58.585777282714844,
      "loss": 0.6919,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.007714986801147461,
      "rewards/margins": 0.002438449999317527,
      "rewards/rejected": 0.0052765365689992905,
      "step": 46
    },
    {
      "epoch": 3.64,
      "grad_norm": 7.582918167114258,
      "learning_rate": 9.587301587301587e-08,
      "logits/chosen": 1.1598496437072754,
      "logits/rejected": 1.0844165086746216,
      "logps/chosen": -34.75708770751953,
      "logps/rejected": -55.96159362792969,
      "loss": 0.6914,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0017622234299778938,
      "rewards/margins": 0.0035580398980528116,
      "rewards/rejected": -0.005320263095200062,
      "step": 47
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 7.396536827087402,
      "learning_rate": 9.571428571428571e-08,
      "logits/chosen": 1.2320778369903564,
      "logits/rejected": 1.226467251777649,
      "logps/chosen": -36.89041519165039,
      "logps/rejected": -60.22931671142578,
      "loss": 0.6928,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.00036735524190589786,
      "rewards/margins": 0.0009093284606933594,
      "rewards/rejected": -0.0005419731605798006,
      "step": 48
    },
    {
      "epoch": 3.8,
      "grad_norm": 7.202041149139404,
      "learning_rate": 9.555555555555556e-08,
      "logits/chosen": 1.1919187307357788,
      "logits/rejected": 1.0636210441589355,
      "logps/chosen": -30.53215789794922,
      "logps/rejected": -47.38115310668945,
      "loss": 0.6933,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0012877463595941663,
      "rewards/margins": -0.0003210068680346012,
      "rewards/rejected": -0.0009667398408055305,
      "step": 49
    },
    {
      "epoch": 3.88,
      "grad_norm": 7.609708786010742,
      "learning_rate": 9.53968253968254e-08,
      "logits/chosen": 1.2728285789489746,
      "logits/rejected": 1.4848206043243408,
      "logps/chosen": -32.01397705078125,
      "logps/rejected": -58.465946197509766,
      "loss": 0.6892,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00184380984865129,
      "rewards/margins": 0.007978035137057304,
      "rewards/rejected": -0.009821845218539238,
      "step": 50
    },
    {
      "epoch": 3.96,
      "grad_norm": 7.814793109893799,
      "learning_rate": 9.523809523809523e-08,
      "logits/chosen": 1.6161357164382935,
      "logits/rejected": 1.4109385013580322,
      "logps/chosen": -40.87925720214844,
      "logps/rejected": -57.54778289794922,
      "loss": 0.694,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0066818236373364925,
      "rewards/margins": -0.001681852270849049,
      "rewards/rejected": 0.008363676257431507,
      "step": 51
    },
    {
      "epoch": 4.0,
      "grad_norm": 10.314535140991211,
      "learning_rate": 9.507936507936507e-08,
      "logits/chosen": 1.2712292671203613,
      "logits/rejected": 1.3791817426681519,
      "logps/chosen": -36.36733627319336,
      "logps/rejected": -45.312355041503906,
      "loss": 0.6933,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0008625506889075041,
      "rewards/margins": -0.00029368395917117596,
      "rewards/rejected": -0.0005688669625669718,
      "step": 52
    },
    {
      "epoch": 4.0,
      "eval_logits/chosen": 1.3007044792175293,
      "eval_logits/rejected": 1.1943516731262207,
      "eval_logps/chosen": -34.473995208740234,
      "eval_logps/rejected": -47.00873565673828,
      "eval_loss": 0.6915371417999268,
      "eval_rewards/accuracies": 0.5600000023841858,
      "eval_rewards/chosen": 0.0025522613432258368,
      "eval_rewards/margins": 0.003307291306555271,
      "eval_rewards/rejected": -0.0007550296722911298,
      "eval_runtime": 2.7242,
      "eval_samples_per_second": 36.708,
      "eval_steps_per_second": 18.354,
      "step": 52
    },
    {
      "epoch": 4.08,
      "grad_norm": 8.005677223205566,
      "learning_rate": 9.492063492063491e-08,
      "logits/chosen": 1.1544880867004395,
      "logits/rejected": 1.1216461658477783,
      "logps/chosen": -34.61668395996094,
      "logps/rejected": -48.496177673339844,
      "loss": 0.6985,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.002633643103763461,
      "rewards/margins": -0.01055285893380642,
      "rewards/rejected": 0.00791921652853489,
      "step": 53
    },
    {
      "epoch": 4.16,
      "grad_norm": 9.633183479309082,
      "learning_rate": 9.476190476190475e-08,
      "logits/chosen": 1.307437777519226,
      "logits/rejected": 1.1332913637161255,
      "logps/chosen": -31.26520538330078,
      "logps/rejected": -50.437400817871094,
      "loss": 0.6955,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0020388364791870117,
      "rewards/margins": -0.0045654065907001495,
      "rewards/rejected": 0.0025265696458518505,
      "step": 54
    },
    {
      "epoch": 4.24,
      "grad_norm": 6.6085100173950195,
      "learning_rate": 9.46031746031746e-08,
      "logits/chosen": 1.409180998802185,
      "logits/rejected": 1.3700002431869507,
      "logps/chosen": -41.55030822753906,
      "logps/rejected": -58.896522521972656,
      "loss": 0.6959,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00564122200012207,
      "rewards/margins": -0.005478763021528721,
      "rewards/rejected": -0.00016245804727077484,
      "step": 55
    },
    {
      "epoch": 4.32,
      "grad_norm": 7.673524856567383,
      "learning_rate": 9.444444444444444e-08,
      "logits/chosen": 1.1339161396026611,
      "logits/rejected": 1.3294917345046997,
      "logps/chosen": -32.60820007324219,
      "logps/rejected": -57.202884674072266,
      "loss": 0.6899,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 7.224082946777344e-05,
      "rewards/margins": 0.006672525778412819,
      "rewards/rejected": -0.006600284017622471,
      "step": 56
    },
    {
      "epoch": 4.4,
      "grad_norm": 6.9141340255737305,
      "learning_rate": 9.428571428571428e-08,
      "logits/chosen": 1.3400936126708984,
      "logits/rejected": 1.3156325817108154,
      "logps/chosen": -37.50007629394531,
      "logps/rejected": -61.1422233581543,
      "loss": 0.6906,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0018209457630291581,
      "rewards/margins": 0.005248642060905695,
      "rewards/rejected": -0.007069587707519531,
      "step": 57
    },
    {
      "epoch": 4.48,
      "grad_norm": 7.877680778503418,
      "learning_rate": 9.412698412698412e-08,
      "logits/chosen": 1.24778151512146,
      "logits/rejected": 1.0591955184936523,
      "logps/chosen": -34.28763961791992,
      "logps/rejected": -45.67257308959961,
      "loss": 0.6941,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002044487278908491,
      "rewards/margins": -0.001808404689654708,
      "rewards/rejected": 0.0038528924342244864,
      "step": 58
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 8.930383682250977,
      "learning_rate": 9.396825396825397e-08,
      "logits/chosen": 1.2290056943893433,
      "logits/rejected": 1.2895803451538086,
      "logps/chosen": -37.70431900024414,
      "logps/rejected": -65.57011413574219,
      "loss": 0.6961,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.004354143515229225,
      "rewards/margins": -0.005671787541359663,
      "rewards/rejected": 0.0013176442589610815,
      "step": 59
    },
    {
      "epoch": 4.64,
      "grad_norm": 7.144107341766357,
      "learning_rate": 9.380952380952381e-08,
      "logits/chosen": 1.4356321096420288,
      "logits/rejected": 1.4133408069610596,
      "logps/chosen": -34.20771789550781,
      "logps/rejected": -57.00114822387695,
      "loss": 0.6881,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004543590359389782,
      "rewards/margins": 0.010161925107240677,
      "rewards/rejected": -0.005618333350867033,
      "step": 60
    },
    {
      "epoch": 4.72,
      "grad_norm": 8.066512107849121,
      "learning_rate": 9.365079365079365e-08,
      "logits/chosen": 1.394779920578003,
      "logits/rejected": 1.2928109169006348,
      "logps/chosen": -34.19990921020508,
      "logps/rejected": -49.57303237915039,
      "loss": 0.6977,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.005753445904701948,
      "rewards/margins": -0.00894620455801487,
      "rewards/rejected": 0.003192758187651634,
      "step": 61
    },
    {
      "epoch": 4.8,
      "grad_norm": 8.594874382019043,
      "learning_rate": 9.349206349206349e-08,
      "logits/chosen": 1.444027066230774,
      "logits/rejected": 1.1852223873138428,
      "logps/chosen": -32.1014289855957,
      "logps/rejected": -54.893924713134766,
      "loss": 0.6987,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0036679268814623356,
      "rewards/margins": -0.010968351736664772,
      "rewards/rejected": 0.007300424389541149,
      "step": 62
    },
    {
      "epoch": 4.88,
      "grad_norm": 6.913033485412598,
      "learning_rate": 9.333333333333334e-08,
      "logits/chosen": 1.3134368658065796,
      "logits/rejected": 1.3059146404266357,
      "logps/chosen": -30.385135650634766,
      "logps/rejected": -51.318634033203125,
      "loss": 0.6915,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008793259039521217,
      "rewards/margins": 0.0034120799973607063,
      "rewards/rejected": 0.005381179042160511,
      "step": 63
    },
    {
      "epoch": 4.96,
      "grad_norm": 7.0011186599731445,
      "learning_rate": 9.317460317460318e-08,
      "logits/chosen": 1.253799319267273,
      "logits/rejected": 1.226568341255188,
      "logps/chosen": -33.354896545410156,
      "logps/rejected": -59.59809494018555,
      "loss": 0.6978,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.006976604461669922,
      "rewards/margins": -0.00902786385267973,
      "rewards/rejected": 0.002051258459687233,
      "step": 64
    },
    {
      "epoch": 5.0,
      "grad_norm": 10.669974327087402,
      "learning_rate": 9.301587301587302e-08,
      "logits/chosen": 1.1272987127304077,
      "logits/rejected": 1.3113441467285156,
      "logps/chosen": -27.844907760620117,
      "logps/rejected": -51.690269470214844,
      "loss": 0.682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018929099664092064,
      "rewards/margins": 0.022610090672969818,
      "rewards/rejected": -0.0036809928715229034,
      "step": 65
    },
    {
      "epoch": 5.0,
      "eval_logits/chosen": 1.3010506629943848,
      "eval_logits/rejected": 1.1946834325790405,
      "eval_logps/chosen": -34.47685623168945,
      "eval_logps/rejected": -47.01823806762695,
      "eval_loss": 0.6912169456481934,
      "eval_rewards/accuracies": 0.6000000238418579,
      "eval_rewards/chosen": 0.0022659150417894125,
      "eval_rewards/margins": 0.0039708372205495834,
      "eval_rewards/rejected": -0.0017049217130988836,
      "eval_runtime": 2.7257,
      "eval_samples_per_second": 36.688,
      "eval_steps_per_second": 18.344,
      "step": 65
    },
    {
      "epoch": 5.08,
      "grad_norm": 8.631247520446777,
      "learning_rate": 9.285714285714286e-08,
      "logits/chosen": 1.2089680433273315,
      "logits/rejected": 1.3095850944519043,
      "logps/chosen": -34.763309478759766,
      "logps/rejected": -54.35471725463867,
      "loss": 0.6911,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.0008827687706798315,
      "rewards/margins": 0.004138660617172718,
      "rewards/rejected": -0.003255891613662243,
      "step": 66
    },
    {
      "epoch": 5.16,
      "grad_norm": 8.163905143737793,
      "learning_rate": 9.269841269841269e-08,
      "logits/chosen": 1.2491484880447388,
      "logits/rejected": 1.2012503147125244,
      "logps/chosen": -34.253684997558594,
      "logps/rejected": -49.175575256347656,
      "loss": 0.6967,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0028197765350341797,
      "rewards/margins": -0.007051229942589998,
      "rewards/rejected": 0.00987100601196289,
      "step": 67
    },
    {
      "epoch": 5.24,
      "grad_norm": 8.432445526123047,
      "learning_rate": 9.253968253968253e-08,
      "logits/chosen": 1.4491361379623413,
      "logits/rejected": 1.2992913722991943,
      "logps/chosen": -39.678001403808594,
      "logps/rejected": -54.339385986328125,
      "loss": 0.695,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.007408237550407648,
      "rewards/margins": -0.003378866706043482,
      "rewards/rejected": 0.010787105187773705,
      "step": 68
    },
    {
      "epoch": 5.32,
      "grad_norm": 7.530491352081299,
      "learning_rate": 9.238095238095238e-08,
      "logits/chosen": 1.3908649682998657,
      "logits/rejected": 1.3644661903381348,
      "logps/chosen": -35.143890380859375,
      "logps/rejected": -57.9501953125,
      "loss": 0.6916,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0029229403007775545,
      "rewards/margins": 0.0032750368118286133,
      "rewards/rejected": -0.0061979773454368114,
      "step": 69
    },
    {
      "epoch": 5.4,
      "grad_norm": 7.256721496582031,
      "learning_rate": 9.222222222222222e-08,
      "logits/chosen": 1.2141203880310059,
      "logits/rejected": 1.1625804901123047,
      "logps/chosen": -33.37965774536133,
      "logps/rejected": -55.47710037231445,
      "loss": 0.688,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005533313844352961,
      "rewards/margins": 0.01045980490744114,
      "rewards/rejected": -0.004926490131765604,
      "step": 70
    },
    {
      "epoch": 5.48,
      "grad_norm": 7.499918460845947,
      "learning_rate": 9.206349206349205e-08,
      "logits/chosen": 1.165770173072815,
      "logits/rejected": 1.3012510538101196,
      "logps/chosen": -30.135456085205078,
      "logps/rejected": -55.858367919921875,
      "loss": 0.693,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.002585863694548607,
      "rewards/margins": 0.00041439570486545563,
      "rewards/rejected": -0.00300025986507535,
      "step": 71
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 7.424239635467529,
      "learning_rate": 9.190476190476189e-08,
      "logits/chosen": 1.303959846496582,
      "logits/rejected": 1.0951049327850342,
      "logps/chosen": -35.51079559326172,
      "logps/rejected": -53.396602630615234,
      "loss": 0.6909,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006943941116333008,
      "rewards/margins": 0.0046187881380319595,
      "rewards/rejected": 0.0023251534439623356,
      "step": 72
    },
    {
      "epoch": 5.64,
      "grad_norm": 7.64024543762207,
      "learning_rate": 9.174603174603173e-08,
      "logits/chosen": 1.270266056060791,
      "logits/rejected": 1.2548789978027344,
      "logps/chosen": -32.95624923706055,
      "logps/rejected": -49.861572265625,
      "loss": 0.696,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.010721397586166859,
      "rewards/margins": -0.00555267371237278,
      "rewards/rejected": -0.005168724339455366,
      "step": 73
    },
    {
      "epoch": 5.72,
      "grad_norm": 6.859419345855713,
      "learning_rate": 9.158730158730157e-08,
      "logits/chosen": 1.5225307941436768,
      "logits/rejected": 1.3723198175430298,
      "logps/chosen": -31.817378997802734,
      "logps/rejected": -49.666358947753906,
      "loss": 0.6876,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0007384062628261745,
      "rewards/margins": 0.011133646592497826,
      "rewards/rejected": -0.010395240969955921,
      "step": 74
    },
    {
      "epoch": 5.8,
      "grad_norm": 7.919564723968506,
      "learning_rate": 9.142857142857142e-08,
      "logits/chosen": 1.238835334777832,
      "logits/rejected": 1.3306537866592407,
      "logps/chosen": -34.00298309326172,
      "logps/rejected": -59.285865783691406,
      "loss": 0.6863,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00535585917532444,
      "rewards/margins": 0.013802457600831985,
      "rewards/rejected": -0.008446598425507545,
      "step": 75
    },
    {
      "epoch": 5.88,
      "grad_norm": 8.254935264587402,
      "learning_rate": 9.126984126984126e-08,
      "logits/chosen": 1.2191135883331299,
      "logits/rejected": 1.2469974756240845,
      "logps/chosen": -34.780296325683594,
      "logps/rejected": -60.13839340209961,
      "loss": 0.6972,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.007872676476836205,
      "rewards/margins": -0.007835340686142445,
      "rewards/rejected": -3.733631456270814e-05,
      "step": 76
    },
    {
      "epoch": 5.96,
      "grad_norm": 7.890141010284424,
      "learning_rate": 9.11111111111111e-08,
      "logits/chosen": 1.3010071516036987,
      "logits/rejected": 1.1580736637115479,
      "logps/chosen": -34.60039520263672,
      "logps/rejected": -63.561866760253906,
      "loss": 0.69,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.001172899967059493,
      "rewards/margins": 0.006375956814736128,
      "rewards/rejected": -0.007548857014626265,
      "step": 77
    },
    {
      "epoch": 6.0,
      "grad_norm": 8.384530067443848,
      "learning_rate": 9.095238095238094e-08,
      "logits/chosen": 1.1372807025909424,
      "logits/rejected": 1.176348328590393,
      "logps/chosen": -33.425682067871094,
      "logps/rejected": -45.84657287597656,
      "loss": 0.69,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003009557258337736,
      "rewards/margins": 0.006384039297699928,
      "rewards/rejected": -0.009393597021698952,
      "step": 78
    },
    {
      "epoch": 6.0,
      "eval_logits/chosen": 1.301066279411316,
      "eval_logits/rejected": 1.194638967514038,
      "eval_logps/chosen": -34.486244201660156,
      "eval_logps/rejected": -47.00080490112305,
      "eval_loss": 0.6925568580627441,
      "eval_rewards/accuracies": 0.5400000214576721,
      "eval_rewards/chosen": 0.0013269844930619001,
      "eval_rewards/margins": 0.0012892228551208973,
      "eval_rewards/rejected": 3.7761852581752464e-05,
      "eval_runtime": 2.7247,
      "eval_samples_per_second": 36.701,
      "eval_steps_per_second": 18.351,
      "step": 78
    },
    {
      "epoch": 6.08,
      "grad_norm": 7.920542240142822,
      "learning_rate": 9.079365079365079e-08,
      "logits/chosen": 1.276604413986206,
      "logits/rejected": 1.3327662944793701,
      "logps/chosen": -31.880226135253906,
      "logps/rejected": -47.77296447753906,
      "loss": 0.6929,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0023688317742198706,
      "rewards/margins": 0.0007004740182310343,
      "rewards/rejected": -0.0030693048611283302,
      "step": 79
    },
    {
      "epoch": 6.16,
      "grad_norm": 7.332720756530762,
      "learning_rate": 9.063492063492063e-08,
      "logits/chosen": 1.3236963748931885,
      "logits/rejected": 1.3819242715835571,
      "logps/chosen": -36.84503936767578,
      "logps/rejected": -60.32972717285156,
      "loss": 0.6907,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.002201175782829523,
      "rewards/margins": 0.004971170797944069,
      "rewards/rejected": -0.007172346115112305,
      "step": 80
    },
    {
      "epoch": 6.24,
      "grad_norm": 6.297440052032471,
      "learning_rate": 9.047619047619047e-08,
      "logits/chosen": 1.185453176498413,
      "logits/rejected": 1.211104154586792,
      "logps/chosen": -31.783571243286133,
      "logps/rejected": -46.414249420166016,
      "loss": 0.6871,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008074736222624779,
      "rewards/margins": 0.01223599910736084,
      "rewards/rejected": -0.004161262884736061,
      "step": 81
    },
    {
      "epoch": 6.32,
      "grad_norm": 9.414315223693848,
      "learning_rate": 9.031746031746031e-08,
      "logits/chosen": 1.1973224878311157,
      "logits/rejected": 1.15255868434906,
      "logps/chosen": -30.157407760620117,
      "logps/rejected": -59.12372589111328,
      "loss": 0.6924,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0015688181156292558,
      "rewards/margins": 0.0016180281527340412,
      "rewards/rejected": -0.003186846151947975,
      "step": 82
    },
    {
      "epoch": 6.4,
      "grad_norm": 7.891414165496826,
      "learning_rate": 9.015873015873016e-08,
      "logits/chosen": 1.459791898727417,
      "logits/rejected": 1.3470947742462158,
      "logps/chosen": -35.68123245239258,
      "logps/rejected": -52.89822006225586,
      "loss": 0.6894,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.00447690486907959,
      "rewards/margins": 0.00768592394888401,
      "rewards/rejected": -0.003209018614143133,
      "step": 83
    },
    {
      "epoch": 6.48,
      "grad_norm": 7.56621789932251,
      "learning_rate": 9e-08,
      "logits/chosen": 1.159156322479248,
      "logits/rejected": 1.0681636333465576,
      "logps/chosen": -32.05260467529297,
      "logps/rejected": -51.800411224365234,
      "loss": 0.6899,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.002373313996940851,
      "rewards/margins": 0.006540203932672739,
      "rewards/rejected": -0.0041668894700706005,
      "step": 84
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 8.787468910217285,
      "learning_rate": 8.984126984126984e-08,
      "logits/chosen": 1.4964861869812012,
      "logits/rejected": 1.105859398841858,
      "logps/chosen": -40.524253845214844,
      "logps/rejected": -49.528411865234375,
      "loss": 0.6855,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.014561939053237438,
      "rewards/margins": 0.015511512756347656,
      "rewards/rejected": -0.0009495734702795744,
      "step": 85
    },
    {
      "epoch": 6.64,
      "grad_norm": 6.216403007507324,
      "learning_rate": 8.968253968253968e-08,
      "logits/chosen": 1.262650728225708,
      "logits/rejected": 1.496795654296875,
      "logps/chosen": -31.885997772216797,
      "logps/rejected": -50.2622184753418,
      "loss": 0.6907,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.001816201489418745,
      "rewards/margins": 0.005052970722317696,
      "rewards/rejected": -0.003236770164221525,
      "step": 86
    },
    {
      "epoch": 6.72,
      "grad_norm": 8.370656967163086,
      "learning_rate": 8.952380952380953e-08,
      "logits/chosen": 1.4978160858154297,
      "logits/rejected": 1.2304582595825195,
      "logps/chosen": -38.747459411621094,
      "logps/rejected": -57.157493591308594,
      "loss": 0.6865,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006664371583610773,
      "rewards/margins": 0.013520478270947933,
      "rewards/rejected": -0.006856108084321022,
      "step": 87
    },
    {
      "epoch": 6.8,
      "grad_norm": 6.878968715667725,
      "learning_rate": 8.936507936507937e-08,
      "logits/chosen": 1.3005001544952393,
      "logits/rejected": 1.3596067428588867,
      "logps/chosen": -31.808298110961914,
      "logps/rejected": -59.86473846435547,
      "loss": 0.687,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.000220036250539124,
      "rewards/margins": 0.012365031987428665,
      "rewards/rejected": -0.012144994921982288,
      "step": 88
    },
    {
      "epoch": 6.88,
      "grad_norm": 6.706499099731445,
      "learning_rate": 8.920634920634921e-08,
      "logits/chosen": 1.2000236511230469,
      "logits/rejected": 1.2413820028305054,
      "logps/chosen": -35.0797119140625,
      "logps/rejected": -60.64302444458008,
      "loss": 0.6876,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0019196032080799341,
      "rewards/margins": 0.011167669668793678,
      "rewards/rejected": -0.013087272644042969,
      "step": 89
    },
    {
      "epoch": 6.96,
      "grad_norm": 8.081245422363281,
      "learning_rate": 8.904761904761904e-08,
      "logits/chosen": 1.1790467500686646,
      "logits/rejected": 1.211045742034912,
      "logps/chosen": -32.767887115478516,
      "logps/rejected": -60.43797302246094,
      "loss": 0.6882,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0033239605836570263,
      "rewards/margins": 0.010030961595475674,
      "rewards/rejected": -0.006707001477479935,
      "step": 90
    },
    {
      "epoch": 7.0,
      "grad_norm": 10.254742622375488,
      "learning_rate": 8.888888888888888e-08,
      "logits/chosen": 1.3001189231872559,
      "logits/rejected": 1.2111891508102417,
      "logps/chosen": -36.205352783203125,
      "logps/rejected": -60.39249038696289,
      "loss": 0.6829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011698293499648571,
      "rewards/margins": 0.02070021629333496,
      "rewards/rejected": -0.00900192279368639,
      "step": 91
    },
    {
      "epoch": 7.0,
      "eval_logits/chosen": 1.301456093788147,
      "eval_logits/rejected": 1.1941496133804321,
      "eval_logps/chosen": -34.45260238647461,
      "eval_logps/rejected": -47.019161224365234,
      "eval_loss": 0.6899533867835999,
      "eval_rewards/accuracies": 0.6200000047683716,
      "eval_rewards/chosen": 0.004690961912274361,
      "eval_rewards/margins": 0.0064881332218647,
      "eval_rewards/rejected": -0.0017971708439290524,
      "eval_runtime": 2.7289,
      "eval_samples_per_second": 36.645,
      "eval_steps_per_second": 18.323,
      "step": 91
    },
    {
      "epoch": 7.08,
      "grad_norm": 7.145890235900879,
      "learning_rate": 8.873015873015872e-08,
      "logits/chosen": 1.3804187774658203,
      "logits/rejected": 1.4716670513153076,
      "logps/chosen": -31.83034896850586,
      "logps/rejected": -52.83613204956055,
      "loss": 0.6918,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.001296019647270441,
      "rewards/margins": 0.002683806698769331,
      "rewards/rejected": -0.0013877868186682463,
      "step": 92
    },
    {
      "epoch": 7.16,
      "grad_norm": 8.105794906616211,
      "learning_rate": 8.857142857142857e-08,
      "logits/chosen": 1.101591944694519,
      "logits/rejected": 1.2808630466461182,
      "logps/chosen": -32.36928176879883,
      "logps/rejected": -55.52438735961914,
      "loss": 0.6944,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.004617739003151655,
      "rewards/margins": -0.0024037836119532585,
      "rewards/rejected": -0.0022139549255371094,
      "step": 93
    },
    {
      "epoch": 7.24,
      "grad_norm": 8.224092483520508,
      "learning_rate": 8.841269841269841e-08,
      "logits/chosen": 1.1502447128295898,
      "logits/rejected": 1.057895541191101,
      "logps/chosen": -31.837505340576172,
      "logps/rejected": -49.044891357421875,
      "loss": 0.7013,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.002415895462036133,
      "rewards/margins": -0.016122961416840553,
      "rewards/rejected": 0.01370706595480442,
      "step": 94
    },
    {
      "epoch": 7.32,
      "grad_norm": 8.358383178710938,
      "learning_rate": 8.825396825396825e-08,
      "logits/chosen": 1.2060658931732178,
      "logits/rejected": 1.1998231410980225,
      "logps/chosen": -35.0042724609375,
      "logps/rejected": -58.47911834716797,
      "loss": 0.6866,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005055212881416082,
      "rewards/margins": 0.01310350839048624,
      "rewards/rejected": -0.008048295974731445,
      "step": 95
    },
    {
      "epoch": 7.4,
      "grad_norm": 8.119536399841309,
      "learning_rate": 8.80952380952381e-08,
      "logits/chosen": 1.5257306098937988,
      "logits/rejected": 1.129490852355957,
      "logps/chosen": -35.208763122558594,
      "logps/rejected": -51.93550109863281,
      "loss": 0.6917,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0010527372360229492,
      "rewards/margins": 0.0029505016282200813,
      "rewards/rejected": -0.004003238398581743,
      "step": 96
    },
    {
      "epoch": 7.48,
      "grad_norm": 7.064610958099365,
      "learning_rate": 8.793650793650794e-08,
      "logits/chosen": 1.3378971815109253,
      "logits/rejected": 1.4366495609283447,
      "logps/chosen": -32.67440414428711,
      "logps/rejected": -50.77534866333008,
      "loss": 0.6841,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00628426019102335,
      "rewards/margins": 0.018287254497408867,
      "rewards/rejected": -0.012002992443740368,
      "step": 97
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 7.78791618347168,
      "learning_rate": 8.777777777777778e-08,
      "logits/chosen": 1.7068989276885986,
      "logits/rejected": 1.603205680847168,
      "logps/chosen": -36.42616653442383,
      "logps/rejected": -60.754791259765625,
      "loss": 0.7006,
      "rewards/accuracies": 0.125,
      "rewards/chosen": -0.007227110676467419,
      "rewards/margins": -0.014706398360431194,
      "rewards/rejected": 0.007479285821318626,
      "step": 98
    },
    {
      "epoch": 7.64,
      "grad_norm": 7.112467288970947,
      "learning_rate": 8.761904761904762e-08,
      "logits/chosen": 1.3684871196746826,
      "logits/rejected": 1.1429246664047241,
      "logps/chosen": -32.95919418334961,
      "logps/rejected": -50.258426666259766,
      "loss": 0.6882,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.005586028564721346,
      "rewards/margins": 0.01009361818432808,
      "rewards/rejected": -0.004507589619606733,
      "step": 99
    },
    {
      "epoch": 7.72,
      "grad_norm": 9.314430236816406,
      "learning_rate": 8.746031746031745e-08,
      "logits/chosen": 1.208166241645813,
      "logits/rejected": 1.0470399856567383,
      "logps/chosen": -35.21957015991211,
      "logps/rejected": -61.474586486816406,
      "loss": 0.6892,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007129240315407515,
      "rewards/margins": 0.008051728829741478,
      "rewards/rejected": -0.0009224892128258944,
      "step": 100
    },
    {
      "epoch": 7.8,
      "grad_norm": 7.564837455749512,
      "learning_rate": 8.730158730158729e-08,
      "logits/chosen": 1.326017141342163,
      "logits/rejected": 1.2829254865646362,
      "logps/chosen": -36.005638122558594,
      "logps/rejected": -52.08599090576172,
      "loss": 0.6826,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01087255496531725,
      "rewards/margins": 0.021289300173521042,
      "rewards/rejected": -0.010416746139526367,
      "step": 101
    },
    {
      "epoch": 7.88,
      "grad_norm": 7.69124174118042,
      "learning_rate": 8.714285714285713e-08,
      "logits/chosen": 1.2223273515701294,
      "logits/rejected": 1.225005030632019,
      "logps/chosen": -36.71186447143555,
      "logps/rejected": -61.478370666503906,
      "loss": 0.6865,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.007717895321547985,
      "rewards/margins": 0.013451958075165749,
      "rewards/rejected": -0.0057340627536177635,
      "step": 102
    },
    {
      "epoch": 7.96,
      "grad_norm": 7.599912166595459,
      "learning_rate": 8.698412698412698e-08,
      "logits/chosen": 1.0523488521575928,
      "logits/rejected": 1.1140923500061035,
      "logps/chosen": -31.93460464477539,
      "logps/rejected": -51.696998596191406,
      "loss": 0.689,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0007695913081988692,
      "rewards/margins": 0.008493638597428799,
      "rewards/rejected": -0.009263229556381702,
      "step": 103
    },
    {
      "epoch": 8.0,
      "grad_norm": 9.620394706726074,
      "learning_rate": 8.682539682539682e-08,
      "logits/chosen": 1.121389627456665,
      "logits/rejected": 1.3823474645614624,
      "logps/chosen": -38.46542739868164,
      "logps/rejected": -59.500144958496094,
      "loss": 0.6864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.003903961041942239,
      "rewards/margins": 0.013493728823959827,
      "rewards/rejected": -0.009589767083525658,
      "step": 104
    },
    {
      "epoch": 8.0,
      "eval_logits/chosen": 1.3017996549606323,
      "eval_logits/rejected": 1.1959604024887085,
      "eval_logps/chosen": -34.433189392089844,
      "eval_logps/rejected": -46.99397277832031,
      "eval_loss": 0.69023597240448,
      "eval_rewards/accuracies": 0.6399999856948853,
      "eval_rewards/chosen": 0.006632665172219276,
      "eval_rewards/margins": 0.005910996347665787,
      "eval_rewards/rejected": 0.000721669930499047,
      "eval_runtime": 2.7286,
      "eval_samples_per_second": 36.648,
      "eval_steps_per_second": 18.324,
      "step": 104
    },
    {
      "epoch": 8.08,
      "grad_norm": 9.178519248962402,
      "learning_rate": 8.666666666666666e-08,
      "logits/chosen": 1.4863508939743042,
      "logits/rejected": 1.2548189163208008,
      "logps/chosen": -38.7215576171875,
      "logps/rejected": -54.38300323486328,
      "loss": 0.6891,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0013930083950981498,
      "rewards/margins": 0.0082169771194458,
      "rewards/rejected": -0.0068239690735936165,
      "step": 105
    },
    {
      "epoch": 8.16,
      "grad_norm": 7.13348388671875,
      "learning_rate": 8.65079365079365e-08,
      "logits/chosen": 1.2739105224609375,
      "logits/rejected": 1.2948524951934814,
      "logps/chosen": -30.85169219970703,
      "logps/rejected": -51.58204650878906,
      "loss": 0.6847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00973885040730238,
      "rewards/margins": 0.01692683808505535,
      "rewards/rejected": -0.007187986746430397,
      "step": 106
    },
    {
      "epoch": 8.24,
      "grad_norm": 7.890925407409668,
      "learning_rate": 8.634920634920635e-08,
      "logits/chosen": 1.1608620882034302,
      "logits/rejected": 1.4263410568237305,
      "logps/chosen": -33.41545867919922,
      "logps/rejected": -60.27329635620117,
      "loss": 0.6793,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.004676604177802801,
      "rewards/margins": 0.028107143938541412,
      "rewards/rejected": -0.023430539295077324,
      "step": 107
    },
    {
      "epoch": 8.32,
      "grad_norm": 8.094196319580078,
      "learning_rate": 8.619047619047619e-08,
      "logits/chosen": 1.1698962450027466,
      "logits/rejected": 1.0443812608718872,
      "logps/chosen": -29.530494689941406,
      "logps/rejected": -48.072200775146484,
      "loss": 0.6869,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00962593499571085,
      "rewards/margins": 0.012633848935365677,
      "rewards/rejected": -0.003007912542670965,
      "step": 108
    },
    {
      "epoch": 8.4,
      "grad_norm": 6.64188289642334,
      "learning_rate": 8.603174603174603e-08,
      "logits/chosen": 1.2564599514007568,
      "logits/rejected": 1.2758336067199707,
      "logps/chosen": -33.1495475769043,
      "logps/rejected": -53.447059631347656,
      "loss": 0.6895,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010875105857849121,
      "rewards/margins": 0.007460094057023525,
      "rewards/rejected": 0.003415012266486883,
      "step": 109
    },
    {
      "epoch": 8.48,
      "grad_norm": 8.018686294555664,
      "learning_rate": 8.587301587301586e-08,
      "logits/chosen": 1.1046714782714844,
      "logits/rejected": 1.4099745750427246,
      "logps/chosen": -40.68235778808594,
      "logps/rejected": -64.900390625,
      "loss": 0.6922,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.004513668827712536,
      "rewards/margins": 0.001985430484637618,
      "rewards/rejected": -0.006499099545180798,
      "step": 110
    },
    {
      "epoch": 8.56,
      "grad_norm": 6.821407318115234,
      "learning_rate": 8.57142857142857e-08,
      "logits/chosen": 1.4573044776916504,
      "logits/rejected": 1.2492185831069946,
      "logps/chosen": -32.39944076538086,
      "logps/rejected": -55.68961715698242,
      "loss": 0.6899,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003029394429177046,
      "rewards/margins": 0.006580829620361328,
      "rewards/rejected": -0.003551435424014926,
      "step": 111
    },
    {
      "epoch": 8.64,
      "grad_norm": 8.089945793151855,
      "learning_rate": 8.555555555555555e-08,
      "logits/chosen": 1.240654468536377,
      "logits/rejected": 1.255719780921936,
      "logps/chosen": -35.15227127075195,
      "logps/rejected": -60.275550842285156,
      "loss": 0.6835,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.018399907276034355,
      "rewards/margins": 0.01949916034936905,
      "rewards/rejected": -0.0010992527240887284,
      "step": 112
    },
    {
      "epoch": 8.72,
      "grad_norm": 7.283406734466553,
      "learning_rate": 8.539682539682539e-08,
      "logits/chosen": 1.202960729598999,
      "logits/rejected": 1.272437572479248,
      "logps/chosen": -35.51648712158203,
      "logps/rejected": -66.22289276123047,
      "loss": 0.6863,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008579755201935768,
      "rewards/margins": 0.013897823169827461,
      "rewards/rejected": -0.005318069830536842,
      "step": 113
    },
    {
      "epoch": 8.8,
      "grad_norm": 6.980158805847168,
      "learning_rate": 8.523809523809523e-08,
      "logits/chosen": 1.2848663330078125,
      "logits/rejected": 1.3325072526931763,
      "logps/chosen": -32.330955505371094,
      "logps/rejected": -45.75669860839844,
      "loss": 0.6852,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005078386981040239,
      "rewards/margins": 0.016079258173704147,
      "rewards/rejected": -0.011000871658325195,
      "step": 114
    },
    {
      "epoch": 8.88,
      "grad_norm": 7.731696128845215,
      "learning_rate": 8.507936507936507e-08,
      "logits/chosen": 1.403479814529419,
      "logits/rejected": 1.1127803325653076,
      "logps/chosen": -34.06074142456055,
      "logps/rejected": -51.93253707885742,
      "loss": 0.6894,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0027910470962524414,
      "rewards/margins": 0.00772750424221158,
      "rewards/rejected": -0.0049364566802978516,
      "step": 115
    },
    {
      "epoch": 8.96,
      "grad_norm": 7.854165077209473,
      "learning_rate": 8.492063492063491e-08,
      "logits/chosen": 1.4290227890014648,
      "logits/rejected": 1.1287697553634644,
      "logps/chosen": -35.75968933105469,
      "logps/rejected": -49.37096405029297,
      "loss": 0.6875,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010489488020539284,
      "rewards/margins": 0.01134040392935276,
      "rewards/rejected": -0.0008509163744747639,
      "step": 116
    },
    {
      "epoch": 9.0,
      "grad_norm": 9.008206367492676,
      "learning_rate": 8.476190476190476e-08,
      "logits/chosen": 1.3955035209655762,
      "logits/rejected": 1.1939480304718018,
      "logps/chosen": -30.592426300048828,
      "logps/rejected": -48.84539794921875,
      "loss": 0.6903,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0019707204774022102,
      "rewards/margins": 0.005810690112411976,
      "rewards/rejected": -0.007781410589814186,
      "step": 117
    },
    {
      "epoch": 9.0,
      "eval_logits/chosen": 1.3013423681259155,
      "eval_logits/rejected": 1.1963272094726562,
      "eval_logps/chosen": -34.47560119628906,
      "eval_logps/rejected": -47.04176712036133,
      "eval_loss": 0.6899804472923279,
      "eval_rewards/accuracies": 0.6499999761581421,
      "eval_rewards/chosen": 0.002391557674854994,
      "eval_rewards/margins": 0.0064491634257137775,
      "eval_rewards/rejected": -0.004057606682181358,
      "eval_runtime": 2.7262,
      "eval_samples_per_second": 36.681,
      "eval_steps_per_second": 18.34,
      "step": 117
    },
    {
      "epoch": 9.08,
      "grad_norm": 8.482686996459961,
      "learning_rate": 8.46031746031746e-08,
      "logits/chosen": 1.5580976009368896,
      "logits/rejected": 1.1498043537139893,
      "logps/chosen": -38.66684341430664,
      "logps/rejected": -56.373741149902344,
      "loss": 0.6893,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00749657116830349,
      "rewards/margins": 0.007753825280815363,
      "rewards/rejected": -0.00025725411251187325,
      "step": 118
    },
    {
      "epoch": 9.16,
      "grad_norm": 9.288324356079102,
      "learning_rate": 8.444444444444444e-08,
      "logits/chosen": 1.0877760648727417,
      "logits/rejected": 1.0996307134628296,
      "logps/chosen": -30.95914077758789,
      "logps/rejected": -60.65544509887695,
      "loss": 0.6876,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.012011170387268066,
      "rewards/margins": 0.011353707872331142,
      "rewards/rejected": 0.0006574629805982113,
      "step": 119
    },
    {
      "epoch": 9.24,
      "grad_norm": 7.2469987869262695,
      "learning_rate": 8.428571428571428e-08,
      "logits/chosen": 1.4278788566589355,
      "logits/rejected": 1.265508770942688,
      "logps/chosen": -34.84336471557617,
      "logps/rejected": -50.40087127685547,
      "loss": 0.6877,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00249328650534153,
      "rewards/margins": 0.010894632898271084,
      "rewards/rejected": -0.008401346392929554,
      "step": 120
    },
    {
      "epoch": 9.32,
      "grad_norm": 7.328564167022705,
      "learning_rate": 8.412698412698413e-08,
      "logits/chosen": 1.2947661876678467,
      "logits/rejected": 1.3413305282592773,
      "logps/chosen": -32.72112274169922,
      "logps/rejected": -49.25379180908203,
      "loss": 0.6858,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005172610282897949,
      "rewards/margins": 0.014804291538894176,
      "rewards/rejected": -0.009631682187318802,
      "step": 121
    },
    {
      "epoch": 9.4,
      "grad_norm": 6.8385114669799805,
      "learning_rate": 8.396825396825397e-08,
      "logits/chosen": 1.2578383684158325,
      "logits/rejected": 1.2950773239135742,
      "logps/chosen": -33.827903747558594,
      "logps/rejected": -53.886314392089844,
      "loss": 0.6876,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0032032490707933903,
      "rewards/margins": 0.011326838284730911,
      "rewards/rejected": -0.008123588748276234,
      "step": 122
    },
    {
      "epoch": 9.48,
      "grad_norm": 9.334724426269531,
      "learning_rate": 8.380952380952381e-08,
      "logits/chosen": 1.3188660144805908,
      "logits/rejected": 1.0083197355270386,
      "logps/chosen": -32.60673522949219,
      "logps/rejected": -51.05059814453125,
      "loss": 0.6889,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010658646002411842,
      "rewards/margins": 0.008738420903682709,
      "rewards/rejected": 0.001920223468914628,
      "step": 123
    },
    {
      "epoch": 9.56,
      "grad_norm": 7.156651973724365,
      "learning_rate": 8.365079365079365e-08,
      "logits/chosen": 1.3692518472671509,
      "logits/rejected": 1.185927152633667,
      "logps/chosen": -34.20256042480469,
      "logps/rejected": -54.91395568847656,
      "loss": 0.6874,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00701861409470439,
      "rewards/margins": 0.011685419827699661,
      "rewards/rejected": -0.004666806198656559,
      "step": 124
    },
    {
      "epoch": 9.64,
      "grad_norm": 8.224193572998047,
      "learning_rate": 8.34920634920635e-08,
      "logits/chosen": 1.2409147024154663,
      "logits/rejected": 1.2122079133987427,
      "logps/chosen": -35.687808990478516,
      "logps/rejected": -70.94515991210938,
      "loss": 0.6885,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010423993691802025,
      "rewards/margins": 0.009352494031190872,
      "rewards/rejected": 0.0010715009411796927,
      "step": 125
    },
    {
      "epoch": 9.72,
      "grad_norm": 7.149396896362305,
      "learning_rate": 8.333333333333334e-08,
      "logits/chosen": 1.1197032928466797,
      "logits/rejected": 1.160905361175537,
      "logps/chosen": -30.65546417236328,
      "logps/rejected": -47.952674865722656,
      "loss": 0.6841,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0035521031823009253,
      "rewards/margins": 0.018163206055760384,
      "rewards/rejected": -0.01461109984666109,
      "step": 126
    },
    {
      "epoch": 9.8,
      "grad_norm": 6.884220123291016,
      "learning_rate": 8.317460317460318e-08,
      "logits/chosen": 1.266771674156189,
      "logits/rejected": 1.3550313711166382,
      "logps/chosen": -32.05845642089844,
      "logps/rejected": -56.1374397277832,
      "loss": 0.6887,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0007790328236296773,
      "rewards/margins": 0.009082626551389694,
      "rewards/rejected": -0.008303595706820488,
      "step": 127
    },
    {
      "epoch": 9.88,
      "grad_norm": 6.285628318786621,
      "learning_rate": 8.301587301587302e-08,
      "logits/chosen": 1.355241298675537,
      "logits/rejected": 1.467958927154541,
      "logps/chosen": -37.66848373413086,
      "logps/rejected": -51.30418395996094,
      "loss": 0.6842,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0066641331650316715,
      "rewards/margins": 0.018198825418949127,
      "rewards/rejected": -0.011534691788256168,
      "step": 128
    },
    {
      "epoch": 9.96,
      "grad_norm": 7.788297176361084,
      "learning_rate": 8.285714285714285e-08,
      "logits/chosen": 1.1222096681594849,
      "logits/rejected": 1.3583273887634277,
      "logps/chosen": -33.79505920410156,
      "logps/rejected": -61.74549865722656,
      "loss": 0.6848,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004608607850968838,
      "rewards/margins": 0.01697828806936741,
      "rewards/rejected": -0.012369681149721146,
      "step": 129
    },
    {
      "epoch": 10.0,
      "grad_norm": 9.522077560424805,
      "learning_rate": 8.26984126984127e-08,
      "logits/chosen": 1.506575584411621,
      "logits/rejected": 1.6359200477600098,
      "logps/chosen": -38.65965270996094,
      "logps/rejected": -43.56055450439453,
      "loss": 0.6952,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.013849925249814987,
      "rewards/margins": -0.003978824242949486,
      "rewards/rejected": -0.009871101006865501,
      "step": 130
    },
    {
      "epoch": 10.0,
      "eval_logits/chosen": 1.302100658416748,
      "eval_logits/rejected": 1.1962031126022339,
      "eval_logps/chosen": -34.438167572021484,
      "eval_logps/rejected": -47.025882720947266,
      "eval_loss": 0.6888996362686157,
      "eval_rewards/accuracies": 0.6600000262260437,
      "eval_rewards/chosen": 0.006134652998298407,
      "eval_rewards/margins": 0.008604451082646847,
      "eval_rewards/rejected": -0.0024697971530258656,
      "eval_runtime": 2.7299,
      "eval_samples_per_second": 36.632,
      "eval_steps_per_second": 18.316,
      "step": 130
    },
    {
      "epoch": 10.08,
      "grad_norm": 8.39865493774414,
      "learning_rate": 8.253968253968254e-08,
      "logits/chosen": 1.2145214080810547,
      "logits/rejected": 1.0176275968551636,
      "logps/chosen": -31.75018882751465,
      "logps/rejected": -48.573848724365234,
      "loss": 0.6861,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0023083449341356754,
      "rewards/margins": 0.014410757459700108,
      "rewards/rejected": -0.012102413922548294,
      "step": 131
    },
    {
      "epoch": 10.16,
      "grad_norm": 7.236316680908203,
      "learning_rate": 8.238095238095238e-08,
      "logits/chosen": 1.4317518472671509,
      "logits/rejected": 1.2061586380004883,
      "logps/chosen": -33.42002868652344,
      "logps/rejected": -51.79861068725586,
      "loss": 0.6842,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006419920828193426,
      "rewards/margins": 0.01792771928012371,
      "rewards/rejected": -0.011507797986268997,
      "step": 132
    },
    {
      "epoch": 10.24,
      "grad_norm": 6.957096576690674,
      "learning_rate": 8.222222222222221e-08,
      "logits/chosen": 1.2844229936599731,
      "logits/rejected": 1.483852744102478,
      "logps/chosen": -33.372188568115234,
      "logps/rejected": -55.41618347167969,
      "loss": 0.6923,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.0014455795753747225,
      "rewards/margins": 0.0017173290252685547,
      "rewards/rejected": -0.0002717494498938322,
      "step": 133
    },
    {
      "epoch": 10.32,
      "grad_norm": 7.733076572418213,
      "learning_rate": 8.206349206349205e-08,
      "logits/chosen": 1.0715405941009521,
      "logits/rejected": 1.1351343393325806,
      "logps/chosen": -34.666481018066406,
      "logps/rejected": -64.2222900390625,
      "loss": 0.6883,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0027884962037205696,
      "rewards/margins": 0.009797620587050915,
      "rewards/rejected": -0.00700912531465292,
      "step": 134
    },
    {
      "epoch": 10.4,
      "grad_norm": 9.081058502197266,
      "learning_rate": 8.190476190476189e-08,
      "logits/chosen": 1.504848599433899,
      "logits/rejected": 1.2550373077392578,
      "logps/chosen": -44.176971435546875,
      "logps/rejected": -64.63531494140625,
      "loss": 0.6834,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011959647759795189,
      "rewards/margins": 0.019585561007261276,
      "rewards/rejected": -0.007625913713127375,
      "step": 135
    },
    {
      "epoch": 10.48,
      "grad_norm": 8.069687843322754,
      "learning_rate": 8.174603174603174e-08,
      "logits/chosen": 1.5116015672683716,
      "logits/rejected": 1.3844174146652222,
      "logps/chosen": -33.76213836669922,
      "logps/rejected": -61.05121612548828,
      "loss": 0.6839,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.014285421930253506,
      "rewards/margins": 0.018717193976044655,
      "rewards/rejected": -0.0044317725114524364,
      "step": 136
    },
    {
      "epoch": 10.56,
      "grad_norm": 6.951304912567139,
      "learning_rate": 8.158730158730158e-08,
      "logits/chosen": 1.259287714958191,
      "logits/rejected": 1.432865858078003,
      "logps/chosen": -33.93182373046875,
      "logps/rejected": -48.84214401245117,
      "loss": 0.6868,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.003079032991081476,
      "rewards/margins": 0.01279215794056654,
      "rewards/rejected": -0.015871191397309303,
      "step": 137
    },
    {
      "epoch": 10.64,
      "grad_norm": 7.9778971672058105,
      "learning_rate": 8.142857142857142e-08,
      "logits/chosen": 1.4312660694122314,
      "logits/rejected": 1.123877763748169,
      "logps/chosen": -30.3276309967041,
      "logps/rejected": -53.512901306152344,
      "loss": 0.6854,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007484674919396639,
      "rewards/margins": 0.015539885498583317,
      "rewards/rejected": -0.00805521011352539,
      "step": 138
    },
    {
      "epoch": 10.72,
      "grad_norm": 7.8790283203125,
      "learning_rate": 8.126984126984126e-08,
      "logits/chosen": 1.1003690958023071,
      "logits/rejected": 1.1874041557312012,
      "logps/chosen": -31.356815338134766,
      "logps/rejected": -57.29014587402344,
      "loss": 0.6764,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01173703745007515,
      "rewards/margins": 0.03385956585407257,
      "rewards/rejected": -0.022122524678707123,
      "step": 139
    },
    {
      "epoch": 10.8,
      "grad_norm": 8.318659782409668,
      "learning_rate": 8.11111111111111e-08,
      "logits/chosen": 1.2148818969726562,
      "logits/rejected": 1.2188334465026855,
      "logps/chosen": -36.21446990966797,
      "logps/rejected": -54.37621307373047,
      "loss": 0.6889,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0060708289965987206,
      "rewards/margins": 0.008642887696623802,
      "rewards/rejected": -0.0025720598641783,
      "step": 140
    },
    {
      "epoch": 10.88,
      "grad_norm": 6.7681965827941895,
      "learning_rate": 8.095238095238095e-08,
      "logits/chosen": 1.5097367763519287,
      "logits/rejected": 1.4563837051391602,
      "logps/chosen": -34.647483825683594,
      "logps/rejected": -52.80586242675781,
      "loss": 0.6842,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00651240348815918,
      "rewards/margins": 0.01812434196472168,
      "rewards/rejected": -0.0116119384765625,
      "step": 141
    },
    {
      "epoch": 10.96,
      "grad_norm": 6.039434432983398,
      "learning_rate": 8.079365079365079e-08,
      "logits/chosen": 1.1738780736923218,
      "logits/rejected": 1.097676396369934,
      "logps/chosen": -32.9928092956543,
      "logps/rejected": -45.99407196044922,
      "loss": 0.6846,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007877779193222523,
      "rewards/margins": 0.017203617841005325,
      "rewards/rejected": -0.009325838647782803,
      "step": 142
    },
    {
      "epoch": 11.0,
      "grad_norm": 8.688104629516602,
      "learning_rate": 8.063492063492063e-08,
      "logits/chosen": 1.3026618957519531,
      "logits/rejected": 1.4410616159439087,
      "logps/chosen": -32.63391876220703,
      "logps/rejected": -56.44984817504883,
      "loss": 0.6815,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010237885639071465,
      "rewards/margins": 0.023584509268403053,
      "rewards/rejected": -0.013346624560654163,
      "step": 143
    },
    {
      "epoch": 11.0,
      "eval_logits/chosen": 1.306066870689392,
      "eval_logits/rejected": 1.2002108097076416,
      "eval_logps/chosen": -34.4067497253418,
      "eval_logps/rejected": -47.005374908447266,
      "eval_loss": 0.6883546710014343,
      "eval_rewards/accuracies": 0.699999988079071,
      "eval_rewards/chosen": 0.009276975877583027,
      "eval_rewards/margins": 0.009695641696453094,
      "eval_rewards/rejected": -0.00041866512037813663,
      "eval_runtime": 2.7313,
      "eval_samples_per_second": 36.612,
      "eval_steps_per_second": 18.306,
      "step": 143
    },
    {
      "epoch": 11.08,
      "grad_norm": 7.690527439117432,
      "learning_rate": 8.047619047619047e-08,
      "logits/chosen": 0.9665671586990356,
      "logits/rejected": 1.2335867881774902,
      "logps/chosen": -32.934329986572266,
      "logps/rejected": -53.451751708984375,
      "loss": 0.6897,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01113660354167223,
      "rewards/margins": 0.007053590379655361,
      "rewards/rejected": 0.004083013162016869,
      "step": 144
    },
    {
      "epoch": 11.16,
      "grad_norm": 7.539001941680908,
      "learning_rate": 8.031746031746032e-08,
      "logits/chosen": 1.2832884788513184,
      "logits/rejected": 1.3871008157730103,
      "logps/chosen": -33.45781326293945,
      "logps/rejected": -58.63209915161133,
      "loss": 0.6881,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.005739093292504549,
      "rewards/margins": 0.010268998332321644,
      "rewards/rejected": -0.01600809209048748,
      "step": 145
    },
    {
      "epoch": 11.24,
      "grad_norm": 7.742546558380127,
      "learning_rate": 8.015873015873016e-08,
      "logits/chosen": 1.230212688446045,
      "logits/rejected": 1.6018853187561035,
      "logps/chosen": -39.59330749511719,
      "logps/rejected": -71.18193054199219,
      "loss": 0.6891,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006668019574135542,
      "rewards/margins": 0.008273720741271973,
      "rewards/rejected": -0.0016057013999670744,
      "step": 146
    },
    {
      "epoch": 11.32,
      "grad_norm": 6.981311798095703,
      "learning_rate": 8e-08,
      "logits/chosen": 1.2591819763183594,
      "logits/rejected": 1.0936741828918457,
      "logps/chosen": -31.34206771850586,
      "logps/rejected": -44.71202850341797,
      "loss": 0.6841,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012680507265031338,
      "rewards/margins": 0.018190359696745872,
      "rewards/rejected": -0.005509853363037109,
      "step": 147
    },
    {
      "epoch": 11.4,
      "grad_norm": 8.3333158493042,
      "learning_rate": 7.984126984126984e-08,
      "logits/chosen": 1.501185655593872,
      "logits/rejected": 1.3003458976745605,
      "logps/chosen": -35.335533142089844,
      "logps/rejected": -59.3675422668457,
      "loss": 0.681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.002568960189819336,
      "rewards/margins": 0.024538230150938034,
      "rewards/rejected": -0.021969271823763847,
      "step": 148
    },
    {
      "epoch": 11.48,
      "grad_norm": 9.517759323120117,
      "learning_rate": 7.968253968253967e-08,
      "logits/chosen": 1.4477739334106445,
      "logits/rejected": 1.1095836162567139,
      "logps/chosen": -32.53271484375,
      "logps/rejected": -55.44138717651367,
      "loss": 0.6847,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013442350551486015,
      "rewards/margins": 0.017102790996432304,
      "rewards/rejected": -0.003660440444946289,
      "step": 149
    },
    {
      "epoch": 11.56,
      "grad_norm": 7.295268535614014,
      "learning_rate": 7.952380952380952e-08,
      "logits/chosen": 1.1243659257888794,
      "logits/rejected": 0.9816529750823975,
      "logps/chosen": -30.736474990844727,
      "logps/rejected": -51.60462188720703,
      "loss": 0.684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0006883860332891345,
      "rewards/margins": 0.01847670041024685,
      "rewards/rejected": -0.017788317054510117,
      "step": 150
    },
    {
      "epoch": 11.64,
      "grad_norm": 6.834798812866211,
      "learning_rate": 7.936507936507936e-08,
      "logits/chosen": 1.4190442562103271,
      "logits/rejected": 1.412647008895874,
      "logps/chosen": -35.36531066894531,
      "logps/rejected": -56.53435516357422,
      "loss": 0.6927,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.005511092953383923,
      "rewards/margins": 0.0008809566497802734,
      "rewards/rejected": -0.006392050534486771,
      "step": 151
    },
    {
      "epoch": 11.72,
      "grad_norm": 6.9919023513793945,
      "learning_rate": 7.92063492063492e-08,
      "logits/chosen": 1.506733775138855,
      "logits/rejected": 1.3286738395690918,
      "logps/chosen": -38.480064392089844,
      "logps/rejected": -48.33959197998047,
      "loss": 0.6871,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.003517674747854471,
      "rewards/margins": 0.012193774804472923,
      "rewards/rejected": -0.008676099590957165,
      "step": 152
    },
    {
      "epoch": 11.8,
      "grad_norm": 7.646460056304932,
      "learning_rate": 7.904761904761904e-08,
      "logits/chosen": 1.4370211362838745,
      "logits/rejected": 1.2395344972610474,
      "logps/chosen": -33.758262634277344,
      "logps/rejected": -49.69507598876953,
      "loss": 0.6903,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.0007315397961065173,
      "rewards/margins": 0.005893159657716751,
      "rewards/rejected": -0.006624698638916016,
      "step": 153
    },
    {
      "epoch": 11.88,
      "grad_norm": 7.634042739868164,
      "learning_rate": 7.888888888888889e-08,
      "logits/chosen": 1.1851109266281128,
      "logits/rejected": 1.2700788974761963,
      "logps/chosen": -35.21155548095703,
      "logps/rejected": -67.46825408935547,
      "loss": 0.6818,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.00041096238419413567,
      "rewards/margins": 0.022824978455901146,
      "rewards/rejected": -0.02323593944311142,
      "step": 154
    },
    {
      "epoch": 11.96,
      "grad_norm": 6.960168361663818,
      "learning_rate": 7.873015873015873e-08,
      "logits/chosen": 1.2287529706954956,
      "logits/rejected": 1.1687355041503906,
      "logps/chosen": -31.837661743164062,
      "logps/rejected": -45.45185470581055,
      "loss": 0.6842,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009267186746001244,
      "rewards/margins": 0.017943238839507103,
      "rewards/rejected": -0.00867605209350586,
      "step": 155
    },
    {
      "epoch": 12.0,
      "grad_norm": 8.70888614654541,
      "learning_rate": 7.857142857142857e-08,
      "logits/chosen": 1.3533434867858887,
      "logits/rejected": 1.3385913372039795,
      "logps/chosen": -32.825836181640625,
      "logps/rejected": -49.84523010253906,
      "loss": 0.6805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022263718768954277,
      "rewards/margins": 0.02557401731610298,
      "rewards/rejected": -0.003310299012809992,
      "step": 156
    },
    {
      "epoch": 12.0,
      "eval_logits/chosen": 1.3044536113739014,
      "eval_logits/rejected": 1.197858452796936,
      "eval_logps/chosen": -34.394073486328125,
      "eval_logps/rejected": -46.984745025634766,
      "eval_loss": 0.6887680292129517,
      "eval_rewards/accuracies": 0.6700000166893005,
      "eval_rewards/chosen": 0.010544625110924244,
      "eval_rewards/margins": 0.008900820277631283,
      "eval_rewards/rejected": 0.0016438063466921449,
      "eval_runtime": 2.7268,
      "eval_samples_per_second": 36.673,
      "eval_steps_per_second": 18.336,
      "step": 156
    },
    {
      "epoch": 12.08,
      "grad_norm": 8.188251495361328,
      "learning_rate": 7.841269841269841e-08,
      "logits/chosen": 1.277921438217163,
      "logits/rejected": 0.9972397089004517,
      "logps/chosen": -31.88448715209961,
      "logps/rejected": -52.17333984375,
      "loss": 0.6809,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.011469555087387562,
      "rewards/margins": 0.02490868605673313,
      "rewards/rejected": -0.01343913096934557,
      "step": 157
    },
    {
      "epoch": 12.16,
      "grad_norm": 8.068220138549805,
      "learning_rate": 7.825396825396825e-08,
      "logits/chosen": 1.4574424028396606,
      "logits/rejected": 1.227955937385559,
      "logps/chosen": -37.67344665527344,
      "logps/rejected": -53.8859748840332,
      "loss": 0.6832,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.012540913186967373,
      "rewards/margins": 0.020147182047367096,
      "rewards/rejected": -0.0076062679290771484,
      "step": 158
    },
    {
      "epoch": 12.24,
      "grad_norm": 6.877861976623535,
      "learning_rate": 7.80952380952381e-08,
      "logits/chosen": 1.4610881805419922,
      "logits/rejected": 1.5408633947372437,
      "logps/chosen": -35.8243522644043,
      "logps/rejected": -60.47868347167969,
      "loss": 0.68,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013062287122011185,
      "rewards/margins": 0.0265805721282959,
      "rewards/rejected": -0.013518285937607288,
      "step": 159
    },
    {
      "epoch": 12.32,
      "grad_norm": 7.344379901885986,
      "learning_rate": 7.793650793650794e-08,
      "logits/chosen": 1.2403945922851562,
      "logits/rejected": 1.1985650062561035,
      "logps/chosen": -33.028717041015625,
      "logps/rejected": -55.263885498046875,
      "loss": 0.6877,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.00017251959070563316,
      "rewards/margins": 0.011002612300217152,
      "rewards/rejected": -0.010830093175172806,
      "step": 160
    },
    {
      "epoch": 12.4,
      "grad_norm": 8.597611427307129,
      "learning_rate": 7.777777777777778e-08,
      "logits/chosen": 1.3499982357025146,
      "logits/rejected": 1.1205511093139648,
      "logps/chosen": -32.264366149902344,
      "logps/rejected": -51.03573989868164,
      "loss": 0.6903,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.0012337923981249332,
      "rewards/margins": 0.005892586428672075,
      "rewards/rejected": -0.007126379758119583,
      "step": 161
    },
    {
      "epoch": 12.48,
      "grad_norm": 7.038087844848633,
      "learning_rate": 7.761904761904761e-08,
      "logits/chosen": 1.2237732410430908,
      "logits/rejected": 1.2679401636123657,
      "logps/chosen": -32.917144775390625,
      "logps/rejected": -56.750728607177734,
      "loss": 0.6881,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0038062576204538345,
      "rewards/margins": 0.010167980566620827,
      "rewards/rejected": -0.013974238187074661,
      "step": 162
    },
    {
      "epoch": 12.56,
      "grad_norm": 8.461194038391113,
      "learning_rate": 7.746031746031745e-08,
      "logits/chosen": 1.1900707483291626,
      "logits/rejected": 1.2754398584365845,
      "logps/chosen": -34.41410446166992,
      "logps/rejected": -64.11072540283203,
      "loss": 0.6929,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.005874108988791704,
      "rewards/margins": 0.0005061146803200245,
      "rewards/rejected": 0.00536799430847168,
      "step": 163
    },
    {
      "epoch": 12.64,
      "grad_norm": 7.086338520050049,
      "learning_rate": 7.73015873015873e-08,
      "logits/chosen": 1.433902621269226,
      "logits/rejected": 1.3114855289459229,
      "logps/chosen": -37.44056701660156,
      "logps/rejected": -50.87558364868164,
      "loss": 0.6925,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0027655363082885742,
      "rewards/margins": 0.0013759376015514135,
      "rewards/rejected": 0.0013895990559831262,
      "step": 164
    },
    {
      "epoch": 12.72,
      "grad_norm": 8.15523910522461,
      "learning_rate": 7.714285714285714e-08,
      "logits/chosen": 1.1409378051757812,
      "logits/rejected": 1.2444682121276855,
      "logps/chosen": -29.6201171875,
      "logps/rejected": -54.037147521972656,
      "loss": 0.68,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01994338072836399,
      "rewards/margins": 0.026592399924993515,
      "rewards/rejected": -0.006649017799645662,
      "step": 165
    },
    {
      "epoch": 12.8,
      "grad_norm": 8.230925559997559,
      "learning_rate": 7.698412698412698e-08,
      "logits/chosen": 1.3817309141159058,
      "logits/rejected": 1.3730847835540771,
      "logps/chosen": -37.00912094116211,
      "logps/rejected": -49.501731872558594,
      "loss": 0.6849,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.002862382447347045,
      "rewards/margins": 0.01680438593029976,
      "rewards/rejected": -0.01394200325012207,
      "step": 166
    },
    {
      "epoch": 12.88,
      "grad_norm": 8.621148109436035,
      "learning_rate": 7.682539682539682e-08,
      "logits/chosen": 1.0633931159973145,
      "logits/rejected": 1.0507019758224487,
      "logps/chosen": -32.88755798339844,
      "logps/rejected": -52.99748229980469,
      "loss": 0.6843,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009534334763884544,
      "rewards/margins": 0.017858242616057396,
      "rewards/rejected": -0.008323907852172852,
      "step": 167
    },
    {
      "epoch": 12.96,
      "grad_norm": 7.368919372558594,
      "learning_rate": 7.666666666666666e-08,
      "logits/chosen": 1.400505781173706,
      "logits/rejected": 1.4591106176376343,
      "logps/chosen": -38.19688415527344,
      "logps/rejected": -60.799468994140625,
      "loss": 0.6884,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.006740307901054621,
      "rewards/margins": 0.009624314494431019,
      "rewards/rejected": -0.016364622861146927,
      "step": 168
    },
    {
      "epoch": 13.0,
      "grad_norm": 8.659003257751465,
      "learning_rate": 7.65079365079365e-08,
      "logits/chosen": 1.2010161876678467,
      "logits/rejected": 1.2677600383758545,
      "logps/chosen": -27.52072525024414,
      "logps/rejected": -49.677310943603516,
      "loss": 0.6818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007824230007827282,
      "rewards/margins": 0.022772502154111862,
      "rewards/rejected": -0.01494827214628458,
      "step": 169
    },
    {
      "epoch": 13.0,
      "eval_logits/chosen": 1.304728388786316,
      "eval_logits/rejected": 1.198588252067566,
      "eval_logps/chosen": -34.467960357666016,
      "eval_logps/rejected": -47.040462493896484,
      "eval_loss": 0.6896610260009766,
      "eval_rewards/accuracies": 0.6399999856948853,
      "eval_rewards/chosen": 0.003155592130497098,
      "eval_rewards/margins": 0.007083395030349493,
      "eval_rewards/rejected": -0.003927803132683039,
      "eval_runtime": 2.7346,
      "eval_samples_per_second": 36.569,
      "eval_steps_per_second": 18.284,
      "step": 169
    },
    {
      "epoch": 13.08,
      "grad_norm": 7.878892421722412,
      "learning_rate": 7.634920634920634e-08,
      "logits/chosen": 1.2086775302886963,
      "logits/rejected": 1.1276261806488037,
      "logps/chosen": -34.46585464477539,
      "logps/rejected": -55.90278244018555,
      "loss": 0.6776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006703066639602184,
      "rewards/margins": 0.03143799304962158,
      "rewards/rejected": -0.024734925478696823,
      "step": 170
    },
    {
      "epoch": 13.16,
      "grad_norm": 6.415688991546631,
      "learning_rate": 7.619047619047618e-08,
      "logits/chosen": 1.1516304016113281,
      "logits/rejected": 1.243544101715088,
      "logps/chosen": -32.5460205078125,
      "logps/rejected": -52.48373794555664,
      "loss": 0.6858,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0006374357617460191,
      "rewards/margins": 0.014969730749726295,
      "rewards/rejected": -0.014332294464111328,
      "step": 171
    },
    {
      "epoch": 13.24,
      "grad_norm": 7.172104358673096,
      "learning_rate": 7.603174603174602e-08,
      "logits/chosen": 1.3947348594665527,
      "logits/rejected": 1.2577123641967773,
      "logps/chosen": -33.31903076171875,
      "logps/rejected": -50.93907928466797,
      "loss": 0.6898,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.006680584046989679,
      "rewards/margins": 0.006783151067793369,
      "rewards/rejected": -0.00010256771929562092,
      "step": 172
    },
    {
      "epoch": 13.32,
      "grad_norm": 7.4617156982421875,
      "learning_rate": 7.587301587301586e-08,
      "logits/chosen": 1.3388644456863403,
      "logits/rejected": 1.3232792615890503,
      "logps/chosen": -37.670082092285156,
      "logps/rejected": -61.57777404785156,
      "loss": 0.6869,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00803842581808567,
      "rewards/margins": 0.01265101507306099,
      "rewards/rejected": -0.004612589254975319,
      "step": 173
    },
    {
      "epoch": 13.4,
      "grad_norm": 7.277202129364014,
      "learning_rate": 7.57142857142857e-08,
      "logits/chosen": 1.3120861053466797,
      "logits/rejected": 1.212661862373352,
      "logps/chosen": -31.905195236206055,
      "logps/rejected": -56.010292053222656,
      "loss": 0.6846,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012361216358840466,
      "rewards/margins": 0.017188549041748047,
      "rewards/rejected": -0.004827332217246294,
      "step": 174
    },
    {
      "epoch": 13.48,
      "grad_norm": 7.8035969734191895,
      "learning_rate": 7.555555555555555e-08,
      "logits/chosen": 1.2734746932983398,
      "logits/rejected": 1.1421858072280884,
      "logps/chosen": -34.21200180053711,
      "logps/rejected": -53.36473083496094,
      "loss": 0.6798,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005699110217392445,
      "rewards/margins": 0.026981018483638763,
      "rewards/rejected": -0.021281912922859192,
      "step": 175
    },
    {
      "epoch": 13.56,
      "grad_norm": 7.678882598876953,
      "learning_rate": 7.539682539682539e-08,
      "logits/chosen": 1.3606157302856445,
      "logits/rejected": 1.451470136642456,
      "logps/chosen": -34.348731994628906,
      "logps/rejected": -50.84039306640625,
      "loss": 0.6813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011360527016222477,
      "rewards/margins": 0.02393167093396187,
      "rewards/rejected": -0.012571144849061966,
      "step": 176
    },
    {
      "epoch": 13.64,
      "grad_norm": 7.6023783683776855,
      "learning_rate": 7.523809523809523e-08,
      "logits/chosen": 1.5578478574752808,
      "logits/rejected": 1.374760627746582,
      "logps/chosen": -32.973243713378906,
      "logps/rejected": -52.5296516418457,
      "loss": 0.6896,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.006397533696144819,
      "rewards/margins": 0.007083940785378218,
      "rewards/rejected": -0.0006864070892333984,
      "step": 177
    },
    {
      "epoch": 13.72,
      "grad_norm": 7.752438068389893,
      "learning_rate": 7.507936507936508e-08,
      "logits/chosen": 1.1134964227676392,
      "logits/rejected": 1.1959714889526367,
      "logps/chosen": -34.00794982910156,
      "logps/rejected": -56.27824401855469,
      "loss": 0.6865,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0009681461378931999,
      "rewards/margins": 0.013490701094269753,
      "rewards/rejected": -0.012522554025053978,
      "step": 178
    },
    {
      "epoch": 13.8,
      "grad_norm": 7.716013431549072,
      "learning_rate": 7.492063492063492e-08,
      "logits/chosen": 1.402164340019226,
      "logits/rejected": 1.1725234985351562,
      "logps/chosen": -38.208984375,
      "logps/rejected": -50.2779541015625,
      "loss": 0.6817,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0061661247164011,
      "rewards/margins": 0.02314586751163006,
      "rewards/rejected": -0.016979742795228958,
      "step": 179
    },
    {
      "epoch": 13.88,
      "grad_norm": 9.222060203552246,
      "learning_rate": 7.476190476190476e-08,
      "logits/chosen": 1.520820140838623,
      "logits/rejected": 1.2641971111297607,
      "logps/chosen": -34.170501708984375,
      "logps/rejected": -50.26655578613281,
      "loss": 0.6761,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013938522897660732,
      "rewards/margins": 0.03443474695086479,
      "rewards/rejected": -0.020496224984526634,
      "step": 180
    },
    {
      "epoch": 13.96,
      "grad_norm": 8.990923881530762,
      "learning_rate": 7.46031746031746e-08,
      "logits/chosen": 1.1933321952819824,
      "logits/rejected": 1.2274620532989502,
      "logps/chosen": -32.85232925415039,
      "logps/rejected": -64.28584289550781,
      "loss": 0.6833,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0023256302811205387,
      "rewards/margins": 0.019996263086795807,
      "rewards/rejected": -0.02232189290225506,
      "step": 181
    },
    {
      "epoch": 14.0,
      "grad_norm": 9.521794319152832,
      "learning_rate": 7.444444444444444e-08,
      "logits/chosen": 1.1760292053222656,
      "logits/rejected": 1.4744716882705688,
      "logps/chosen": -32.41904830932617,
      "logps/rejected": -64.92343139648438,
      "loss": 0.6839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0001457691250834614,
      "rewards/margins": 0.01868157461285591,
      "rewards/rejected": -0.018535804003477097,
      "step": 182
    },
    {
      "epoch": 14.0,
      "eval_logits/chosen": 1.3056693077087402,
      "eval_logits/rejected": 1.1996577978134155,
      "eval_logps/chosen": -34.41496658325195,
      "eval_logps/rejected": -47.029781341552734,
      "eval_loss": 0.6875668168067932,
      "eval_rewards/accuracies": 0.6899999976158142,
      "eval_rewards/chosen": 0.008454819209873676,
      "eval_rewards/margins": 0.011314298957586288,
      "eval_rewards/rejected": -0.002859479980543256,
      "eval_runtime": 2.7295,
      "eval_samples_per_second": 36.637,
      "eval_steps_per_second": 18.318,
      "step": 182
    },
    {
      "epoch": 14.08,
      "grad_norm": 7.397454261779785,
      "learning_rate": 7.428571428571429e-08,
      "logits/chosen": 1.3418375253677368,
      "logits/rejected": 1.1680539846420288,
      "logps/chosen": -32.52648162841797,
      "logps/rejected": -55.609657287597656,
      "loss": 0.6874,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0024029253982007504,
      "rewards/margins": 0.011634253896772861,
      "rewards/rejected": -0.0140371797606349,
      "step": 183
    },
    {
      "epoch": 14.16,
      "grad_norm": 8.02993392944336,
      "learning_rate": 7.412698412698413e-08,
      "logits/chosen": 1.3336079120635986,
      "logits/rejected": 1.3547532558441162,
      "logps/chosen": -34.95410919189453,
      "logps/rejected": -56.219879150390625,
      "loss": 0.6855,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.004980825819075108,
      "rewards/margins": 0.015597367659211159,
      "rewards/rejected": -0.010616540908813477,
      "step": 184
    },
    {
      "epoch": 14.24,
      "grad_norm": 6.560757637023926,
      "learning_rate": 7.396825396825397e-08,
      "logits/chosen": 1.370485544204712,
      "logits/rejected": 1.2559840679168701,
      "logps/chosen": -34.777198791503906,
      "logps/rejected": -48.41969680786133,
      "loss": 0.6789,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006619691848754883,
      "rewards/margins": 0.02871871180832386,
      "rewards/rejected": -0.022099018096923828,
      "step": 185
    },
    {
      "epoch": 14.32,
      "grad_norm": 8.23790168762207,
      "learning_rate": 7.380952380952381e-08,
      "logits/chosen": 1.4258390665054321,
      "logits/rejected": 1.2825932502746582,
      "logps/chosen": -35.76443862915039,
      "logps/rejected": -48.80711364746094,
      "loss": 0.6854,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.015022659674286842,
      "rewards/margins": 0.015592384152114391,
      "rewards/rejected": -0.0005697251763194799,
      "step": 186
    },
    {
      "epoch": 14.4,
      "grad_norm": 7.895158290863037,
      "learning_rate": 7.365079365079366e-08,
      "logits/chosen": 1.1500864028930664,
      "logits/rejected": 1.132167100906372,
      "logps/chosen": -34.29308319091797,
      "logps/rejected": -58.015995025634766,
      "loss": 0.6796,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0064792390912771225,
      "rewards/margins": 0.02739412896335125,
      "rewards/rejected": -0.020914889872074127,
      "step": 187
    },
    {
      "epoch": 14.48,
      "grad_norm": 8.112027168273926,
      "learning_rate": 7.34920634920635e-08,
      "logits/chosen": 1.3499984741210938,
      "logits/rejected": 1.4336472749710083,
      "logps/chosen": -29.73453140258789,
      "logps/rejected": -49.95113754272461,
      "loss": 0.6806,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010739303193986416,
      "rewards/margins": 0.02534472942352295,
      "rewards/rejected": -0.014605427160859108,
      "step": 188
    },
    {
      "epoch": 14.56,
      "grad_norm": 7.114919185638428,
      "learning_rate": 7.333333333333333e-08,
      "logits/chosen": 1.1732288599014282,
      "logits/rejected": 1.2734019756317139,
      "logps/chosen": -34.236900329589844,
      "logps/rejected": -52.8986930847168,
      "loss": 0.6859,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004888057708740234,
      "rewards/margins": 0.014719797298312187,
      "rewards/rejected": -0.009831738658249378,
      "step": 189
    },
    {
      "epoch": 14.64,
      "grad_norm": 6.963634490966797,
      "learning_rate": 7.317460317460317e-08,
      "logits/chosen": 1.174574613571167,
      "logits/rejected": 1.3062944412231445,
      "logps/chosen": -36.489959716796875,
      "logps/rejected": -58.95549011230469,
      "loss": 0.6821,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007622266188263893,
      "rewards/margins": 0.02232949808239937,
      "rewards/rejected": -0.014707231894135475,
      "step": 190
    },
    {
      "epoch": 14.72,
      "grad_norm": 7.600866794586182,
      "learning_rate": 7.301587301587301e-08,
      "logits/chosen": 1.3684157133102417,
      "logits/rejected": 1.2342149019241333,
      "logps/chosen": -33.43239212036133,
      "logps/rejected": -54.86415100097656,
      "loss": 0.6784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008042573928833008,
      "rewards/margins": 0.029781579971313477,
      "rewards/rejected": -0.02173900604248047,
      "step": 191
    },
    {
      "epoch": 14.8,
      "grad_norm": 7.365416526794434,
      "learning_rate": 7.285714285714286e-08,
      "logits/chosen": 1.3520128726959229,
      "logits/rejected": 1.3558157682418823,
      "logps/chosen": -34.60595703125,
      "logps/rejected": -66.77467346191406,
      "loss": 0.682,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007559227757155895,
      "rewards/margins": 0.022510170936584473,
      "rewards/rejected": -0.014950942248106003,
      "step": 192
    },
    {
      "epoch": 14.88,
      "grad_norm": 7.634554386138916,
      "learning_rate": 7.26984126984127e-08,
      "logits/chosen": 1.3193657398223877,
      "logits/rejected": 1.1608121395111084,
      "logps/chosen": -35.31288146972656,
      "logps/rejected": -50.10521697998047,
      "loss": 0.6786,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015333032235503197,
      "rewards/margins": 0.029351424425840378,
      "rewards/rejected": -0.014018392190337181,
      "step": 193
    },
    {
      "epoch": 14.96,
      "grad_norm": 7.687429428100586,
      "learning_rate": 7.253968253968254e-08,
      "logits/chosen": 1.3576627969741821,
      "logits/rejected": 1.1561949253082275,
      "logps/chosen": -33.8281135559082,
      "logps/rejected": -54.98713302612305,
      "loss": 0.6731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012683725915849209,
      "rewards/margins": 0.04060106351971626,
      "rewards/rejected": -0.02791733853518963,
      "step": 194
    },
    {
      "epoch": 15.0,
      "grad_norm": 12.181891441345215,
      "learning_rate": 7.238095238095238e-08,
      "logits/chosen": 1.1701816320419312,
      "logits/rejected": 1.118044137954712,
      "logps/chosen": -33.54560852050781,
      "logps/rejected": -63.57556915283203,
      "loss": 0.6788,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005929326638579369,
      "rewards/margins": 0.02891726791858673,
      "rewards/rejected": -0.022987939417362213,
      "step": 195
    },
    {
      "epoch": 15.0,
      "eval_logits/chosen": 1.3056544065475464,
      "eval_logits/rejected": 1.1987757682800293,
      "eval_logps/chosen": -34.4434700012207,
      "eval_logps/rejected": -47.055816650390625,
      "eval_loss": 0.6876863241195679,
      "eval_rewards/accuracies": 0.7099999785423279,
      "eval_rewards/chosen": 0.005604270845651627,
      "eval_rewards/margins": 0.011067155748605728,
      "eval_rewards/rejected": -0.0054628849029541016,
      "eval_runtime": 2.7315,
      "eval_samples_per_second": 36.61,
      "eval_steps_per_second": 18.305,
      "step": 195
    },
    {
      "epoch": 15.08,
      "grad_norm": 6.695777893066406,
      "learning_rate": 7.222222222222221e-08,
      "logits/chosen": 1.4176855087280273,
      "logits/rejected": 1.3717244863510132,
      "logps/chosen": -32.608436584472656,
      "logps/rejected": -43.00373840332031,
      "loss": 0.6821,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008336258120834827,
      "rewards/margins": 0.02235403098165989,
      "rewards/rejected": -0.014017772860825062,
      "step": 196
    },
    {
      "epoch": 15.16,
      "grad_norm": 6.4071879386901855,
      "learning_rate": 7.206349206349205e-08,
      "logits/chosen": 1.461728572845459,
      "logits/rejected": 1.4544706344604492,
      "logps/chosen": -39.00246810913086,
      "logps/rejected": -44.802947998046875,
      "loss": 0.6861,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.005992245860397816,
      "rewards/margins": 0.014329599216580391,
      "rewards/rejected": -0.02032184600830078,
      "step": 197
    },
    {
      "epoch": 15.24,
      "grad_norm": 8.036434173583984,
      "learning_rate": 7.19047619047619e-08,
      "logits/chosen": 1.390833854675293,
      "logits/rejected": 1.4805490970611572,
      "logps/chosen": -35.26197814941406,
      "logps/rejected": -56.272727966308594,
      "loss": 0.6855,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0067961690947413445,
      "rewards/margins": 0.01554331835359335,
      "rewards/rejected": -0.008747149258852005,
      "step": 198
    },
    {
      "epoch": 15.32,
      "grad_norm": 8.005674362182617,
      "learning_rate": 7.174603174603174e-08,
      "logits/chosen": 1.0210189819335938,
      "logits/rejected": 1.1419004201889038,
      "logps/chosen": -38.32044982910156,
      "logps/rejected": -56.33720397949219,
      "loss": 0.6854,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0033739330247044563,
      "rewards/margins": 0.015702366828918457,
      "rewards/rejected": -0.012328433804214,
      "step": 199
    },
    {
      "epoch": 15.4,
      "grad_norm": 7.759169101715088,
      "learning_rate": 7.158730158730158e-08,
      "logits/chosen": 1.1781162023544312,
      "logits/rejected": 1.17864990234375,
      "logps/chosen": -31.689464569091797,
      "logps/rejected": -57.58491897583008,
      "loss": 0.687,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.002159047406166792,
      "rewards/margins": 0.012418771162629128,
      "rewards/rejected": -0.014577819034457207,
      "step": 200
    },
    {
      "epoch": 15.48,
      "grad_norm": 8.869379997253418,
      "learning_rate": 7.142857142857142e-08,
      "logits/chosen": 1.1803460121154785,
      "logits/rejected": 1.2844080924987793,
      "logps/chosen": -34.26789474487305,
      "logps/rejected": -57.25679016113281,
      "loss": 0.6868,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01022479496896267,
      "rewards/margins": 0.012811089865863323,
      "rewards/rejected": -0.002586293499916792,
      "step": 201
    },
    {
      "epoch": 15.56,
      "grad_norm": 6.9853010177612305,
      "learning_rate": 7.126984126984127e-08,
      "logits/chosen": 1.2047815322875977,
      "logits/rejected": 1.2825525999069214,
      "logps/chosen": -33.255210876464844,
      "logps/rejected": -56.693626403808594,
      "loss": 0.6796,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013313103467226028,
      "rewards/margins": 0.02744770050048828,
      "rewards/rejected": -0.014134598895907402,
      "step": 202
    },
    {
      "epoch": 15.64,
      "grad_norm": 7.755886077880859,
      "learning_rate": 7.111111111111111e-08,
      "logits/chosen": 1.2344738245010376,
      "logits/rejected": 1.3523731231689453,
      "logps/chosen": -33.99864196777344,
      "logps/rejected": -57.574256896972656,
      "loss": 0.6847,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009022665210068226,
      "rewards/margins": 0.017050504684448242,
      "rewards/rejected": -0.008027839474380016,
      "step": 203
    },
    {
      "epoch": 15.72,
      "grad_norm": 9.209673881530762,
      "learning_rate": 7.095238095238095e-08,
      "logits/chosen": 1.4058667421340942,
      "logits/rejected": 1.0921728610992432,
      "logps/chosen": -33.66017532348633,
      "logps/rejected": -48.38990783691406,
      "loss": 0.6774,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011016417294740677,
      "rewards/margins": 0.03188662603497505,
      "rewards/rejected": -0.020870208740234375,
      "step": 204
    },
    {
      "epoch": 15.8,
      "grad_norm": 6.980284214019775,
      "learning_rate": 7.079365079365079e-08,
      "logits/chosen": 1.4305787086486816,
      "logits/rejected": 1.170391321182251,
      "logps/chosen": -34.858253479003906,
      "logps/rejected": -57.1378288269043,
      "loss": 0.6817,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0038416385650634766,
      "rewards/margins": 0.023174811154603958,
      "rewards/rejected": -0.01933317258954048,
      "step": 205
    },
    {
      "epoch": 15.88,
      "grad_norm": 8.228848457336426,
      "learning_rate": 7.063492063492064e-08,
      "logits/chosen": 1.2772636413574219,
      "logits/rejected": 1.0154571533203125,
      "logps/chosen": -30.16450309753418,
      "logps/rejected": -56.135955810546875,
      "loss": 0.6744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014643598347902298,
      "rewards/margins": 0.03787529468536377,
      "rewards/rejected": -0.02323169820010662,
      "step": 206
    },
    {
      "epoch": 15.96,
      "grad_norm": 7.9866557121276855,
      "learning_rate": 7.047619047619048e-08,
      "logits/chosen": 1.241518497467041,
      "logits/rejected": 1.2201584577560425,
      "logps/chosen": -33.55266571044922,
      "logps/rejected": -68.33220672607422,
      "loss": 0.6754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008858872577548027,
      "rewards/margins": 0.03587312623858452,
      "rewards/rejected": -0.02701425738632679,
      "step": 207
    },
    {
      "epoch": 16.0,
      "grad_norm": 9.365086555480957,
      "learning_rate": 7.031746031746032e-08,
      "logits/chosen": 1.495176911354065,
      "logits/rejected": 1.3540046215057373,
      "logps/chosen": -32.25311279296875,
      "logps/rejected": -56.08213806152344,
      "loss": 0.6702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020641088485717773,
      "rewards/margins": 0.04646172747015953,
      "rewards/rejected": -0.025820637121796608,
      "step": 208
    },
    {
      "epoch": 16.0,
      "eval_logits/chosen": 1.3061045408248901,
      "eval_logits/rejected": 1.1978192329406738,
      "eval_logps/chosen": -34.45049285888672,
      "eval_logps/rejected": -47.05585479736328,
      "eval_loss": 0.688031792640686,
      "eval_rewards/accuracies": 0.6800000071525574,
      "eval_rewards/chosen": 0.00490187294781208,
      "eval_rewards/margins": 0.010368730872869492,
      "eval_rewards/rejected": -0.005466857459396124,
      "eval_runtime": 2.7405,
      "eval_samples_per_second": 36.489,
      "eval_steps_per_second": 18.245,
      "step": 208
    },
    {
      "epoch": 16.08,
      "grad_norm": 7.7263312339782715,
      "learning_rate": 7.015873015873015e-08,
      "logits/chosen": 1.390500545501709,
      "logits/rejected": 1.3492757081985474,
      "logps/chosen": -45.84214401245117,
      "logps/rejected": -56.558929443359375,
      "loss": 0.6926,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.002943658735603094,
      "rewards/margins": 0.0012718203943222761,
      "rewards/rejected": -0.004215479362756014,
      "step": 209
    },
    {
      "epoch": 16.16,
      "grad_norm": 8.617122650146484,
      "learning_rate": 6.999999999999999e-08,
      "logits/chosen": 1.2374935150146484,
      "logits/rejected": 1.185265302658081,
      "logps/chosen": -34.727012634277344,
      "logps/rejected": -58.357967376708984,
      "loss": 0.6851,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.011933112516999245,
      "rewards/margins": 0.016187025234103203,
      "rewards/rejected": -0.004253912717103958,
      "step": 210
    },
    {
      "epoch": 16.24,
      "grad_norm": 8.155075073242188,
      "learning_rate": 6.984126984126983e-08,
      "logits/chosen": 1.3979072570800781,
      "logits/rejected": 1.0598398447036743,
      "logps/chosen": -29.696353912353516,
      "logps/rejected": -51.185699462890625,
      "loss": 0.6797,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.013558674603700638,
      "rewards/margins": 0.027152061462402344,
      "rewards/rejected": -0.013593388721346855,
      "step": 211
    },
    {
      "epoch": 16.32,
      "grad_norm": 7.613036155700684,
      "learning_rate": 6.968253968253968e-08,
      "logits/chosen": 1.2621378898620605,
      "logits/rejected": 1.376543402671814,
      "logps/chosen": -33.14143371582031,
      "logps/rejected": -53.73899841308594,
      "loss": 0.6779,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006280208006501198,
      "rewards/margins": 0.030795646831393242,
      "rewards/rejected": -0.024515438824892044,
      "step": 212
    },
    {
      "epoch": 16.4,
      "grad_norm": 7.389136791229248,
      "learning_rate": 6.952380952380952e-08,
      "logits/chosen": 1.4325391054153442,
      "logits/rejected": 1.3775620460510254,
      "logps/chosen": -34.87468338012695,
      "logps/rejected": -59.407432556152344,
      "loss": 0.6862,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004649424459785223,
      "rewards/margins": 0.014032579958438873,
      "rewards/rejected": -0.009383154101669788,
      "step": 213
    },
    {
      "epoch": 16.48,
      "grad_norm": 7.481785297393799,
      "learning_rate": 6.936507936507936e-08,
      "logits/chosen": 0.9981432557106018,
      "logits/rejected": 1.1462833881378174,
      "logps/chosen": -30.969892501831055,
      "logps/rejected": -47.052589416503906,
      "loss": 0.6862,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.006584263406693935,
      "rewards/margins": 0.014199303463101387,
      "rewards/rejected": -0.0076150414533913136,
      "step": 214
    },
    {
      "epoch": 16.56,
      "grad_norm": 6.449438571929932,
      "learning_rate": 6.92063492063492e-08,
      "logits/chosen": 1.4137849807739258,
      "logits/rejected": 1.283324122428894,
      "logps/chosen": -34.913909912109375,
      "logps/rejected": -56.605445861816406,
      "loss": 0.6862,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009150862693786621,
      "rewards/margins": 0.014118265360593796,
      "rewards/rejected": -0.004967403132468462,
      "step": 215
    },
    {
      "epoch": 16.64,
      "grad_norm": 7.111197471618652,
      "learning_rate": 6.904761904761905e-08,
      "logits/chosen": 1.3559515476226807,
      "logits/rejected": 1.2101850509643555,
      "logps/chosen": -34.21483612060547,
      "logps/rejected": -55.650146484375,
      "loss": 0.679,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014013601467013359,
      "rewards/margins": 0.0287276990711689,
      "rewards/rejected": -0.01471409760415554,
      "step": 216
    },
    {
      "epoch": 16.72,
      "grad_norm": 7.312015533447266,
      "learning_rate": 6.888888888888889e-08,
      "logits/chosen": 1.2393890619277954,
      "logits/rejected": 1.3078293800354004,
      "logps/chosen": -31.260604858398438,
      "logps/rejected": -54.643096923828125,
      "loss": 0.6815,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.00978844240307808,
      "rewards/margins": 0.023605801165103912,
      "rewards/rejected": -0.013817357830703259,
      "step": 217
    },
    {
      "epoch": 16.8,
      "grad_norm": 7.873908519744873,
      "learning_rate": 6.873015873015873e-08,
      "logits/chosen": 1.2273471355438232,
      "logits/rejected": 1.2957203388214111,
      "logps/chosen": -34.83939743041992,
      "logps/rejected": -62.27695846557617,
      "loss": 0.6766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012587095610797405,
      "rewards/margins": 0.03347919136285782,
      "rewards/rejected": -0.02089209482073784,
      "step": 218
    },
    {
      "epoch": 16.88,
      "grad_norm": 7.586362838745117,
      "learning_rate": 6.857142857142857e-08,
      "logits/chosen": 1.2783571481704712,
      "logits/rejected": 1.4442189931869507,
      "logps/chosen": -32.12321472167969,
      "logps/rejected": -50.930503845214844,
      "loss": 0.6914,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0006319999229162931,
      "rewards/margins": 0.003645706456154585,
      "rewards/rejected": -0.004277706146240234,
      "step": 219
    },
    {
      "epoch": 16.96,
      "grad_norm": 8.268556594848633,
      "learning_rate": 6.841269841269842e-08,
      "logits/chosen": 1.275315761566162,
      "logits/rejected": 1.0188673734664917,
      "logps/chosen": -32.55352783203125,
      "logps/rejected": -49.34156799316406,
      "loss": 0.6717,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01692485809326172,
      "rewards/margins": 0.043839313089847565,
      "rewards/rejected": -0.026914453133940697,
      "step": 220
    },
    {
      "epoch": 17.0,
      "grad_norm": 8.624120712280273,
      "learning_rate": 6.825396825396826e-08,
      "logits/chosen": 1.2285149097442627,
      "logits/rejected": 1.369361400604248,
      "logps/chosen": -34.987937927246094,
      "logps/rejected": -62.759368896484375,
      "loss": 0.6848,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004792356863617897,
      "rewards/margins": 0.016838598996400833,
      "rewards/rejected": -0.012046242132782936,
      "step": 221
    },
    {
      "epoch": 17.0,
      "eval_logits/chosen": 1.306372046470642,
      "eval_logits/rejected": 1.1994189023971558,
      "eval_logps/chosen": -34.411190032958984,
      "eval_logps/rejected": -47.051300048828125,
      "eval_loss": 0.686311662197113,
      "eval_rewards/accuracies": 0.7200000286102295,
      "eval_rewards/chosen": 0.008832357823848724,
      "eval_rewards/margins": 0.013843416236341,
      "eval_rewards/rejected": -0.0050110588781535625,
      "eval_runtime": 2.7371,
      "eval_samples_per_second": 36.535,
      "eval_steps_per_second": 18.268,
      "step": 221
    },
    {
      "epoch": 17.08,
      "grad_norm": 9.36155891418457,
      "learning_rate": 6.80952380952381e-08,
      "logits/chosen": 1.341434121131897,
      "logits/rejected": 1.0232713222503662,
      "logps/chosen": -33.04039764404297,
      "logps/rejected": -55.810272216796875,
      "loss": 0.6847,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.0011754750739783049,
      "rewards/margins": 0.017216183245182037,
      "rewards/rejected": -0.01839165762066841,
      "step": 222
    },
    {
      "epoch": 17.16,
      "grad_norm": 6.928870677947998,
      "learning_rate": 6.793650793650794e-08,
      "logits/chosen": 1.273419976234436,
      "logits/rejected": 1.457549810409546,
      "logps/chosen": -35.57657241821289,
      "logps/rejected": -48.562767028808594,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009975790977478027,
      "rewards/margins": 0.033815838396549225,
      "rewards/rejected": -0.02384004555642605,
      "step": 223
    },
    {
      "epoch": 17.24,
      "grad_norm": 7.569497585296631,
      "learning_rate": 6.777777777777778e-08,
      "logits/chosen": 1.274759292602539,
      "logits/rejected": 1.2387852668762207,
      "logps/chosen": -35.1732292175293,
      "logps/rejected": -55.881935119628906,
      "loss": 0.6786,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009849620051681995,
      "rewards/margins": 0.029485106468200684,
      "rewards/rejected": -0.019635487347841263,
      "step": 224
    },
    {
      "epoch": 17.32,
      "grad_norm": 7.477481365203857,
      "learning_rate": 6.761904761904761e-08,
      "logits/chosen": 1.341923475265503,
      "logits/rejected": 1.338810920715332,
      "logps/chosen": -32.77936935424805,
      "logps/rejected": -59.758399963378906,
      "loss": 0.6788,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013265633955597878,
      "rewards/margins": 0.02905881591141224,
      "rewards/rejected": -0.015793180093169212,
      "step": 225
    },
    {
      "epoch": 17.4,
      "grad_norm": 6.168572425842285,
      "learning_rate": 6.746031746031746e-08,
      "logits/chosen": 1.6370618343353271,
      "logits/rejected": 1.4506672620773315,
      "logps/chosen": -36.23149108886719,
      "logps/rejected": -55.1496467590332,
      "loss": 0.6858,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0027849909383803606,
      "rewards/margins": 0.014930463396012783,
      "rewards/rejected": -0.012145470827817917,
      "step": 226
    },
    {
      "epoch": 17.48,
      "grad_norm": 8.198533058166504,
      "learning_rate": 6.73015873015873e-08,
      "logits/chosen": 1.3567066192626953,
      "logits/rejected": 1.276167392730713,
      "logps/chosen": -36.786067962646484,
      "logps/rejected": -58.544437408447266,
      "loss": 0.6794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011464477516710758,
      "rewards/margins": 0.027654577046632767,
      "rewards/rejected": -0.016190100461244583,
      "step": 227
    },
    {
      "epoch": 17.56,
      "grad_norm": 7.341919422149658,
      "learning_rate": 6.714285714285714e-08,
      "logits/chosen": 1.1531935930252075,
      "logits/rejected": 1.2316361665725708,
      "logps/chosen": -34.122474670410156,
      "logps/rejected": -63.018131256103516,
      "loss": 0.6799,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0061893705278635025,
      "rewards/margins": 0.026819920167326927,
      "rewards/rejected": -0.020630549639463425,
      "step": 228
    },
    {
      "epoch": 17.64,
      "grad_norm": 7.982844829559326,
      "learning_rate": 6.698412698412697e-08,
      "logits/chosen": 1.185041904449463,
      "logits/rejected": 1.2338995933532715,
      "logps/chosen": -33.82074737548828,
      "logps/rejected": -53.162147521972656,
      "loss": 0.6823,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004855656996369362,
      "rewards/margins": 0.02186276763677597,
      "rewards/rejected": -0.017007112503051758,
      "step": 229
    },
    {
      "epoch": 17.72,
      "grad_norm": 7.874823570251465,
      "learning_rate": 6.682539682539681e-08,
      "logits/chosen": 1.4779863357543945,
      "logits/rejected": 1.4274914264678955,
      "logps/chosen": -33.44736862182617,
      "logps/rejected": -52.40522003173828,
      "loss": 0.6868,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0032043936662375927,
      "rewards/margins": 0.012935638427734375,
      "rewards/rejected": -0.00973124522715807,
      "step": 230
    },
    {
      "epoch": 17.8,
      "grad_norm": 7.488699436187744,
      "learning_rate": 6.666666666666665e-08,
      "logits/chosen": 1.2062411308288574,
      "logits/rejected": 0.9111225605010986,
      "logps/chosen": -31.041973114013672,
      "logps/rejected": -45.2642707824707,
      "loss": 0.6817,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0031031605321913958,
      "rewards/margins": 0.023090768605470657,
      "rewards/rejected": -0.01998760737478733,
      "step": 231
    },
    {
      "epoch": 17.88,
      "grad_norm": 8.096761703491211,
      "learning_rate": 6.65079365079365e-08,
      "logits/chosen": 1.3763126134872437,
      "logits/rejected": 1.2849857807159424,
      "logps/chosen": -33.85319519042969,
      "logps/rejected": -60.07947540283203,
      "loss": 0.684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004977845586836338,
      "rewards/margins": 0.018463708460330963,
      "rewards/rejected": -0.01348586194217205,
      "step": 232
    },
    {
      "epoch": 17.96,
      "grad_norm": 7.4992780685424805,
      "learning_rate": 6.634920634920634e-08,
      "logits/chosen": 1.243652105331421,
      "logits/rejected": 1.2218544483184814,
      "logps/chosen": -34.85960006713867,
      "logps/rejected": -50.98888397216797,
      "loss": 0.6815,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0046520475298166275,
      "rewards/margins": 0.023494888097047806,
      "rewards/rejected": -0.01884284056723118,
      "step": 233
    },
    {
      "epoch": 18.0,
      "grad_norm": 10.30646800994873,
      "learning_rate": 6.619047619047618e-08,
      "logits/chosen": 0.8937042951583862,
      "logits/rejected": 1.4392118453979492,
      "logps/chosen": -32.31179428100586,
      "logps/rejected": -58.45008087158203,
      "loss": 0.6799,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0023849965073168278,
      "rewards/margins": 0.026854466646909714,
      "rewards/rejected": -0.029239464551210403,
      "step": 234
    },
    {
      "epoch": 18.0,
      "eval_logits/chosen": 1.3072938919067383,
      "eval_logits/rejected": 1.2005904912948608,
      "eval_logps/chosen": -34.38663864135742,
      "eval_logps/rejected": -46.99895095825195,
      "eval_loss": 0.6876839995384216,
      "eval_rewards/accuracies": 0.7200000286102295,
      "eval_rewards/chosen": 0.011287926696240902,
      "eval_rewards/margins": 0.011064263992011547,
      "eval_rewards/rejected": 0.0002236614964203909,
      "eval_runtime": 2.7368,
      "eval_samples_per_second": 36.539,
      "eval_steps_per_second": 18.27,
      "step": 234
    },
    {
      "epoch": 18.08,
      "grad_norm": 7.396026611328125,
      "learning_rate": 6.603174603174602e-08,
      "logits/chosen": 1.1044812202453613,
      "logits/rejected": 1.3030784130096436,
      "logps/chosen": -34.70198059082031,
      "logps/rejected": -56.99087905883789,
      "loss": 0.6872,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004207253456115723,
      "rewards/margins": 0.012029385194182396,
      "rewards/rejected": -0.007822131738066673,
      "step": 235
    },
    {
      "epoch": 18.16,
      "grad_norm": 7.556771755218506,
      "learning_rate": 6.587301587301587e-08,
      "logits/chosen": 1.2846180200576782,
      "logits/rejected": 1.1814594268798828,
      "logps/chosen": -33.70095443725586,
      "logps/rejected": -53.77091979980469,
      "loss": 0.68,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.005752944853156805,
      "rewards/margins": 0.026667213067412376,
      "rewards/rejected": -0.020914269611239433,
      "step": 236
    },
    {
      "epoch": 18.24,
      "grad_norm": 6.860888481140137,
      "learning_rate": 6.571428571428571e-08,
      "logits/chosen": 1.2605820894241333,
      "logits/rejected": 1.4597748517990112,
      "logps/chosen": -32.46463394165039,
      "logps/rejected": -56.24284362792969,
      "loss": 0.6869,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0084244254976511,
      "rewards/margins": 0.012603331357240677,
      "rewards/rejected": -0.004178905859589577,
      "step": 237
    },
    {
      "epoch": 18.32,
      "grad_norm": 8.357401847839355,
      "learning_rate": 6.555555555555555e-08,
      "logits/chosen": 1.2455929517745972,
      "logits/rejected": 1.3314040899276733,
      "logps/chosen": -41.09320831298828,
      "logps/rejected": -77.50395202636719,
      "loss": 0.6819,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.013531493954360485,
      "rewards/margins": 0.022744322195649147,
      "rewards/rejected": -0.009212829172611237,
      "step": 238
    },
    {
      "epoch": 18.4,
      "grad_norm": 7.671013355255127,
      "learning_rate": 6.53968253968254e-08,
      "logits/chosen": 1.3797996044158936,
      "logits/rejected": 1.4190183877944946,
      "logps/chosen": -33.96410369873047,
      "logps/rejected": -46.882511138916016,
      "loss": 0.6864,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005802154541015625,
      "rewards/margins": 0.013650608249008656,
      "rewards/rejected": -0.00784845370799303,
      "step": 239
    },
    {
      "epoch": 18.48,
      "grad_norm": 7.909109115600586,
      "learning_rate": 6.523809523809524e-08,
      "logits/chosen": 1.463541030883789,
      "logits/rejected": 1.3970286846160889,
      "logps/chosen": -35.190555572509766,
      "logps/rejected": -48.88050079345703,
      "loss": 0.6758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010999703779816628,
      "rewards/margins": 0.03523442894220352,
      "rewards/rejected": -0.024234723299741745,
      "step": 240
    },
    {
      "epoch": 18.56,
      "grad_norm": 7.0554327964782715,
      "learning_rate": 6.507936507936508e-08,
      "logits/chosen": 1.4734697341918945,
      "logits/rejected": 1.203689694404602,
      "logps/chosen": -33.65220642089844,
      "logps/rejected": -51.091487884521484,
      "loss": 0.6833,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.002413034439086914,
      "rewards/margins": 0.01999533176422119,
      "rewards/rejected": -0.022408366203308105,
      "step": 241
    },
    {
      "epoch": 18.64,
      "grad_norm": 7.327019214630127,
      "learning_rate": 6.492063492063492e-08,
      "logits/chosen": 1.4661941528320312,
      "logits/rejected": 1.479799747467041,
      "logps/chosen": -31.636674880981445,
      "logps/rejected": -53.11186218261719,
      "loss": 0.6841,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012093424797058105,
      "rewards/margins": 0.018196702003479004,
      "rewards/rejected": -0.006103276740759611,
      "step": 242
    },
    {
      "epoch": 18.72,
      "grad_norm": 8.03642749786377,
      "learning_rate": 6.476190476190476e-08,
      "logits/chosen": 1.1794748306274414,
      "logits/rejected": 1.115383505821228,
      "logps/chosen": -31.780141830444336,
      "logps/rejected": -53.550384521484375,
      "loss": 0.675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01573333702981472,
      "rewards/margins": 0.03688240051269531,
      "rewards/rejected": -0.021149063482880592,
      "step": 243
    },
    {
      "epoch": 18.8,
      "grad_norm": 8.436429977416992,
      "learning_rate": 6.46031746031746e-08,
      "logits/chosen": 1.3654098510742188,
      "logits/rejected": 1.0531706809997559,
      "logps/chosen": -32.97766876220703,
      "logps/rejected": -60.437965393066406,
      "loss": 0.673,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007689547725021839,
      "rewards/margins": 0.040990233421325684,
      "rewards/rejected": -0.03330068662762642,
      "step": 244
    },
    {
      "epoch": 18.88,
      "grad_norm": 8.235516548156738,
      "learning_rate": 6.444444444444445e-08,
      "logits/chosen": 1.3759535551071167,
      "logits/rejected": 1.0677343606948853,
      "logps/chosen": -37.968658447265625,
      "logps/rejected": -58.459964752197266,
      "loss": 0.677,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007487272843718529,
      "rewards/margins": 0.03280317783355713,
      "rewards/rejected": -0.02531590312719345,
      "step": 245
    },
    {
      "epoch": 18.96,
      "grad_norm": 7.548087120056152,
      "learning_rate": 6.428571428571429e-08,
      "logits/chosen": 0.9669411778450012,
      "logits/rejected": 1.0426464080810547,
      "logps/chosen": -30.44912338256836,
      "logps/rejected": -48.45035171508789,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006390786729753017,
      "rewards/margins": 0.03359434753656387,
      "rewards/rejected": -0.02720356173813343,
      "step": 246
    },
    {
      "epoch": 19.0,
      "grad_norm": 9.123390197753906,
      "learning_rate": 6.412698412698413e-08,
      "logits/chosen": 1.422229528427124,
      "logits/rejected": 1.3270609378814697,
      "logps/chosen": -34.38983917236328,
      "logps/rejected": -44.89951705932617,
      "loss": 0.6861,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.003047084901481867,
      "rewards/margins": 0.014337348751723766,
      "rewards/rejected": -0.01738443598151207,
      "step": 247
    },
    {
      "epoch": 19.0,
      "eval_logits/chosen": 1.3051345348358154,
      "eval_logits/rejected": 1.1979477405548096,
      "eval_logps/chosen": -34.39334487915039,
      "eval_logps/rejected": -47.012290954589844,
      "eval_loss": 0.68735671043396,
      "eval_rewards/accuracies": 0.7599999904632568,
      "eval_rewards/chosen": 0.010616984218358994,
      "eval_rewards/margins": 0.011726881377398968,
      "eval_rewards/rejected": -0.0011098977411165833,
      "eval_runtime": 2.7394,
      "eval_samples_per_second": 36.505,
      "eval_steps_per_second": 18.252,
      "step": 247
    },
    {
      "epoch": 19.08,
      "grad_norm": 9.444762229919434,
      "learning_rate": 6.396825396825396e-08,
      "logits/chosen": 1.23648202419281,
      "logits/rejected": 1.3142735958099365,
      "logps/chosen": -34.6543083190918,
      "logps/rejected": -62.460689544677734,
      "loss": 0.6794,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010876274667680264,
      "rewards/margins": 0.02816915698349476,
      "rewards/rejected": -0.01729288324713707,
      "step": 248
    },
    {
      "epoch": 19.16,
      "grad_norm": 8.145179748535156,
      "learning_rate": 6.38095238095238e-08,
      "logits/chosen": 1.074934959411621,
      "logits/rejected": 1.0430848598480225,
      "logps/chosen": -28.37932586669922,
      "logps/rejected": -48.77903747558594,
      "loss": 0.6797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011479998007416725,
      "rewards/margins": 0.027188444510102272,
      "rewards/rejected": -0.015708446502685547,
      "step": 249
    },
    {
      "epoch": 19.24,
      "grad_norm": 7.69069766998291,
      "learning_rate": 6.365079365079365e-08,
      "logits/chosen": 1.258103370666504,
      "logits/rejected": 1.2188047170639038,
      "logps/chosen": -37.35995101928711,
      "logps/rejected": -57.17645263671875,
      "loss": 0.6759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0014054295606911182,
      "rewards/margins": 0.034941576421260834,
      "rewards/rejected": -0.0335361510515213,
      "step": 250
    },
    {
      "epoch": 19.32,
      "grad_norm": 8.107440948486328,
      "learning_rate": 6.349206349206349e-08,
      "logits/chosen": 1.2338682413101196,
      "logits/rejected": 0.9904031753540039,
      "logps/chosen": -29.760982513427734,
      "logps/rejected": -45.997161865234375,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.000835728831589222,
      "rewards/margins": 0.03367578983306885,
      "rewards/rejected": -0.0328400656580925,
      "step": 251
    },
    {
      "epoch": 19.4,
      "grad_norm": 8.168128967285156,
      "learning_rate": 6.333333333333333e-08,
      "logits/chosen": 1.3232200145721436,
      "logits/rejected": 1.3984320163726807,
      "logps/chosen": -42.823585510253906,
      "logps/rejected": -60.69043731689453,
      "loss": 0.6882,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.01159436721354723,
      "rewards/margins": 0.009901691228151321,
      "rewards/rejected": -0.021496057510375977,
      "step": 252
    },
    {
      "epoch": 19.48,
      "grad_norm": 7.511041641235352,
      "learning_rate": 6.317460317460317e-08,
      "logits/chosen": 1.468877911567688,
      "logits/rejected": 1.1620736122131348,
      "logps/chosen": -32.60952377319336,
      "logps/rejected": -57.491519927978516,
      "loss": 0.6825,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01449198741465807,
      "rewards/margins": 0.021450424566864967,
      "rewards/rejected": -0.006958437152206898,
      "step": 253
    },
    {
      "epoch": 19.56,
      "grad_norm": 8.058494567871094,
      "learning_rate": 6.301587301587302e-08,
      "logits/chosen": 1.1526371240615845,
      "logits/rejected": 1.2405049800872803,
      "logps/chosen": -29.175870895385742,
      "logps/rejected": -56.019317626953125,
      "loss": 0.6789,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008976172655820847,
      "rewards/margins": 0.02889261022210121,
      "rewards/rejected": -0.019916439428925514,
      "step": 254
    },
    {
      "epoch": 19.64,
      "grad_norm": 6.968778133392334,
      "learning_rate": 6.285714285714286e-08,
      "logits/chosen": 1.164546012878418,
      "logits/rejected": 1.312155842781067,
      "logps/chosen": -32.19699478149414,
      "logps/rejected": -58.666053771972656,
      "loss": 0.6747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011590003967285156,
      "rewards/margins": 0.037315890192985535,
      "rewards/rejected": -0.025725889950990677,
      "step": 255
    },
    {
      "epoch": 19.72,
      "grad_norm": 6.3985490798950195,
      "learning_rate": 6.26984126984127e-08,
      "logits/chosen": 1.2948211431503296,
      "logits/rejected": 1.3190215826034546,
      "logps/chosen": -34.78340530395508,
      "logps/rejected": -48.38725280761719,
      "loss": 0.6841,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01652679592370987,
      "rewards/margins": 0.01823406293988228,
      "rewards/rejected": -0.0017072679474949837,
      "step": 256
    },
    {
      "epoch": 19.8,
      "grad_norm": 7.14121675491333,
      "learning_rate": 6.253968253968254e-08,
      "logits/chosen": 1.2545859813690186,
      "logits/rejected": 1.352416753768921,
      "logps/chosen": -31.898143768310547,
      "logps/rejected": -52.413970947265625,
      "loss": 0.6753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016907835379242897,
      "rewards/margins": 0.036127377301454544,
      "rewards/rejected": -0.019219541922211647,
      "step": 257
    },
    {
      "epoch": 19.88,
      "grad_norm": 7.912086009979248,
      "learning_rate": 6.238095238095237e-08,
      "logits/chosen": 1.4417669773101807,
      "logits/rejected": 1.3409674167633057,
      "logps/chosen": -38.20209503173828,
      "logps/rejected": -52.15772247314453,
      "loss": 0.6802,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012609338387846947,
      "rewards/margins": 0.02628145180642605,
      "rewards/rejected": -0.013672111555933952,
      "step": 258
    },
    {
      "epoch": 19.96,
      "grad_norm": 6.740735054016113,
      "learning_rate": 6.222222222222221e-08,
      "logits/chosen": 1.4559099674224854,
      "logits/rejected": 1.3571336269378662,
      "logps/chosen": -36.55305099487305,
      "logps/rejected": -56.324859619140625,
      "loss": 0.6777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01181042194366455,
      "rewards/margins": 0.03116295486688614,
      "rewards/rejected": -0.01935253106057644,
      "step": 259
    },
    {
      "epoch": 20.0,
      "grad_norm": 9.53689956665039,
      "learning_rate": 6.206349206349206e-08,
      "logits/chosen": 1.4670467376708984,
      "logits/rejected": 1.4455664157867432,
      "logps/chosen": -36.316986083984375,
      "logps/rejected": -62.721988677978516,
      "loss": 0.6822,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.009206105023622513,
      "rewards/margins": 0.022065065801143646,
      "rewards/rejected": -0.012858962640166283,
      "step": 260
    },
    {
      "epoch": 20.0,
      "eval_logits/chosen": 1.3086358308792114,
      "eval_logits/rejected": 1.2011535167694092,
      "eval_logps/chosen": -34.392295837402344,
      "eval_logps/rejected": -47.04705047607422,
      "eval_loss": 0.685580313205719,
      "eval_rewards/accuracies": 0.800000011920929,
      "eval_rewards/chosen": 0.010722040198743343,
      "eval_rewards/margins": 0.015308388508856297,
      "eval_rewards/rejected": -0.004586349707096815,
      "eval_runtime": 2.7423,
      "eval_samples_per_second": 36.465,
      "eval_steps_per_second": 18.233,
      "step": 260
    },
    {
      "epoch": 20.08,
      "grad_norm": 8.51907730102539,
      "learning_rate": 6.19047619047619e-08,
      "logits/chosen": 1.3740551471710205,
      "logits/rejected": 1.3550750017166138,
      "logps/chosen": -35.402320861816406,
      "logps/rejected": -52.01441192626953,
      "loss": 0.6815,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011845182627439499,
      "rewards/margins": 0.023491550236940384,
      "rewards/rejected": -0.011646365746855736,
      "step": 261
    },
    {
      "epoch": 20.16,
      "grad_norm": 7.70278263092041,
      "learning_rate": 6.174603174603174e-08,
      "logits/chosen": 1.3176491260528564,
      "logits/rejected": 1.2775144577026367,
      "logps/chosen": -31.577810287475586,
      "logps/rejected": -50.782859802246094,
      "loss": 0.6749,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01700427569448948,
      "rewards/margins": 0.03692539036273956,
      "rewards/rejected": -0.019921112805604935,
      "step": 262
    },
    {
      "epoch": 20.24,
      "grad_norm": 7.109773635864258,
      "learning_rate": 6.158730158730158e-08,
      "logits/chosen": 1.190568447113037,
      "logits/rejected": 1.2342108488082886,
      "logps/chosen": -35.5697021484375,
      "logps/rejected": -56.04062271118164,
      "loss": 0.6774,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0036227938253432512,
      "rewards/margins": 0.03187921270728111,
      "rewards/rejected": -0.02825641632080078,
      "step": 263
    },
    {
      "epoch": 20.32,
      "grad_norm": 8.496485710144043,
      "learning_rate": 6.142857142857143e-08,
      "logits/chosen": 1.2192782163619995,
      "logits/rejected": 1.3927569389343262,
      "logps/chosen": -35.10258102416992,
      "logps/rejected": -61.42609405517578,
      "loss": 0.6776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020161963999271393,
      "rewards/margins": 0.03154482692480087,
      "rewards/rejected": -0.01138286478817463,
      "step": 264
    },
    {
      "epoch": 20.4,
      "grad_norm": 6.520631790161133,
      "learning_rate": 6.126984126984127e-08,
      "logits/chosen": 1.463146686553955,
      "logits/rejected": 1.2704838514328003,
      "logps/chosen": -37.075927734375,
      "logps/rejected": -55.10307312011719,
      "loss": 0.6905,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.00019311916548758745,
      "rewards/margins": 0.005381155293434858,
      "rewards/rejected": -0.005574274808168411,
      "step": 265
    },
    {
      "epoch": 20.48,
      "grad_norm": 8.633841514587402,
      "learning_rate": 6.111111111111111e-08,
      "logits/chosen": 1.0179030895233154,
      "logits/rejected": 1.0206128358840942,
      "logps/chosen": -29.294116973876953,
      "logps/rejected": -56.60291290283203,
      "loss": 0.6804,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01006538886576891,
      "rewards/margins": 0.025761056691408157,
      "rewards/rejected": -0.015695666894316673,
      "step": 266
    },
    {
      "epoch": 20.56,
      "grad_norm": 7.064386367797852,
      "learning_rate": 6.095238095238095e-08,
      "logits/chosen": 1.6131267547607422,
      "logits/rejected": 1.433811902999878,
      "logps/chosen": -36.47580337524414,
      "logps/rejected": -61.187049865722656,
      "loss": 0.68,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013385225087404251,
      "rewards/margins": 0.02660207822918892,
      "rewards/rejected": -0.013216853141784668,
      "step": 267
    },
    {
      "epoch": 20.64,
      "grad_norm": 7.42241907119751,
      "learning_rate": 6.079365079365078e-08,
      "logits/chosen": 1.3292181491851807,
      "logits/rejected": 1.1323161125183105,
      "logps/chosen": -32.897308349609375,
      "logps/rejected": -47.206520080566406,
      "loss": 0.6813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0062681203708052635,
      "rewards/margins": 0.024001169949769974,
      "rewards/rejected": -0.017733048647642136,
      "step": 268
    },
    {
      "epoch": 20.72,
      "grad_norm": 6.900797367095947,
      "learning_rate": 6.063492063492063e-08,
      "logits/chosen": 1.3485426902770996,
      "logits/rejected": 1.2525330781936646,
      "logps/chosen": -32.503780364990234,
      "logps/rejected": -50.719703674316406,
      "loss": 0.6732,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01513450127094984,
      "rewards/margins": 0.040502097457647324,
      "rewards/rejected": -0.02536759525537491,
      "step": 269
    },
    {
      "epoch": 20.8,
      "grad_norm": 7.377501010894775,
      "learning_rate": 6.047619047619047e-08,
      "logits/chosen": 1.1206759214401245,
      "logits/rejected": 1.2629345655441284,
      "logps/chosen": -34.901390075683594,
      "logps/rejected": -54.14433288574219,
      "loss": 0.684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005949545186012983,
      "rewards/margins": 0.01859769970178604,
      "rewards/rejected": -0.01264815405011177,
      "step": 270
    },
    {
      "epoch": 20.88,
      "grad_norm": 7.663497447967529,
      "learning_rate": 6.031746031746031e-08,
      "logits/chosen": 1.2279858589172363,
      "logits/rejected": 1.2390756607055664,
      "logps/chosen": -30.804893493652344,
      "logps/rejected": -52.090789794921875,
      "loss": 0.6689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01170971430838108,
      "rewards/margins": 0.049198225140571594,
      "rewards/rejected": -0.037488508969545364,
      "step": 271
    },
    {
      "epoch": 20.96,
      "grad_norm": 8.11119270324707,
      "learning_rate": 6.015873015873015e-08,
      "logits/chosen": 1.2776029109954834,
      "logits/rejected": 1.126745581626892,
      "logps/chosen": -33.0528564453125,
      "logps/rejected": -58.20905685424805,
      "loss": 0.6754,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012248683720827103,
      "rewards/margins": 0.03596861660480499,
      "rewards/rejected": -0.02371993288397789,
      "step": 272
    },
    {
      "epoch": 21.0,
      "grad_norm": 11.020797729492188,
      "learning_rate": 6e-08,
      "logits/chosen": 1.3653061389923096,
      "logits/rejected": 1.452946424484253,
      "logps/chosen": -43.38144302368164,
      "logps/rejected": -64.86553192138672,
      "loss": 0.6935,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.006865405943244696,
      "rewards/margins": -0.0007514951284974813,
      "rewards/rejected": -0.006113911047577858,
      "step": 273
    },
    {
      "epoch": 21.0,
      "eval_logits/chosen": 1.309390902519226,
      "eval_logits/rejected": 1.2011399269104004,
      "eval_logps/chosen": -34.40015411376953,
      "eval_logps/rejected": -47.05327224731445,
      "eval_loss": 0.6856635212898254,
      "eval_rewards/accuracies": 0.7300000190734863,
      "eval_rewards/chosen": 0.009936166927218437,
      "eval_rewards/margins": 0.01514491718262434,
      "eval_rewards/rejected": -0.005208749324083328,
      "eval_runtime": 2.742,
      "eval_samples_per_second": 36.469,
      "eval_steps_per_second": 18.235,
      "step": 273
    },
    {
      "epoch": 21.08,
      "grad_norm": 8.561697959899902,
      "learning_rate": 5.984126984126984e-08,
      "logits/chosen": 0.9195665121078491,
      "logits/rejected": 1.016045331954956,
      "logps/chosen": -30.859676361083984,
      "logps/rejected": -53.48408508300781,
      "loss": 0.667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01869330368936062,
      "rewards/margins": 0.05309147760272026,
      "rewards/rejected": -0.03439817577600479,
      "step": 274
    },
    {
      "epoch": 21.16,
      "grad_norm": 7.28751802444458,
      "learning_rate": 5.968253968253968e-08,
      "logits/chosen": 1.4885724782943726,
      "logits/rejected": 1.247053623199463,
      "logps/chosen": -38.99732971191406,
      "logps/rejected": -51.0269660949707,
      "loss": 0.6724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020758628845214844,
      "rewards/margins": 0.042025044560432434,
      "rewards/rejected": -0.021266411989927292,
      "step": 275
    },
    {
      "epoch": 21.24,
      "grad_norm": 7.575044631958008,
      "learning_rate": 5.952380952380952e-08,
      "logits/chosen": 1.3216561079025269,
      "logits/rejected": 1.3203991651535034,
      "logps/chosen": -32.80436706542969,
      "logps/rejected": -57.15895462036133,
      "loss": 0.6749,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01783928833901882,
      "rewards/margins": 0.03711142763495445,
      "rewards/rejected": -0.01927213743329048,
      "step": 276
    },
    {
      "epoch": 21.32,
      "grad_norm": 7.328850746154785,
      "learning_rate": 5.9365079365079364e-08,
      "logits/chosen": 1.366019606590271,
      "logits/rejected": 1.1365008354187012,
      "logps/chosen": -35.085960388183594,
      "logps/rejected": -52.479061126708984,
      "loss": 0.6821,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007068348117172718,
      "rewards/margins": 0.022393180057406425,
      "rewards/rejected": -0.015324831008911133,
      "step": 277
    },
    {
      "epoch": 21.4,
      "grad_norm": 8.545698165893555,
      "learning_rate": 5.9206349206349206e-08,
      "logits/chosen": 1.20033597946167,
      "logits/rejected": 1.2976959943771362,
      "logps/chosen": -31.222576141357422,
      "logps/rejected": -60.533870697021484,
      "loss": 0.6796,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02316911146044731,
      "rewards/margins": 0.02741839736700058,
      "rewards/rejected": -0.004249286837875843,
      "step": 278
    },
    {
      "epoch": 21.48,
      "grad_norm": 7.106836795806885,
      "learning_rate": 5.904761904761905e-08,
      "logits/chosen": 1.3194818496704102,
      "logits/rejected": 1.13883638381958,
      "logps/chosen": -34.756404876708984,
      "logps/rejected": -56.67572021484375,
      "loss": 0.6721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010569143109023571,
      "rewards/margins": 0.04267878457903862,
      "rewards/rejected": -0.032109640538692474,
      "step": 279
    },
    {
      "epoch": 21.56,
      "grad_norm": 7.045468807220459,
      "learning_rate": 5.888888888888889e-08,
      "logits/chosen": 1.355114459991455,
      "logits/rejected": 1.5806992053985596,
      "logps/chosen": -33.97032165527344,
      "logps/rejected": -51.61976623535156,
      "loss": 0.6835,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015593052841722965,
      "rewards/margins": 0.01953601837158203,
      "rewards/rejected": -0.003942967392504215,
      "step": 280
    },
    {
      "epoch": 21.64,
      "grad_norm": 7.102438449859619,
      "learning_rate": 5.873015873015873e-08,
      "logits/chosen": 1.5353798866271973,
      "logits/rejected": 1.4489729404449463,
      "logps/chosen": -37.49497604370117,
      "logps/rejected": -54.61145782470703,
      "loss": 0.6838,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.006073904223740101,
      "rewards/margins": 0.019085120409727097,
      "rewards/rejected": -0.025159025564789772,
      "step": 281
    },
    {
      "epoch": 21.72,
      "grad_norm": 8.08450698852539,
      "learning_rate": 5.857142857142857e-08,
      "logits/chosen": 1.2747745513916016,
      "logits/rejected": 1.2111144065856934,
      "logps/chosen": -33.5156135559082,
      "logps/rejected": -51.62544250488281,
      "loss": 0.684,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01074135396629572,
      "rewards/margins": 0.018390728160738945,
      "rewards/rejected": -0.007649374194443226,
      "step": 282
    },
    {
      "epoch": 21.8,
      "grad_norm": 6.824275970458984,
      "learning_rate": 5.841269841269841e-08,
      "logits/chosen": 1.3567413091659546,
      "logits/rejected": 1.3640880584716797,
      "logps/chosen": -32.97051239013672,
      "logps/rejected": -58.442901611328125,
      "loss": 0.677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01689004898071289,
      "rewards/margins": 0.03273153305053711,
      "rewards/rejected": -0.01584148406982422,
      "step": 283
    },
    {
      "epoch": 21.88,
      "grad_norm": 7.343379020690918,
      "learning_rate": 5.8253968253968254e-08,
      "logits/chosen": 1.2697949409484863,
      "logits/rejected": 1.2226929664611816,
      "logps/chosen": -35.18805694580078,
      "logps/rejected": -54.07412338256836,
      "loss": 0.6867,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.002896594814956188,
      "rewards/margins": 0.013003682717680931,
      "rewards/rejected": -0.010107088834047318,
      "step": 284
    },
    {
      "epoch": 21.96,
      "grad_norm": 8.394634246826172,
      "learning_rate": 5.8095238095238096e-08,
      "logits/chosen": 1.1821497678756714,
      "logits/rejected": 1.3506567478179932,
      "logps/chosen": -32.77284240722656,
      "logps/rejected": -59.20153045654297,
      "loss": 0.6734,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01238186378031969,
      "rewards/margins": 0.04001190885901451,
      "rewards/rejected": -0.027630044147372246,
      "step": 285
    },
    {
      "epoch": 22.0,
      "grad_norm": 11.288620948791504,
      "learning_rate": 5.793650793650794e-08,
      "logits/chosen": 1.1611758470535278,
      "logits/rejected": 1.0833539962768555,
      "logps/chosen": -33.090797424316406,
      "logps/rejected": -54.11377716064453,
      "loss": 0.6755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0050133224576711655,
      "rewards/margins": 0.035677578300237656,
      "rewards/rejected": -0.04069089889526367,
      "step": 286
    },
    {
      "epoch": 22.0,
      "eval_logits/chosen": 1.3072755336761475,
      "eval_logits/rejected": 1.2001209259033203,
      "eval_logps/chosen": -34.385520935058594,
      "eval_logps/rejected": -47.049320220947266,
      "eval_loss": 0.6851210594177246,
      "eval_rewards/accuracies": 0.800000011920929,
      "eval_rewards/chosen": 0.011399420909583569,
      "eval_rewards/margins": 0.01621289551258087,
      "eval_rewards/rejected": -0.004813474602997303,
      "eval_runtime": 2.7448,
      "eval_samples_per_second": 36.433,
      "eval_steps_per_second": 18.216,
      "step": 286
    },
    {
      "epoch": 22.08,
      "grad_norm": 8.138148307800293,
      "learning_rate": 5.777777777777777e-08,
      "logits/chosen": 1.421372413635254,
      "logits/rejected": 1.2697848081588745,
      "logps/chosen": -32.581634521484375,
      "logps/rejected": -66.25033569335938,
      "loss": 0.6778,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006967926397919655,
      "rewards/margins": 0.031003188341856003,
      "rewards/rejected": -0.024035263806581497,
      "step": 287
    },
    {
      "epoch": 22.16,
      "grad_norm": 7.3087029457092285,
      "learning_rate": 5.761904761904761e-08,
      "logits/chosen": 1.4019359350204468,
      "logits/rejected": 1.291166067123413,
      "logps/chosen": -33.22587585449219,
      "logps/rejected": -60.29023361206055,
      "loss": 0.6824,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011339235119521618,
      "rewards/margins": 0.021811485290527344,
      "rewards/rejected": -0.0104722511023283,
      "step": 288
    },
    {
      "epoch": 22.24,
      "grad_norm": 6.79379415512085,
      "learning_rate": 5.746031746031745e-08,
      "logits/chosen": 1.352813482284546,
      "logits/rejected": 1.4910616874694824,
      "logps/chosen": -37.90147018432617,
      "logps/rejected": -52.673484802246094,
      "loss": 0.6817,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007543778512626886,
      "rewards/margins": 0.02323444001376629,
      "rewards/rejected": -0.01569066010415554,
      "step": 289
    },
    {
      "epoch": 22.32,
      "grad_norm": 7.420479774475098,
      "learning_rate": 5.7301587301587295e-08,
      "logits/chosen": 1.2844808101654053,
      "logits/rejected": 1.316704273223877,
      "logps/chosen": -31.813980102539062,
      "logps/rejected": -58.786781311035156,
      "loss": 0.6684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015881039202213287,
      "rewards/margins": 0.05030624940991402,
      "rewards/rejected": -0.03442521393299103,
      "step": 290
    },
    {
      "epoch": 22.4,
      "grad_norm": 7.1561279296875,
      "learning_rate": 5.714285714285714e-08,
      "logits/chosen": 1.338827133178711,
      "logits/rejected": 1.4570846557617188,
      "logps/chosen": -31.616783142089844,
      "logps/rejected": -52.28722381591797,
      "loss": 0.674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013422084040939808,
      "rewards/margins": 0.03878214210271835,
      "rewards/rejected": -0.02536006085574627,
      "step": 291
    },
    {
      "epoch": 22.48,
      "grad_norm": 7.118061542510986,
      "learning_rate": 5.698412698412698e-08,
      "logits/chosen": 1.3435683250427246,
      "logits/rejected": 1.1774864196777344,
      "logps/chosen": -35.09850311279297,
      "logps/rejected": -50.92275619506836,
      "loss": 0.6751,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01007990911602974,
      "rewards/margins": 0.03669991344213486,
      "rewards/rejected": -0.026620006188750267,
      "step": 292
    },
    {
      "epoch": 22.56,
      "grad_norm": 7.038270473480225,
      "learning_rate": 5.682539682539682e-08,
      "logits/chosen": 1.2984285354614258,
      "logits/rejected": 1.1045950651168823,
      "logps/chosen": -32.629493713378906,
      "logps/rejected": -46.848941802978516,
      "loss": 0.6818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015320850536227226,
      "rewards/margins": 0.022901369258761406,
      "rewards/rejected": -0.007580518256872892,
      "step": 293
    },
    {
      "epoch": 22.64,
      "grad_norm": 7.664999008178711,
      "learning_rate": 5.6666666666666665e-08,
      "logits/chosen": 1.385124683380127,
      "logits/rejected": 1.2693920135498047,
      "logps/chosen": -32.461856842041016,
      "logps/rejected": -46.272735595703125,
      "loss": 0.677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007658482063561678,
      "rewards/margins": 0.03273329883813858,
      "rewards/rejected": -0.02507481724023819,
      "step": 294
    },
    {
      "epoch": 22.72,
      "grad_norm": 9.278231620788574,
      "learning_rate": 5.650793650793651e-08,
      "logits/chosen": 0.9933678507804871,
      "logits/rejected": 1.1547505855560303,
      "logps/chosen": -30.880069732666016,
      "logps/rejected": -57.05930709838867,
      "loss": 0.6711,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013866901397705078,
      "rewards/margins": 0.04482216760516167,
      "rewards/rejected": -0.03095526620745659,
      "step": 295
    },
    {
      "epoch": 22.8,
      "grad_norm": 8.217208862304688,
      "learning_rate": 5.634920634920635e-08,
      "logits/chosen": 1.4661451578140259,
      "logits/rejected": 1.1610424518585205,
      "logps/chosen": -42.705291748046875,
      "logps/rejected": -61.46971130371094,
      "loss": 0.6745,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009716462343931198,
      "rewards/margins": 0.03782615810632706,
      "rewards/rejected": -0.02810969576239586,
      "step": 296
    },
    {
      "epoch": 22.88,
      "grad_norm": 7.335231781005859,
      "learning_rate": 5.6190476190476185e-08,
      "logits/chosen": 1.1095490455627441,
      "logits/rejected": 1.2718102931976318,
      "logps/chosen": -35.08552551269531,
      "logps/rejected": -57.4196891784668,
      "loss": 0.668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014413547702133656,
      "rewards/margins": 0.051076605916023254,
      "rewards/rejected": -0.036663055419921875,
      "step": 297
    },
    {
      "epoch": 22.96,
      "grad_norm": 8.360320091247559,
      "learning_rate": 5.603174603174603e-08,
      "logits/chosen": 1.1241062879562378,
      "logits/rejected": 1.092047929763794,
      "logps/chosen": -31.36312484741211,
      "logps/rejected": -50.755767822265625,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011191201396286488,
      "rewards/margins": 0.034159254282712936,
      "rewards/rejected": -0.022968051955103874,
      "step": 298
    },
    {
      "epoch": 23.0,
      "grad_norm": 12.551698684692383,
      "learning_rate": 5.587301587301587e-08,
      "logits/chosen": 1.3129404783248901,
      "logits/rejected": 1.334599494934082,
      "logps/chosen": -37.88395309448242,
      "logps/rejected": -55.154319763183594,
      "loss": 0.6837,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.010202694684267044,
      "rewards/margins": 0.019178103655576706,
      "rewards/rejected": -0.0293808002024889,
      "step": 299
    },
    {
      "epoch": 23.0,
      "eval_logits/chosen": 1.3078280687332153,
      "eval_logits/rejected": 1.2007434368133545,
      "eval_logps/chosen": -34.389102935791016,
      "eval_logps/rejected": -47.04755783081055,
      "eval_loss": 0.6854034662246704,
      "eval_rewards/accuracies": 0.7900000214576721,
      "eval_rewards/chosen": 0.01104142889380455,
      "eval_rewards/margins": 0.015678580850362778,
      "eval_rewards/rejected": -0.0046371519565582275,
      "eval_runtime": 2.7465,
      "eval_samples_per_second": 36.41,
      "eval_steps_per_second": 18.205,
      "step": 299
    },
    {
      "epoch": 23.08,
      "grad_norm": 7.034237861633301,
      "learning_rate": 5.571428571428571e-08,
      "logits/chosen": 1.4251854419708252,
      "logits/rejected": 1.3041229248046875,
      "logps/chosen": -35.154300689697266,
      "logps/rejected": -60.100379943847656,
      "loss": 0.6791,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01119546964764595,
      "rewards/margins": 0.028531933203339577,
      "rewards/rejected": -0.017336463555693626,
      "step": 300
    },
    {
      "epoch": 23.16,
      "grad_norm": 7.992337226867676,
      "learning_rate": 5.5555555555555555e-08,
      "logits/chosen": 1.537543535232544,
      "logits/rejected": 1.282334327697754,
      "logps/chosen": -31.53125762939453,
      "logps/rejected": -55.894386291503906,
      "loss": 0.682,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01796887069940567,
      "rewards/margins": 0.022489286959171295,
      "rewards/rejected": -0.004520416725426912,
      "step": 301
    },
    {
      "epoch": 23.24,
      "grad_norm": 8.00604248046875,
      "learning_rate": 5.53968253968254e-08,
      "logits/chosen": 1.0211780071258545,
      "logits/rejected": 1.334932804107666,
      "logps/chosen": -28.068328857421875,
      "logps/rejected": -53.09251403808594,
      "loss": 0.6789,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009636545553803444,
      "rewards/margins": 0.0288435947149992,
      "rewards/rejected": -0.019207049161195755,
      "step": 302
    },
    {
      "epoch": 23.32,
      "grad_norm": 8.145037651062012,
      "learning_rate": 5.523809523809524e-08,
      "logits/chosen": 1.4415569305419922,
      "logits/rejected": 1.0513917207717896,
      "logps/chosen": -34.732322692871094,
      "logps/rejected": -53.783267974853516,
      "loss": 0.6704,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.018162274733185768,
      "rewards/margins": 0.04638929292559624,
      "rewards/rejected": -0.02822702005505562,
      "step": 303
    },
    {
      "epoch": 23.4,
      "grad_norm": 7.180902004241943,
      "learning_rate": 5.507936507936508e-08,
      "logits/chosen": 1.4365653991699219,
      "logits/rejected": 1.2397209405899048,
      "logps/chosen": -33.869503021240234,
      "logps/rejected": -47.418521881103516,
      "loss": 0.6744,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010325622744858265,
      "rewards/margins": 0.0379217155277729,
      "rewards/rejected": -0.027596093714237213,
      "step": 304
    },
    {
      "epoch": 23.48,
      "grad_norm": 8.292470932006836,
      "learning_rate": 5.4920634920634924e-08,
      "logits/chosen": 1.2767584323883057,
      "logits/rejected": 1.386757731437683,
      "logps/chosen": -33.498374938964844,
      "logps/rejected": -55.297027587890625,
      "loss": 0.677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01587855815887451,
      "rewards/margins": 0.0326828733086586,
      "rewards/rejected": -0.016804315149784088,
      "step": 305
    },
    {
      "epoch": 23.56,
      "grad_norm": 7.9862542152404785,
      "learning_rate": 5.4761904761904766e-08,
      "logits/chosen": 1.2510347366333008,
      "logits/rejected": 1.2620030641555786,
      "logps/chosen": -35.56211853027344,
      "logps/rejected": -50.22828674316406,
      "loss": 0.6756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006791639141738415,
      "rewards/margins": 0.035671666264534,
      "rewards/rejected": -0.028880024328827858,
      "step": 306
    },
    {
      "epoch": 23.64,
      "grad_norm": 7.577815055847168,
      "learning_rate": 5.4603174603174595e-08,
      "logits/chosen": 1.3005534410476685,
      "logits/rejected": 1.3334413766860962,
      "logps/chosen": -37.96558380126953,
      "logps/rejected": -56.904747009277344,
      "loss": 0.6795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008692074567079544,
      "rewards/margins": 0.027551840990781784,
      "rewards/rejected": -0.01885976828634739,
      "step": 307
    },
    {
      "epoch": 23.72,
      "grad_norm": 7.951311111450195,
      "learning_rate": 5.444444444444444e-08,
      "logits/chosen": 1.4040125608444214,
      "logits/rejected": 1.2866002321243286,
      "logps/chosen": -32.25107192993164,
      "logps/rejected": -49.61554718017578,
      "loss": 0.6713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017408180981874466,
      "rewards/margins": 0.04422598332166672,
      "rewards/rejected": -0.026817798614501953,
      "step": 308
    },
    {
      "epoch": 23.8,
      "grad_norm": 7.061567783355713,
      "learning_rate": 5.428571428571428e-08,
      "logits/chosen": 1.005380630493164,
      "logits/rejected": 1.012687087059021,
      "logps/chosen": -34.5272102355957,
      "logps/rejected": -51.285560607910156,
      "loss": 0.6806,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014118099585175514,
      "rewards/margins": 0.025412511080503464,
      "rewards/rejected": -0.011294412426650524,
      "step": 309
    },
    {
      "epoch": 23.88,
      "grad_norm": 6.849966526031494,
      "learning_rate": 5.412698412698412e-08,
      "logits/chosen": 1.253040075302124,
      "logits/rejected": 1.4054969549179077,
      "logps/chosen": -36.08549880981445,
      "logps/rejected": -56.734657287597656,
      "loss": 0.6807,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0008392331656068563,
      "rewards/margins": 0.025153160095214844,
      "rewards/rejected": -0.024313926696777344,
      "step": 310
    },
    {
      "epoch": 23.96,
      "grad_norm": 9.198447227478027,
      "learning_rate": 5.3968253968253965e-08,
      "logits/chosen": 1.1339647769927979,
      "logits/rejected": 1.1381995677947998,
      "logps/chosen": -33.65784454345703,
      "logps/rejected": -62.14797592163086,
      "loss": 0.6739,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01028439961373806,
      "rewards/margins": 0.03937662020325661,
      "rewards/rejected": -0.029092218726873398,
      "step": 311
    },
    {
      "epoch": 24.0,
      "grad_norm": 11.422773361206055,
      "learning_rate": 5.380952380952381e-08,
      "logits/chosen": 1.3569046258926392,
      "logits/rejected": 1.299774408340454,
      "logps/chosen": -38.57056427001953,
      "logps/rejected": -71.76886749267578,
      "loss": 0.6727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.002777099609375,
      "rewards/margins": 0.04140195995569229,
      "rewards/rejected": -0.03862486034631729,
      "step": 312
    },
    {
      "epoch": 24.0,
      "eval_logits/chosen": 1.309482216835022,
      "eval_logits/rejected": 1.2017251253128052,
      "eval_logps/chosen": -34.358253479003906,
      "eval_logps/rejected": -47.05937576293945,
      "eval_loss": 0.6832771897315979,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.014126325026154518,
      "eval_rewards/margins": 0.019944844767451286,
      "eval_rewards/rejected": -0.0058185202069580555,
      "eval_runtime": 2.7423,
      "eval_samples_per_second": 36.466,
      "eval_steps_per_second": 18.233,
      "step": 312
    },
    {
      "epoch": 24.08,
      "grad_norm": 8.753740310668945,
      "learning_rate": 5.365079365079365e-08,
      "logits/chosen": 1.1850531101226807,
      "logits/rejected": 0.9726535081863403,
      "logps/chosen": -33.09176254272461,
      "logps/rejected": -55.01913070678711,
      "loss": 0.6653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024859141558408737,
      "rewards/margins": 0.05664868280291557,
      "rewards/rejected": -0.031789541244506836,
      "step": 313
    },
    {
      "epoch": 24.16,
      "grad_norm": 8.887551307678223,
      "learning_rate": 5.3492063492063485e-08,
      "logits/chosen": 1.2857677936553955,
      "logits/rejected": 1.339371681213379,
      "logps/chosen": -30.176063537597656,
      "logps/rejected": -58.223541259765625,
      "loss": 0.6752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021148325875401497,
      "rewards/margins": 0.03636310249567032,
      "rewards/rejected": -0.015214776620268822,
      "step": 314
    },
    {
      "epoch": 24.24,
      "grad_norm": 6.797233581542969,
      "learning_rate": 5.333333333333333e-08,
      "logits/chosen": 1.3204514980316162,
      "logits/rejected": 1.3205004930496216,
      "logps/chosen": -32.90489959716797,
      "logps/rejected": -54.839508056640625,
      "loss": 0.6719,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012633800506591797,
      "rewards/margins": 0.04315552860498428,
      "rewards/rejected": -0.030521728098392487,
      "step": 315
    },
    {
      "epoch": 24.32,
      "grad_norm": 6.999444007873535,
      "learning_rate": 5.317460317460317e-08,
      "logits/chosen": 1.4602677822113037,
      "logits/rejected": 1.2079722881317139,
      "logps/chosen": -31.3979434967041,
      "logps/rejected": -52.53855895996094,
      "loss": 0.6787,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01567554473876953,
      "rewards/margins": 0.029206562787294388,
      "rewards/rejected": -0.013531017117202282,
      "step": 316
    },
    {
      "epoch": 24.4,
      "grad_norm": 8.103947639465332,
      "learning_rate": 5.301587301587301e-08,
      "logits/chosen": 1.1717218160629272,
      "logits/rejected": 1.275923728942871,
      "logps/chosen": -35.5377197265625,
      "logps/rejected": -54.65531921386719,
      "loss": 0.6791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014822197146713734,
      "rewards/margins": 0.02847924456000328,
      "rewards/rejected": -0.013657045550644398,
      "step": 317
    },
    {
      "epoch": 24.48,
      "grad_norm": 8.117148399353027,
      "learning_rate": 5.2857142857142855e-08,
      "logits/chosen": 1.4844249486923218,
      "logits/rejected": 1.2195014953613281,
      "logps/chosen": -41.53240203857422,
      "logps/rejected": -55.10487365722656,
      "loss": 0.678,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0003488303627818823,
      "rewards/margins": 0.030761457979679108,
      "rewards/rejected": -0.031110286712646484,
      "step": 318
    },
    {
      "epoch": 24.56,
      "grad_norm": 6.876767158508301,
      "learning_rate": 5.26984126984127e-08,
      "logits/chosen": 1.3053653240203857,
      "logits/rejected": 1.2640997171401978,
      "logps/chosen": -33.82462692260742,
      "logps/rejected": -53.658653259277344,
      "loss": 0.673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00821077823638916,
      "rewards/margins": 0.04075346142053604,
      "rewards/rejected": -0.03254268318414688,
      "step": 319
    },
    {
      "epoch": 24.64,
      "grad_norm": 8.192028045654297,
      "learning_rate": 5.253968253968254e-08,
      "logits/chosen": 1.2401179075241089,
      "logits/rejected": 1.2029106616973877,
      "logps/chosen": -29.802635192871094,
      "logps/rejected": -60.837249755859375,
      "loss": 0.6832,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008100295439362526,
      "rewards/margins": 0.020355723798274994,
      "rewards/rejected": -0.012255430221557617,
      "step": 320
    },
    {
      "epoch": 24.72,
      "grad_norm": 8.11317253112793,
      "learning_rate": 5.238095238095238e-08,
      "logits/chosen": 1.01759934425354,
      "logits/rejected": 1.280348539352417,
      "logps/chosen": -28.477081298828125,
      "logps/rejected": -59.15161895751953,
      "loss": 0.6645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022507404908537865,
      "rewards/margins": 0.058327700942754745,
      "rewards/rejected": -0.03582029417157173,
      "step": 321
    },
    {
      "epoch": 24.8,
      "grad_norm": 7.156313896179199,
      "learning_rate": 5.2222222222222224e-08,
      "logits/chosen": 1.4865458011627197,
      "logits/rejected": 1.2675113677978516,
      "logps/chosen": -39.300941467285156,
      "logps/rejected": -49.04819107055664,
      "loss": 0.6768,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006640220060944557,
      "rewards/margins": 0.033093906939029694,
      "rewards/rejected": -0.026453685015439987,
      "step": 322
    },
    {
      "epoch": 24.88,
      "grad_norm": 6.394407272338867,
      "learning_rate": 5.206349206349207e-08,
      "logits/chosen": 1.3306950330734253,
      "logits/rejected": 1.4075803756713867,
      "logps/chosen": -33.513607025146484,
      "logps/rejected": -54.63337707519531,
      "loss": 0.6812,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006569529417902231,
      "rewards/margins": 0.02404303476214409,
      "rewards/rejected": -0.017473505809903145,
      "step": 323
    },
    {
      "epoch": 24.96,
      "grad_norm": 7.019012928009033,
      "learning_rate": 5.190476190476191e-08,
      "logits/chosen": 1.3929443359375,
      "logits/rejected": 1.3177084922790527,
      "logps/chosen": -40.14817810058594,
      "logps/rejected": -51.64851379394531,
      "loss": 0.6849,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0009781359694898129,
      "rewards/margins": 0.016704797744750977,
      "rewards/rejected": -0.015726663172245026,
      "step": 324
    },
    {
      "epoch": 25.0,
      "grad_norm": 11.878734588623047,
      "learning_rate": 5.174603174603175e-08,
      "logits/chosen": 1.141259789466858,
      "logits/rejected": 1.407641887664795,
      "logps/chosen": -32.96437072753906,
      "logps/rejected": -58.460166931152344,
      "loss": 0.6762,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.006392240524291992,
      "rewards/margins": 0.03423190116882324,
      "rewards/rejected": -0.02783966064453125,
      "step": 325
    },
    {
      "epoch": 25.0,
      "eval_logits/chosen": 1.3105708360671997,
      "eval_logits/rejected": 1.2021293640136719,
      "eval_logps/chosen": -34.35811996459961,
      "eval_logps/rejected": -47.052711486816406,
      "eval_loss": 0.6836003065109253,
      "eval_rewards/accuracies": 0.7900000214576721,
      "eval_rewards/chosen": 0.014139512553811073,
      "eval_rewards/margins": 0.01929142326116562,
      "eval_rewards/rejected": -0.005151911173015833,
      "eval_runtime": 2.745,
      "eval_samples_per_second": 36.43,
      "eval_steps_per_second": 18.215,
      "step": 325
    },
    {
      "epoch": 25.08,
      "grad_norm": 6.528058052062988,
      "learning_rate": 5.158730158730159e-08,
      "logits/chosen": 1.1985950469970703,
      "logits/rejected": 1.3406014442443848,
      "logps/chosen": -36.00376892089844,
      "logps/rejected": -54.738197326660156,
      "loss": 0.6797,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.003941035829484463,
      "rewards/margins": 0.027259230613708496,
      "rewards/rejected": -0.023318195715546608,
      "step": 326
    },
    {
      "epoch": 25.16,
      "grad_norm": 7.561387538909912,
      "learning_rate": 5.142857142857142e-08,
      "logits/chosen": 1.3368103504180908,
      "logits/rejected": 1.2495323419570923,
      "logps/chosen": -34.86846160888672,
      "logps/rejected": -60.77140426635742,
      "loss": 0.681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013512944802641869,
      "rewards/margins": 0.02476177178323269,
      "rewards/rejected": -0.01124882698059082,
      "step": 327
    },
    {
      "epoch": 25.24,
      "grad_norm": 7.16916036605835,
      "learning_rate": 5.1269841269841265e-08,
      "logits/chosen": 1.3357521295547485,
      "logits/rejected": 1.296463966369629,
      "logps/chosen": -33.855934143066406,
      "logps/rejected": -64.13607788085938,
      "loss": 0.6752,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015616417862474918,
      "rewards/margins": 0.03641700744628906,
      "rewards/rejected": -0.020800592377781868,
      "step": 328
    },
    {
      "epoch": 25.32,
      "grad_norm": 7.383398532867432,
      "learning_rate": 5.111111111111111e-08,
      "logits/chosen": 1.114903211593628,
      "logits/rejected": 0.9606260061264038,
      "logps/chosen": -30.530149459838867,
      "logps/rejected": -55.800228118896484,
      "loss": 0.6755,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013487505726516247,
      "rewards/margins": 0.03568003326654434,
      "rewards/rejected": -0.02219252660870552,
      "step": 329
    },
    {
      "epoch": 25.4,
      "grad_norm": 7.602718353271484,
      "learning_rate": 5.0952380952380944e-08,
      "logits/chosen": 1.4226521253585815,
      "logits/rejected": 1.3354613780975342,
      "logps/chosen": -34.48309326171875,
      "logps/rejected": -49.93170166015625,
      "loss": 0.6728,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.029810406267642975,
      "rewards/margins": 0.04136235639452934,
      "rewards/rejected": -0.011551952920854092,
      "step": 330
    },
    {
      "epoch": 25.48,
      "grad_norm": 7.601851463317871,
      "learning_rate": 5.0793650793650786e-08,
      "logits/chosen": 1.3805392980575562,
      "logits/rejected": 1.0449775457382202,
      "logps/chosen": -37.75537872314453,
      "logps/rejected": -54.45185089111328,
      "loss": 0.6811,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.005825018975883722,
      "rewards/margins": 0.024350333958864212,
      "rewards/rejected": -0.018525313585996628,
      "step": 331
    },
    {
      "epoch": 25.56,
      "grad_norm": 6.915829658508301,
      "learning_rate": 5.063492063492063e-08,
      "logits/chosen": 1.3042057752609253,
      "logits/rejected": 1.3482155799865723,
      "logps/chosen": -34.66257858276367,
      "logps/rejected": -58.38945770263672,
      "loss": 0.6792,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011799931526184082,
      "rewards/margins": 0.028132177889347076,
      "rewards/rejected": -0.016332246363162994,
      "step": 332
    },
    {
      "epoch": 25.64,
      "grad_norm": 7.015352725982666,
      "learning_rate": 5.047619047619047e-08,
      "logits/chosen": 1.2654955387115479,
      "logits/rejected": 1.296133041381836,
      "logps/chosen": -33.498287200927734,
      "logps/rejected": -47.90754699707031,
      "loss": 0.674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023250769823789597,
      "rewards/margins": 0.038716837763786316,
      "rewards/rejected": -0.015466070733964443,
      "step": 333
    },
    {
      "epoch": 25.72,
      "grad_norm": 6.69611120223999,
      "learning_rate": 5.031746031746031e-08,
      "logits/chosen": 1.3459266424179077,
      "logits/rejected": 1.290442943572998,
      "logps/chosen": -31.34527587890625,
      "logps/rejected": -52.81444549560547,
      "loss": 0.6753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02066659927368164,
      "rewards/margins": 0.03600268438458443,
      "rewards/rejected": -0.015336085110902786,
      "step": 334
    },
    {
      "epoch": 25.8,
      "grad_norm": 9.680695533752441,
      "learning_rate": 5.0158730158730155e-08,
      "logits/chosen": 1.1239570379257202,
      "logits/rejected": 1.052567958831787,
      "logps/chosen": -32.192230224609375,
      "logps/rejected": -53.05568313598633,
      "loss": 0.669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013681603595614433,
      "rewards/margins": 0.04901028051972389,
      "rewards/rejected": -0.03532867506146431,
      "step": 335
    },
    {
      "epoch": 25.88,
      "grad_norm": 9.693388938903809,
      "learning_rate": 5e-08,
      "logits/chosen": 1.24326753616333,
      "logits/rejected": 1.320113182067871,
      "logps/chosen": -31.81572151184082,
      "logps/rejected": -59.57512283325195,
      "loss": 0.6673,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016295600682497025,
      "rewards/margins": 0.05325191095471382,
      "rewards/rejected": -0.0369563102722168,
      "step": 336
    },
    {
      "epoch": 25.96,
      "grad_norm": 7.4713826179504395,
      "learning_rate": 4.984126984126984e-08,
      "logits/chosen": 1.4416100978851318,
      "logits/rejected": 1.389223337173462,
      "logps/chosen": -38.23309326171875,
      "logps/rejected": -53.68145751953125,
      "loss": 0.6716,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00808627624064684,
      "rewards/margins": 0.04376981407403946,
      "rewards/rejected": -0.035683535039424896,
      "step": 337
    },
    {
      "epoch": 26.0,
      "grad_norm": 9.058026313781738,
      "learning_rate": 4.968253968253968e-08,
      "logits/chosen": 1.5389217138290405,
      "logits/rejected": 1.6608366966247559,
      "logps/chosen": -33.221824645996094,
      "logps/rejected": -46.1828727722168,
      "loss": 0.6857,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.0144516471773386,
      "rewards/margins": 0.015049409121274948,
      "rewards/rejected": -0.0005977629916742444,
      "step": 338
    },
    {
      "epoch": 26.0,
      "eval_logits/chosen": 1.3096383810043335,
      "eval_logits/rejected": 1.2016583681106567,
      "eval_logps/chosen": -34.40806579589844,
      "eval_logps/rejected": -47.086978912353516,
      "eval_loss": 0.6843994855880737,
      "eval_rewards/accuracies": 0.7699999809265137,
      "eval_rewards/chosen": 0.009144952520728111,
      "eval_rewards/margins": 0.017723890021443367,
      "eval_rewards/rejected": -0.00857893843203783,
      "eval_runtime": 2.739,
      "eval_samples_per_second": 36.509,
      "eval_steps_per_second": 18.255,
      "step": 338
    },
    {
      "epoch": 26.08,
      "grad_norm": 7.47946310043335,
      "learning_rate": 4.9523809523809525e-08,
      "logits/chosen": 1.2364205121994019,
      "logits/rejected": 1.1182146072387695,
      "logps/chosen": -31.179960250854492,
      "logps/rejected": -48.53714370727539,
      "loss": 0.6716,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012270498089492321,
      "rewards/margins": 0.043709445744752884,
      "rewards/rejected": -0.03143894672393799,
      "step": 339
    },
    {
      "epoch": 26.16,
      "grad_norm": 8.326992988586426,
      "learning_rate": 4.936507936507937e-08,
      "logits/chosen": 1.3981804847717285,
      "logits/rejected": 1.219610571861267,
      "logps/chosen": -37.21002960205078,
      "logps/rejected": -54.88434600830078,
      "loss": 0.6697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01922926865518093,
      "rewards/margins": 0.04741387441754341,
      "rewards/rejected": -0.02818460576236248,
      "step": 340
    },
    {
      "epoch": 26.24,
      "grad_norm": 9.198646545410156,
      "learning_rate": 4.92063492063492e-08,
      "logits/chosen": 1.3330919742584229,
      "logits/rejected": 1.1425089836120605,
      "logps/chosen": -36.40745544433594,
      "logps/rejected": -65.47516632080078,
      "loss": 0.6752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009555578231811523,
      "rewards/margins": 0.03620152547955513,
      "rewards/rejected": -0.026645947247743607,
      "step": 341
    },
    {
      "epoch": 26.32,
      "grad_norm": 8.313111305236816,
      "learning_rate": 4.9047619047619045e-08,
      "logits/chosen": 1.2011528015136719,
      "logits/rejected": 1.3817073106765747,
      "logps/chosen": -30.274951934814453,
      "logps/rejected": -54.44229507446289,
      "loss": 0.6656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02431352250277996,
      "rewards/margins": 0.05591409280896187,
      "rewards/rejected": -0.03160057216882706,
      "step": 342
    },
    {
      "epoch": 26.4,
      "grad_norm": 7.8047261238098145,
      "learning_rate": 4.888888888888889e-08,
      "logits/chosen": 1.3333640098571777,
      "logits/rejected": 1.230628252029419,
      "logps/chosen": -32.308311462402344,
      "logps/rejected": -49.935630798339844,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014118243008852005,
      "rewards/margins": 0.05692591518163681,
      "rewards/rejected": -0.042807675898075104,
      "step": 343
    },
    {
      "epoch": 26.48,
      "grad_norm": 6.564061641693115,
      "learning_rate": 4.873015873015873e-08,
      "logits/chosen": 1.298338770866394,
      "logits/rejected": 1.1831001043319702,
      "logps/chosen": -33.805973052978516,
      "logps/rejected": -47.02113342285156,
      "loss": 0.6786,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012923169881105423,
      "rewards/margins": 0.029502080753445625,
      "rewards/rejected": -0.01657891273498535,
      "step": 344
    },
    {
      "epoch": 26.56,
      "grad_norm": 8.042909622192383,
      "learning_rate": 4.8571428571428566e-08,
      "logits/chosen": 1.2542831897735596,
      "logits/rejected": 1.0892419815063477,
      "logps/chosen": -33.048065185546875,
      "logps/rejected": -51.142364501953125,
      "loss": 0.6763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0045265438966453075,
      "rewards/margins": 0.034119680523872375,
      "rewards/rejected": -0.029593132436275482,
      "step": 345
    },
    {
      "epoch": 26.64,
      "grad_norm": 7.155557155609131,
      "learning_rate": 4.841269841269841e-08,
      "logits/chosen": 1.285176157951355,
      "logits/rejected": 1.332289457321167,
      "logps/chosen": -34.76597595214844,
      "logps/rejected": -56.05931854248047,
      "loss": 0.6795,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.021162033081054688,
      "rewards/margins": 0.027692509815096855,
      "rewards/rejected": -0.006530475802719593,
      "step": 346
    },
    {
      "epoch": 26.72,
      "grad_norm": 7.616876125335693,
      "learning_rate": 4.825396825396825e-08,
      "logits/chosen": 1.3309845924377441,
      "logits/rejected": 1.421320915222168,
      "logps/chosen": -36.14878463745117,
      "logps/rejected": -61.22239685058594,
      "loss": 0.6735,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012446976266801357,
      "rewards/margins": 0.03980236127972603,
      "rewards/rejected": -0.027355385944247246,
      "step": 347
    },
    {
      "epoch": 26.8,
      "grad_norm": 6.900057315826416,
      "learning_rate": 4.809523809523809e-08,
      "logits/chosen": 1.2690696716308594,
      "logits/rejected": 1.2248297929763794,
      "logps/chosen": -35.58887481689453,
      "logps/rejected": -51.908653259277344,
      "loss": 0.682,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0031393771059811115,
      "rewards/margins": 0.02257683128118515,
      "rewards/rejected": -0.019437456503510475,
      "step": 348
    },
    {
      "epoch": 26.88,
      "grad_norm": 7.517904281616211,
      "learning_rate": 4.7936507936507935e-08,
      "logits/chosen": 1.1171691417694092,
      "logits/rejected": 1.3744075298309326,
      "logps/chosen": -30.327152252197266,
      "logps/rejected": -61.27783966064453,
      "loss": 0.6713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02499690279364586,
      "rewards/margins": 0.04420051723718643,
      "rewards/rejected": -0.019203614443540573,
      "step": 349
    },
    {
      "epoch": 26.96,
      "grad_norm": 6.811594009399414,
      "learning_rate": 4.777777777777778e-08,
      "logits/chosen": 1.4383313655853271,
      "logits/rejected": 1.385555386543274,
      "logps/chosen": -39.25811767578125,
      "logps/rejected": -59.555084228515625,
      "loss": 0.6835,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0031336068641394377,
      "rewards/margins": 0.019434714689850807,
      "rewards/rejected": -0.01630110666155815,
      "step": 350
    },
    {
      "epoch": 27.0,
      "grad_norm": 9.559231758117676,
      "learning_rate": 4.7619047619047613e-08,
      "logits/chosen": 1.43792724609375,
      "logits/rejected": 1.382808804512024,
      "logps/chosen": -31.501510620117188,
      "logps/rejected": -54.77241897583008,
      "loss": 0.666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013067483901977539,
      "rewards/margins": 0.05525660887360573,
      "rewards/rejected": -0.04218912124633789,
      "step": 351
    },
    {
      "epoch": 27.0,
      "eval_logits/chosen": 1.3090980052947998,
      "eval_logits/rejected": 1.20199453830719,
      "eval_logps/chosen": -34.38499450683594,
      "eval_logps/rejected": -47.125732421875,
      "eval_loss": 0.6813281178474426,
      "eval_rewards/accuracies": 0.8700000047683716,
      "eval_rewards/chosen": 0.01145197544246912,
      "eval_rewards/margins": 0.02390655316412449,
      "eval_rewards/rejected": -0.012454577721655369,
      "eval_runtime": 2.7356,
      "eval_samples_per_second": 36.555,
      "eval_steps_per_second": 18.278,
      "step": 351
    },
    {
      "epoch": 27.08,
      "grad_norm": 7.954404830932617,
      "learning_rate": 4.7460317460317456e-08,
      "logits/chosen": 1.36701500415802,
      "logits/rejected": 1.2815189361572266,
      "logps/chosen": -30.68621826171875,
      "logps/rejected": -52.37248229980469,
      "loss": 0.6813,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.011114358901977539,
      "rewards/margins": 0.02416863478720188,
      "rewards/rejected": -0.013054275885224342,
      "step": 352
    },
    {
      "epoch": 27.16,
      "grad_norm": 7.451570987701416,
      "learning_rate": 4.73015873015873e-08,
      "logits/chosen": 1.2516560554504395,
      "logits/rejected": 1.3319979906082153,
      "logps/chosen": -29.734161376953125,
      "logps/rejected": -52.16932678222656,
      "loss": 0.6677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01939840242266655,
      "rewards/margins": 0.05178072676062584,
      "rewards/rejected": -0.03238232433795929,
      "step": 353
    },
    {
      "epoch": 27.24,
      "grad_norm": 7.431336879730225,
      "learning_rate": 4.714285714285714e-08,
      "logits/chosen": 1.3178038597106934,
      "logits/rejected": 1.2510532140731812,
      "logps/chosen": -31.514087677001953,
      "logps/rejected": -54.77128982543945,
      "loss": 0.673,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03106877952814102,
      "rewards/margins": 0.040946125984191895,
      "rewards/rejected": -0.009877348318696022,
      "step": 354
    },
    {
      "epoch": 27.32,
      "grad_norm": 6.794918060302734,
      "learning_rate": 4.698412698412698e-08,
      "logits/chosen": 1.2309720516204834,
      "logits/rejected": 1.1858441829681396,
      "logps/chosen": -33.363990783691406,
      "logps/rejected": -54.179649353027344,
      "loss": 0.6813,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007193374913185835,
      "rewards/margins": 0.023956727236509323,
      "rewards/rejected": -0.01676335372030735,
      "step": 355
    },
    {
      "epoch": 27.4,
      "grad_norm": 7.611382961273193,
      "learning_rate": 4.6825396825396825e-08,
      "logits/chosen": 1.2863142490386963,
      "logits/rejected": 1.1892403364181519,
      "logps/chosen": -39.18844223022461,
      "logps/rejected": -59.84917449951172,
      "loss": 0.6708,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015934085473418236,
      "rewards/margins": 0.04520568996667862,
      "rewards/rejected": -0.029271602630615234,
      "step": 356
    },
    {
      "epoch": 27.48,
      "grad_norm": 6.150338649749756,
      "learning_rate": 4.666666666666667e-08,
      "logits/chosen": 1.423720121383667,
      "logits/rejected": 1.411360502243042,
      "logps/chosen": -35.460445404052734,
      "logps/rejected": -54.35812759399414,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014483332633972168,
      "rewards/margins": 0.03373076766729355,
      "rewards/rejected": -0.01924743689596653,
      "step": 357
    },
    {
      "epoch": 27.56,
      "grad_norm": 7.479555130004883,
      "learning_rate": 4.650793650793651e-08,
      "logits/chosen": 1.4426347017288208,
      "logits/rejected": 1.3161698579788208,
      "logps/chosen": -39.7600212097168,
      "logps/rejected": -58.354270935058594,
      "loss": 0.677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010017108172178268,
      "rewards/margins": 0.03271622955799103,
      "rewards/rejected": -0.02269911766052246,
      "step": 358
    },
    {
      "epoch": 27.64,
      "grad_norm": 8.20340347290039,
      "learning_rate": 4.6349206349206346e-08,
      "logits/chosen": 1.4052209854125977,
      "logits/rejected": 1.3408513069152832,
      "logps/chosen": -36.056304931640625,
      "logps/rejected": -55.73759460449219,
      "loss": 0.6713,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.021172070875763893,
      "rewards/margins": 0.0442577600479126,
      "rewards/rejected": -0.023085691034793854,
      "step": 359
    },
    {
      "epoch": 27.72,
      "grad_norm": 9.113856315612793,
      "learning_rate": 4.619047619047619e-08,
      "logits/chosen": 1.3228563070297241,
      "logits/rejected": 1.2409602403640747,
      "logps/chosen": -34.63850784301758,
      "logps/rejected": -50.419254302978516,
      "loss": 0.6665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02217090129852295,
      "rewards/margins": 0.05437939241528511,
      "rewards/rejected": -0.03220849111676216,
      "step": 360
    },
    {
      "epoch": 27.8,
      "grad_norm": 7.7394795417785645,
      "learning_rate": 4.6031746031746024e-08,
      "logits/chosen": 1.1042320728302002,
      "logits/rejected": 1.1649137735366821,
      "logps/chosen": -32.377559661865234,
      "logps/rejected": -61.384735107421875,
      "loss": 0.6741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010725641623139381,
      "rewards/margins": 0.038631729781627655,
      "rewards/rejected": -0.027906086295843124,
      "step": 361
    },
    {
      "epoch": 27.88,
      "grad_norm": 7.72910737991333,
      "learning_rate": 4.5873015873015866e-08,
      "logits/chosen": 1.3636384010314941,
      "logits/rejected": 1.2454099655151367,
      "logps/chosen": -36.58795166015625,
      "logps/rejected": -56.72418212890625,
      "loss": 0.6711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013362647034227848,
      "rewards/margins": 0.04466858133673668,
      "rewards/rejected": -0.031305935233831406,
      "step": 362
    },
    {
      "epoch": 27.96,
      "grad_norm": 6.957189083099365,
      "learning_rate": 4.571428571428571e-08,
      "logits/chosen": 1.189171314239502,
      "logits/rejected": 1.3904633522033691,
      "logps/chosen": -28.73043441772461,
      "logps/rejected": -54.65465545654297,
      "loss": 0.6672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026756595820188522,
      "rewards/margins": 0.05284712463617325,
      "rewards/rejected": -0.026090526953339577,
      "step": 363
    },
    {
      "epoch": 28.0,
      "grad_norm": 11.322678565979004,
      "learning_rate": 4.555555555555555e-08,
      "logits/chosen": 1.3875093460083008,
      "logits/rejected": 0.9809158444404602,
      "logps/chosen": -35.37419128417969,
      "logps/rejected": -47.538787841796875,
      "loss": 0.6725,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.0011299606412649155,
      "rewards/margins": 0.04223752021789551,
      "rewards/rejected": -0.04336748272180557,
      "step": 364
    },
    {
      "epoch": 28.0,
      "eval_logits/chosen": 1.3105833530426025,
      "eval_logits/rejected": 1.2021888494491577,
      "eval_logps/chosen": -34.34812927246094,
      "eval_logps/rejected": -47.0517692565918,
      "eval_loss": 0.6831662654876709,
      "eval_rewards/accuracies": 0.8299999833106995,
      "eval_rewards/chosen": 0.015138886868953705,
      "eval_rewards/margins": 0.020196832716464996,
      "eval_rewards/rejected": -0.005057945381850004,
      "eval_runtime": 2.7437,
      "eval_samples_per_second": 36.447,
      "eval_steps_per_second": 18.223,
      "step": 364
    },
    {
      "epoch": 28.08,
      "grad_norm": 7.366457462310791,
      "learning_rate": 4.5396825396825393e-08,
      "logits/chosen": 1.245638370513916,
      "logits/rejected": 1.3537893295288086,
      "logps/chosen": -37.96733856201172,
      "logps/rejected": -61.37535095214844,
      "loss": 0.6819,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012625932693481445,
      "rewards/margins": 0.022713329643011093,
      "rewards/rejected": -0.010087394155561924,
      "step": 365
    },
    {
      "epoch": 28.16,
      "grad_norm": 7.191084861755371,
      "learning_rate": 4.5238095238095236e-08,
      "logits/chosen": 1.2359663248062134,
      "logits/rejected": 1.3204255104064941,
      "logps/chosen": -31.41814422607422,
      "logps/rejected": -55.681396484375,
      "loss": 0.6684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023150324821472168,
      "rewards/margins": 0.050170354545116425,
      "rewards/rejected": -0.027020025998353958,
      "step": 366
    },
    {
      "epoch": 28.24,
      "grad_norm": 8.015780448913574,
      "learning_rate": 4.507936507936508e-08,
      "logits/chosen": 1.5127999782562256,
      "logits/rejected": 1.2924710512161255,
      "logps/chosen": -35.7962646484375,
      "logps/rejected": -57.693687438964844,
      "loss": 0.6726,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016261791810393333,
      "rewards/margins": 0.041727472096681595,
      "rewards/rejected": -0.025465678423643112,
      "step": 367
    },
    {
      "epoch": 28.32,
      "grad_norm": 5.805884838104248,
      "learning_rate": 4.492063492063492e-08,
      "logits/chosen": 1.1060785055160522,
      "logits/rejected": 1.2275594472885132,
      "logps/chosen": -34.103084564208984,
      "logps/rejected": -49.1679801940918,
      "loss": 0.6805,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008263206109404564,
      "rewards/margins": 0.025748014450073242,
      "rewards/rejected": -0.017484810203313828,
      "step": 368
    },
    {
      "epoch": 28.4,
      "grad_norm": 7.859996795654297,
      "learning_rate": 4.476190476190476e-08,
      "logits/chosen": 1.366650104522705,
      "logits/rejected": 1.3718665838241577,
      "logps/chosen": -34.702003479003906,
      "logps/rejected": -60.07427978515625,
      "loss": 0.6745,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012790822423994541,
      "rewards/margins": 0.037659596651792526,
      "rewards/rejected": -0.02486877329647541,
      "step": 369
    },
    {
      "epoch": 28.48,
      "grad_norm": 9.006523132324219,
      "learning_rate": 4.4603174603174605e-08,
      "logits/chosen": 1.2216804027557373,
      "logits/rejected": 1.1128363609313965,
      "logps/chosen": -32.20756912231445,
      "logps/rejected": -52.20637893676758,
      "loss": 0.6609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018819022923707962,
      "rewards/margins": 0.06606046855449677,
      "rewards/rejected": -0.0472414493560791,
      "step": 370
    },
    {
      "epoch": 28.56,
      "grad_norm": 8.176825523376465,
      "learning_rate": 4.444444444444444e-08,
      "logits/chosen": 1.5666654109954834,
      "logits/rejected": 1.068640112876892,
      "logps/chosen": -33.89333724975586,
      "logps/rejected": -49.646270751953125,
      "loss": 0.6686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023724772036075592,
      "rewards/margins": 0.04992396757006645,
      "rewards/rejected": -0.02619919925928116,
      "step": 371
    },
    {
      "epoch": 28.64,
      "grad_norm": 8.341043472290039,
      "learning_rate": 4.4285714285714283e-08,
      "logits/chosen": 1.3697080612182617,
      "logits/rejected": 1.3894133567810059,
      "logps/chosen": -33.59996032714844,
      "logps/rejected": -59.1190071105957,
      "loss": 0.6772,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.011678362265229225,
      "rewards/margins": 0.03224353864789009,
      "rewards/rejected": -0.020565174520015717,
      "step": 372
    },
    {
      "epoch": 28.72,
      "grad_norm": 7.525383472442627,
      "learning_rate": 4.4126984126984126e-08,
      "logits/chosen": 1.1845414638519287,
      "logits/rejected": 1.1887233257293701,
      "logps/chosen": -33.13636779785156,
      "logps/rejected": -45.43964767456055,
      "loss": 0.6785,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015402221120893955,
      "rewards/margins": 0.02964186854660511,
      "rewards/rejected": -0.014239645563066006,
      "step": 373
    },
    {
      "epoch": 28.8,
      "grad_norm": 8.454269409179688,
      "learning_rate": 4.396825396825397e-08,
      "logits/chosen": 1.2545373439788818,
      "logits/rejected": 1.2018529176712036,
      "logps/chosen": -33.48710632324219,
      "logps/rejected": -64.11509704589844,
      "loss": 0.6603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022107888013124466,
      "rewards/margins": 0.06698303669691086,
      "rewards/rejected": -0.044875144958496094,
      "step": 374
    },
    {
      "epoch": 28.88,
      "grad_norm": 6.958135604858398,
      "learning_rate": 4.380952380952381e-08,
      "logits/chosen": 1.0799460411071777,
      "logits/rejected": 1.1762335300445557,
      "logps/chosen": -30.306827545166016,
      "logps/rejected": -51.07567596435547,
      "loss": 0.6742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01740112341940403,
      "rewards/margins": 0.03836784511804581,
      "rewards/rejected": -0.020966719835996628,
      "step": 375
    },
    {
      "epoch": 28.96,
      "grad_norm": 6.8677873611450195,
      "learning_rate": 4.3650793650793646e-08,
      "logits/chosen": 1.4173612594604492,
      "logits/rejected": 1.467810034751892,
      "logps/chosen": -38.08295822143555,
      "logps/rejected": -59.52442932128906,
      "loss": 0.6746,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013813900761306286,
      "rewards/margins": 0.03754594177007675,
      "rewards/rejected": -0.02373204380273819,
      "step": 376
    },
    {
      "epoch": 29.0,
      "grad_norm": 10.9064302444458,
      "learning_rate": 4.349206349206349e-08,
      "logits/chosen": 1.2101144790649414,
      "logits/rejected": 1.154310941696167,
      "logps/chosen": -34.04877471923828,
      "logps/rejected": -47.71276092529297,
      "loss": 0.659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023873329162597656,
      "rewards/margins": 0.06957092881202698,
      "rewards/rejected": -0.045697592198848724,
      "step": 377
    },
    {
      "epoch": 29.0,
      "eval_logits/chosen": 1.306998610496521,
      "eval_logits/rejected": 1.200827956199646,
      "eval_logps/chosen": -34.36876678466797,
      "eval_logps/rejected": -47.088233947753906,
      "eval_loss": 0.6823820471763611,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.013074967078864574,
      "eval_rewards/margins": 0.021779587492346764,
      "eval_rewards/rejected": -0.008704621344804764,
      "eval_runtime": 2.739,
      "eval_samples_per_second": 36.51,
      "eval_steps_per_second": 18.255,
      "step": 377
    },
    {
      "epoch": 29.08,
      "grad_norm": 8.169174194335938,
      "learning_rate": 4.333333333333333e-08,
      "logits/chosen": 1.569151759147644,
      "logits/rejected": 1.3334195613861084,
      "logps/chosen": -42.89222717285156,
      "logps/rejected": -54.20890808105469,
      "loss": 0.6739,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0040360926650464535,
      "rewards/margins": 0.03887429088354111,
      "rewards/rejected": -0.034838199615478516,
      "step": 378
    },
    {
      "epoch": 29.16,
      "grad_norm": 7.301225185394287,
      "learning_rate": 4.317460317460317e-08,
      "logits/chosen": 1.350480318069458,
      "logits/rejected": 1.0124659538269043,
      "logps/chosen": -30.49785041809082,
      "logps/rejected": -52.09638977050781,
      "loss": 0.6733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022612620145082474,
      "rewards/margins": 0.040198806673288345,
      "rewards/rejected": -0.017586184665560722,
      "step": 379
    },
    {
      "epoch": 29.24,
      "grad_norm": 7.772829055786133,
      "learning_rate": 4.3015873015873016e-08,
      "logits/chosen": 1.1208032369613647,
      "logits/rejected": 1.1966242790222168,
      "logps/chosen": -32.49734878540039,
      "logps/rejected": -53.81519317626953,
      "loss": 0.6708,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016804121434688568,
      "rewards/margins": 0.04543118178844452,
      "rewards/rejected": -0.02862706407904625,
      "step": 380
    },
    {
      "epoch": 29.32,
      "grad_norm": 7.892575740814209,
      "learning_rate": 4.285714285714285e-08,
      "logits/chosen": 1.4529688358306885,
      "logits/rejected": 1.266871690750122,
      "logps/chosen": -32.82938766479492,
      "logps/rejected": -55.81767654418945,
      "loss": 0.6667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02204265631735325,
      "rewards/margins": 0.05374035984277725,
      "rewards/rejected": -0.031697701662778854,
      "step": 381
    },
    {
      "epoch": 29.4,
      "grad_norm": 6.364035129547119,
      "learning_rate": 4.2698412698412694e-08,
      "logits/chosen": 1.370117425918579,
      "logits/rejected": 1.3133175373077393,
      "logps/chosen": -35.318359375,
      "logps/rejected": -57.45523452758789,
      "loss": 0.6713,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01612236350774765,
      "rewards/margins": 0.04428236559033394,
      "rewards/rejected": -0.02816000021994114,
      "step": 382
    },
    {
      "epoch": 29.48,
      "grad_norm": 7.44180965423584,
      "learning_rate": 4.2539682539682536e-08,
      "logits/chosen": 1.2923133373260498,
      "logits/rejected": 1.3002514839172363,
      "logps/chosen": -35.82526397705078,
      "logps/rejected": -62.679473876953125,
      "loss": 0.6706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014193393290042877,
      "rewards/margins": 0.04570617899298668,
      "rewards/rejected": -0.0315127857029438,
      "step": 383
    },
    {
      "epoch": 29.56,
      "grad_norm": 7.336416721343994,
      "learning_rate": 4.238095238095238e-08,
      "logits/chosen": 1.2939376831054688,
      "logits/rejected": 1.3025919198989868,
      "logps/chosen": -37.52849197387695,
      "logps/rejected": -54.06553649902344,
      "loss": 0.6745,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004547476768493652,
      "rewards/margins": 0.037984393537044525,
      "rewards/rejected": -0.03343692049384117,
      "step": 384
    },
    {
      "epoch": 29.64,
      "grad_norm": 7.539641380310059,
      "learning_rate": 4.222222222222222e-08,
      "logits/chosen": 1.2283637523651123,
      "logits/rejected": 1.53005850315094,
      "logps/chosen": -32.21272277832031,
      "logps/rejected": -52.07169723510742,
      "loss": 0.6694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020335601642727852,
      "rewards/margins": 0.04831840842962265,
      "rewards/rejected": -0.027982808649539948,
      "step": 385
    },
    {
      "epoch": 29.72,
      "grad_norm": 7.5836501121521,
      "learning_rate": 4.206349206349206e-08,
      "logits/chosen": 1.3669829368591309,
      "logits/rejected": 1.3501553535461426,
      "logps/chosen": -30.0163631439209,
      "logps/rejected": -49.06438446044922,
      "loss": 0.6723,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02570624276995659,
      "rewards/margins": 0.04224148020148277,
      "rewards/rejected": -0.016535235568881035,
      "step": 386
    },
    {
      "epoch": 29.8,
      "grad_norm": 8.901724815368652,
      "learning_rate": 4.1904761904761906e-08,
      "logits/chosen": 1.192025899887085,
      "logits/rejected": 1.1212973594665527,
      "logps/chosen": -35.970741271972656,
      "logps/rejected": -61.51569366455078,
      "loss": 0.6662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015366912819445133,
      "rewards/margins": 0.055178143084049225,
      "rewards/rejected": -0.039811231195926666,
      "step": 387
    },
    {
      "epoch": 29.88,
      "grad_norm": 6.941256046295166,
      "learning_rate": 4.174603174603175e-08,
      "logits/chosen": 1.341408371925354,
      "logits/rejected": 1.2024614810943604,
      "logps/chosen": -28.832246780395508,
      "logps/rejected": -45.2697639465332,
      "loss": 0.6664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010634947568178177,
      "rewards/margins": 0.05431797355413437,
      "rewards/rejected": -0.04368302971124649,
      "step": 388
    },
    {
      "epoch": 29.96,
      "grad_norm": 8.003681182861328,
      "learning_rate": 4.158730158730159e-08,
      "logits/chosen": 1.3410614728927612,
      "logits/rejected": 1.3253116607666016,
      "logps/chosen": -34.74722671508789,
      "logps/rejected": -60.31476974487305,
      "loss": 0.677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014839483425021172,
      "rewards/margins": 0.03259098529815674,
      "rewards/rejected": -0.017751503735780716,
      "step": 389
    },
    {
      "epoch": 30.0,
      "grad_norm": 10.76366901397705,
      "learning_rate": 4.1428571428571426e-08,
      "logits/chosen": 0.9095838069915771,
      "logits/rejected": 1.0373631715774536,
      "logps/chosen": -33.1845817565918,
      "logps/rejected": -61.46837615966797,
      "loss": 0.6755,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.007834815420210361,
      "rewards/margins": 0.03594827651977539,
      "rewards/rejected": -0.028113460168242455,
      "step": 390
    },
    {
      "epoch": 30.0,
      "eval_logits/chosen": 1.308949589729309,
      "eval_logits/rejected": 1.1999878883361816,
      "eval_logps/chosen": -34.352046966552734,
      "eval_logps/rejected": -47.07530212402344,
      "eval_loss": 0.6821942925453186,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.01474702823907137,
      "eval_rewards/margins": 0.022158358246088028,
      "eval_rewards/rejected": -0.007411329075694084,
      "eval_runtime": 2.7403,
      "eval_samples_per_second": 36.492,
      "eval_steps_per_second": 18.246,
      "step": 390
    },
    {
      "epoch": 30.08,
      "grad_norm": 9.33734130859375,
      "learning_rate": 4.126984126984127e-08,
      "logits/chosen": 1.400557041168213,
      "logits/rejected": 1.147376298904419,
      "logps/chosen": -34.272769927978516,
      "logps/rejected": -61.58372497558594,
      "loss": 0.6723,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024641036987304688,
      "rewards/margins": 0.04239116236567497,
      "rewards/rejected": -0.017750119790434837,
      "step": 391
    },
    {
      "epoch": 30.16,
      "grad_norm": 7.46895694732666,
      "learning_rate": 4.1111111111111104e-08,
      "logits/chosen": 1.2686318159103394,
      "logits/rejected": 1.200438141822815,
      "logps/chosen": -30.025897979736328,
      "logps/rejected": -60.49510192871094,
      "loss": 0.6817,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012920808978378773,
      "rewards/margins": 0.023080922663211823,
      "rewards/rejected": -0.010160112753510475,
      "step": 392
    },
    {
      "epoch": 30.24,
      "grad_norm": 8.6347074508667,
      "learning_rate": 4.0952380952380947e-08,
      "logits/chosen": 1.3578097820281982,
      "logits/rejected": 0.9806253910064697,
      "logps/chosen": -29.35013198852539,
      "logps/rejected": -49.02892303466797,
      "loss": 0.6613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02333512343466282,
      "rewards/margins": 0.06561923027038574,
      "rewards/rejected": -0.04228410869836807,
      "step": 393
    },
    {
      "epoch": 30.32,
      "grad_norm": 7.597570419311523,
      "learning_rate": 4.079365079365079e-08,
      "logits/chosen": 1.2915410995483398,
      "logits/rejected": 1.3124350309371948,
      "logps/chosen": -36.66054916381836,
      "logps/rejected": -55.40325164794922,
      "loss": 0.6662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014658761210739613,
      "rewards/margins": 0.054927803575992584,
      "rewards/rejected": -0.04026903957128525,
      "step": 394
    },
    {
      "epoch": 30.4,
      "grad_norm": 8.167840957641602,
      "learning_rate": 4.063492063492063e-08,
      "logits/chosen": 1.191222906112671,
      "logits/rejected": 1.4247864484786987,
      "logps/chosen": -35.24845886230469,
      "logps/rejected": -59.87513732910156,
      "loss": 0.668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02081782929599285,
      "rewards/margins": 0.05101563781499863,
      "rewards/rejected": -0.030197810381650925,
      "step": 395
    },
    {
      "epoch": 30.48,
      "grad_norm": 7.116304874420166,
      "learning_rate": 4.0476190476190474e-08,
      "logits/chosen": 1.3767125606536865,
      "logits/rejected": 1.3828041553497314,
      "logps/chosen": -36.948726654052734,
      "logps/rejected": -53.739219665527344,
      "loss": 0.6688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026096059009432793,
      "rewards/margins": 0.0494019016623497,
      "rewards/rejected": -0.023305846378207207,
      "step": 396
    },
    {
      "epoch": 30.56,
      "grad_norm": 7.011618137359619,
      "learning_rate": 4.0317460317460316e-08,
      "logits/chosen": 1.1762712001800537,
      "logits/rejected": 1.2249524593353271,
      "logps/chosen": -29.436601638793945,
      "logps/rejected": -55.028099060058594,
      "loss": 0.6685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03089335188269615,
      "rewards/margins": 0.049968935549259186,
      "rewards/rejected": -0.019075583666563034,
      "step": 397
    },
    {
      "epoch": 30.64,
      "grad_norm": 6.911332607269287,
      "learning_rate": 4.015873015873016e-08,
      "logits/chosen": 1.235501766204834,
      "logits/rejected": 1.3381500244140625,
      "logps/chosen": -38.682029724121094,
      "logps/rejected": -48.314247131347656,
      "loss": 0.6809,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.004534506238996983,
      "rewards/margins": 0.02506892755627632,
      "rewards/rejected": -0.020534420385956764,
      "step": 398
    },
    {
      "epoch": 30.72,
      "grad_norm": 7.620301723480225,
      "learning_rate": 4e-08,
      "logits/chosen": 1.124079942703247,
      "logits/rejected": 1.3097198009490967,
      "logps/chosen": -31.766603469848633,
      "logps/rejected": -54.842185974121094,
      "loss": 0.6778,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008486509323120117,
      "rewards/margins": 0.031107090413570404,
      "rewards/rejected": -0.022620582953095436,
      "step": 399
    },
    {
      "epoch": 30.8,
      "grad_norm": 7.900156497955322,
      "learning_rate": 3.9841269841269837e-08,
      "logits/chosen": 1.2894377708435059,
      "logits/rejected": 1.1655657291412354,
      "logps/chosen": -36.85523986816406,
      "logps/rejected": -56.371456146240234,
      "loss": 0.6708,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009238195605576038,
      "rewards/margins": 0.045359015464782715,
      "rewards/rejected": -0.03612082079052925,
      "step": 400
    },
    {
      "epoch": 30.88,
      "grad_norm": 7.956189155578613,
      "learning_rate": 3.968253968253968e-08,
      "logits/chosen": 1.4540530443191528,
      "logits/rejected": 1.3383508920669556,
      "logps/chosen": -35.68250274658203,
      "logps/rejected": -58.935340881347656,
      "loss": 0.6784,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01220610085874796,
      "rewards/margins": 0.02992413006722927,
      "rewards/rejected": -0.017718028277158737,
      "step": 401
    },
    {
      "epoch": 30.96,
      "grad_norm": 6.713281631469727,
      "learning_rate": 3.952380952380952e-08,
      "logits/chosen": 1.3844330310821533,
      "logits/rejected": 1.279719352722168,
      "logps/chosen": -35.537315368652344,
      "logps/rejected": -51.87919616699219,
      "loss": 0.6721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028455186635255814,
      "rewards/margins": 0.0426253080368042,
      "rewards/rejected": -0.01417012233287096,
      "step": 402
    },
    {
      "epoch": 31.0,
      "grad_norm": 8.577080726623535,
      "learning_rate": 3.9365079365079364e-08,
      "logits/chosen": 1.2072792053222656,
      "logits/rejected": 1.2785453796386719,
      "logps/chosen": -30.02802276611328,
      "logps/rejected": -46.473594665527344,
      "loss": 0.6842,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.008720970712602139,
      "rewards/margins": 0.018200017511844635,
      "rewards/rejected": -0.009479045867919922,
      "step": 403
    },
    {
      "epoch": 31.0,
      "eval_logits/chosen": 1.3086724281311035,
      "eval_logits/rejected": 1.2015697956085205,
      "eval_logps/chosen": -34.36033248901367,
      "eval_logps/rejected": -47.109947204589844,
      "eval_loss": 0.6808852553367615,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.013918112963438034,
      "eval_rewards/margins": 0.024794230237603188,
      "eval_rewards/rejected": -0.010876121930778027,
      "eval_runtime": 2.7383,
      "eval_samples_per_second": 36.519,
      "eval_steps_per_second": 18.259,
      "step": 403
    },
    {
      "epoch": 31.08,
      "grad_norm": 7.633491039276123,
      "learning_rate": 3.9206349206349206e-08,
      "logits/chosen": 1.450360655784607,
      "logits/rejected": 1.2189557552337646,
      "logps/chosen": -28.80171012878418,
      "logps/rejected": -49.939231872558594,
      "loss": 0.671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018560076132416725,
      "rewards/margins": 0.04488516226410866,
      "rewards/rejected": -0.026325084269046783,
      "step": 404
    },
    {
      "epoch": 31.16,
      "grad_norm": 7.369604587554932,
      "learning_rate": 3.904761904761905e-08,
      "logits/chosen": 1.3045547008514404,
      "logits/rejected": 1.0716171264648438,
      "logps/chosen": -32.488441467285156,
      "logps/rejected": -57.406707763671875,
      "loss": 0.6748,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007828234694898129,
      "rewards/margins": 0.03705267980694771,
      "rewards/rejected": -0.029224444180727005,
      "step": 405
    },
    {
      "epoch": 31.24,
      "grad_norm": 7.769664287567139,
      "learning_rate": 3.888888888888889e-08,
      "logits/chosen": 1.2599520683288574,
      "logits/rejected": 1.2606478929519653,
      "logps/chosen": -35.870819091796875,
      "logps/rejected": -63.12469482421875,
      "loss": 0.6794,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0009931803215295076,
      "rewards/margins": 0.027796007692813873,
      "rewards/rejected": -0.028789186850190163,
      "step": 406
    },
    {
      "epoch": 31.32,
      "grad_norm": 8.001116752624512,
      "learning_rate": 3.8730158730158727e-08,
      "logits/chosen": 1.273396611213684,
      "logits/rejected": 1.3327035903930664,
      "logps/chosen": -38.54448699951172,
      "logps/rejected": -66.7636489868164,
      "loss": 0.6747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0034851557575166225,
      "rewards/margins": 0.03748593479394913,
      "rewards/rejected": -0.03400077670812607,
      "step": 407
    },
    {
      "epoch": 31.4,
      "grad_norm": 8.30517578125,
      "learning_rate": 3.857142857142857e-08,
      "logits/chosen": 1.2458035945892334,
      "logits/rejected": 1.2289612293243408,
      "logps/chosen": -34.17776870727539,
      "logps/rejected": -49.06776428222656,
      "loss": 0.6694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019343256950378418,
      "rewards/margins": 0.048095062375068665,
      "rewards/rejected": -0.028751803562045097,
      "step": 408
    },
    {
      "epoch": 31.48,
      "grad_norm": 8.80705451965332,
      "learning_rate": 3.841269841269841e-08,
      "logits/chosen": 1.1381946802139282,
      "logits/rejected": 1.246354579925537,
      "logps/chosen": -33.596160888671875,
      "logps/rejected": -58.59119415283203,
      "loss": 0.6646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01963989809155464,
      "rewards/margins": 0.05835855007171631,
      "rewards/rejected": -0.03871865198016167,
      "step": 409
    },
    {
      "epoch": 31.56,
      "grad_norm": 7.385908603668213,
      "learning_rate": 3.825396825396825e-08,
      "logits/chosen": 1.4499852657318115,
      "logits/rejected": 1.387290120124817,
      "logps/chosen": -32.34325408935547,
      "logps/rejected": -54.516300201416016,
      "loss": 0.6715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021219326183199883,
      "rewards/margins": 0.04381239414215088,
      "rewards/rejected": -0.022593069821596146,
      "step": 410
    },
    {
      "epoch": 31.64,
      "grad_norm": 6.464962959289551,
      "learning_rate": 3.809523809523809e-08,
      "logits/chosen": 1.4562150239944458,
      "logits/rejected": 1.341080665588379,
      "logps/chosen": -33.752105712890625,
      "logps/rejected": -57.16054916381836,
      "loss": 0.676,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02102193981409073,
      "rewards/margins": 0.034974098205566406,
      "rewards/rejected": -0.013952159322798252,
      "step": 411
    },
    {
      "epoch": 31.72,
      "grad_norm": 6.696891784667969,
      "learning_rate": 3.793650793650793e-08,
      "logits/chosen": 1.0351797342300415,
      "logits/rejected": 1.3745039701461792,
      "logps/chosen": -34.91449737548828,
      "logps/rejected": -58.370460510253906,
      "loss": 0.6763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007292628288269043,
      "rewards/margins": 0.034043051302433014,
      "rewards/rejected": -0.02675042301416397,
      "step": 412
    },
    {
      "epoch": 31.8,
      "grad_norm": 9.22788143157959,
      "learning_rate": 3.7777777777777774e-08,
      "logits/chosen": 1.1418704986572266,
      "logits/rejected": 1.1142348051071167,
      "logps/chosen": -32.221256256103516,
      "logps/rejected": -48.036773681640625,
      "loss": 0.6682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02558767795562744,
      "rewards/margins": 0.0506364107131958,
      "rewards/rejected": -0.02504873275756836,
      "step": 413
    },
    {
      "epoch": 31.88,
      "grad_norm": 7.092567443847656,
      "learning_rate": 3.7619047619047617e-08,
      "logits/chosen": 1.3882042169570923,
      "logits/rejected": 1.37361478805542,
      "logps/chosen": -36.296875,
      "logps/rejected": -47.60612487792969,
      "loss": 0.6716,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017244935035705566,
      "rewards/margins": 0.04374735429883003,
      "rewards/rejected": -0.026502421125769615,
      "step": 414
    },
    {
      "epoch": 31.96,
      "grad_norm": 7.831509113311768,
      "learning_rate": 3.746031746031746e-08,
      "logits/chosen": 1.5074108839035034,
      "logits/rejected": 1.1608635187149048,
      "logps/chosen": -34.08054733276367,
      "logps/rejected": -45.43617248535156,
      "loss": 0.6716,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028423571959137917,
      "rewards/margins": 0.04368465021252632,
      "rewards/rejected": -0.015261078253388405,
      "step": 415
    },
    {
      "epoch": 32.0,
      "grad_norm": 12.154305458068848,
      "learning_rate": 3.73015873015873e-08,
      "logits/chosen": 1.5208723545074463,
      "logits/rejected": 1.219205617904663,
      "logps/chosen": -37.01228713989258,
      "logps/rejected": -66.01480865478516,
      "loss": 0.6622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02728714793920517,
      "rewards/margins": 0.06296658515930176,
      "rewards/rejected": -0.03567943722009659,
      "step": 416
    },
    {
      "epoch": 32.0,
      "eval_logits/chosen": 1.3098849058151245,
      "eval_logits/rejected": 1.2026647329330444,
      "eval_logps/chosen": -34.371360778808594,
      "eval_logps/rejected": -47.11701965332031,
      "eval_loss": 0.681100606918335,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.012815522961318493,
      "eval_rewards/margins": 0.02439894713461399,
      "eval_rewards/rejected": -0.011583423241972923,
      "eval_runtime": 2.7422,
      "eval_samples_per_second": 36.467,
      "eval_steps_per_second": 18.233,
      "step": 416
    },
    {
      "epoch": 32.08,
      "grad_norm": 6.047023296356201,
      "learning_rate": 3.7142857142857144e-08,
      "logits/chosen": 1.2808873653411865,
      "logits/rejected": 1.335012435913086,
      "logps/chosen": -37.1719970703125,
      "logps/rejected": -52.14815139770508,
      "loss": 0.6804,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.003023386001586914,
      "rewards/margins": 0.025736000388860703,
      "rewards/rejected": -0.02271261252462864,
      "step": 417
    },
    {
      "epoch": 32.16,
      "grad_norm": 7.423065185546875,
      "learning_rate": 3.6984126984126986e-08,
      "logits/chosen": 1.25384521484375,
      "logits/rejected": 1.2381861209869385,
      "logps/chosen": -36.362144470214844,
      "logps/rejected": -58.49082565307617,
      "loss": 0.6737,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.001868128776550293,
      "rewards/margins": 0.03961308300495148,
      "rewards/rejected": -0.04148120805621147,
      "step": 418
    },
    {
      "epoch": 32.24,
      "grad_norm": 7.78044319152832,
      "learning_rate": 3.682539682539683e-08,
      "logits/chosen": 1.386929988861084,
      "logits/rejected": 1.3272712230682373,
      "logps/chosen": -35.044822692871094,
      "logps/rejected": -53.5078125,
      "loss": 0.668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022547651082277298,
      "rewards/margins": 0.05114419758319855,
      "rewards/rejected": -0.0285965446382761,
      "step": 419
    },
    {
      "epoch": 32.32,
      "grad_norm": 8.34743595123291,
      "learning_rate": 3.6666666666666664e-08,
      "logits/chosen": 1.1428773403167725,
      "logits/rejected": 1.1797031164169312,
      "logps/chosen": -32.99810791015625,
      "logps/rejected": -64.30101013183594,
      "loss": 0.6719,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013050531968474388,
      "rewards/margins": 0.04319441691040993,
      "rewards/rejected": -0.03014388307929039,
      "step": 420
    },
    {
      "epoch": 32.4,
      "grad_norm": 8.511870384216309,
      "learning_rate": 3.6507936507936506e-08,
      "logits/chosen": 1.4113949537277222,
      "logits/rejected": 1.3414783477783203,
      "logps/chosen": -35.11406707763672,
      "logps/rejected": -68.71812438964844,
      "loss": 0.6737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026264000684022903,
      "rewards/margins": 0.03944115713238716,
      "rewards/rejected": -0.013177156448364258,
      "step": 421
    },
    {
      "epoch": 32.48,
      "grad_norm": 6.316720008850098,
      "learning_rate": 3.634920634920635e-08,
      "logits/chosen": 1.4680602550506592,
      "logits/rejected": 1.354975700378418,
      "logps/chosen": -32.248443603515625,
      "logps/rejected": -59.79944610595703,
      "loss": 0.6767,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02108149603009224,
      "rewards/margins": 0.033322811126708984,
      "rewards/rejected": -0.012241315096616745,
      "step": 422
    },
    {
      "epoch": 32.56,
      "grad_norm": 8.830583572387695,
      "learning_rate": 3.619047619047619e-08,
      "logits/chosen": 1.24998939037323,
      "logits/rejected": 1.1903800964355469,
      "logps/chosen": -30.026395797729492,
      "logps/rejected": -51.43700408935547,
      "loss": 0.6697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015189265832304955,
      "rewards/margins": 0.04762902483344078,
      "rewards/rejected": -0.03243975713849068,
      "step": 423
    },
    {
      "epoch": 32.64,
      "grad_norm": 7.406064510345459,
      "learning_rate": 3.603174603174603e-08,
      "logits/chosen": 1.4377096891403198,
      "logits/rejected": 1.1250289678573608,
      "logps/chosen": -38.06059646606445,
      "logps/rejected": -47.64955520629883,
      "loss": 0.6706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01683838479220867,
      "rewards/margins": 0.04590423405170441,
      "rewards/rejected": -0.029065849259495735,
      "step": 424
    },
    {
      "epoch": 32.72,
      "grad_norm": 7.182457447052002,
      "learning_rate": 3.587301587301587e-08,
      "logits/chosen": 1.1109230518341064,
      "logits/rejected": 1.3654663562774658,
      "logps/chosen": -28.692428588867188,
      "logps/rejected": -53.84072494506836,
      "loss": 0.6675,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.027564216405153275,
      "rewards/margins": 0.05220778286457062,
      "rewards/rejected": -0.024643564596772194,
      "step": 425
    },
    {
      "epoch": 32.8,
      "grad_norm": 8.632458686828613,
      "learning_rate": 3.571428571428571e-08,
      "logits/chosen": 1.269928216934204,
      "logits/rejected": 1.2449966669082642,
      "logps/chosen": -35.7657470703125,
      "logps/rejected": -59.57209014892578,
      "loss": 0.6678,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03027365170419216,
      "rewards/margins": 0.051475074142217636,
      "rewards/rejected": -0.021201420575380325,
      "step": 426
    },
    {
      "epoch": 32.88,
      "grad_norm": 8.910959243774414,
      "learning_rate": 3.5555555555555554e-08,
      "logits/chosen": 1.3862868547439575,
      "logits/rejected": 1.0781606435775757,
      "logps/chosen": -35.239192962646484,
      "logps/rejected": -52.78126907348633,
      "loss": 0.6666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011023450642824173,
      "rewards/margins": 0.053919676691293716,
      "rewards/rejected": -0.04289622604846954,
      "step": 427
    },
    {
      "epoch": 32.96,
      "grad_norm": 6.771306037902832,
      "learning_rate": 3.5396825396825396e-08,
      "logits/chosen": 1.3256913423538208,
      "logits/rejected": 1.3275591135025024,
      "logps/chosen": -35.23405838012695,
      "logps/rejected": -43.15639877319336,
      "loss": 0.6753,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0163070447742939,
      "rewards/margins": 0.036214377731084824,
      "rewards/rejected": -0.019907331094145775,
      "step": 428
    },
    {
      "epoch": 33.0,
      "grad_norm": 9.488099098205566,
      "learning_rate": 3.523809523809524e-08,
      "logits/chosen": 1.2674126625061035,
      "logits/rejected": 1.504623532295227,
      "logps/chosen": -27.329421997070312,
      "logps/rejected": -47.04234313964844,
      "loss": 0.6701,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.03057846985757351,
      "rewards/margins": 0.04692797735333443,
      "rewards/rejected": -0.016349507495760918,
      "step": 429
    },
    {
      "epoch": 33.0,
      "eval_logits/chosen": 1.311285376548767,
      "eval_logits/rejected": 1.2022030353546143,
      "eval_logps/chosen": -34.330650329589844,
      "eval_logps/rejected": -47.08342361450195,
      "eval_loss": 0.6807548999786377,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.016886688768863678,
      "eval_rewards/margins": 0.025110311806201935,
      "eval_rewards/rejected": -0.008223619312047958,
      "eval_runtime": 2.7413,
      "eval_samples_per_second": 36.478,
      "eval_steps_per_second": 18.239,
      "step": 429
    },
    {
      "epoch": 33.08,
      "grad_norm": 7.2579569816589355,
      "learning_rate": 3.5079365079365075e-08,
      "logits/chosen": 1.6212174892425537,
      "logits/rejected": 1.416581630706787,
      "logps/chosen": -41.217430114746094,
      "logps/rejected": -53.85881423950195,
      "loss": 0.6753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00636367779225111,
      "rewards/margins": 0.03623586148023605,
      "rewards/rejected": -0.02987217903137207,
      "step": 430
    },
    {
      "epoch": 33.16,
      "grad_norm": 8.564245223999023,
      "learning_rate": 3.492063492063492e-08,
      "logits/chosen": 1.4487338066101074,
      "logits/rejected": 1.1389639377593994,
      "logps/chosen": -30.968481063842773,
      "logps/rejected": -53.986549377441406,
      "loss": 0.6617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018774772062897682,
      "rewards/margins": 0.06424477696418762,
      "rewards/rejected": -0.04546999931335449,
      "step": 431
    },
    {
      "epoch": 33.24,
      "grad_norm": 7.794315814971924,
      "learning_rate": 3.476190476190476e-08,
      "logits/chosen": 1.301712155342102,
      "logits/rejected": 1.2690579891204834,
      "logps/chosen": -39.27137756347656,
      "logps/rejected": -52.28510665893555,
      "loss": 0.6807,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0036963224411010742,
      "rewards/margins": 0.02523639425635338,
      "rewards/rejected": -0.021540069952607155,
      "step": 432
    },
    {
      "epoch": 33.32,
      "grad_norm": 7.3188371658325195,
      "learning_rate": 3.46031746031746e-08,
      "logits/chosen": 1.3453882932662964,
      "logits/rejected": 1.2037442922592163,
      "logps/chosen": -37.32102584838867,
      "logps/rejected": -56.111106872558594,
      "loss": 0.6703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011406111530959606,
      "rewards/margins": 0.046238113194704056,
      "rewards/rejected": -0.034832000732421875,
      "step": 433
    },
    {
      "epoch": 33.4,
      "grad_norm": 7.691816329956055,
      "learning_rate": 3.4444444444444444e-08,
      "logits/chosen": 1.3790372610092163,
      "logits/rejected": 1.3287123441696167,
      "logps/chosen": -32.8033447265625,
      "logps/rejected": -56.49340057373047,
      "loss": 0.6719,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02273266389966011,
      "rewards/margins": 0.04323737323284149,
      "rewards/rejected": -0.02050471305847168,
      "step": 434
    },
    {
      "epoch": 33.48,
      "grad_norm": 7.012847900390625,
      "learning_rate": 3.4285714285714286e-08,
      "logits/chosen": 1.178617000579834,
      "logits/rejected": 1.386914610862732,
      "logps/chosen": -35.24661636352539,
      "logps/rejected": -60.404388427734375,
      "loss": 0.6701,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.021993350237607956,
      "rewards/margins": 0.04702649265527725,
      "rewards/rejected": -0.025033140555024147,
      "step": 435
    },
    {
      "epoch": 33.56,
      "grad_norm": 7.305661201477051,
      "learning_rate": 3.412698412698413e-08,
      "logits/chosen": 1.0854086875915527,
      "logits/rejected": 1.1550347805023193,
      "logps/chosen": -31.571765899658203,
      "logps/rejected": -53.60218811035156,
      "loss": 0.6729,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.01788153685629368,
      "rewards/margins": 0.04109778627753258,
      "rewards/rejected": -0.0232162456959486,
      "step": 436
    },
    {
      "epoch": 33.64,
      "grad_norm": 8.255343437194824,
      "learning_rate": 3.396825396825397e-08,
      "logits/chosen": 1.0950851440429688,
      "logits/rejected": 1.183267593383789,
      "logps/chosen": -32.70664978027344,
      "logps/rejected": -54.60853576660156,
      "loss": 0.6634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021239567548036575,
      "rewards/margins": 0.06055746227502823,
      "rewards/rejected": -0.03931789472699165,
      "step": 437
    },
    {
      "epoch": 33.72,
      "grad_norm": 7.707691192626953,
      "learning_rate": 3.380952380952381e-08,
      "logits/chosen": 1.1860891580581665,
      "logits/rejected": 1.1951457262039185,
      "logps/chosen": -30.06858253479004,
      "logps/rejected": -56.90007781982422,
      "loss": 0.6752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02561180666089058,
      "rewards/margins": 0.036356184631586075,
      "rewards/rejected": -0.010744381695985794,
      "step": 438
    },
    {
      "epoch": 33.8,
      "grad_norm": 6.8160400390625,
      "learning_rate": 3.365079365079365e-08,
      "logits/chosen": 1.1909050941467285,
      "logits/rejected": 1.2613632678985596,
      "logps/chosen": -32.91545104980469,
      "logps/rejected": -43.603790283203125,
      "loss": 0.6644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01659398153424263,
      "rewards/margins": 0.058371949940919876,
      "rewards/rejected": -0.041777968406677246,
      "step": 439
    },
    {
      "epoch": 33.88,
      "grad_norm": 6.781989097595215,
      "learning_rate": 3.3492063492063485e-08,
      "logits/chosen": 1.4491734504699707,
      "logits/rejected": 1.3502569198608398,
      "logps/chosen": -32.79804229736328,
      "logps/rejected": -58.285152435302734,
      "loss": 0.6776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010844040662050247,
      "rewards/margins": 0.03134579584002495,
      "rewards/rejected": -0.02050175704061985,
      "step": 440
    },
    {
      "epoch": 33.96,
      "grad_norm": 9.309718132019043,
      "learning_rate": 3.333333333333333e-08,
      "logits/chosen": 1.1975971460342407,
      "logits/rejected": 1.178749680519104,
      "logps/chosen": -31.992460250854492,
      "logps/rejected": -58.97723388671875,
      "loss": 0.6679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013223242945969105,
      "rewards/margins": 0.051351286470890045,
      "rewards/rejected": -0.03812804073095322,
      "step": 441
    },
    {
      "epoch": 34.0,
      "grad_norm": 11.352494239807129,
      "learning_rate": 3.317460317460317e-08,
      "logits/chosen": 1.5163111686706543,
      "logits/rejected": 1.318882942199707,
      "logps/chosen": -33.49330520629883,
      "logps/rejected": -60.457313537597656,
      "loss": 0.6637,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026769496500492096,
      "rewards/margins": 0.05988879129290581,
      "rewards/rejected": -0.03311929851770401,
      "step": 442
    },
    {
      "epoch": 34.0,
      "eval_logits/chosen": 1.3107355833053589,
      "eval_logits/rejected": 1.2026934623718262,
      "eval_logps/chosen": -34.315338134765625,
      "eval_logps/rejected": -47.0698127746582,
      "eval_loss": 0.6806604862213135,
      "eval_rewards/accuracies": 0.8600000143051147,
      "eval_rewards/chosen": 0.018417827785015106,
      "eval_rewards/margins": 0.02528052031993866,
      "eval_rewards/rejected": -0.006862693931907415,
      "eval_runtime": 2.7442,
      "eval_samples_per_second": 36.44,
      "eval_steps_per_second": 18.22,
      "step": 442
    },
    {
      "epoch": 34.08,
      "grad_norm": 8.330178260803223,
      "learning_rate": 3.301587301587301e-08,
      "logits/chosen": 1.3078571557998657,
      "logits/rejected": 1.2965912818908691,
      "logps/chosen": -37.26897430419922,
      "logps/rejected": -54.00286865234375,
      "loss": 0.6724,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.020170165225863457,
      "rewards/margins": 0.042436935007572174,
      "rewards/rejected": -0.022266769781708717,
      "step": 443
    },
    {
      "epoch": 34.16,
      "grad_norm": 7.2092604637146,
      "learning_rate": 3.2857142857142855e-08,
      "logits/chosen": 1.1768471002578735,
      "logits/rejected": 1.4472790956497192,
      "logps/chosen": -38.87610626220703,
      "logps/rejected": -65.47322082519531,
      "loss": 0.6779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022276807576417923,
      "rewards/margins": 0.030786681920289993,
      "rewards/rejected": -0.00850987434387207,
      "step": 444
    },
    {
      "epoch": 34.24,
      "grad_norm": 8.215408325195312,
      "learning_rate": 3.26984126984127e-08,
      "logits/chosen": 1.2735357284545898,
      "logits/rejected": 1.2211796045303345,
      "logps/chosen": -35.522605895996094,
      "logps/rejected": -59.22642135620117,
      "loss": 0.6721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014234614558517933,
      "rewards/margins": 0.04271509498357773,
      "rewards/rejected": -0.02848048321902752,
      "step": 445
    },
    {
      "epoch": 34.32,
      "grad_norm": 8.800716400146484,
      "learning_rate": 3.253968253968254e-08,
      "logits/chosen": 1.0860207080841064,
      "logits/rejected": 1.0088567733764648,
      "logps/chosen": -30.973207473754883,
      "logps/rejected": -55.45708084106445,
      "loss": 0.6587,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02805624157190323,
      "rewards/margins": 0.07070331275463104,
      "rewards/rejected": -0.04264707863330841,
      "step": 446
    },
    {
      "epoch": 34.4,
      "grad_norm": 7.566588878631592,
      "learning_rate": 3.238095238095238e-08,
      "logits/chosen": 1.3834885358810425,
      "logits/rejected": 1.1176764965057373,
      "logps/chosen": -34.118709564208984,
      "logps/rejected": -43.824947357177734,
      "loss": 0.6656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02615373209118843,
      "rewards/margins": 0.056047871708869934,
      "rewards/rejected": -0.029894137755036354,
      "step": 447
    },
    {
      "epoch": 34.48,
      "grad_norm": 7.551087379455566,
      "learning_rate": 3.2222222222222224e-08,
      "logits/chosen": 1.268444538116455,
      "logits/rejected": 1.195860743522644,
      "logps/chosen": -30.79438018798828,
      "logps/rejected": -55.77253341674805,
      "loss": 0.6678,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019290447235107422,
      "rewards/margins": 0.051340293139219284,
      "rewards/rejected": -0.03204984590411186,
      "step": 448
    },
    {
      "epoch": 34.56,
      "grad_norm": 7.527178764343262,
      "learning_rate": 3.2063492063492066e-08,
      "logits/chosen": 1.3573532104492188,
      "logits/rejected": 1.2917146682739258,
      "logps/chosen": -36.14569091796875,
      "logps/rejected": -56.81207275390625,
      "loss": 0.6741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009505987167358398,
      "rewards/margins": 0.03852119669318199,
      "rewards/rejected": -0.029015207663178444,
      "step": 449
    },
    {
      "epoch": 34.64,
      "grad_norm": 7.16538667678833,
      "learning_rate": 3.19047619047619e-08,
      "logits/chosen": 1.6075984239578247,
      "logits/rejected": 1.3947311639785767,
      "logps/chosen": -33.331398010253906,
      "logps/rejected": -64.68087005615234,
      "loss": 0.6712,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016733240336179733,
      "rewards/margins": 0.04455916956067085,
      "rewards/rejected": -0.02782592736184597,
      "step": 450
    },
    {
      "epoch": 34.72,
      "grad_norm": 6.494694232940674,
      "learning_rate": 3.1746031746031744e-08,
      "logits/chosen": 1.1091289520263672,
      "logits/rejected": 1.3101191520690918,
      "logps/chosen": -34.08195495605469,
      "logps/rejected": -52.55885314941406,
      "loss": 0.6803,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010100889950990677,
      "rewards/margins": 0.026062916964292526,
      "rewards/rejected": -0.01596202701330185,
      "step": 451
    },
    {
      "epoch": 34.8,
      "grad_norm": 8.21272087097168,
      "learning_rate": 3.158730158730159e-08,
      "logits/chosen": 1.2935271263122559,
      "logits/rejected": 1.285776138305664,
      "logps/chosen": -33.740848541259766,
      "logps/rejected": -54.45021057128906,
      "loss": 0.6678,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.026320315897464752,
      "rewards/margins": 0.05162949860095978,
      "rewards/rejected": -0.025309182703495026,
      "step": 452
    },
    {
      "epoch": 34.88,
      "grad_norm": 6.950564384460449,
      "learning_rate": 3.142857142857143e-08,
      "logits/chosen": 1.4537408351898193,
      "logits/rejected": 1.2999320030212402,
      "logps/chosen": -33.43877410888672,
      "logps/rejected": -51.673011779785156,
      "loss": 0.6639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02871672995388508,
      "rewards/margins": 0.05954106152057648,
      "rewards/rejected": -0.03082432597875595,
      "step": 453
    },
    {
      "epoch": 34.96,
      "grad_norm": 7.64746618270874,
      "learning_rate": 3.126984126984127e-08,
      "logits/chosen": 1.2742501497268677,
      "logits/rejected": 1.141770362854004,
      "logps/chosen": -33.35884475708008,
      "logps/rejected": -52.13706970214844,
      "loss": 0.673,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012056684121489525,
      "rewards/margins": 0.04089469835162163,
      "rewards/rejected": -0.028838014230132103,
      "step": 454
    },
    {
      "epoch": 35.0,
      "grad_norm": 9.905311584472656,
      "learning_rate": 3.111111111111111e-08,
      "logits/chosen": 1.4634804725646973,
      "logits/rejected": 1.4534233808517456,
      "logps/chosen": -27.199329376220703,
      "logps/rejected": -46.031166076660156,
      "loss": 0.6652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04000148922204971,
      "rewards/margins": 0.05677499622106552,
      "rewards/rejected": -0.016773510724306107,
      "step": 455
    },
    {
      "epoch": 35.0,
      "eval_logits/chosen": 1.3129202127456665,
      "eval_logits/rejected": 1.204656720161438,
      "eval_logps/chosen": -34.317413330078125,
      "eval_logps/rejected": -47.060035705566406,
      "eval_loss": 0.6812382340431213,
      "eval_rewards/accuracies": 0.8500000238418579,
      "eval_rewards/chosen": 0.018210208043456078,
      "eval_rewards/margins": 0.024094827473163605,
      "eval_rewards/rejected": -0.005884620361030102,
      "eval_runtime": 2.7381,
      "eval_samples_per_second": 36.522,
      "eval_steps_per_second": 18.261,
      "step": 455
    },
    {
      "epoch": 35.08,
      "grad_norm": 6.986245155334473,
      "learning_rate": 3.095238095238095e-08,
      "logits/chosen": 1.3191442489624023,
      "logits/rejected": 1.4492924213409424,
      "logps/chosen": -41.97180938720703,
      "logps/rejected": -62.20384979248047,
      "loss": 0.6757,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.007522296626120806,
      "rewards/margins": 0.03533124923706055,
      "rewards/rejected": -0.02780895307660103,
      "step": 456
    },
    {
      "epoch": 35.16,
      "grad_norm": 6.716361999511719,
      "learning_rate": 3.079365079365079e-08,
      "logits/chosen": 1.345574140548706,
      "logits/rejected": 1.245510220527649,
      "logps/chosen": -31.86522674560547,
      "logps/rejected": -47.57400894165039,
      "loss": 0.672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021018149331212044,
      "rewards/margins": 0.0429280549287796,
      "rewards/rejected": -0.02190990559756756,
      "step": 457
    },
    {
      "epoch": 35.24,
      "grad_norm": 8.08052921295166,
      "learning_rate": 3.0634920634920634e-08,
      "logits/chosen": 1.3349894285202026,
      "logits/rejected": 1.1570806503295898,
      "logps/chosen": -36.66511535644531,
      "logps/rejected": -61.38526916503906,
      "loss": 0.6655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014040090143680573,
      "rewards/margins": 0.056290674954652786,
      "rewards/rejected": -0.04225058853626251,
      "step": 458
    },
    {
      "epoch": 35.32,
      "grad_norm": 8.668148040771484,
      "learning_rate": 3.047619047619048e-08,
      "logits/chosen": 1.4721213579177856,
      "logits/rejected": 1.2798280715942383,
      "logps/chosen": -33.47821044921875,
      "logps/rejected": -54.637794494628906,
      "loss": 0.664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021324824541807175,
      "rewards/margins": 0.05919136852025986,
      "rewards/rejected": -0.03786654397845268,
      "step": 459
    },
    {
      "epoch": 35.4,
      "grad_norm": 8.357986450195312,
      "learning_rate": 3.031746031746031e-08,
      "logits/chosen": 1.3935749530792236,
      "logits/rejected": 1.1419638395309448,
      "logps/chosen": -32.61894989013672,
      "logps/rejected": -53.235443115234375,
      "loss": 0.6623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02307281456887722,
      "rewards/margins": 0.06300453841686249,
      "rewards/rejected": -0.039931729435920715,
      "step": 460
    },
    {
      "epoch": 35.48,
      "grad_norm": 7.488224029541016,
      "learning_rate": 3.0158730158730155e-08,
      "logits/chosen": 1.2591034173965454,
      "logits/rejected": 1.1229478120803833,
      "logps/chosen": -32.90925598144531,
      "logps/rejected": -51.49504470825195,
      "loss": 0.6729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01626770570874214,
      "rewards/margins": 0.041161179542541504,
      "rewards/rejected": -0.024893473833799362,
      "step": 461
    },
    {
      "epoch": 35.56,
      "grad_norm": 7.161564826965332,
      "learning_rate": 3e-08,
      "logits/chosen": 1.2677193880081177,
      "logits/rejected": 1.2342630624771118,
      "logps/chosen": -34.713478088378906,
      "logps/rejected": -50.48540496826172,
      "loss": 0.6717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009980964474380016,
      "rewards/margins": 0.04351920634508133,
      "rewards/rejected": -0.03353824466466904,
      "step": 462
    },
    {
      "epoch": 35.64,
      "grad_norm": 7.880445957183838,
      "learning_rate": 2.984126984126984e-08,
      "logits/chosen": 1.27773118019104,
      "logits/rejected": 1.1812326908111572,
      "logps/chosen": -32.42955780029297,
      "logps/rejected": -58.47216796875,
      "loss": 0.6626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02167060226202011,
      "rewards/margins": 0.06271326541900635,
      "rewards/rejected": -0.04104266315698624,
      "step": 463
    },
    {
      "epoch": 35.72,
      "grad_norm": 7.232729434967041,
      "learning_rate": 2.9682539682539682e-08,
      "logits/chosen": 1.1586463451385498,
      "logits/rejected": 1.2249407768249512,
      "logps/chosen": -33.77111053466797,
      "logps/rejected": -58.24184036254883,
      "loss": 0.6644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01579568348824978,
      "rewards/margins": 0.05839845910668373,
      "rewards/rejected": -0.0426027774810791,
      "step": 464
    },
    {
      "epoch": 35.8,
      "grad_norm": 7.509264945983887,
      "learning_rate": 2.9523809523809524e-08,
      "logits/chosen": 1.3515357971191406,
      "logits/rejected": 1.3114571571350098,
      "logps/chosen": -32.107269287109375,
      "logps/rejected": -54.099029541015625,
      "loss": 0.6681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019405316561460495,
      "rewards/margins": 0.05087637901306152,
      "rewards/rejected": -0.03147106245160103,
      "step": 465
    },
    {
      "epoch": 35.88,
      "grad_norm": 7.375650882720947,
      "learning_rate": 2.9365079365079363e-08,
      "logits/chosen": 1.199765682220459,
      "logits/rejected": 1.3345015048980713,
      "logps/chosen": -34.383792877197266,
      "logps/rejected": -62.97307586669922,
      "loss": 0.6666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021057676523923874,
      "rewards/margins": 0.05391871929168701,
      "rewards/rejected": -0.03286104276776314,
      "step": 466
    },
    {
      "epoch": 35.96,
      "grad_norm": 8.00654125213623,
      "learning_rate": 2.9206349206349206e-08,
      "logits/chosen": 1.3465501070022583,
      "logits/rejected": 1.6736018657684326,
      "logps/chosen": -32.46733856201172,
      "logps/rejected": -52.559288024902344,
      "loss": 0.673,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.018375517800450325,
      "rewards/margins": 0.04102366045117378,
      "rewards/rejected": -0.022648142650723457,
      "step": 467
    },
    {
      "epoch": 36.0,
      "grad_norm": 10.333760261535645,
      "learning_rate": 2.9047619047619048e-08,
      "logits/chosen": 1.3836477994918823,
      "logits/rejected": 1.0703186988830566,
      "logps/chosen": -32.185951232910156,
      "logps/rejected": -44.737220764160156,
      "loss": 0.6667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026271868497133255,
      "rewards/margins": 0.05374865606427193,
      "rewards/rejected": -0.027476787567138672,
      "step": 468
    },
    {
      "epoch": 36.0,
      "eval_logits/chosen": 1.3112541437149048,
      "eval_logits/rejected": 1.2028241157531738,
      "eval_logps/chosen": -34.34098815917969,
      "eval_logps/rejected": -47.077335357666016,
      "eval_loss": 0.6815485954284668,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.01585245691239834,
      "eval_rewards/margins": 0.023467643186450005,
      "eval_rewards/rejected": -0.007615187671035528,
      "eval_runtime": 2.7452,
      "eval_samples_per_second": 36.428,
      "eval_steps_per_second": 18.214,
      "step": 468
    },
    {
      "epoch": 36.08,
      "grad_norm": 7.124721050262451,
      "learning_rate": 2.8888888888888884e-08,
      "logits/chosen": 1.2104871273040771,
      "logits/rejected": 1.254697322845459,
      "logps/chosen": -38.6005859375,
      "logps/rejected": -55.098388671875,
      "loss": 0.6748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.002730035688728094,
      "rewards/margins": 0.037169598042964935,
      "rewards/rejected": -0.03989963233470917,
      "step": 469
    },
    {
      "epoch": 36.16,
      "grad_norm": 8.18189525604248,
      "learning_rate": 2.8730158730158726e-08,
      "logits/chosen": 1.2509337663650513,
      "logits/rejected": 1.065449833869934,
      "logps/chosen": -31.139305114746094,
      "logps/rejected": -44.23744583129883,
      "loss": 0.6687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012804055586457253,
      "rewards/margins": 0.04965818300843239,
      "rewards/rejected": -0.03685412555932999,
      "step": 470
    },
    {
      "epoch": 36.24,
      "grad_norm": 8.948390007019043,
      "learning_rate": 2.857142857142857e-08,
      "logits/chosen": 1.1976195573806763,
      "logits/rejected": 1.0335243940353394,
      "logps/chosen": -29.04488182067871,
      "logps/rejected": -54.23561096191406,
      "loss": 0.6674,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.024082159623503685,
      "rewards/margins": 0.05251772329211235,
      "rewards/rejected": -0.028435565531253815,
      "step": 471
    },
    {
      "epoch": 36.32,
      "grad_norm": 6.826013565063477,
      "learning_rate": 2.841269841269841e-08,
      "logits/chosen": 1.1956632137298584,
      "logits/rejected": 1.1097034215927124,
      "logps/chosen": -34.78199768066406,
      "logps/rejected": -49.40433120727539,
      "loss": 0.6689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018260931596159935,
      "rewards/margins": 0.04937656223773956,
      "rewards/rejected": -0.03111562877893448,
      "step": 472
    },
    {
      "epoch": 36.4,
      "grad_norm": 8.157906532287598,
      "learning_rate": 2.8253968253968253e-08,
      "logits/chosen": 1.469719648361206,
      "logits/rejected": 1.128951907157898,
      "logps/chosen": -32.05405044555664,
      "logps/rejected": -61.93632125854492,
      "loss": 0.6676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02561192587018013,
      "rewards/margins": 0.0519527904689312,
      "rewards/rejected": -0.026340866461396217,
      "step": 473
    },
    {
      "epoch": 36.48,
      "grad_norm": 7.744637489318848,
      "learning_rate": 2.8095238095238093e-08,
      "logits/chosen": 1.2158130407333374,
      "logits/rejected": 1.434712290763855,
      "logps/chosen": -35.21641540527344,
      "logps/rejected": -57.775489807128906,
      "loss": 0.6693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.033315133303403854,
      "rewards/margins": 0.04842681810259819,
      "rewards/rejected": -0.015111684799194336,
      "step": 474
    },
    {
      "epoch": 36.56,
      "grad_norm": 8.050175666809082,
      "learning_rate": 2.7936507936507935e-08,
      "logits/chosen": 1.3698934316635132,
      "logits/rejected": 1.2723708152770996,
      "logps/chosen": -34.24491882324219,
      "logps/rejected": -51.584991455078125,
      "loss": 0.6665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011251425370573997,
      "rewards/margins": 0.054116420447826385,
      "rewards/rejected": -0.04286499321460724,
      "step": 475
    },
    {
      "epoch": 36.64,
      "grad_norm": 8.482917785644531,
      "learning_rate": 2.7777777777777777e-08,
      "logits/chosen": 1.2620089054107666,
      "logits/rejected": 1.3008745908737183,
      "logps/chosen": -33.87223434448242,
      "logps/rejected": -49.3338737487793,
      "loss": 0.6676,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010622000321745872,
      "rewards/margins": 0.05186903476715088,
      "rewards/rejected": -0.04124703258275986,
      "step": 476
    },
    {
      "epoch": 36.72,
      "grad_norm": 6.677375793457031,
      "learning_rate": 2.761904761904762e-08,
      "logits/chosen": 1.5837699174880981,
      "logits/rejected": 1.470211148262024,
      "logps/chosen": -37.27122497558594,
      "logps/rejected": -61.03005599975586,
      "loss": 0.6639,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023525001481175423,
      "rewards/margins": 0.059563495218753815,
      "rewards/rejected": -0.03603849560022354,
      "step": 477
    },
    {
      "epoch": 36.8,
      "grad_norm": 6.632266044616699,
      "learning_rate": 2.7460317460317462e-08,
      "logits/chosen": 1.236547589302063,
      "logits/rejected": 1.257065773010254,
      "logps/chosen": -30.565887451171875,
      "logps/rejected": -52.99717330932617,
      "loss": 0.6763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018748141825199127,
      "rewards/margins": 0.034123800694942474,
      "rewards/rejected": -0.015375661663711071,
      "step": 478
    },
    {
      "epoch": 36.88,
      "grad_norm": 7.9352922439575195,
      "learning_rate": 2.7301587301587298e-08,
      "logits/chosen": 1.3141998052597046,
      "logits/rejected": 1.3652666807174683,
      "logps/chosen": -33.56006622314453,
      "logps/rejected": -57.61106491088867,
      "loss": 0.6702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014695549383759499,
      "rewards/margins": 0.046538397669792175,
      "rewards/rejected": -0.031842850148677826,
      "step": 479
    },
    {
      "epoch": 36.96,
      "grad_norm": 6.742045879364014,
      "learning_rate": 2.714285714285714e-08,
      "logits/chosen": 1.4187489748001099,
      "logits/rejected": 1.4985500574111938,
      "logps/chosen": -34.3148193359375,
      "logps/rejected": -64.1096420288086,
      "loss": 0.6686,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014976335689425468,
      "rewards/margins": 0.050116442143917084,
      "rewards/rejected": -0.035140108317136765,
      "step": 480
    },
    {
      "epoch": 37.0,
      "grad_norm": 11.759425163269043,
      "learning_rate": 2.6984126984126982e-08,
      "logits/chosen": 1.3454515933990479,
      "logits/rejected": 1.227341890335083,
      "logps/chosen": -41.58617401123047,
      "logps/rejected": -60.181800842285156,
      "loss": 0.6651,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016064977273344994,
      "rewards/margins": 0.05701594799757004,
      "rewards/rejected": -0.0409509651362896,
      "step": 481
    },
    {
      "epoch": 37.0,
      "eval_logits/chosen": 1.3137791156768799,
      "eval_logits/rejected": 1.2061524391174316,
      "eval_logps/chosen": -34.33562469482422,
      "eval_logps/rejected": -47.059383392333984,
      "eval_loss": 0.6821702718734741,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.01638912409543991,
      "eval_rewards/margins": 0.022208798676729202,
      "eval_rewards/rejected": -0.005819672718644142,
      "eval_runtime": 2.7385,
      "eval_samples_per_second": 36.517,
      "eval_steps_per_second": 18.258,
      "step": 481
    },
    {
      "epoch": 37.08,
      "grad_norm": 6.949084758758545,
      "learning_rate": 2.6825396825396825e-08,
      "logits/chosen": 1.4166852235794067,
      "logits/rejected": 1.4225409030914307,
      "logps/chosen": -34.72080993652344,
      "logps/rejected": -57.54736328125,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03330416604876518,
      "rewards/margins": 0.05662508308887482,
      "rewards/rejected": -0.023320913314819336,
      "step": 482
    },
    {
      "epoch": 37.16,
      "grad_norm": 7.574038505554199,
      "learning_rate": 2.6666666666666664e-08,
      "logits/chosen": 1.2388145923614502,
      "logits/rejected": 1.2098050117492676,
      "logps/chosen": -35.11428451538086,
      "logps/rejected": -53.105735778808594,
      "loss": 0.6705,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.017406940460205078,
      "rewards/margins": 0.04599723964929581,
      "rewards/rejected": -0.02859029918909073,
      "step": 483
    },
    {
      "epoch": 37.24,
      "grad_norm": 8.531033515930176,
      "learning_rate": 2.6507936507936506e-08,
      "logits/chosen": 1.1353763341903687,
      "logits/rejected": 1.220870018005371,
      "logps/chosen": -33.786346435546875,
      "logps/rejected": -59.44420623779297,
      "loss": 0.6629,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020039081573486328,
      "rewards/margins": 0.0621856227517128,
      "rewards/rejected": -0.04214654117822647,
      "step": 484
    },
    {
      "epoch": 37.32,
      "grad_norm": 8.638345718383789,
      "learning_rate": 2.634920634920635e-08,
      "logits/chosen": 1.2901403903961182,
      "logits/rejected": 1.4065850973129272,
      "logps/chosen": -31.268978118896484,
      "logps/rejected": -54.45625305175781,
      "loss": 0.6731,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.019628001376986504,
      "rewards/margins": 0.04094080999493599,
      "rewards/rejected": -0.021312808617949486,
      "step": 485
    },
    {
      "epoch": 37.4,
      "grad_norm": 6.6536784172058105,
      "learning_rate": 2.619047619047619e-08,
      "logits/chosen": 1.4180340766906738,
      "logits/rejected": 1.4974972009658813,
      "logps/chosen": -34.181968688964844,
      "logps/rejected": -52.92531967163086,
      "loss": 0.6707,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02270696312189102,
      "rewards/margins": 0.04578816890716553,
      "rewards/rejected": -0.023081209510564804,
      "step": 486
    },
    {
      "epoch": 37.48,
      "grad_norm": 7.7684173583984375,
      "learning_rate": 2.6031746031746033e-08,
      "logits/chosen": 1.179222822189331,
      "logits/rejected": 1.2518075704574585,
      "logps/chosen": -33.60582733154297,
      "logps/rejected": -53.902259826660156,
      "loss": 0.6677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009803986176848412,
      "rewards/margins": 0.05155942589044571,
      "rewards/rejected": -0.04175543785095215,
      "step": 487
    },
    {
      "epoch": 37.56,
      "grad_norm": 7.387866497039795,
      "learning_rate": 2.5873015873015876e-08,
      "logits/chosen": 1.3361918926239014,
      "logits/rejected": 1.2810969352722168,
      "logps/chosen": -34.91489791870117,
      "logps/rejected": -63.43867874145508,
      "loss": 0.6702,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.022307371720671654,
      "rewards/margins": 0.04672267660498619,
      "rewards/rejected": -0.024415303021669388,
      "step": 488
    },
    {
      "epoch": 37.64,
      "grad_norm": 8.114768028259277,
      "learning_rate": 2.571428571428571e-08,
      "logits/chosen": 1.3269656896591187,
      "logits/rejected": 1.0663646459579468,
      "logps/chosen": -31.65770149230957,
      "logps/rejected": -60.00477981567383,
      "loss": 0.6645,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.026895929127931595,
      "rewards/margins": 0.05843279883265495,
      "rewards/rejected": -0.03153686597943306,
      "step": 489
    },
    {
      "epoch": 37.72,
      "grad_norm": 8.430771827697754,
      "learning_rate": 2.5555555555555554e-08,
      "logits/chosen": 1.160313606262207,
      "logits/rejected": 1.1328072547912598,
      "logps/chosen": -35.639434814453125,
      "logps/rejected": -60.57509231567383,
      "loss": 0.6605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02063431777060032,
      "rewards/margins": 0.06649580597877502,
      "rewards/rejected": -0.04586148262023926,
      "step": 490
    },
    {
      "epoch": 37.8,
      "grad_norm": 7.691536903381348,
      "learning_rate": 2.5396825396825393e-08,
      "logits/chosen": 1.4154642820358276,
      "logits/rejected": 1.2219212055206299,
      "logps/chosen": -32.554786682128906,
      "logps/rejected": -54.605186462402344,
      "loss": 0.6742,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.012011909857392311,
      "rewards/margins": 0.03838658332824707,
      "rewards/rejected": -0.02637467347085476,
      "step": 491
    },
    {
      "epoch": 37.88,
      "grad_norm": 6.884189128875732,
      "learning_rate": 2.5238095238095235e-08,
      "logits/chosen": 1.1071865558624268,
      "logits/rejected": 1.175279140472412,
      "logps/chosen": -32.45613479614258,
      "logps/rejected": -52.01643371582031,
      "loss": 0.6696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0031427147332578897,
      "rewards/margins": 0.04783833026885986,
      "rewards/rejected": -0.04469561204314232,
      "step": 492
    },
    {
      "epoch": 37.96,
      "grad_norm": 6.917513370513916,
      "learning_rate": 2.5079365079365078e-08,
      "logits/chosen": 1.3586781024932861,
      "logits/rejected": 1.292445421218872,
      "logps/chosen": -38.44862365722656,
      "logps/rejected": -47.045440673828125,
      "loss": 0.6692,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01213381253182888,
      "rewards/margins": 0.048775602132081985,
      "rewards/rejected": -0.036641787737607956,
      "step": 493
    },
    {
      "epoch": 38.0,
      "grad_norm": 8.653748512268066,
      "learning_rate": 2.492063492063492e-08,
      "logits/chosen": 1.6871328353881836,
      "logits/rejected": 1.2786535024642944,
      "logps/chosen": -34.15046691894531,
      "logps/rejected": -41.21589660644531,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028377246111631393,
      "rewards/margins": 0.05632772669196129,
      "rewards/rejected": -0.027950476855039597,
      "step": 494
    },
    {
      "epoch": 38.0,
      "eval_logits/chosen": 1.3105435371398926,
      "eval_logits/rejected": 1.2032196521759033,
      "eval_logps/chosen": -34.350624084472656,
      "eval_logps/rejected": -47.113468170166016,
      "eval_loss": 0.6802551746368408,
      "eval_rewards/accuracies": 0.800000011920929,
      "eval_rewards/chosen": 0.014889192767441273,
      "eval_rewards/margins": 0.026116900146007538,
      "eval_rewards/rejected": -0.01122770830988884,
      "eval_runtime": 2.74,
      "eval_samples_per_second": 36.497,
      "eval_steps_per_second": 18.248,
      "step": 494
    },
    {
      "epoch": 38.08,
      "grad_norm": 8.234865188598633,
      "learning_rate": 2.4761904761904762e-08,
      "logits/chosen": 1.622502088546753,
      "logits/rejected": 1.288867712020874,
      "logps/chosen": -42.514015197753906,
      "logps/rejected": -56.571006774902344,
      "loss": 0.667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014256883412599564,
      "rewards/margins": 0.053245190531015396,
      "rewards/rejected": -0.038988303393125534,
      "step": 495
    },
    {
      "epoch": 38.16,
      "grad_norm": 7.7793803215026855,
      "learning_rate": 2.46031746031746e-08,
      "logits/chosen": 1.1589410305023193,
      "logits/rejected": 1.3548318147659302,
      "logps/chosen": -37.199134826660156,
      "logps/rejected": -57.99726104736328,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0013038875767961144,
      "rewards/margins": 0.03375227376818657,
      "rewards/rejected": -0.035056162625551224,
      "step": 496
    },
    {
      "epoch": 38.24,
      "grad_norm": 7.058011531829834,
      "learning_rate": 2.4444444444444444e-08,
      "logits/chosen": 1.3607264757156372,
      "logits/rejected": 1.1885547637939453,
      "logps/chosen": -32.71746063232422,
      "logps/rejected": -46.68580627441406,
      "loss": 0.6672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010305618867278099,
      "rewards/margins": 0.05274679511785507,
      "rewards/rejected": -0.042441174387931824,
      "step": 497
    },
    {
      "epoch": 38.32,
      "grad_norm": 6.822643756866455,
      "learning_rate": 2.4285714285714283e-08,
      "logits/chosen": 1.179891586303711,
      "logits/rejected": 0.9714660048484802,
      "logps/chosen": -31.71924591064453,
      "logps/rejected": -51.804168701171875,
      "loss": 0.6636,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022306563332676888,
      "rewards/margins": 0.060068681836128235,
      "rewards/rejected": -0.0377621166408062,
      "step": 498
    },
    {
      "epoch": 38.4,
      "grad_norm": 8.979275703430176,
      "learning_rate": 2.4126984126984125e-08,
      "logits/chosen": 1.0194838047027588,
      "logits/rejected": 1.2373390197753906,
      "logps/chosen": -30.497411727905273,
      "logps/rejected": -50.175315856933594,
      "loss": 0.6655,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.028364159166812897,
      "rewards/margins": 0.05641987919807434,
      "rewards/rejected": -0.028055718168616295,
      "step": 499
    },
    {
      "epoch": 38.48,
      "grad_norm": 7.595550060272217,
      "learning_rate": 2.3968253968253968e-08,
      "logits/chosen": 1.4199037551879883,
      "logits/rejected": 1.254797339439392,
      "logps/chosen": -31.189857482910156,
      "logps/rejected": -56.30426788330078,
      "loss": 0.6627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021991325542330742,
      "rewards/margins": 0.061936646699905396,
      "rewards/rejected": -0.039945319294929504,
      "step": 500
    },
    {
      "epoch": 38.56,
      "grad_norm": 7.013937473297119,
      "learning_rate": 2.3809523809523807e-08,
      "logits/chosen": 1.1974155902862549,
      "logits/rejected": 1.4494526386260986,
      "logps/chosen": -32.19476318359375,
      "logps/rejected": -56.963172912597656,
      "loss": 0.6687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013573383912444115,
      "rewards/margins": 0.04966242238879204,
      "rewards/rejected": -0.03608904406428337,
      "step": 501
    },
    {
      "epoch": 38.64,
      "grad_norm": 7.682193756103516,
      "learning_rate": 2.365079365079365e-08,
      "logits/chosen": 1.5906219482421875,
      "logits/rejected": 1.3926570415496826,
      "logps/chosen": -32.60905456542969,
      "logps/rejected": -54.8104362487793,
      "loss": 0.6656,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014149927534162998,
      "rewards/margins": 0.0561261922121048,
      "rewards/rejected": -0.041976261883974075,
      "step": 502
    },
    {
      "epoch": 38.72,
      "grad_norm": 8.618107795715332,
      "learning_rate": 2.349206349206349e-08,
      "logits/chosen": 1.212303638458252,
      "logits/rejected": 1.1730501651763916,
      "logps/chosen": -31.500438690185547,
      "logps/rejected": -64.90733337402344,
      "loss": 0.6571,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02167649380862713,
      "rewards/margins": 0.07411250472068787,
      "rewards/rejected": -0.05243602395057678,
      "step": 503
    },
    {
      "epoch": 38.8,
      "grad_norm": 7.1416449546813965,
      "learning_rate": 2.3333333333333334e-08,
      "logits/chosen": 1.3259942531585693,
      "logits/rejected": 1.3173094987869263,
      "logps/chosen": -35.05219650268555,
      "logps/rejected": -51.118873596191406,
      "loss": 0.6649,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017429281026124954,
      "rewards/margins": 0.05750753730535507,
      "rewards/rejected": -0.040078260004520416,
      "step": 504
    },
    {
      "epoch": 38.88,
      "grad_norm": 7.518530368804932,
      "learning_rate": 2.3174603174603173e-08,
      "logits/chosen": 1.2873820066452026,
      "logits/rejected": 1.374449610710144,
      "logps/chosen": -39.37558364868164,
      "logps/rejected": -64.51753234863281,
      "loss": 0.6778,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.006327343173325062,
      "rewards/margins": 0.031220676377415657,
      "rewards/rejected": -0.02489333227276802,
      "step": 505
    },
    {
      "epoch": 38.96,
      "grad_norm": 7.370420455932617,
      "learning_rate": 2.3015873015873012e-08,
      "logits/chosen": 1.247984766960144,
      "logits/rejected": 1.0571790933609009,
      "logps/chosen": -33.80860137939453,
      "logps/rejected": -49.3740119934082,
      "loss": 0.6658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027112985029816628,
      "rewards/margins": 0.05568487569689751,
      "rewards/rejected": -0.02857189252972603,
      "step": 506
    },
    {
      "epoch": 39.0,
      "grad_norm": 8.74307632446289,
      "learning_rate": 2.2857142857142854e-08,
      "logits/chosen": 1.3717434406280518,
      "logits/rejected": 1.3638445138931274,
      "logps/chosen": -30.53512191772461,
      "logps/rejected": -57.66724395751953,
      "loss": 0.6833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011128759011626244,
      "rewards/margins": 0.019724130630493164,
      "rewards/rejected": -0.00859537161886692,
      "step": 507
    },
    {
      "epoch": 39.0,
      "eval_logits/chosen": 1.3102344274520874,
      "eval_logits/rejected": 1.2035433053970337,
      "eval_logps/chosen": -34.36457824707031,
      "eval_logps/rejected": -47.120792388916016,
      "eval_loss": 0.6805935502052307,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.013493554666638374,
      "eval_rewards/margins": 0.025453897193074226,
      "eval_rewards/rejected": -0.011960341595113277,
      "eval_runtime": 2.7401,
      "eval_samples_per_second": 36.494,
      "eval_steps_per_second": 18.247,
      "step": 507
    },
    {
      "epoch": 39.08,
      "grad_norm": 7.060155868530273,
      "learning_rate": 2.2698412698412697e-08,
      "logits/chosen": 1.3672016859054565,
      "logits/rejected": 1.3544853925704956,
      "logps/chosen": -36.81601333618164,
      "logps/rejected": -49.56494903564453,
      "loss": 0.6731,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014855647459626198,
      "rewards/margins": 0.04068415239453316,
      "rewards/rejected": -0.02582850307226181,
      "step": 508
    },
    {
      "epoch": 39.16,
      "grad_norm": 7.589931488037109,
      "learning_rate": 2.253968253968254e-08,
      "logits/chosen": 1.398071050643921,
      "logits/rejected": 1.1967960596084595,
      "logps/chosen": -37.44353485107422,
      "logps/rejected": -58.24568557739258,
      "loss": 0.677,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.015591860748827457,
      "rewards/margins": 0.032819654792547226,
      "rewards/rejected": -0.017227793112397194,
      "step": 509
    },
    {
      "epoch": 39.24,
      "grad_norm": 7.423515796661377,
      "learning_rate": 2.238095238095238e-08,
      "logits/chosen": 1.4485752582550049,
      "logits/rejected": 1.2218108177185059,
      "logps/chosen": -30.064380645751953,
      "logps/rejected": -52.72199630737305,
      "loss": 0.666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01233687438070774,
      "rewards/margins": 0.05509686470031738,
      "rewards/rejected": -0.04275999218225479,
      "step": 510
    },
    {
      "epoch": 39.32,
      "grad_norm": 7.047268867492676,
      "learning_rate": 2.222222222222222e-08,
      "logits/chosen": 1.0129480361938477,
      "logits/rejected": 1.0335174798965454,
      "logps/chosen": -31.651098251342773,
      "logps/rejected": -53.797950744628906,
      "loss": 0.6702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.013690616004168987,
      "rewards/margins": 0.04666643589735031,
      "rewards/rejected": -0.03297581523656845,
      "step": 511
    },
    {
      "epoch": 39.4,
      "grad_norm": 8.017868995666504,
      "learning_rate": 2.2063492063492063e-08,
      "logits/chosen": 1.2319157123565674,
      "logits/rejected": 1.415984869003296,
      "logps/chosen": -30.484851837158203,
      "logps/rejected": -52.76054382324219,
      "loss": 0.6681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.025649499148130417,
      "rewards/margins": 0.051009416580200195,
      "rewards/rejected": -0.02535991743206978,
      "step": 512
    },
    {
      "epoch": 39.48,
      "grad_norm": 8.012622833251953,
      "learning_rate": 2.1904761904761905e-08,
      "logits/chosen": 1.506862998008728,
      "logits/rejected": 1.2437282800674438,
      "logps/chosen": -30.157094955444336,
      "logps/rejected": -48.232261657714844,
      "loss": 0.6578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0348326712846756,
      "rewards/margins": 0.07211265712976456,
      "rewards/rejected": -0.03727998957037926,
      "step": 513
    },
    {
      "epoch": 39.56,
      "grad_norm": 7.2386088371276855,
      "learning_rate": 2.1746031746031744e-08,
      "logits/chosen": 1.4890682697296143,
      "logits/rejected": 1.1785956621170044,
      "logps/chosen": -33.948822021484375,
      "logps/rejected": -46.91767883300781,
      "loss": 0.6597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022069787606596947,
      "rewards/margins": 0.06820778548717499,
      "rewards/rejected": -0.04613800346851349,
      "step": 514
    },
    {
      "epoch": 39.64,
      "grad_norm": 7.602634429931641,
      "learning_rate": 2.1587301587301587e-08,
      "logits/chosen": 1.004936933517456,
      "logits/rejected": 1.3865325450897217,
      "logps/chosen": -35.3886604309082,
      "logps/rejected": -59.50959014892578,
      "loss": 0.6671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029925847426056862,
      "rewards/margins": 0.052916597574949265,
      "rewards/rejected": -0.022990752011537552,
      "step": 515
    },
    {
      "epoch": 39.72,
      "grad_norm": 7.119951248168945,
      "learning_rate": 2.1428571428571426e-08,
      "logits/chosen": 1.2855592966079712,
      "logits/rejected": 1.2512203454971313,
      "logps/chosen": -33.16913604736328,
      "logps/rejected": -51.58228302001953,
      "loss": 0.6725,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.019580911844968796,
      "rewards/margins": 0.04196389019489288,
      "rewards/rejected": -0.02238297462463379,
      "step": 516
    },
    {
      "epoch": 39.8,
      "grad_norm": 7.182333469390869,
      "learning_rate": 2.1269841269841268e-08,
      "logits/chosen": 1.3187453746795654,
      "logits/rejected": 1.4424245357513428,
      "logps/chosen": -35.591793060302734,
      "logps/rejected": -62.91700744628906,
      "loss": 0.6737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02455735206604004,
      "rewards/margins": 0.03930401802062988,
      "rewards/rejected": -0.014746666885912418,
      "step": 517
    },
    {
      "epoch": 39.88,
      "grad_norm": 11.548563957214355,
      "learning_rate": 2.111111111111111e-08,
      "logits/chosen": 1.3767085075378418,
      "logits/rejected": 1.0743366479873657,
      "logps/chosen": -39.354366302490234,
      "logps/rejected": -62.121307373046875,
      "loss": 0.6547,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009183931164443493,
      "rewards/margins": 0.0789613276720047,
      "rewards/rejected": -0.06977739185094833,
      "step": 518
    },
    {
      "epoch": 39.96,
      "grad_norm": 8.170186996459961,
      "learning_rate": 2.0952380952380953e-08,
      "logits/chosen": 1.1600896120071411,
      "logits/rejected": 1.2776074409484863,
      "logps/chosen": -33.42875671386719,
      "logps/rejected": -62.37267303466797,
      "loss": 0.6619,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017757320776581764,
      "rewards/margins": 0.06387858837842941,
      "rewards/rejected": -0.0461212657392025,
      "step": 519
    },
    {
      "epoch": 40.0,
      "grad_norm": 8.033698081970215,
      "learning_rate": 2.0793650793650795e-08,
      "logits/chosen": 1.5236177444458008,
      "logits/rejected": 1.4982943534851074,
      "logps/chosen": -35.351314544677734,
      "logps/rejected": -58.0489501953125,
      "loss": 0.6707,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014310979284346104,
      "rewards/margins": 0.04555344581604004,
      "rewards/rejected": -0.03124246746301651,
      "step": 520
    },
    {
      "epoch": 40.0,
      "eval_logits/chosen": 1.3117012977600098,
      "eval_logits/rejected": 1.2044776678085327,
      "eval_logps/chosen": -34.3039665222168,
      "eval_logps/rejected": -47.07477951049805,
      "eval_loss": 0.679863452911377,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.019554588943719864,
      "eval_rewards/margins": 0.026913616806268692,
      "eval_rewards/rejected": -0.007359027862548828,
      "eval_runtime": 2.7335,
      "eval_samples_per_second": 36.584,
      "eval_steps_per_second": 18.292,
      "step": 520
    },
    {
      "epoch": 40.08,
      "grad_norm": 8.03708553314209,
      "learning_rate": 2.0634920634920634e-08,
      "logits/chosen": 1.364646077156067,
      "logits/rejected": 1.289689064025879,
      "logps/chosen": -35.03890609741211,
      "logps/rejected": -58.698890686035156,
      "loss": 0.6631,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02525189146399498,
      "rewards/margins": 0.0618087500333786,
      "rewards/rejected": -0.03655686601996422,
      "step": 521
    },
    {
      "epoch": 40.16,
      "grad_norm": 7.478936195373535,
      "learning_rate": 2.0476190476190473e-08,
      "logits/chosen": 1.5777661800384521,
      "logits/rejected": 1.3336418867111206,
      "logps/chosen": -36.88003921508789,
      "logps/rejected": -51.079864501953125,
      "loss": 0.6747,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0019164085388183594,
      "rewards/margins": 0.03747763857245445,
      "rewards/rejected": -0.03556123003363609,
      "step": 522
    },
    {
      "epoch": 40.24,
      "grad_norm": 7.086171627044678,
      "learning_rate": 2.0317460317460316e-08,
      "logits/chosen": 1.2336385250091553,
      "logits/rejected": 1.3318191766738892,
      "logps/chosen": -33.42576217651367,
      "logps/rejected": -63.35859298706055,
      "loss": 0.6696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01748502254486084,
      "rewards/margins": 0.04762613773345947,
      "rewards/rejected": -0.030141115188598633,
      "step": 523
    },
    {
      "epoch": 40.32,
      "grad_norm": 8.234684944152832,
      "learning_rate": 2.0158730158730158e-08,
      "logits/chosen": 1.0376032590866089,
      "logits/rejected": 1.1594572067260742,
      "logps/chosen": -32.30574035644531,
      "logps/rejected": -57.61882019042969,
      "loss": 0.6657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015203524380922318,
      "rewards/margins": 0.055728767067193985,
      "rewards/rejected": -0.040525246411561966,
      "step": 524
    },
    {
      "epoch": 40.4,
      "grad_norm": 7.348629474639893,
      "learning_rate": 2e-08,
      "logits/chosen": 1.3980640172958374,
      "logits/rejected": 1.261973261833191,
      "logps/chosen": -36.702518463134766,
      "logps/rejected": -48.70622634887695,
      "loss": 0.6787,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.018605709075927734,
      "rewards/margins": 0.029268836602568626,
      "rewards/rejected": -0.010663128457963467,
      "step": 525
    },
    {
      "epoch": 40.48,
      "grad_norm": 7.681241035461426,
      "learning_rate": 1.984126984126984e-08,
      "logits/chosen": 1.3897442817687988,
      "logits/rejected": 1.3385469913482666,
      "logps/chosen": -39.82041931152344,
      "logps/rejected": -64.94450378417969,
      "loss": 0.6709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010246324352920055,
      "rewards/margins": 0.04517979547381401,
      "rewards/rejected": -0.03493347018957138,
      "step": 526
    },
    {
      "epoch": 40.56,
      "grad_norm": 7.5622735023498535,
      "learning_rate": 1.9682539682539682e-08,
      "logits/chosen": 1.2273337841033936,
      "logits/rejected": 1.1954245567321777,
      "logps/chosen": -29.65106964111328,
      "logps/rejected": -51.20531463623047,
      "loss": 0.6616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021863270550966263,
      "rewards/margins": 0.06441827118396759,
      "rewards/rejected": -0.04255499690771103,
      "step": 527
    },
    {
      "epoch": 40.64,
      "grad_norm": 7.957828044891357,
      "learning_rate": 1.9523809523809524e-08,
      "logits/chosen": 1.2968671321868896,
      "logits/rejected": 1.3171316385269165,
      "logps/chosen": -32.328819274902344,
      "logps/rejected": -59.476234436035156,
      "loss": 0.6571,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02390735223889351,
      "rewards/margins": 0.07367189228534698,
      "rewards/rejected": -0.04976453632116318,
      "step": 528
    },
    {
      "epoch": 40.72,
      "grad_norm": 7.664337635040283,
      "learning_rate": 1.9365079365079363e-08,
      "logits/chosen": 1.353139042854309,
      "logits/rejected": 1.1889904737472534,
      "logps/chosen": -36.290016174316406,
      "logps/rejected": -51.108009338378906,
      "loss": 0.6693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014696909114718437,
      "rewards/margins": 0.048691440373659134,
      "rewards/rejected": -0.033994533121585846,
      "step": 529
    },
    {
      "epoch": 40.8,
      "grad_norm": 8.26128101348877,
      "learning_rate": 1.9206349206349206e-08,
      "logits/chosen": 1.2200343608856201,
      "logits/rejected": 1.2372965812683105,
      "logps/chosen": -29.95836639404297,
      "logps/rejected": -53.12646484375,
      "loss": 0.6651,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015915393829345703,
      "rewards/margins": 0.05708136409521103,
      "rewards/rejected": -0.041165973991155624,
      "step": 530
    },
    {
      "epoch": 40.88,
      "grad_norm": 7.403697490692139,
      "learning_rate": 1.9047619047619045e-08,
      "logits/chosen": 1.2091783285140991,
      "logits/rejected": 1.2300829887390137,
      "logps/chosen": -33.53654479980469,
      "logps/rejected": -51.79684829711914,
      "loss": 0.6684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02562537230551243,
      "rewards/margins": 0.05033593252301216,
      "rewards/rejected": -0.024710560217499733,
      "step": 531
    },
    {
      "epoch": 40.96,
      "grad_norm": 7.90093469619751,
      "learning_rate": 1.8888888888888887e-08,
      "logits/chosen": 1.3138253688812256,
      "logits/rejected": 1.3104641437530518,
      "logps/chosen": -31.44261360168457,
      "logps/rejected": -53.42430877685547,
      "loss": 0.6666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022169018164277077,
      "rewards/margins": 0.05392281711101532,
      "rewards/rejected": -0.03175380080938339,
      "step": 532
    },
    {
      "epoch": 41.0,
      "grad_norm": 9.910913467407227,
      "learning_rate": 1.873015873015873e-08,
      "logits/chosen": 1.1477237939834595,
      "logits/rejected": 1.1283438205718994,
      "logps/chosen": -36.12953186035156,
      "logps/rejected": -50.60066223144531,
      "loss": 0.676,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.010694503784179688,
      "rewards/margins": 0.034661293029785156,
      "rewards/rejected": -0.02396678924560547,
      "step": 533
    },
    {
      "epoch": 41.0,
      "eval_logits/chosen": 1.3117470741271973,
      "eval_logits/rejected": 1.2040574550628662,
      "eval_logps/chosen": -34.32304000854492,
      "eval_logps/rejected": -47.09872055053711,
      "eval_loss": 0.6796248555183411,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.017647473141551018,
      "eval_rewards/margins": 0.027400951832532883,
      "eval_rewards/rejected": -0.009753475897014141,
      "eval_runtime": 2.738,
      "eval_samples_per_second": 36.523,
      "eval_steps_per_second": 18.262,
      "step": 533
    },
    {
      "epoch": 41.08,
      "grad_norm": 7.5380659103393555,
      "learning_rate": 1.8571428571428572e-08,
      "logits/chosen": 1.3744622468948364,
      "logits/rejected": 1.3085980415344238,
      "logps/chosen": -37.5321159362793,
      "logps/rejected": -52.99485778808594,
      "loss": 0.6682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020794034004211426,
      "rewards/margins": 0.05068214237689972,
      "rewards/rejected": -0.029888106510043144,
      "step": 534
    },
    {
      "epoch": 41.16,
      "grad_norm": 7.296586036682129,
      "learning_rate": 1.8412698412698414e-08,
      "logits/chosen": 1.5090924501419067,
      "logits/rejected": 1.154224157333374,
      "logps/chosen": -31.422374725341797,
      "logps/rejected": -56.31514358520508,
      "loss": 0.6716,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008364344015717506,
      "rewards/margins": 0.043843746185302734,
      "rewards/rejected": -0.03547940403223038,
      "step": 535
    },
    {
      "epoch": 41.24,
      "grad_norm": 7.019463539123535,
      "learning_rate": 1.8253968253968253e-08,
      "logits/chosen": 1.3511652946472168,
      "logits/rejected": 1.1353778839111328,
      "logps/chosen": -31.975282669067383,
      "logps/rejected": -55.08031463623047,
      "loss": 0.6673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015782594680786133,
      "rewards/margins": 0.052550699561834335,
      "rewards/rejected": -0.036768101155757904,
      "step": 536
    },
    {
      "epoch": 41.32,
      "grad_norm": 7.534206867218018,
      "learning_rate": 1.8095238095238096e-08,
      "logits/chosen": 1.282469391822815,
      "logits/rejected": 1.3123130798339844,
      "logps/chosen": -33.697940826416016,
      "logps/rejected": -50.54511260986328,
      "loss": 0.6662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020859692245721817,
      "rewards/margins": 0.054953932762145996,
      "rewards/rejected": -0.03409424051642418,
      "step": 537
    },
    {
      "epoch": 41.4,
      "grad_norm": 8.514604568481445,
      "learning_rate": 1.7936507936507935e-08,
      "logits/chosen": 1.532733678817749,
      "logits/rejected": 1.2182954549789429,
      "logps/chosen": -34.880859375,
      "logps/rejected": -57.23463439941406,
      "loss": 0.6638,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010155749507248402,
      "rewards/margins": 0.059780195355415344,
      "rewards/rejected": -0.04962444305419922,
      "step": 538
    },
    {
      "epoch": 41.48,
      "grad_norm": 7.711457252502441,
      "learning_rate": 1.7777777777777777e-08,
      "logits/chosen": 1.2154490947723389,
      "logits/rejected": 1.1573305130004883,
      "logps/chosen": -36.614654541015625,
      "logps/rejected": -48.82936477661133,
      "loss": 0.6714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02173612266778946,
      "rewards/margins": 0.04400455951690674,
      "rewards/rejected": -0.02226843871176243,
      "step": 539
    },
    {
      "epoch": 41.56,
      "grad_norm": 7.465668201446533,
      "learning_rate": 1.761904761904762e-08,
      "logits/chosen": 1.1889315843582153,
      "logits/rejected": 1.328528642654419,
      "logps/chosen": -31.80617904663086,
      "logps/rejected": -57.543357849121094,
      "loss": 0.6648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017787553369998932,
      "rewards/margins": 0.05760250240564346,
      "rewards/rejected": -0.03981494903564453,
      "step": 540
    },
    {
      "epoch": 41.64,
      "grad_norm": 8.59281063079834,
      "learning_rate": 1.746031746031746e-08,
      "logits/chosen": 1.0497524738311768,
      "logits/rejected": 1.3603605031967163,
      "logps/chosen": -28.59978485107422,
      "logps/rejected": -55.819244384765625,
      "loss": 0.6603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03426926210522652,
      "rewards/margins": 0.06693156063556671,
      "rewards/rejected": -0.032662298530340195,
      "step": 541
    },
    {
      "epoch": 41.72,
      "grad_norm": 8.22222900390625,
      "learning_rate": 1.73015873015873e-08,
      "logits/chosen": 1.4879461526870728,
      "logits/rejected": 1.2587958574295044,
      "logps/chosen": -38.68415069580078,
      "logps/rejected": -56.91594314575195,
      "loss": 0.6588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02379138395190239,
      "rewards/margins": 0.07019493728876114,
      "rewards/rejected": -0.04640354961156845,
      "step": 542
    },
    {
      "epoch": 41.8,
      "grad_norm": 6.244041442871094,
      "learning_rate": 1.7142857142857143e-08,
      "logits/chosen": 1.2634276151657104,
      "logits/rejected": 1.2899441719055176,
      "logps/chosen": -35.827064514160156,
      "logps/rejected": -52.946659088134766,
      "loss": 0.6765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015497398562729359,
      "rewards/margins": 0.03357953950762749,
      "rewards/rejected": -0.018082141876220703,
      "step": 543
    },
    {
      "epoch": 41.88,
      "grad_norm": 9.423896789550781,
      "learning_rate": 1.6984126984126986e-08,
      "logits/chosen": 1.2193799018859863,
      "logits/rejected": 1.1167502403259277,
      "logps/chosen": -31.446170806884766,
      "logps/rejected": -58.18144989013672,
      "loss": 0.668,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.017295312136411667,
      "rewards/margins": 0.051291849464178085,
      "rewards/rejected": -0.03399653732776642,
      "step": 544
    },
    {
      "epoch": 41.96,
      "grad_norm": 6.793395042419434,
      "learning_rate": 1.6825396825396825e-08,
      "logits/chosen": 1.256441354751587,
      "logits/rejected": 1.4134379625320435,
      "logps/chosen": -34.105838775634766,
      "logps/rejected": -57.452354431152344,
      "loss": 0.6709,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01857943646609783,
      "rewards/margins": 0.04524991661310196,
      "rewards/rejected": -0.02667047828435898,
      "step": 545
    },
    {
      "epoch": 42.0,
      "grad_norm": 9.199718475341797,
      "learning_rate": 1.6666666666666664e-08,
      "logits/chosen": 1.134975552558899,
      "logits/rejected": 1.4468799829483032,
      "logps/chosen": -37.76205825805664,
      "logps/rejected": -60.116851806640625,
      "loss": 0.6807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.000329398550093174,
      "rewards/margins": 0.025139236822724342,
      "rewards/rejected": -0.02546863630414009,
      "step": 546
    },
    {
      "epoch": 42.0,
      "eval_logits/chosen": 1.3119590282440186,
      "eval_logits/rejected": 1.204301118850708,
      "eval_logps/chosen": -34.339500427246094,
      "eval_logps/rejected": -47.118255615234375,
      "eval_loss": 0.6794678568840027,
      "eval_rewards/accuracies": 0.8899999856948853,
      "eval_rewards/chosen": 0.016001522541046143,
      "eval_rewards/margins": 0.027708496898412704,
      "eval_rewards/rejected": -0.011706974357366562,
      "eval_runtime": 2.7354,
      "eval_samples_per_second": 36.558,
      "eval_steps_per_second": 18.279,
      "step": 546
    },
    {
      "epoch": 42.08,
      "grad_norm": 8.052242279052734,
      "learning_rate": 1.6507936507936506e-08,
      "logits/chosen": 1.2251577377319336,
      "logits/rejected": 1.4630932807922363,
      "logps/chosen": -28.983720779418945,
      "logps/rejected": -48.910972595214844,
      "loss": 0.658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03187692165374756,
      "rewards/margins": 0.07164318859577179,
      "rewards/rejected": -0.03976626694202423,
      "step": 547
    },
    {
      "epoch": 42.16,
      "grad_norm": 7.17144775390625,
      "learning_rate": 1.634920634920635e-08,
      "logits/chosen": 1.168402910232544,
      "logits/rejected": 1.287885308265686,
      "logps/chosen": -33.45464324951172,
      "logps/rejected": -59.309173583984375,
      "loss": 0.6736,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.010186934843659401,
      "rewards/margins": 0.039711691439151764,
      "rewards/rejected": -0.029524754732847214,
      "step": 548
    },
    {
      "epoch": 42.24,
      "grad_norm": 8.604331016540527,
      "learning_rate": 1.619047619047619e-08,
      "logits/chosen": 1.3152289390563965,
      "logits/rejected": 1.0215212106704712,
      "logps/chosen": -32.89393997192383,
      "logps/rejected": -57.35820007324219,
      "loss": 0.6632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01685953140258789,
      "rewards/margins": 0.06105160713195801,
      "rewards/rejected": -0.04419207572937012,
      "step": 549
    },
    {
      "epoch": 42.32,
      "grad_norm": 7.7011189460754395,
      "learning_rate": 1.6031746031746033e-08,
      "logits/chosen": 1.3107173442840576,
      "logits/rejected": 1.3489434719085693,
      "logps/chosen": -29.397823333740234,
      "logps/rejected": -47.3259391784668,
      "loss": 0.6664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02067878283560276,
      "rewards/margins": 0.0543992817401886,
      "rewards/rejected": -0.03372049331665039,
      "step": 550
    },
    {
      "epoch": 42.4,
      "grad_norm": 6.720361232757568,
      "learning_rate": 1.5873015873015872e-08,
      "logits/chosen": 1.2265684604644775,
      "logits/rejected": 1.305466651916504,
      "logps/chosen": -33.243186950683594,
      "logps/rejected": -55.49380874633789,
      "loss": 0.6626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.029552005231380463,
      "rewards/margins": 0.06225664168596268,
      "rewards/rejected": -0.03270464017987251,
      "step": 551
    },
    {
      "epoch": 42.48,
      "grad_norm": 7.610989093780518,
      "learning_rate": 1.5714285714285715e-08,
      "logits/chosen": 1.3960275650024414,
      "logits/rejected": 1.3933647871017456,
      "logps/chosen": -33.36021423339844,
      "logps/rejected": -53.51681137084961,
      "loss": 0.6681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.014753580093383789,
      "rewards/margins": 0.05096454918384552,
      "rewards/rejected": -0.03621096909046173,
      "step": 552
    },
    {
      "epoch": 42.56,
      "grad_norm": 7.481933116912842,
      "learning_rate": 1.5555555555555554e-08,
      "logits/chosen": 1.262209177017212,
      "logits/rejected": 1.0687856674194336,
      "logps/chosen": -32.121742248535156,
      "logps/rejected": -54.72550964355469,
      "loss": 0.67,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018353914842009544,
      "rewards/margins": 0.046998195350170135,
      "rewards/rejected": -0.028644276782870293,
      "step": 553
    },
    {
      "epoch": 42.64,
      "grad_norm": 8.536561965942383,
      "learning_rate": 1.5396825396825396e-08,
      "logits/chosen": 1.338703989982605,
      "logits/rejected": 1.243916630744934,
      "logps/chosen": -38.21813201904297,
      "logps/rejected": -64.27627563476562,
      "loss": 0.6727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008350158110260963,
      "rewards/margins": 0.04133107513189316,
      "rewards/rejected": -0.032980918884277344,
      "step": 554
    },
    {
      "epoch": 42.72,
      "grad_norm": 6.7735466957092285,
      "learning_rate": 1.523809523809524e-08,
      "logits/chosen": 1.372094750404358,
      "logits/rejected": 1.2875651121139526,
      "logps/chosen": -35.71189880371094,
      "logps/rejected": -60.846622467041016,
      "loss": 0.6617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014684629626572132,
      "rewards/margins": 0.06416886299848557,
      "rewards/rejected": -0.04948423057794571,
      "step": 555
    },
    {
      "epoch": 42.8,
      "grad_norm": 7.713381290435791,
      "learning_rate": 1.5079365079365077e-08,
      "logits/chosen": 1.5441868305206299,
      "logits/rejected": 1.2344248294830322,
      "logps/chosen": -37.29353332519531,
      "logps/rejected": -49.71714782714844,
      "loss": 0.6666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021884489804506302,
      "rewards/margins": 0.05392108112573624,
      "rewards/rejected": -0.032036591321229935,
      "step": 556
    },
    {
      "epoch": 42.88,
      "grad_norm": 6.723560810089111,
      "learning_rate": 1.492063492063492e-08,
      "logits/chosen": 1.277968406677246,
      "logits/rejected": 1.3102864027023315,
      "logps/chosen": -39.2269287109375,
      "logps/rejected": -57.49256134033203,
      "loss": 0.6702,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008311247453093529,
      "rewards/margins": 0.04665806144475937,
      "rewards/rejected": -0.03834681585431099,
      "step": 557
    },
    {
      "epoch": 42.96,
      "grad_norm": 8.656109809875488,
      "learning_rate": 1.4761904761904762e-08,
      "logits/chosen": 1.2334164381027222,
      "logits/rejected": 1.1057542562484741,
      "logps/chosen": -33.427330017089844,
      "logps/rejected": -57.21388244628906,
      "loss": 0.6662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02276158332824707,
      "rewards/margins": 0.055051468312740326,
      "rewards/rejected": -0.032289884984493256,
      "step": 558
    },
    {
      "epoch": 43.0,
      "grad_norm": 10.555360794067383,
      "learning_rate": 1.4603174603174603e-08,
      "logits/chosen": 1.0595089197158813,
      "logits/rejected": 1.376817226409912,
      "logps/chosen": -36.05320739746094,
      "logps/rejected": -47.89042663574219,
      "loss": 0.6661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015144205652177334,
      "rewards/margins": 0.05508151650428772,
      "rewards/rejected": -0.03993730992078781,
      "step": 559
    },
    {
      "epoch": 43.0,
      "eval_logits/chosen": 1.311517596244812,
      "eval_logits/rejected": 1.2028406858444214,
      "eval_logps/chosen": -34.3487434387207,
      "eval_logps/rejected": -47.10737228393555,
      "eval_loss": 0.6804624199867249,
      "eval_rewards/accuracies": 0.800000011920929,
      "eval_rewards/chosen": 0.015076970681548119,
      "eval_rewards/margins": 0.02569521591067314,
      "eval_rewards/rejected": -0.010618247091770172,
      "eval_runtime": 2.7376,
      "eval_samples_per_second": 36.529,
      "eval_steps_per_second": 18.264,
      "step": 559
    },
    {
      "epoch": 43.08,
      "grad_norm": 7.515207290649414,
      "learning_rate": 1.4444444444444442e-08,
      "logits/chosen": 1.471869707107544,
      "logits/rejected": 1.3902403116226196,
      "logps/chosen": -34.75071716308594,
      "logps/rejected": -49.876869201660156,
      "loss": 0.6688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03461093828082085,
      "rewards/margins": 0.04933929443359375,
      "rewards/rejected": -0.014728356152772903,
      "step": 560
    },
    {
      "epoch": 43.16,
      "grad_norm": 6.613427639007568,
      "learning_rate": 1.4285714285714284e-08,
      "logits/chosen": 1.3620537519454956,
      "logits/rejected": 1.4396201372146606,
      "logps/chosen": -38.31395721435547,
      "logps/rejected": -57.79454803466797,
      "loss": 0.6689,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018273210152983665,
      "rewards/margins": 0.04920930787920952,
      "rewards/rejected": -0.030936099588871002,
      "step": 561
    },
    {
      "epoch": 43.24,
      "grad_norm": 6.49244499206543,
      "learning_rate": 1.4126984126984127e-08,
      "logits/chosen": 1.3265457153320312,
      "logits/rejected": 1.4098122119903564,
      "logps/chosen": -36.12732696533203,
      "logps/rejected": -51.792808532714844,
      "loss": 0.6625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03009650856256485,
      "rewards/margins": 0.06253311783075333,
      "rewards/rejected": -0.03243660926818848,
      "step": 562
    },
    {
      "epoch": 43.32,
      "grad_norm": 9.287764549255371,
      "learning_rate": 1.3968253968253967e-08,
      "logits/chosen": 1.2912191152572632,
      "logits/rejected": 1.075825572013855,
      "logps/chosen": -30.476585388183594,
      "logps/rejected": -49.84471130371094,
      "loss": 0.6585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021950459107756615,
      "rewards/margins": 0.07097733020782471,
      "rewards/rejected": -0.04902687296271324,
      "step": 563
    },
    {
      "epoch": 43.4,
      "grad_norm": 8.06457805633545,
      "learning_rate": 1.380952380952381e-08,
      "logits/chosen": 1.1817294359207153,
      "logits/rejected": 1.2049171924591064,
      "logps/chosen": -35.082183837890625,
      "logps/rejected": -62.25227737426758,
      "loss": 0.6694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012776064686477184,
      "rewards/margins": 0.04814350605010986,
      "rewards/rejected": -0.0353674441576004,
      "step": 564
    },
    {
      "epoch": 43.48,
      "grad_norm": 7.035678863525391,
      "learning_rate": 1.3650793650793649e-08,
      "logits/chosen": 1.213099718093872,
      "logits/rejected": 1.3523812294006348,
      "logps/chosen": -31.222028732299805,
      "logps/rejected": -64.64669036865234,
      "loss": 0.671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018749402835965157,
      "rewards/margins": 0.04496967792510986,
      "rewards/rejected": -0.026220275089144707,
      "step": 565
    },
    {
      "epoch": 43.56,
      "grad_norm": 7.192677974700928,
      "learning_rate": 1.3492063492063491e-08,
      "logits/chosen": 1.2264059782028198,
      "logits/rejected": 1.1914629936218262,
      "logps/chosen": -30.881183624267578,
      "logps/rejected": -53.05048370361328,
      "loss": 0.6654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016907978802919388,
      "rewards/margins": 0.05639500916004181,
      "rewards/rejected": -0.03948703035712242,
      "step": 566
    },
    {
      "epoch": 43.64,
      "grad_norm": 8.847015380859375,
      "learning_rate": 1.3333333333333332e-08,
      "logits/chosen": 1.3468272686004639,
      "logits/rejected": 1.3384175300598145,
      "logps/chosen": -34.57513427734375,
      "logps/rejected": -55.91547775268555,
      "loss": 0.6622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01883072964847088,
      "rewards/margins": 0.06311669200658798,
      "rewards/rejected": -0.04428596794605255,
      "step": 567
    },
    {
      "epoch": 43.72,
      "grad_norm": 7.322692394256592,
      "learning_rate": 1.3174603174603174e-08,
      "logits/chosen": 1.190506100654602,
      "logits/rejected": 1.1059577465057373,
      "logps/chosen": -33.92833709716797,
      "logps/rejected": -50.66615676879883,
      "loss": 0.6632,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.013704348355531693,
      "rewards/margins": 0.06121373176574707,
      "rewards/rejected": -0.04750938341021538,
      "step": 568
    },
    {
      "epoch": 43.8,
      "grad_norm": 7.7188944816589355,
      "learning_rate": 1.3015873015873017e-08,
      "logits/chosen": 1.3099756240844727,
      "logits/rejected": 1.2207094430923462,
      "logps/chosen": -35.759796142578125,
      "logps/rejected": -54.65993118286133,
      "loss": 0.6675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019042659550905228,
      "rewards/margins": 0.05209362879395485,
      "rewards/rejected": -0.03305096551775932,
      "step": 569
    },
    {
      "epoch": 43.88,
      "grad_norm": 7.750808238983154,
      "learning_rate": 1.2857142857142856e-08,
      "logits/chosen": 1.4302775859832764,
      "logits/rejected": 1.2994455099105835,
      "logps/chosen": -34.566856384277344,
      "logps/rejected": -60.67634582519531,
      "loss": 0.6682,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.020805692300200462,
      "rewards/margins": 0.05078940838575363,
      "rewards/rejected": -0.02998371236026287,
      "step": 570
    },
    {
      "epoch": 43.96,
      "grad_norm": 7.019712924957275,
      "learning_rate": 1.2698412698412696e-08,
      "logits/chosen": 1.136729121208191,
      "logits/rejected": 1.100770115852356,
      "logps/chosen": -34.23523712158203,
      "logps/rejected": -50.5103874206543,
      "loss": 0.6688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019690372049808502,
      "rewards/margins": 0.04928221553564072,
      "rewards/rejected": -0.029591847211122513,
      "step": 571
    },
    {
      "epoch": 44.0,
      "grad_norm": 10.968121528625488,
      "learning_rate": 1.2539682539682539e-08,
      "logits/chosen": 1.3432761430740356,
      "logits/rejected": 1.3313416242599487,
      "logps/chosen": -30.681751251220703,
      "logps/rejected": -56.466552734375,
      "loss": 0.6729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012838935479521751,
      "rewards/margins": 0.041083432734012604,
      "rewards/rejected": -0.028244495391845703,
      "step": 572
    },
    {
      "epoch": 44.0,
      "eval_logits/chosen": 1.310092806816101,
      "eval_logits/rejected": 1.2020633220672607,
      "eval_logps/chosen": -34.3371467590332,
      "eval_logps/rejected": -47.10553741455078,
      "eval_loss": 0.6799915432929993,
      "eval_rewards/accuracies": 0.8399999737739563,
      "eval_rewards/chosen": 0.016236942261457443,
      "eval_rewards/margins": 0.02667156420648098,
      "eval_rewards/rejected": -0.010434621945023537,
      "eval_runtime": 2.7362,
      "eval_samples_per_second": 36.548,
      "eval_steps_per_second": 18.274,
      "step": 572
    },
    {
      "epoch": 44.08,
      "grad_norm": 7.331940650939941,
      "learning_rate": 1.2380952380952381e-08,
      "logits/chosen": 1.351506233215332,
      "logits/rejected": 1.4232354164123535,
      "logps/chosen": -34.320831298828125,
      "logps/rejected": -54.341224670410156,
      "loss": 0.6647,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025514984503388405,
      "rewards/margins": 0.05783471837639809,
      "rewards/rejected": -0.03231973946094513,
      "step": 573
    },
    {
      "epoch": 44.16,
      "grad_norm": 8.18313217163086,
      "learning_rate": 1.2222222222222222e-08,
      "logits/chosen": 1.2189137935638428,
      "logits/rejected": 1.2516448497772217,
      "logps/chosen": -33.70977020263672,
      "logps/rejected": -55.48017120361328,
      "loss": 0.6709,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02041485160589218,
      "rewards/margins": 0.04534108564257622,
      "rewards/rejected": -0.024926234036684036,
      "step": 574
    },
    {
      "epoch": 44.24,
      "grad_norm": 7.516282558441162,
      "learning_rate": 1.2063492063492063e-08,
      "logits/chosen": 1.3883368968963623,
      "logits/rejected": 1.3914076089859009,
      "logps/chosen": -35.03459548950195,
      "logps/rejected": -63.73322296142578,
      "loss": 0.6765,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01605391502380371,
      "rewards/margins": 0.03368964418768883,
      "rewards/rejected": -0.017635725438594818,
      "step": 575
    },
    {
      "epoch": 44.32,
      "grad_norm": 7.289220333099365,
      "learning_rate": 1.1904761904761903e-08,
      "logits/chosen": 1.5515459775924683,
      "logits/rejected": 1.2652790546417236,
      "logps/chosen": -34.426143646240234,
      "logps/rejected": -53.077171325683594,
      "loss": 0.6641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024446941912174225,
      "rewards/margins": 0.05916488170623779,
      "rewards/rejected": -0.03471794351935387,
      "step": 576
    },
    {
      "epoch": 44.4,
      "grad_norm": 7.215850353240967,
      "learning_rate": 1.1746031746031746e-08,
      "logits/chosen": 1.3166329860687256,
      "logits/rejected": 1.224648118019104,
      "logps/chosen": -37.92424774169922,
      "logps/rejected": -54.49734115600586,
      "loss": 0.6748,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.009376979433000088,
      "rewards/margins": 0.03722264617681503,
      "rewards/rejected": -0.02784566953778267,
      "step": 577
    },
    {
      "epoch": 44.48,
      "grad_norm": 7.703251838684082,
      "learning_rate": 1.1587301587301586e-08,
      "logits/chosen": 1.1743577718734741,
      "logits/rejected": 1.294292688369751,
      "logps/chosen": -34.02317810058594,
      "logps/rejected": -53.9676399230957,
      "loss": 0.6597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01931629329919815,
      "rewards/margins": 0.06828784942626953,
      "rewards/rejected": -0.04897155985236168,
      "step": 578
    },
    {
      "epoch": 44.56,
      "grad_norm": 7.760773658752441,
      "learning_rate": 1.1428571428571427e-08,
      "logits/chosen": 1.2893671989440918,
      "logits/rejected": 1.2009122371673584,
      "logps/chosen": -30.635597229003906,
      "logps/rejected": -56.78949737548828,
      "loss": 0.6732,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010369325056672096,
      "rewards/margins": 0.040459178388118744,
      "rewards/rejected": -0.030089857056736946,
      "step": 579
    },
    {
      "epoch": 44.64,
      "grad_norm": 6.382068157196045,
      "learning_rate": 1.126984126984127e-08,
      "logits/chosen": 1.2366547584533691,
      "logits/rejected": 1.1234909296035767,
      "logps/chosen": -35.16710662841797,
      "logps/rejected": -52.629554748535156,
      "loss": 0.6688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01245045755058527,
      "rewards/margins": 0.049433041363954544,
      "rewards/rejected": -0.03698258474469185,
      "step": 580
    },
    {
      "epoch": 44.72,
      "grad_norm": 7.624048709869385,
      "learning_rate": 1.111111111111111e-08,
      "logits/chosen": 1.3247580528259277,
      "logits/rejected": 1.281791090965271,
      "logps/chosen": -35.418766021728516,
      "logps/rejected": -64.02513122558594,
      "loss": 0.666,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02486398257315159,
      "rewards/margins": 0.0551045686006546,
      "rewards/rejected": -0.030240584164857864,
      "step": 581
    },
    {
      "epoch": 44.8,
      "grad_norm": 8.447123527526855,
      "learning_rate": 1.0952380952380953e-08,
      "logits/chosen": 0.9154519438743591,
      "logits/rejected": 1.2063844203948975,
      "logps/chosen": -28.797273635864258,
      "logps/rejected": -58.241092681884766,
      "loss": 0.667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019853925332427025,
      "rewards/margins": 0.05310502275824547,
      "rewards/rejected": -0.033251095563173294,
      "step": 582
    },
    {
      "epoch": 44.88,
      "grad_norm": 7.797859191894531,
      "learning_rate": 1.0793650793650793e-08,
      "logits/chosen": 1.415432333946228,
      "logits/rejected": 1.2126555442810059,
      "logps/chosen": -40.298580169677734,
      "logps/rejected": -47.58103561401367,
      "loss": 0.6753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005338073242455721,
      "rewards/margins": 0.036033131182193756,
      "rewards/rejected": -0.030695056542754173,
      "step": 583
    },
    {
      "epoch": 44.96,
      "grad_norm": 8.546854019165039,
      "learning_rate": 1.0634920634920634e-08,
      "logits/chosen": 1.3664121627807617,
      "logits/rejected": 1.144059419631958,
      "logps/chosen": -27.80597496032715,
      "logps/rejected": -54.48566436767578,
      "loss": 0.6505,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.033776119351387024,
      "rewards/margins": 0.08771059662103653,
      "rewards/rejected": -0.053934477269649506,
      "step": 584
    },
    {
      "epoch": 45.0,
      "grad_norm": 8.806236267089844,
      "learning_rate": 1.0476190476190476e-08,
      "logits/chosen": 1.4424893856048584,
      "logits/rejected": 1.5332961082458496,
      "logps/chosen": -35.64817810058594,
      "logps/rejected": -42.24121856689453,
      "loss": 0.6745,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.008875321596860886,
      "rewards/margins": 0.03774847835302353,
      "rewards/rejected": -0.028873158618807793,
      "step": 585
    },
    {
      "epoch": 45.0,
      "eval_logits/chosen": 1.3140063285827637,
      "eval_logits/rejected": 1.205025553703308,
      "eval_logps/chosen": -34.3449821472168,
      "eval_logps/rejected": -47.12773895263672,
      "eval_loss": 0.6792728900909424,
      "eval_rewards/accuracies": 0.8199999928474426,
      "eval_rewards/chosen": 0.015453433617949486,
      "eval_rewards/margins": 0.028108801692724228,
      "eval_rewards/rejected": -0.012655369006097317,
      "eval_runtime": 2.7376,
      "eval_samples_per_second": 36.528,
      "eval_steps_per_second": 18.264,
      "step": 585
    },
    {
      "epoch": 45.08,
      "grad_norm": 7.066267013549805,
      "learning_rate": 1.0317460317460317e-08,
      "logits/chosen": 1.2855184078216553,
      "logits/rejected": 1.2937538623809814,
      "logps/chosen": -34.64859390258789,
      "logps/rejected": -52.922706604003906,
      "loss": 0.6766,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.008928108029067516,
      "rewards/margins": 0.03386487811803818,
      "rewards/rejected": -0.024936772882938385,
      "step": 586
    },
    {
      "epoch": 45.16,
      "grad_norm": 8.333399772644043,
      "learning_rate": 1.0158730158730158e-08,
      "logits/chosen": 1.0247080326080322,
      "logits/rejected": 1.1089043617248535,
      "logps/chosen": -29.78730583190918,
      "logps/rejected": -54.64146041870117,
      "loss": 0.6596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03269503265619278,
      "rewards/margins": 0.06837217509746552,
      "rewards/rejected": -0.03567714989185333,
      "step": 587
    },
    {
      "epoch": 45.24,
      "grad_norm": 9.043840408325195,
      "learning_rate": 1e-08,
      "logits/chosen": 1.3867475986480713,
      "logits/rejected": 1.1576347351074219,
      "logps/chosen": -33.381675720214844,
      "logps/rejected": -53.23252868652344,
      "loss": 0.6615,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02897493913769722,
      "rewards/margins": 0.06482389569282532,
      "rewards/rejected": -0.0358489528298378,
      "step": 588
    },
    {
      "epoch": 45.32,
      "grad_norm": 7.752118110656738,
      "learning_rate": 9.841269841269841e-09,
      "logits/chosen": 1.4268097877502441,
      "logits/rejected": 1.5603351593017578,
      "logps/chosen": -34.97694778442383,
      "logps/rejected": -58.454917907714844,
      "loss": 0.668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.017790650948882103,
      "rewards/margins": 0.051073502749204636,
      "rewards/rejected": -0.03328285366296768,
      "step": 589
    },
    {
      "epoch": 45.4,
      "grad_norm": 6.029078960418701,
      "learning_rate": 9.682539682539682e-09,
      "logits/chosen": 1.3715217113494873,
      "logits/rejected": 1.4755115509033203,
      "logps/chosen": -34.10825729370117,
      "logps/rejected": -50.388729095458984,
      "loss": 0.6694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02988586202263832,
      "rewards/margins": 0.04810462146997452,
      "rewards/rejected": -0.0182187557220459,
      "step": 590
    },
    {
      "epoch": 45.48,
      "grad_norm": 7.450568199157715,
      "learning_rate": 9.523809523809522e-09,
      "logits/chosen": 1.2003564834594727,
      "logits/rejected": 1.3305833339691162,
      "logps/chosen": -27.986328125,
      "logps/rejected": -55.34025573730469,
      "loss": 0.6599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.028021501377224922,
      "rewards/margins": 0.06783439964056015,
      "rewards/rejected": -0.03981290012598038,
      "step": 591
    },
    {
      "epoch": 45.56,
      "grad_norm": 7.637822151184082,
      "learning_rate": 9.365079365079365e-09,
      "logits/chosen": 1.313366174697876,
      "logits/rejected": 1.1008292436599731,
      "logps/chosen": -40.245445251464844,
      "logps/rejected": -51.04536056518555,
      "loss": 0.6755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0043769837357103825,
      "rewards/margins": 0.03584613651037216,
      "rewards/rejected": -0.040223121643066406,
      "step": 592
    },
    {
      "epoch": 45.64,
      "grad_norm": 9.029645919799805,
      "learning_rate": 9.206349206349207e-09,
      "logits/chosen": 1.1289517879486084,
      "logits/rejected": 1.2389907836914062,
      "logps/chosen": -32.93152618408203,
      "logps/rejected": -56.060569763183594,
      "loss": 0.6579,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030792664736509323,
      "rewards/margins": 0.07243287563323975,
      "rewards/rejected": -0.04164021089673042,
      "step": 593
    },
    {
      "epoch": 45.72,
      "grad_norm": 6.9727678298950195,
      "learning_rate": 9.047619047619048e-09,
      "logits/chosen": 1.291884422302246,
      "logits/rejected": 1.1635477542877197,
      "logps/chosen": -33.60945129394531,
      "logps/rejected": -57.60594177246094,
      "loss": 0.6732,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.014114928431808949,
      "rewards/margins": 0.04049232229590416,
      "rewards/rejected": -0.026377392932772636,
      "step": 594
    },
    {
      "epoch": 45.8,
      "grad_norm": 8.283711433410645,
      "learning_rate": 8.888888888888889e-09,
      "logits/chosen": 1.45229172706604,
      "logits/rejected": 1.3519474267959595,
      "logps/chosen": -38.08029556274414,
      "logps/rejected": -65.50437927246094,
      "loss": 0.6693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007633495144546032,
      "rewards/margins": 0.04831499978899956,
      "rewards/rejected": -0.04068150743842125,
      "step": 595
    },
    {
      "epoch": 45.88,
      "grad_norm": 7.701519966125488,
      "learning_rate": 8.73015873015873e-09,
      "logits/chosen": 1.7457549571990967,
      "logits/rejected": 1.2174495458602905,
      "logps/chosen": -34.766605377197266,
      "logps/rejected": -53.229217529296875,
      "loss": 0.662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02569584734737873,
      "rewards/margins": 0.06344037503004074,
      "rewards/rejected": -0.03774452209472656,
      "step": 596
    },
    {
      "epoch": 45.96,
      "grad_norm": 6.943743705749512,
      "learning_rate": 8.571428571428572e-09,
      "logits/chosen": 1.041069746017456,
      "logits/rejected": 1.0888773202896118,
      "logps/chosen": -32.569061279296875,
      "logps/rejected": -49.51691436767578,
      "loss": 0.6696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010506700724363327,
      "rewards/margins": 0.047861456871032715,
      "rewards/rejected": -0.03735475614666939,
      "step": 597
    },
    {
      "epoch": 46.0,
      "grad_norm": 8.247053146362305,
      "learning_rate": 8.412698412698412e-09,
      "logits/chosen": 1.283599853515625,
      "logits/rejected": 1.5124492645263672,
      "logps/chosen": -36.3665885925293,
      "logps/rejected": -64.02910614013672,
      "loss": 0.6697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.036328744143247604,
      "rewards/margins": 0.04753909260034561,
      "rewards/rejected": -0.011210346594452858,
      "step": 598
    },
    {
      "epoch": 46.0,
      "eval_logits/chosen": 1.3134151697158813,
      "eval_logits/rejected": 1.2062008380889893,
      "eval_logps/chosen": -34.330528259277344,
      "eval_logps/rejected": -47.093727111816406,
      "eval_loss": 0.6802383661270142,
      "eval_rewards/accuracies": 0.8700000047683716,
      "eval_rewards/chosen": 0.016898423433303833,
      "eval_rewards/margins": 0.02615245431661606,
      "eval_rewards/rejected": -0.009254032745957375,
      "eval_runtime": 2.7391,
      "eval_samples_per_second": 36.508,
      "eval_steps_per_second": 18.254,
      "step": 598
    },
    {
      "epoch": 46.08,
      "grad_norm": 6.611502647399902,
      "learning_rate": 8.253968253968253e-09,
      "logits/chosen": 1.4034442901611328,
      "logits/rejected": 1.505276083946228,
      "logps/chosen": -34.27245330810547,
      "logps/rejected": -60.29255676269531,
      "loss": 0.6663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02547900751233101,
      "rewards/margins": 0.054667163640260696,
      "rewards/rejected": -0.029188156127929688,
      "step": 599
    },
    {
      "epoch": 46.16,
      "grad_norm": 7.824469566345215,
      "learning_rate": 8.095238095238095e-09,
      "logits/chosen": 1.3102428913116455,
      "logits/rejected": 1.3659157752990723,
      "logps/chosen": -34.68026351928711,
      "logps/rejected": -49.84021759033203,
      "loss": 0.6673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018726134672760963,
      "rewards/margins": 0.05260021984577179,
      "rewards/rejected": -0.03387408331036568,
      "step": 600
    },
    {
      "epoch": 46.24,
      "grad_norm": 7.425407409667969,
      "learning_rate": 7.936507936507936e-09,
      "logits/chosen": 1.3792667388916016,
      "logits/rejected": 1.282132863998413,
      "logps/chosen": -38.496124267578125,
      "logps/rejected": -48.83547592163086,
      "loss": 0.6665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02524850331246853,
      "rewards/margins": 0.05427978187799454,
      "rewards/rejected": -0.02903127670288086,
      "step": 601
    },
    {
      "epoch": 46.32,
      "grad_norm": 8.592225074768066,
      "learning_rate": 7.777777777777777e-09,
      "logits/chosen": 1.166175365447998,
      "logits/rejected": 1.1333400011062622,
      "logps/chosen": -35.401336669921875,
      "logps/rejected": -55.44270324707031,
      "loss": 0.6691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.007442116737365723,
      "rewards/margins": 0.049355484545230865,
      "rewards/rejected": -0.04191336780786514,
      "step": 602
    },
    {
      "epoch": 46.4,
      "grad_norm": 7.485150337219238,
      "learning_rate": 7.61904761904762e-09,
      "logits/chosen": 1.2324227094650269,
      "logits/rejected": 1.2606462240219116,
      "logps/chosen": -29.881629943847656,
      "logps/rejected": -54.89281463623047,
      "loss": 0.6585,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03255622461438179,
      "rewards/margins": 0.07064846158027649,
      "rewards/rejected": -0.0380922332406044,
      "step": 603
    },
    {
      "epoch": 46.48,
      "grad_norm": 6.716530799865723,
      "learning_rate": 7.46031746031746e-09,
      "logits/chosen": 1.3545582294464111,
      "logits/rejected": 1.5026464462280273,
      "logps/chosen": -33.92668533325195,
      "logps/rejected": -68.67478942871094,
      "loss": 0.6698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01647064834833145,
      "rewards/margins": 0.04738805443048477,
      "rewards/rejected": -0.03091740794479847,
      "step": 604
    },
    {
      "epoch": 46.56,
      "grad_norm": 7.399959564208984,
      "learning_rate": 7.3015873015873015e-09,
      "logits/chosen": 1.2207354307174683,
      "logits/rejected": 1.109311819076538,
      "logps/chosen": -31.545303344726562,
      "logps/rejected": -49.794464111328125,
      "loss": 0.6643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.016412973403930664,
      "rewards/margins": 0.0587586835026741,
      "rewards/rejected": -0.042345717549324036,
      "step": 605
    },
    {
      "epoch": 46.64,
      "grad_norm": 8.07672119140625,
      "learning_rate": 7.142857142857142e-09,
      "logits/chosen": 1.2090723514556885,
      "logits/rejected": 1.2424702644348145,
      "logps/chosen": -35.56467056274414,
      "logps/rejected": -60.193687438964844,
      "loss": 0.6589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019496871158480644,
      "rewards/margins": 0.06984315067529678,
      "rewards/rejected": -0.05034627765417099,
      "step": 606
    },
    {
      "epoch": 46.72,
      "grad_norm": 7.276434421539307,
      "learning_rate": 6.984126984126984e-09,
      "logits/chosen": 0.9794069528579712,
      "logits/rejected": 1.2694463729858398,
      "logps/chosen": -32.91032791137695,
      "logps/rejected": -56.11771011352539,
      "loss": 0.6687,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01648137718439102,
      "rewards/margins": 0.04972832277417183,
      "rewards/rejected": -0.033246949315071106,
      "step": 607
    },
    {
      "epoch": 46.8,
      "grad_norm": 7.723635673522949,
      "learning_rate": 6.8253968253968244e-09,
      "logits/chosen": 1.462661862373352,
      "logits/rejected": 1.1177605390548706,
      "logps/chosen": -31.655065536499023,
      "logps/rejected": -53.51127624511719,
      "loss": 0.6604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.030509736388921738,
      "rewards/margins": 0.06668255478143692,
      "rewards/rejected": -0.03617282211780548,
      "step": 608
    },
    {
      "epoch": 46.88,
      "grad_norm": 8.774600982666016,
      "learning_rate": 6.666666666666666e-09,
      "logits/chosen": 1.599945068359375,
      "logits/rejected": 1.0880944728851318,
      "logps/chosen": -36.26955032348633,
      "logps/rejected": -50.86227035522461,
      "loss": 0.6592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03274963051080704,
      "rewards/margins": 0.06927052140235901,
      "rewards/rejected": -0.03652088716626167,
      "step": 609
    },
    {
      "epoch": 46.96,
      "grad_norm": 7.2248921394348145,
      "learning_rate": 6.507936507936508e-09,
      "logits/chosen": 1.4862983226776123,
      "logits/rejected": 1.3979182243347168,
      "logps/chosen": -35.30976104736328,
      "logps/rejected": -56.25617218017578,
      "loss": 0.664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.015332461334764957,
      "rewards/margins": 0.05921797454357147,
      "rewards/rejected": -0.04388551786541939,
      "step": 610
    },
    {
      "epoch": 47.0,
      "grad_norm": 9.103631019592285,
      "learning_rate": 6.349206349206348e-09,
      "logits/chosen": 1.3208003044128418,
      "logits/rejected": 1.1493302583694458,
      "logps/chosen": -30.21441078186035,
      "logps/rejected": -51.12171936035156,
      "loss": 0.6655,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02879371866583824,
      "rewards/margins": 0.05665311962366104,
      "rewards/rejected": -0.027859404683113098,
      "step": 611
    },
    {
      "epoch": 47.0,
      "eval_logits/chosen": 1.3110066652297974,
      "eval_logits/rejected": 1.203131914138794,
      "eval_logps/chosen": -34.331268310546875,
      "eval_logps/rejected": -47.14936065673828,
      "eval_loss": 0.6775261759757996,
      "eval_rewards/accuracies": 0.9100000262260437,
      "eval_rewards/chosen": 0.016824617981910706,
      "eval_rewards/margins": 0.03164192661643028,
      "eval_rewards/rejected": -0.014817306771874428,
      "eval_runtime": 2.7365,
      "eval_samples_per_second": 36.543,
      "eval_steps_per_second": 18.271,
      "step": 611
    },
    {
      "epoch": 47.08,
      "grad_norm": 8.137162208557129,
      "learning_rate": 6.190476190476191e-09,
      "logits/chosen": 1.2676326036453247,
      "logits/rejected": 1.1563092470169067,
      "logps/chosen": -31.571218490600586,
      "logps/rejected": -52.17366027832031,
      "loss": 0.6616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023112963885068893,
      "rewards/margins": 0.06436000019311905,
      "rewards/rejected": -0.041247036308050156,
      "step": 612
    },
    {
      "epoch": 47.16,
      "grad_norm": 7.462883949279785,
      "learning_rate": 6.031746031746031e-09,
      "logits/chosen": 1.3377127647399902,
      "logits/rejected": 1.1922812461853027,
      "logps/chosen": -27.768918991088867,
      "logps/rejected": -53.29825210571289,
      "loss": 0.6616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.034598805010318756,
      "rewards/margins": 0.06423888355493546,
      "rewards/rejected": -0.0296400785446167,
      "step": 613
    },
    {
      "epoch": 47.24,
      "grad_norm": 6.473727226257324,
      "learning_rate": 5.873015873015873e-09,
      "logits/chosen": 1.2654558420181274,
      "logits/rejected": 1.3881326913833618,
      "logps/chosen": -34.80750274658203,
      "logps/rejected": -48.93934631347656,
      "loss": 0.6681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009741092100739479,
      "rewards/margins": 0.05093185976147652,
      "rewards/rejected": -0.04119076579809189,
      "step": 614
    },
    {
      "epoch": 47.32,
      "grad_norm": 7.337726593017578,
      "learning_rate": 5.7142857142857136e-09,
      "logits/chosen": 1.1229875087738037,
      "logits/rejected": 1.2921056747436523,
      "logps/chosen": -30.886280059814453,
      "logps/rejected": -58.96839904785156,
      "loss": 0.6724,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.016476035118103027,
      "rewards/margins": 0.04242050647735596,
      "rewards/rejected": -0.02594447135925293,
      "step": 615
    },
    {
      "epoch": 47.4,
      "grad_norm": 7.061221599578857,
      "learning_rate": 5.555555555555555e-09,
      "logits/chosen": 1.3907586336135864,
      "logits/rejected": 1.2695481777191162,
      "logps/chosen": -33.840152740478516,
      "logps/rejected": -49.214012145996094,
      "loss": 0.6682,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.021690869703888893,
      "rewards/margins": 0.05086839199066162,
      "rewards/rejected": -0.029177524149417877,
      "step": 616
    },
    {
      "epoch": 47.48,
      "grad_norm": 7.656937599182129,
      "learning_rate": 5.396825396825397e-09,
      "logits/chosen": 1.257968783378601,
      "logits/rejected": 1.1656930446624756,
      "logps/chosen": -33.77376174926758,
      "logps/rejected": -59.04812240600586,
      "loss": 0.6613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024001814424991608,
      "rewards/margins": 0.06487476825714111,
      "rewards/rejected": -0.040872957557439804,
      "step": 617
    },
    {
      "epoch": 47.56,
      "grad_norm": 8.498764038085938,
      "learning_rate": 5.238095238095238e-09,
      "logits/chosen": 1.195823073387146,
      "logits/rejected": 1.1491899490356445,
      "logps/chosen": -36.01171875,
      "logps/rejected": -55.168148040771484,
      "loss": 0.6577,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03420732170343399,
      "rewards/margins": 0.07312139123678207,
      "rewards/rejected": -0.03891405835747719,
      "step": 618
    },
    {
      "epoch": 47.64,
      "grad_norm": 7.399302005767822,
      "learning_rate": 5.079365079365079e-09,
      "logits/chosen": 1.333632469177246,
      "logits/rejected": 1.154288411140442,
      "logps/chosen": -33.31168746948242,
      "logps/rejected": -55.1946907043457,
      "loss": 0.6725,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0050203558057546616,
      "rewards/margins": 0.042133163660764694,
      "rewards/rejected": -0.03711280971765518,
      "step": 619
    },
    {
      "epoch": 47.72,
      "grad_norm": 7.50702428817749,
      "learning_rate": 4.9206349206349205e-09,
      "logits/chosen": 1.1547200679779053,
      "logits/rejected": 1.3040786981582642,
      "logps/chosen": -35.165077209472656,
      "logps/rejected": -61.939002990722656,
      "loss": 0.6689,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01641390472650528,
      "rewards/margins": 0.04936620965600014,
      "rewards/rejected": -0.032952308654785156,
      "step": 620
    },
    {
      "epoch": 47.8,
      "grad_norm": 8.114594459533691,
      "learning_rate": 4.761904761904761e-09,
      "logits/chosen": 1.4809120893478394,
      "logits/rejected": 1.3234599828720093,
      "logps/chosen": -38.491432189941406,
      "logps/rejected": -52.1189079284668,
      "loss": 0.6681,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.008816576562821865,
      "rewards/margins": 0.05100731924176216,
      "rewards/rejected": -0.04219074174761772,
      "step": 621
    },
    {
      "epoch": 47.88,
      "grad_norm": 7.322052955627441,
      "learning_rate": 4.6031746031746035e-09,
      "logits/chosen": 1.251402735710144,
      "logits/rejected": 1.4119441509246826,
      "logps/chosen": -39.40276336669922,
      "logps/rejected": -56.358116149902344,
      "loss": 0.6674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02554044872522354,
      "rewards/margins": 0.05241021886467934,
      "rewards/rejected": -0.026869773864746094,
      "step": 622
    },
    {
      "epoch": 47.96,
      "grad_norm": 8.456169128417969,
      "learning_rate": 4.444444444444444e-09,
      "logits/chosen": 1.3860775232315063,
      "logits/rejected": 1.1192632913589478,
      "logps/chosen": -34.41167449951172,
      "logps/rejected": -66.65910339355469,
      "loss": 0.661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.012541914358735085,
      "rewards/margins": 0.06557588279247284,
      "rewards/rejected": -0.0530339740216732,
      "step": 623
    },
    {
      "epoch": 48.0,
      "grad_norm": 11.516127586364746,
      "learning_rate": 4.285714285714286e-09,
      "logits/chosen": 1.4834579229354858,
      "logits/rejected": 1.729149580001831,
      "logps/chosen": -31.52228355407715,
      "logps/rejected": -42.24557113647461,
      "loss": 0.664,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022510003298521042,
      "rewards/margins": 0.05932211875915527,
      "rewards/rejected": -0.03681211546063423,
      "step": 624
    },
    {
      "epoch": 48.0,
      "eval_logits/chosen": 1.312414288520813,
      "eval_logits/rejected": 1.2035982608795166,
      "eval_logps/chosen": -34.346683502197266,
      "eval_logps/rejected": -47.110477447509766,
      "eval_loss": 0.68022620677948,
      "eval_rewards/accuracies": 0.8299999833106995,
      "eval_rewards/chosen": 0.015283317305147648,
      "eval_rewards/margins": 0.02621258981525898,
      "eval_rewards/rejected": -0.010929273441433907,
      "eval_runtime": 2.7444,
      "eval_samples_per_second": 36.438,
      "eval_steps_per_second": 18.219,
      "step": 624
    },
    {
      "epoch": 48.08,
      "grad_norm": 7.695365905761719,
      "learning_rate": 4.1269841269841265e-09,
      "logits/chosen": 1.2760510444641113,
      "logits/rejected": 1.1928980350494385,
      "logps/chosen": -36.205780029296875,
      "logps/rejected": -64.95352172851562,
      "loss": 0.6681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00961680430918932,
      "rewards/margins": 0.05088524520397186,
      "rewards/rejected": -0.04126844182610512,
      "step": 625
    },
    {
      "epoch": 48.16,
      "grad_norm": 7.105169296264648,
      "learning_rate": 3.968253968253968e-09,
      "logits/chosen": 1.4808989763259888,
      "logits/rejected": 1.3842016458511353,
      "logps/chosen": -37.230369567871094,
      "logps/rejected": -57.203758239746094,
      "loss": 0.6619,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.021233271807432175,
      "rewards/margins": 0.06368108093738556,
      "rewards/rejected": -0.042447805404663086,
      "step": 626
    },
    {
      "epoch": 48.24,
      "grad_norm": 7.112485408782959,
      "learning_rate": 3.80952380952381e-09,
      "logits/chosen": 1.3035680055618286,
      "logits/rejected": 1.4833555221557617,
      "logps/chosen": -30.19742202758789,
      "logps/rejected": -57.79140090942383,
      "loss": 0.6641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025153351947665215,
      "rewards/margins": 0.05908679962158203,
      "rewards/rejected": -0.033933449536561966,
      "step": 627
    },
    {
      "epoch": 48.32,
      "grad_norm": 6.7614545822143555,
      "learning_rate": 3.6507936507936507e-09,
      "logits/chosen": 1.147709846496582,
      "logits/rejected": 1.154338002204895,
      "logps/chosen": -34.58790588378906,
      "logps/rejected": -51.3058967590332,
      "loss": 0.6675,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02355504035949707,
      "rewards/margins": 0.05207862704992294,
      "rewards/rejected": -0.028523586690425873,
      "step": 628
    },
    {
      "epoch": 48.4,
      "grad_norm": 8.10053539276123,
      "learning_rate": 3.492063492063492e-09,
      "logits/chosen": 1.3352866172790527,
      "logits/rejected": 1.1969552040100098,
      "logps/chosen": -34.302513122558594,
      "logps/rejected": -63.733856201171875,
      "loss": 0.6668,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02366664446890354,
      "rewards/margins": 0.05353729426860809,
      "rewards/rejected": -0.0298706516623497,
      "step": 629
    },
    {
      "epoch": 48.48,
      "grad_norm": 7.792654991149902,
      "learning_rate": 3.333333333333333e-09,
      "logits/chosen": 1.168723464012146,
      "logits/rejected": 1.1991287469863892,
      "logps/chosen": -28.515335083007812,
      "logps/rejected": -46.33506774902344,
      "loss": 0.6663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019813992083072662,
      "rewards/margins": 0.05456230789422989,
      "rewards/rejected": -0.03474831581115723,
      "step": 630
    },
    {
      "epoch": 48.56,
      "grad_norm": 8.999493598937988,
      "learning_rate": 3.174603174603174e-09,
      "logits/chosen": 1.1852405071258545,
      "logits/rejected": 1.0833027362823486,
      "logps/chosen": -33.664466857910156,
      "logps/rejected": -55.39967727661133,
      "loss": 0.6615,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.01865220069885254,
      "rewards/margins": 0.06471844017505646,
      "rewards/rejected": -0.04606623575091362,
      "step": 631
    },
    {
      "epoch": 48.64,
      "grad_norm": 7.141781806945801,
      "learning_rate": 3.0158730158730157e-09,
      "logits/chosen": 1.1846367120742798,
      "logits/rejected": 1.311032772064209,
      "logps/chosen": -31.439666748046875,
      "logps/rejected": -49.191734313964844,
      "loss": 0.6653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025618767365813255,
      "rewards/margins": 0.05658738687634468,
      "rewards/rejected": -0.030968617647886276,
      "step": 632
    },
    {
      "epoch": 48.72,
      "grad_norm": 7.801325798034668,
      "learning_rate": 2.8571428571428568e-09,
      "logits/chosen": 1.275578498840332,
      "logits/rejected": 1.1279842853546143,
      "logps/chosen": -36.440162658691406,
      "logps/rejected": -49.89682388305664,
      "loss": 0.6627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.009977603331208229,
      "rewards/margins": 0.062056660652160645,
      "rewards/rejected": -0.052079055458307266,
      "step": 633
    },
    {
      "epoch": 48.8,
      "grad_norm": 7.44372034072876,
      "learning_rate": 2.6984126984126983e-09,
      "logits/chosen": 1.261885166168213,
      "logits/rejected": 1.3655892610549927,
      "logps/chosen": -38.886356353759766,
      "logps/rejected": -59.57069396972656,
      "loss": 0.6722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010815739631652832,
      "rewards/margins": 0.04261195659637451,
      "rewards/rejected": -0.03179621696472168,
      "step": 634
    },
    {
      "epoch": 48.88,
      "grad_norm": 7.714693546295166,
      "learning_rate": 2.5396825396825395e-09,
      "logits/chosen": 1.4011962413787842,
      "logits/rejected": 1.1643880605697632,
      "logps/chosen": -34.69929504394531,
      "logps/rejected": -55.07535934448242,
      "loss": 0.6589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026268696412444115,
      "rewards/margins": 0.06993210315704346,
      "rewards/rejected": -0.04366340488195419,
      "step": 635
    },
    {
      "epoch": 48.96,
      "grad_norm": 7.30285120010376,
      "learning_rate": 2.3809523809523806e-09,
      "logits/chosen": 1.5097477436065674,
      "logits/rejected": 1.392197847366333,
      "logps/chosen": -33.28883361816406,
      "logps/rejected": -54.08199691772461,
      "loss": 0.6651,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.018336940556764603,
      "rewards/margins": 0.057080820202827454,
      "rewards/rejected": -0.03874387592077255,
      "step": 636
    },
    {
      "epoch": 49.0,
      "grad_norm": 9.56160831451416,
      "learning_rate": 2.222222222222222e-09,
      "logits/chosen": 1.4525043964385986,
      "logits/rejected": 1.5191023349761963,
      "logps/chosen": -31.201303482055664,
      "logps/rejected": -51.26512908935547,
      "loss": 0.6645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04484419897198677,
      "rewards/margins": 0.05821194872260094,
      "rewards/rejected": -0.013367748819291592,
      "step": 637
    },
    {
      "epoch": 49.0,
      "eval_logits/chosen": 1.311860203742981,
      "eval_logits/rejected": 1.2027920484542847,
      "eval_logps/chosen": -34.32286834716797,
      "eval_logps/rejected": -47.077049255371094,
      "eval_loss": 0.6806831359863281,
      "eval_rewards/accuracies": 0.8600000143051147,
      "eval_rewards/chosen": 0.01766497641801834,
      "eval_rewards/margins": 0.02525150775909424,
      "eval_rewards/rejected": -0.00758653087541461,
      "eval_runtime": 2.7361,
      "eval_samples_per_second": 36.549,
      "eval_steps_per_second": 18.274,
      "step": 637
    },
    {
      "epoch": 49.08,
      "grad_norm": 8.16126537322998,
      "learning_rate": 2.0634920634920633e-09,
      "logits/chosen": 1.3294541835784912,
      "logits/rejected": 1.1207759380340576,
      "logps/chosen": -29.263479232788086,
      "logps/rejected": -47.98115158081055,
      "loss": 0.6674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026501893997192383,
      "rewards/margins": 0.05235777050256729,
      "rewards/rejected": -0.02585587650537491,
      "step": 638
    },
    {
      "epoch": 49.16,
      "grad_norm": 7.735451698303223,
      "learning_rate": 1.904761904761905e-09,
      "logits/chosen": 1.4159116744995117,
      "logits/rejected": 1.3008692264556885,
      "logps/chosen": -41.25018310546875,
      "logps/rejected": -59.830078125,
      "loss": 0.671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.002069425769150257,
      "rewards/margins": 0.045015569776296616,
      "rewards/rejected": -0.04294614866375923,
      "step": 639
    },
    {
      "epoch": 49.24,
      "grad_norm": 7.497091293334961,
      "learning_rate": 1.746031746031746e-09,
      "logits/chosen": 1.4169665575027466,
      "logits/rejected": 1.4863263368606567,
      "logps/chosen": -32.03565979003906,
      "logps/rejected": -53.108795166015625,
      "loss": 0.6699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024829603731632233,
      "rewards/margins": 0.0472121462225914,
      "rewards/rejected": -0.022382546216249466,
      "step": 640
    },
    {
      "epoch": 49.32,
      "grad_norm": 6.325227737426758,
      "learning_rate": 1.587301587301587e-09,
      "logits/chosen": 1.183350920677185,
      "logits/rejected": 1.170093059539795,
      "logps/chosen": -32.378604888916016,
      "logps/rejected": -52.454063415527344,
      "loss": 0.6687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.019765568897128105,
      "rewards/margins": 0.049767471849918365,
      "rewards/rejected": -0.03000190295279026,
      "step": 641
    },
    {
      "epoch": 49.4,
      "grad_norm": 7.2552876472473145,
      "learning_rate": 1.4285714285714284e-09,
      "logits/chosen": 1.080028772354126,
      "logits/rejected": 1.212784767150879,
      "logps/chosen": -37.65555191040039,
      "logps/rejected": -56.38458251953125,
      "loss": 0.6668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.024686478078365326,
      "rewards/margins": 0.05355830118060112,
      "rewards/rejected": -0.028871823102235794,
      "step": 642
    },
    {
      "epoch": 49.48,
      "grad_norm": 8.74852466583252,
      "learning_rate": 1.2698412698412697e-09,
      "logits/chosen": 1.554993987083435,
      "logits/rejected": 1.2824708223342896,
      "logps/chosen": -41.73979568481445,
      "logps/rejected": -51.06783676147461,
      "loss": 0.6602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01403663121163845,
      "rewards/margins": 0.0672198086977005,
      "rewards/rejected": -0.0531831718981266,
      "step": 643
    },
    {
      "epoch": 49.56,
      "grad_norm": 6.125124931335449,
      "learning_rate": 1.111111111111111e-09,
      "logits/chosen": 1.092503547668457,
      "logits/rejected": 1.4037272930145264,
      "logps/chosen": -29.235591888427734,
      "logps/rejected": -49.747528076171875,
      "loss": 0.6714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020128821954131126,
      "rewards/margins": 0.04417496174573898,
      "rewards/rejected": -0.02404613420367241,
      "step": 644
    },
    {
      "epoch": 49.64,
      "grad_norm": 7.897089958190918,
      "learning_rate": 9.523809523809524e-10,
      "logits/chosen": 1.1504172086715698,
      "logits/rejected": 1.196687936782837,
      "logps/chosen": -36.152156829833984,
      "logps/rejected": -60.052616119384766,
      "loss": 0.6738,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.008614850230515003,
      "rewards/margins": 0.03928253427147865,
      "rewards/rejected": -0.030667686834931374,
      "step": 645
    },
    {
      "epoch": 49.72,
      "grad_norm": 7.317562103271484,
      "learning_rate": 7.936507936507935e-10,
      "logits/chosen": 1.2979732751846313,
      "logits/rejected": 1.4068059921264648,
      "logps/chosen": -32.072357177734375,
      "logps/rejected": -57.74829864501953,
      "loss": 0.6596,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.027453232556581497,
      "rewards/margins": 0.06846356391906738,
      "rewards/rejected": -0.041010335087776184,
      "step": 646
    },
    {
      "epoch": 49.8,
      "grad_norm": 8.52966594696045,
      "learning_rate": 6.349206349206349e-10,
      "logits/chosen": 1.3616505861282349,
      "logits/rejected": 1.0741045475006104,
      "logps/chosen": -31.212360382080078,
      "logps/rejected": -64.1790771484375,
      "loss": 0.6631,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.02477262169122696,
      "rewards/margins": 0.06185300648212433,
      "rewards/rejected": -0.03708038479089737,
      "step": 647
    },
    {
      "epoch": 49.88,
      "grad_norm": 7.8521013259887695,
      "learning_rate": 4.761904761904762e-10,
      "logits/chosen": 1.3686401844024658,
      "logits/rejected": 1.28376042842865,
      "logps/chosen": -32.82405090332031,
      "logps/rejected": -52.54851531982422,
      "loss": 0.6642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.026122022420167923,
      "rewards/margins": 0.0588824525475502,
      "rewards/rejected": -0.03276043012738228,
      "step": 648
    },
    {
      "epoch": 49.96,
      "grad_norm": 7.715237617492676,
      "learning_rate": 3.1746031746031743e-10,
      "logits/chosen": 1.1542778015136719,
      "logits/rejected": 1.1517772674560547,
      "logps/chosen": -32.951988220214844,
      "logps/rejected": -54.98108673095703,
      "loss": 0.6696,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.00661504315212369,
      "rewards/margins": 0.0479569174349308,
      "rewards/rejected": -0.0413418747484684,
      "step": 649
    },
    {
      "epoch": 50.0,
      "grad_norm": 11.626633644104004,
      "learning_rate": 1.5873015873015872e-10,
      "logits/chosen": 1.5164004564285278,
      "logits/rejected": 1.3969591856002808,
      "logps/chosen": -33.14698028564453,
      "logps/rejected": -59.64397430419922,
      "loss": 0.6617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.02564377896487713,
      "rewards/margins": 0.06416640430688858,
      "rewards/rejected": -0.0385226272046566,
      "step": 650
    },
    {
      "epoch": 50.0,
      "eval_logits/chosen": 1.3131223917007446,
      "eval_logits/rejected": 1.2037056684494019,
      "eval_logps/chosen": -34.33409118652344,
      "eval_logps/rejected": -47.107147216796875,
      "eval_loss": 0.6797475218772888,
      "eval_rewards/accuracies": 0.8799999952316284,
      "eval_rewards/chosen": 0.01654248684644699,
      "eval_rewards/margins": 0.027138568460941315,
      "eval_rewards/rejected": -0.010596083477139473,
      "eval_runtime": 2.7426,
      "eval_samples_per_second": 36.462,
      "eval_steps_per_second": 18.231,
      "step": 650
    },
    {
      "epoch": 50.0,
      "step": 650,
      "total_flos": 0.0,
      "train_loss": 0.6770771607068868,
      "train_runtime": 523.3005,
      "train_samples_per_second": 9.555,
      "train_steps_per_second": 1.242
    }
  ],
  "logging_steps": 1,
  "max_steps": 650,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
