{
  "experiments_plan_config": {
    "name": "Goodreads initial SFT phase for the OLMo-1B model",
    "description": "Supervised fine-tuning on Goodreads prompt\u2192chosen pairs.",
    "skip": 0,
    "repetitions": 1,
    "largest": false,
    "multiprocess": false,
    "num_parallel": 1,
    "gpu_ids_pool": [
      0
    ],
    "configurations": [
      {
        "base_config": {
          "experiment_name": "olmo1b_sft_goodreads_{objective}",
          "random_seed": -1,
          "gpu_ids": [
            0
          ],
          "trainer_checkpoint": "",
          "epochs": 1,
          "validate_every": 1,
          "outputs_dir": "outputs/goodreads_models",
          "disable_console_log": true,
          "save_logs": true,
          "train_batch_log_interval": 5,
          "epoch_log_interval": 1,
          "save_metric_plots": false,
          "save_every_num_val": 1,
          "use_tensorboard": false,
          "use_wandb": false,
          "wandb_resume_path": "",
          "wandb_project_name": "goodreads_sft",
          "wandb_entity_name": "",
          "wandb_track_model": null,
          "wandb_exclude_files": [
            "plots/**"
          ],
          "score_metric_name": "train loss",
          "is_train_metric": true,
          "score_largest": false,
          "return_best_score": false,
          "save_checkpoints": false,
          "num_checkpoints": 1,
          "save_checkpoints_by_score": false,
          "early_stop": false,
          "early_stop_min_delta": 0,
          "early_stop_patience": 0,
          "early_stop_cooldown": 0,
          "early_stop_restore_best_weights": false,
          "dataset": "data_files/goodreads/train.json",
          "num_train_samples": -1,
          "answer_matching_behavior_to_use": "",
          "train_samples_random_seed": -1,
          "batch_size": 32,
          "load_dataset_to_gpu": false,
          "model": "/scratch/user/chuanhsin0110/hf_models/allenai-OLMo-1B-hf",
          "model_cache_dir": "/scratch/user/chuanhsin0110/hf_cache",
          "load_model_checkpoint": null,
          "is_lora_checkpoint": false,
          "use_lora": false,
          "lora_rank": 8,
          "kl_coeff": 0.01,
          "objective": "cross_entropy",
          "optimizer": "rmsprop",
          "lr": 1e-07,
          "track_logits_for_tokens": [],
          "log_top_token_logit_change_interval": -1,
          "save_model": true,
          "save_finegrained_token_metrics": false
        },
        "options": {}
      }
    ]
  }
}